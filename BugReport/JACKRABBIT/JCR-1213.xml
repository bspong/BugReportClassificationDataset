<!-- 
RSS generated by JIRA (5.2.8#851-sha1:3262fdc28b4bc8b23784e13eadc26a22399f5d88) at Sat Jul 27 05:32:14 UTC 2013

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/JCR-1213/JCR-1213.xml?field=key&field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>5.2.8</version>
        <build-number>851</build-number>
        <build-date>26-02-2013</build-date>
    </build-info>

<item>
            <title>[JCR-1213] UUIDDocId cache does not work properly because of weakReferences in combination with new instance for combined indexreader </title>
                <link>https://issues.apache.org/jira/browse/JCR-1213</link>
                <project id="10591" key="JCR">Jackrabbit Content Repository</project>
                        <description>Queries that use ChildAxisQuery or DescendantSelfAxisQuery make use of getParent() functions to know wether the parents are correct and if the result is allowed. The getParent() is called recursively for every hit, and can become very expensive. Hence, in DocId.UUIDDocId, the parents are cached. &lt;br/&gt;
&lt;br/&gt;
Currently,  docId.UUIDDocId&amp;#39;s are cached by having a WeakRefence to the CombinedIndexReader, but, this CombinedIndexReader is recreated all the time, implying that a gc() is allowed to remove the &amp;#39;expensive&amp;#39; cache.&lt;br/&gt;
&lt;br/&gt;
A much better solution is to not have a weakReference to the CombinedIndexReader, but to a reference of each indexreader segment. This means, that in getParent(int n) in SearchIndex the return &lt;br/&gt;
&lt;br/&gt;
return id.getDocumentNumber(this) needs to be replaced by return id.getDocumentNumber(subReaders[i]); and something similar in CachingMultiReader. &lt;br/&gt;
&lt;br/&gt;
That is all. Obviously, when a node/property is added/removed/changed, some parts of the cached DocId.UUIDDocId will be invalid, but mainly small indexes are updated frequently, which obviously are less expensive to recompute.</description>
                <environment></environment>
            <key id="12382332">JCR-1213</key>
            <summary>UUIDDocId cache does not work properly because of weakReferences in combination with new instance for combined indexreader </summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                    <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png">Closed</status>
                    <resolution id="1">Fixed</resolution>
                                <assignee username="-1">Unassigned</assignee>
                                <reporter username="aschrijvers">Ard Schrijvers</reporter>
                        <labels>
                    </labels>
                <created>Mon, 12 Nov 2007 10:56:15 +0000</created>
                <updated>Tue, 15 Jan 2008 23:27:03 +0000</updated>
                    <resolved>Wed, 5 Dec 2007 14:20:59 +0000</resolved>
                                            <fixVersion>1.4</fixVersion>
                                <component>query</component>
                        <due></due>
                    <votes>0</votes>
                        <watches>0</watches>
                                                    <comments>
                    <comment id="12541745" author="aschrijvers" created="Mon, 12 Nov 2007 11:23:48 +0000"  >When this JIRA issue has been solved, &lt;a href=&quot;https://issues.apache.org/jira/browse/JCR-1196&quot; title=&quot;Optimize queries for DescendantSelfAxisWeight/ChildAxisQuery&quot;&gt;&lt;strike&gt;JCR-1196&lt;/strike&gt;&lt;/a&gt; will be resolved/improved partly:&lt;br/&gt;
&lt;br/&gt;
In &lt;a href=&quot;https://issues.apache.org/jira/browse/JCR-1196&quot; title=&quot;Optimize queries for DescendantSelfAxisWeight/ChildAxisQuery&quot;&gt;&lt;strike&gt;JCR-1196&lt;/strike&gt;&lt;/a&gt;, the problem about slow DescendantSelfAxisWeight/ChildAxisQuery will mainly stay for the first query that extensively uses getParent() calls, or when a large index reader has been changed. &lt;br/&gt;
&lt;br/&gt;
Subsequent DescendantSelfAxisWeight/ChildAxisQuery  queries will run fast when only small indexes are changed, or no index has been changed. &lt;br/&gt;
&lt;br/&gt;
</comment>
                    <comment id="12541821" author="aschrijvers" created="Mon, 12 Nov 2007 16:21:13 +0000"  >&amp;quot;return id.getDocumentNumber(this) needs to be replaced by return id.getDocumentNumber(subReaders[i]); and something similar in CachingMultiReader.&amp;quot;&lt;br/&gt;
&lt;br/&gt;
The above does solve the problem.&lt;br/&gt;
In SearchIndex it is more complicated than this. In SearchIndex&lt;br/&gt;
&lt;br/&gt;
public int getParent(int n) throws IOException {&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;int i = readerIndex(n);&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;DocId id = subReaders[i].getParentDocId(n - starts[i]);&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;id = id.applyOffset(starts[i]);&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;return id.getDocumentNumber(subReaders[i]);&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;//return id.getDocumentNumber(this);&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;}&lt;br/&gt;
&lt;br/&gt;
replacing the last line by the subReaders[i] is not enough, because I missed the part that  subReaders[i]  returns a CachingMultiReader, keeping the problem of a cache which will be cleared to often (when a single index changes). This is also logical, because I did not understand how a parent document number could be found if the parent would be in a different lucene index. &lt;br/&gt;
&lt;br/&gt;
So, in the id.getDocumentNumber(subReaders[i]) I think I need to check in which indexReader the parent is found, and use this indexReader instance for the WeakReference. I&amp;#39;ll try to implement this.&lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
</comment>
                    <comment id="12541979" author="aschrijvers" created="Mon, 12 Nov 2007 23:13:22 +0000"  >&amp;quot;The above does solve the problem.&lt;br/&gt;
In SearchIndex it is more complicated than this. In SearchIndex &amp;quot;&lt;br/&gt;
&lt;br/&gt;
Obviously, the first line should have been: &amp;quot;does not solve the problem&amp;quot; : I was in a hurry :-)&lt;br/&gt;
&lt;br/&gt;
In UUIDDocId getDocumentNumber(IndexReader reader)  when the parent docNumber is found, I can look up in which indexReader instance it was found in, and use this instance for the weakreference. Then, I should be able to check wether this instance is still available as an indexReader in the CachingMultiReader which is the arg in getDocumentNumber. However, I need to check wether this extra step does not involve to much overhead. I&amp;#39;ll get back on this&lt;br/&gt;
&lt;br/&gt;
&amp;#39;ll try to implement it this week. </comment>
                    <comment id="12542078" author="mreutegg" created="Tue, 13 Nov 2007 09:13:05 +0000"  >Just wanted to let you know that what you described is exactly how I imagined a solution. And the same concerns about the reader lookup crossed my mind... But let&amp;#39;s see if it even matters.&lt;br/&gt;
&lt;br/&gt;
Looking forward to seeing your patch.</comment>
                    <comment id="12542083" author="aschrijvers" created="Tue, 13 Nov 2007 09:32:47 +0000"  >I&amp;#39;ll use a profiler to see wether the extra step might use to much cpu. If so, I&amp;#39;&amp;#39;ll rethink the solution. First of all I&amp;#39;ll just measure it&lt;br/&gt;
&lt;br/&gt;
&amp;quot;Looking forward to seeing your patch&amp;quot; &lt;br/&gt;
&lt;br/&gt;
I&amp;#39;ll try to find time ASAP :-) </comment>
                    <comment id="12542406" author="mreutegg" created="Wed, 14 Nov 2007 10:40:02 +0000"  >Ard wrote:&lt;br/&gt;
&amp;gt; Am thinking about a two step check, where first a reference to the entire&lt;br/&gt;
&amp;gt; MultiIndexReader is checked.&lt;br/&gt;
&amp;gt; &lt;br/&gt;
&amp;gt; IF (1): check reference to the entire MultiIndexReader instance is positive,&lt;br/&gt;
&amp;gt; return cached results. ELSE IF (2) :check the index reader segment instance the&lt;br/&gt;
&amp;gt; parent docnumber was in: if instance present, recompute docNumber with&lt;br/&gt;
&amp;gt; respect to the new offsets in MultiIndexReader and return (almost) cached&lt;br/&gt;
&amp;gt; result. ELSE (3): recompute docNumber by search in MultiIndexReader (the&lt;br/&gt;
&amp;gt; uncached case)&lt;br/&gt;
&lt;br/&gt;
I would rather make it simple and just use one approach. The first check (1) is the reason why you created this issue. I think we should therefore remove this check and replace it with something that works better. The additional check (2) is not necessary IMO because we have DocId.applyOffset(), though we will have to modify the signature because the code currently assumes that the returned DocId is tied to the index segment it originated from. Thus the offset for that segment is passed at applyOffset(). Because the UUIDDocId also relates to another index segment (parent points to another segment) the applyOffset() in its current form is useless for the UUIDDocId implementation. Maybe we should pass in the complete information. All readers and their offsets. This allows the UUIDDocId to apply an offset properly. As for (3), this is again part of the issue we should try to solve, thus we should not relate a UUIDDocId to the MultiIndexReader but to a index segment/reader within it.&lt;br/&gt;
&lt;br/&gt;
I&amp;#39;ll also start with a diagram explaining the various readers and how they relate to each other.</comment>
                    <comment id="12542418" author="aschrijvers" created="Wed, 14 Nov 2007 11:12:32 +0000"  >&amp;quot;The first check (1) is the reason why you created this issue&amp;quot; &lt;br/&gt;
&lt;br/&gt;
Not entirely: currently, the CombinedIndexReader instance is used as a WeakReference, and this one is recreated for every search. The MultiIndexReader instance is kept AFAICS as long as all indexes are the same. So, in SearchIndex, changing &lt;br/&gt;
&lt;br/&gt;
public int getParent(int n) throws IOException {&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;.....&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;return id.getDocumentNumber(this);&lt;br/&gt;
}&lt;br/&gt;
&lt;br/&gt;
into &lt;br/&gt;
&lt;br/&gt;
public int getParent(int n) throws IOException {&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;.....&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;return id.getDocumentNumber(subReaders[i]);&lt;br/&gt;
}&lt;br/&gt;
&lt;br/&gt;
would already implement (1).  This one holds when *every* index reader instance is the same. &lt;br/&gt;
&lt;br/&gt;
If, one of the instances has changed, we would need step (2) IIUC.  Then we could check wether the instance the parent was found in is still valid, and, as you indicate, should return the &amp;#39;corrected&amp;#39; DocNumber, which might be different due to applyOffSet. When (1) and (2) are both invalid, then the search for the parent node in subReaders[i] should be done again. &lt;br/&gt;
&lt;br/&gt;
I agree, that (1) is redundant because (2) captures (1) , but I added it, because first of all, it is something we can add right away, and secondly, because I think (but I should measure) that if the subReaders[i] instance (MultiIndexReader) did not change, it is useless to do a lookup of the index reader segment the parent was in and check wether the instance is still valid. &lt;br/&gt;
&lt;br/&gt;
I do agree with you that if removing (1) does not imply any performance loss, we should only go for (2). But it is not correct that (1) does not solve anything to the original problem: instead of the CombinedIndexReader which is recreated all the time, I pass in the MultiIndexReader whose instance is kept as long as no indexes change. This is at least what I understand from the mechanism, but I am not as familiar as you are with it ofcourse, so I might be off. &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
</comment>
                    <comment id="12542427" author="mreutegg" created="Wed, 14 Nov 2007 12:04:19 +0000"  >&amp;gt; But it is not correct that (1) does not solve anything to the original problem: instead of the CombinedIndexReader&lt;br/&gt;
&amp;gt; which is recreated all the time, I pass in the MultiIndexReader whose instance is kept as long as no indexes change.&lt;br/&gt;
&lt;br/&gt;
If we can make the MultiIndexReader instance more stable in terms of re-using it as many times as possible this will of course help us and keep cache entries valid. But since this only applies to cases where there are no changes to the workspace, it seems to me that this will not buy use much, except for special occasions where the workspace is not modified for some time.&lt;br/&gt;
&lt;br/&gt;
&amp;gt; This is at least what I understand from the mechanism, but I am not as familiar as you are with it ofcourse, so I&lt;br/&gt;
&amp;gt; might be off.&lt;br/&gt;
&lt;br/&gt;
your understanding is correct. I guess we just have a differing judgment about when and how often the cost of building cache entries and maintaining them should be spent.</comment>
                    <comment id="12542432" author="aschrijvers" created="Wed, 14 Nov 2007 12:22:51 +0000"  >&amp;quot;I guess we just have a differing judgment about when and how often the cost of building cache entries and maintaining them should be spent.&amp;quot; &lt;br/&gt;
&lt;br/&gt;
I think we have the same end goal: If the index segment instance in which the parent lookup was found is still valid --&amp;gt; return cached docNumber. This is the main performance we look for. And I also think we agree on the implementation regarding the segment instance reference.  I only referred to option (1) as the simple first test for valid cache, and then (2). So, in UUIDDocId, I would create a weakReference to MultiIndexReader and a seperate one to CachingIndexReader (a single segment) . If (1) is valid, you are ready, otherwise check (2). If (1) is equally fast as (2) (performance test) I agree on removing (1)&lt;br/&gt;
&lt;br/&gt;
I really think we are on the same track, and are talking about the same mechanism for maintaining the cache. I was referring to a light weight instance validity  test first, and then fall back to the segment instance test.  But, as you indicate, this one might be totally useless in a frequently modifying workspace. &lt;br/&gt;
&lt;br/&gt;
I&amp;#39;ll try to implement some of these options sunday, and try to capture some performance figures. WDYT?&lt;br/&gt;
</comment>
                    <comment id="12542435" author="mreutegg" created="Wed, 14 Nov 2007 12:31:19 +0000"  >You are right, instead of talking we should just try it out and see whether it makes a different ;)</comment>
                    <comment id="12542437" author="aschrijvers" created="Wed, 14 Nov 2007 12:35:25 +0000"  >:-)&lt;br/&gt;
&lt;br/&gt;
will have post my findings Sunday! </comment>
                    <comment id="12543374" author="aschrijvers" created="Sun, 18 Nov 2007 13:58:39 +0000"  >ATM I have been able to change some parts to store in UUIDDocId a reference to the segmentIndexReader the documentNumber was found in.  This means that not the entire cache is lost when the multi Index changes, but only those parts that involve a segment change. &lt;br/&gt;
&lt;br/&gt;
Now, I am looking at a clean way to recompute the docNumber, because even if the segment index reader did not change, the docNumber might (quite likely) because the multiIndexReader has changed, hence the  individual reader offsets as well. &lt;br/&gt;
&lt;br/&gt;
I&amp;#39;ll try to find time next week for it. Perhaps somebody has an idea how to implement it &amp;#39;clean&amp;#39;, because I do not really like the way I am heading with changing the SingleTermDocs to store the docNumber with offset, and also store the docNumber without, to have the doc number available in the segment. This implies, in DocId I have to cast to SingleTermDocs....etc etc which is not nice. &lt;br/&gt;
&lt;br/&gt;
WDOT? Any ideas? Or should we refactor a few parts,  to be able to recompute the docNumber? &lt;br/&gt;
&lt;br/&gt;
</comment>
                    <comment id="12543513" author="mreutegg" created="Mon, 19 Nov 2007 10:29:51 +0000"  >I think whatever UUIDDocId calculates should be independent of the multi index reader. That is, it should only hold the document number as retrieved from the index segment. Then in a second step an offset should be applied, as with the&lt;br/&gt;
PlainDocId to accommodate the multi index reader wrapping. This probably means we have to change some of the signatures, but that&amp;#39;s OK.</comment>
                    <comment id="12543520" author="aschrijvers" created="Mon, 19 Nov 2007 10:55:21 +0000"  >&amp;quot;I think whatever UUIDDocId calculates should be independent of the multi index reader. That is, it should only hold the document number as retrieved from the index segment. Then in a second step an offset should be applied&amp;quot;&lt;br/&gt;
&lt;br/&gt;
Yes, this is probably the cleanest way. I now also understand why we had the discussion about how to solve the issue. You were already thinking about computing the docNumber in a second step, hence, all that matters is the segment instance. &lt;br/&gt;
&lt;br/&gt;
So, the latter part, about the segment instance I did build, though we might discuss wether it is a good way. I added a method to MultiIndexReader interface, &lt;br/&gt;
&lt;br/&gt;
public boolean hasIndexReaderInstance(IndexReader indexReader);&lt;br/&gt;
&lt;br/&gt;
and in CachingMultiReader and CombinedIndexReader I keep track of subreaders instances with an IdentityHashMap().&lt;br/&gt;
&lt;br/&gt;
In UUIDDocId I can find the reader instance the doc was found in by changing SingleTermDocs by having a reference to its segment reader. Obviously, now I have to cast reader.termDocs(id) to SingleTermDocs which we might not like.&lt;br/&gt;
&lt;br/&gt;
Anyway, I&amp;#39;ll try to add the second step offset in calculating the docNumber as you suggested somewhere this week, and create a patch (might be easier than talking about a solution).  &lt;br/&gt;
&lt;br/&gt;
</comment>
                    <comment id="12543985" author="aschrijvers" created="Tue, 20 Nov 2007 18:20:47 +0000"  >Follow up:&lt;br/&gt;
&lt;br/&gt;
I have been trying to cache docNumbers with respect to their IndexSegments, which obviously do change less frequently.  Caching based on an entire CachingMultiReader is trivial, but also, the performance gain is to small, since the multiReader changes to  frequently.&lt;br/&gt;
&lt;br/&gt;
But, I am having difficulties somebody might be able to help me with&lt;br/&gt;
&lt;br/&gt;
Bottom line is, we do not want to cache based on the entire CachingMultiReader, but on its segments it consists of. Now, I build (hacked for the time being)  something that in DocId.UUIDDocId I keep track of the segment reference through a WeakReference. But....as I didn&amp;#39;t see behavior I was expecting, I found another difficulty:&lt;br/&gt;
&lt;br/&gt;
The multiReader which is created in MultiIndex is a CachingMultiReader consisting of ReadOnlyIndexReader&amp;#39;s. When something changed in one of the indexes, a new multiReader is constructed....but instead of reusing the non-changed ReadOnlyIndexReader instances, every ReadOnlyIndexReader is re-constructed (not the shared/caching reader they consist of though ) , but, since the instances our multiReader consists of are recreated, my WeakReferences based on segment instances are useless. &lt;br/&gt;
&lt;br/&gt;
So, instead of using a WeakReference on the multiReader segments, I could get the sharedReader instance out of it, but this means casting and adding methods, something we really do not want of course (and i am not sure if the BitSet keeing track of deleted might have changed without  the sharedReader being changed (  to be honest, I cannot yet grasp the big picture about keeping track of the deleted bitset )  ).&lt;br/&gt;
&lt;br/&gt;
So, does anybody have an idea how we might be able to have in MultiIndex.getIndexReader()  only new instances of the ReadOnlyIndexReaders which actually changed...Or is this not an option? I did try to add it to the AbstractIndex to check wether there was already an instance of ReadOnlyIndexReader but then I get  AlreadyClosedException in lucene. &lt;br/&gt;
&lt;br/&gt;
I can make another JIRA issue for it if others think it might be valuable and not part of this issue. WDOT?</comment>
                    <comment id="12544401" author="mreutegg" created="Wed, 21 Nov 2007 10:11:54 +0000"  >I recently added some documentation to the website about the index readers:&lt;br/&gt;
&lt;br/&gt;
&lt;a href=&quot;http://jackrabbit.apache.org/doc/arch/operate/index-readers.html&quot;&gt;http://jackrabbit.apache.org/doc/arch/operate/index-readers.html&lt;/a&gt;&lt;br/&gt;
&lt;br/&gt;
&amp;gt; to be honest, I cannot yet grasp the big picture about keeping track of the deleted bitset&lt;br/&gt;
&lt;br/&gt;
The new documentation shows how and when the deleted bit set for the ReadOnlyIndexReader is created.&lt;br/&gt;
&lt;br/&gt;
The ReadOnlyIndexReaders are indeed constructed on every change. That&amp;#39;s very unfortunate and should be changed. I&amp;#39;ll create an issue for that. While this will fix the case where an ReadOnlyIndexReader is re-constructed even though nothing changed in that segment, we will still have the issue that a new ReadOnlyIndexReader is constructed if a node is deleted in that segment. Even in that case we don&amp;#39;t want to re-calculate all the UUIDDocIds that point to this segment.&lt;br/&gt;
&lt;br/&gt;
&amp;gt; So, instead of using a WeakReference on the multiReader segments, I could get the sharedReader instance out of it&lt;br/&gt;
&lt;br/&gt;
Yes, that&amp;#39;s probably the only way how to keep the UUIDDocIds valid as long as possible. A chose a similar approach in CachingMultiReader.termDocs(Term). The relation between the shared reader and the read only reader is held in readersByBase. But that&amp;#39;s quite ugly.&lt;br/&gt;
&lt;br/&gt;
Thinking more about this issue it might be worth looking at an alternative. There is a DocNumberCache, which maps a UUID to a CachingIndexReader with a document number. This is exactly the information that is also present in a UUIDDocId. So we might just as well not cache the result in UUIDDocId but always use the DocNumberCache to resolve it. However I&amp;#39;m not sure how much overhead that adds. I&amp;#39;ll have to investigate that first...</comment>
                    <comment id="12544424" author="aschrijvers" created="Wed, 21 Nov 2007 11:33:39 +0000"  >&amp;quot;&lt;a href=&quot;http://jackrabbit.apache.org/doc/arch/operate/index-readers.html&quot;&gt;http://jackrabbit.apache.org/doc/arch/operate/index-readers.html&lt;/a&gt; &amp;quot; &lt;br/&gt;
&lt;br/&gt;
This is really really nice to read! I just only now understand, the deleted BitSet idea, and that SharedIndexReader lives during the entire life of a PersistentIndex.  Since in &amp;#39;older&amp;#39; (existing?) indexes only documents can be deleted, we keep the same SharedIndexReader  even if the index changed, and keep track of the deleted items in the deleted BitSet. And this should give us a very good possibility to cache the parent relationships of a node, even though underlying lucene indexes change because of the deletion of a document (I am pretty much recapitulating and adding nothing new, and certainly nothing you don&amp;#39;t already know, but see it as thinking out loud  :-) )&lt;br/&gt;
&lt;br/&gt;
I&amp;#39;ll try to look at the end of the day at your suggestion at the end of your comment, and also see if i can get a &amp;#39;hacky&amp;#39; working version with the readersByBase. A nice solution can be made afterwards if it is a succes. After reading your documentation I am really confident we can make a very efficient cache for the docNumbers.  I&amp;#39;ll investigate as well.... :-) </comment>
                    <comment id="12544983" author="aschrijvers" created="Fri, 23 Nov 2007 11:12:58 +0000"  >Minor thing:&lt;br/&gt;
&lt;br/&gt;
why in DocId.UUIDDocId getDocumentNumber  the synchronized method is needed at the end?&lt;br/&gt;
&lt;br/&gt;
synchronized (this) {&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;docNumber = doc;&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;this.reader = new WeakReference(reader);&lt;br/&gt;
}&lt;br/&gt;
&lt;br/&gt;
It must be for this.reader = new WeakReference(reader) AFAICS. But for setting a WeakReference, does it matter when at that moment the reader instance is removed? I can set a WeakReference(null) without problem.&lt;br/&gt;
&lt;br/&gt;
</comment>
                    <comment id="12545016" author="mreutegg" created="Fri, 23 Nov 2007 12:55:52 +0000"  >Because getDocumentNumber() may be called from multiple concurrent threads. If the block is not synchronized, there is no guarantee that the docNumber and the reader are consistent. A JVM may update the docNumber and the reader out-of-order if the code is not synchronized. Likewise if no synchronization is present the JVM may operate on local memory that e.g. represents a stale docNumber.</comment>
                    <comment id="12545025" author="aschrijvers" created="Fri, 23 Nov 2007 13:42:37 +0000"  >Aaaah yes, you are right.&lt;br/&gt;
&lt;br/&gt;
ATM I have a working test version, that seems to solve this issue,  keep consecutive DescendantSelfAxisWeight/ChildAxisQuery queries fast when gc() has done its work (so the WeakReferences are correct now), and is also fast when incremental nodes are added/deleted from the index. &lt;br/&gt;
&lt;br/&gt;
To test  the performance improvement, you need a *large* repository (for 1.000.000 nodes) where parent nodes are frequently found in different indexes.  Then running queries like xpath = &amp;quot;//documents//*[@caption]&amp;quot; , where many nodes have this property will be much faster in consecutive runs. A query like  &amp;quot;//documents//*[@date]&amp;quot; that has many common parents with @caption should run fast. The problem of inital &amp;#39;slow&amp;#39; DescendantSelfAxisWeight/ChildAxisQuery keeps being a problem. OTOH, we might do some cache warming up if we start the repository. Since CachingIndexReader are kept during the live time of a persistent index, it might be quite useful. Here is also what I think is confusing about  &amp;quot;&lt;a href=&quot;http://jackrabbit.apache.org/doc/arch/operate/index-readers.html&quot;&gt;http://jackrabbit.apache.org/doc/arch/operate/index-readers.html&lt;/a&gt; &amp;quot;  :&lt;br/&gt;
&lt;br/&gt;
There it says:  &amp;quot;A SharedIndexReader is kept open for the entire lifetime of a PersistentIndex&amp;quot; but AFAIU, the CachingIndexReader which is wrapped by SharedIndexReader is already kept for lifetime of a PersistentIndex, and the SharedIndexReader is merely kept for the lifetime of all running requests by reference counting. (If I am correct I can change the documentation slightly). &lt;br/&gt;
&lt;br/&gt;
Furthermore, I tested the impact of the step (1) --&amp;gt; step(2) check for the reference to the MultiIndexReader  (if valid return docNumber instantly) or, when invalid but segment reader is valid, recompute docNumber. If I remove step(1) I see no performance change, therefore, will refactor to only have step(2), and I will always recompute the actual docNumber. &lt;br/&gt;
&lt;br/&gt;
I&amp;#39;ll try to have a patch for testing ready today&lt;br/&gt;
&lt;br/&gt;
I have not invested  &amp;quot;Thinking more about this issue it might be worth looking at an alternative. There is a DocNumberCache, which maps a UUID to a CachingIndexReader with a document number. This is exactly the information that is also present in a UUIDDocId. So we might just as well not cache the result in UUIDDocId but always use the DocNumberCache to resolve it. However I&amp;#39;m not sure how much overhead that adds. I&amp;#39;ll have to investigate that first...&amp;quot;&lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
</comment>
                    <comment id="12545059" author="aschrijvers" created="Fri, 23 Nov 2007 15:37:28 +0000"  >This is a patch solving the WeakReferences and improving the ChildAxisQuery and DescendantSelfAxisQuery queries speed bu properly caching parent nodex/ hierarchy.&lt;br/&gt;
&lt;br/&gt;
Obviously,  I do not really like the dependency in DocId.UUIDDocId on SingleTermDocs with this patch, and dependency on MultiIndexReader. Perhaps we can change this later. &lt;br/&gt;
&lt;br/&gt;
For now, perhaps somebody likes to test the patch (specifically on large repositories with ChildAxisQuery  or  DescendantSelfAxisQuery ). Test results for me show an enormous performance gain after the initial queries which are executed with empty caches. &lt;br/&gt;
&lt;br/&gt;
Hopefully somebody can test it. </comment>
                    <comment id="12545786" author="mreutegg" created="Tue, 27 Nov 2007 10:39:05 +0000"  >Ard, thank you very much for the patch. I&amp;#39;m about to create a performance test, which basically does the following:&lt;br/&gt;
&lt;br/&gt;
- create lots of nodes ;)&lt;br/&gt;
- run queries that use DescendantSelfAxisQuery and/or ChildAxisQuery&lt;br/&gt;
- at the same time randomly modify content&lt;br/&gt;
&lt;br/&gt;
I reviewed you patch and I also don&amp;#39;t like the dependency to SingleTermDocs in UUIDDocId.&lt;br/&gt;
&lt;br/&gt;
I&amp;#39;ve created a patch as well, but took a somewhat different approach. Instead of using a weak reference to the index reader, I used the creation tick in the CachingIndexReader. The creation tick uniquely identifies an index segment as well as the version of the segment. E.g. if a document is added a new CachingIndexReader is created for that segment with a new creation tick. The same will probably also work for the DocNumberCache, which currently uses strong references. I&amp;#39;d like to change that as well, but that&amp;#39;s a bit off topic and and different issue.&lt;br/&gt;
&lt;br/&gt;
I will run the above test with 1) the current code base, 2) your patch and 3) my patch.&lt;br/&gt;
&lt;br/&gt;
I&amp;#39;ll let you know about the results....</comment>
                    <comment id="12545796" author="aschrijvers" created="Tue, 27 Nov 2007 11:08:55 +0000"  >Hello Marcel,&lt;br/&gt;
&lt;br/&gt;
just read your patch.  I&amp;#39;ll try to test your solution tomorrow at the end of the day as well. AFAICS, I think performance between both solutions won&amp;#39;t be measurable.  Your code is nicer, as I already indicated I had some dependencies I did not like at all. &lt;br/&gt;
&lt;br/&gt;
When creating a lot of nodes, also remember to &amp;quot;update&amp;quot; a lot of nodes, to create the &amp;#39;gabs&amp;#39; in the index, and lots of  parents that are found in different indexes. &lt;br/&gt;
&lt;br/&gt;
I never new about the creation tick.  If it is unique for a reader instance, it should obviously work. Also nice to not have the SingleTermDocs dependance in UUIDDocId!  Anyway, I&amp;#39;ll check your patch tomorrow, and think we have a very much better working cache here for the hierarchical relations. </comment>
                    <comment id="12545805" author="mreutegg" created="Tue, 27 Nov 2007 12:30:14 +0000"  >I also expect that the two patches will have similar performance characteristics. In the end both implement the same idea just slightly different.&lt;br/&gt;
&lt;br/&gt;
In contrast to your patch mine is nearly twice as large and I had to modify many existing signatures. Instead of IndexReader many methods now deal with concrete extensions of IndexReader. I&amp;#39;m not sure if this is desirable, but in some occasions it helps to better understand whether code deals with content just present in one index segment or the overall index.&lt;br/&gt;
&lt;br/&gt;
&amp;gt; When creating a lot of nodes, also remember to &amp;quot;update&amp;quot; a lot of nodes, to create the &amp;#39;gabs&amp;#39; in the index.&lt;br/&gt;
&lt;br/&gt;
I try to simulate this by running a concurrent thread that modifies content while the test runs. I plan to run the tests for an hour or two to see what effect it has.</comment>
                    <comment id="12545813" author="aschrijvers" created="Tue, 27 Nov 2007 12:52:06 +0000"  >If you can/want to attach your test as well, I can tomorrow evening do some or the same tests as well (Also look at some profiling memory snapshots and some processor hotspots.....just out curiosity. Might be nice to see the getParent taking 99% cpu (!!! I saw this actually after a gc() ) being really downgraded with your patch and mine, and see if I can spot differcences )</comment>
                    <comment id="12545849" author="mreutegg" created="Tue, 27 Nov 2007 14:18:40 +0000"  >sure, here you go.&lt;br/&gt;
&lt;br/&gt;
The test creates about 1 million nodes and then runs queries using two threads for one minute. As mentioned before, another thread will randomly modify nodes at the same time.</comment>
                    <comment id="12545852" author="aschrijvers" created="Tue, 27 Nov 2007 14:24:20 +0000"  >thx....I&amp;#39;ll keep you posted</comment>
                    <comment id="12546151" author="ckiehl" created="Wed, 28 Nov 2007 08:13:10 +0000"  >I like Marcels idea to use the creation tick to identity the base index reader without caring about the index reader hierarchy. This patch is a modified version of Marcels patch moving the logic out of UUIDDocId to CachingMultiReader which removes the necessity to expose OffsetIndexReaders. UUIDDocId doesn&amp;#39;t even know about offsets anymore. I&amp;#39;m not sure though if creating those MultiIndexReaderDoc objects is to expensive performance and memory wise although I got similar performance numbers using Marcels test.&lt;br/&gt;
This code could easily be used for DocNumberCache as well as Marcel stated which is a big plus I think.&lt;br/&gt;
Ok then, beat me for just modifying your code ;) I really appreciate your work on this issue.</comment>
                    <comment id="12546153" author="ckiehl" created="Wed, 28 Nov 2007 08:26:19 +0000"  >Fixed a small glitch. And btw, there is still some javadoc missing. This patch is just a prototype.</comment>
                    <comment id="12546483" author="aschrijvers" created="Wed, 28 Nov 2007 23:36:54 +0000"  >I have tested all patches. All three patches seem to have similar performance improvements (compared to the former code they are all *very* much faster in the cached version). ATM I am reshuffle the indexes to have more  parent lookups in other indexes, and then will really see if all have the same performance. It might boil down to which patch has the nicest solution. Mine with the WeakReferences is obviously outdated, and can be discarded. &lt;br/&gt;
&lt;br/&gt;
I think you have to decide which one you want to choose. I think Christoph&amp;#39;s patch uses a little more memory because it keeps MultiIndexReaderDoc objects in memory, but, instead of keeping the MultiIndexReaderDoc  in memory, you could store the int and long in the DocUUID (just like instead of a UUID isntance we store msb and lsb). Though, we are talking only about the object overhead (so 1 million MultiIndexReaderDoc  would imply some 12 Mb extra memory, not really shocking)&lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
But still...during the test, having 1.200.000 nodes in the repository, I realized we are still doing something &amp;#39;irrational&amp;#39;. It won&amp;#39;t be easy to implement I think, because it also depends/involves wether people have implemented an AccessManager, but if I have the following test:&lt;br/&gt;
&lt;br/&gt;
Query q = qm.createQuery(&amp;quot;stuff//*[@count]&amp;quot;, Query.XPATH);&lt;br/&gt;
if (q instanceof QueryImpl) {&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;// limit the result set&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;((QueryImpl) q).setLimit(1);&lt;br/&gt;
}&lt;br/&gt;
&lt;br/&gt;
Since my &amp;quot;stuff//*[@count]&amp;quot; gives me 1.200.000, it makes perfect sense to users I think, that even with our patches and a working cache, that retaining them all would be slow. But if I set the limit to 1 or 10, I would expect to have performance (certainly when you have not implemented any AccessManager).&lt;br/&gt;
&lt;br/&gt;
But, if I set limit to 1, why would we have to check all 1.200.000 parents wether the path is correct? &lt;br/&gt;
&lt;br/&gt;
If I get a sorted hits by lucene, I would want to start with the first one, and check the parent, then the second, etc, untill I have a hit that is correct according its path. If I have a limit of 10, we would need to get 10 successes. Obviously, in the worst case scenario, we would still have to check every hit for its parents, but this would be rather exceptional i think.&lt;br/&gt;
&lt;br/&gt;
Ofcourse, when people have a custom AccessManager impl, you only know after the access manager wether the hit was a real hit. But when having &lt;br/&gt;
&lt;br/&gt;
Query q = qm.createQuery(&amp;quot;stuff//*[@count]&amp;quot;, Query.XPATH);&lt;br/&gt;
if (q instanceof QueryImpl) {&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;// limit the result set&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;((QueryImpl) q).setLimit(1);&lt;br/&gt;
}&lt;br/&gt;
&lt;br/&gt;
and I have &amp;gt; 1.000.000 hits, and I have to wait, even in the cached version, a few seconds, but changing &amp;quot;stuff//*[@count]&amp;quot; into &amp;quot;//*[@count]&amp;quot; reduces it to a couple of ms, that does not make sense. &lt;br/&gt;
&lt;br/&gt;
I think we should consider wether we could do the DescendantSelfAxisQuery or ChildAxisQuery as some sort of lazy filter. In the end, when users want to also  have the total hits for &amp;quot;stuff//*[@count]&amp;quot;, we obviously are still facing a slow query. WDOT?  This though obviously might belong to a new jira issue, or to the existing one about the DescendantSelfAxisQuery  and ChildAxisQuery  performance.&lt;br/&gt;
</comment>
                    <comment id="12547036" author="mreutegg" created="Fri, 30 Nov 2007 08:14:21 +0000"  >Christoph wrote:&lt;br/&gt;
&amp;gt; Ok then, beat me for just modifying your code ;)&lt;br/&gt;
&lt;br/&gt;
if it were possible I would turn that into a unix command, so I could always do:&lt;br/&gt;
&lt;br/&gt;
cat MyHackyCode.java | kielify -&lt;br/&gt;
&lt;br/&gt;
;)</comment>
                    <comment id="12547041" author="mreutegg" created="Fri, 30 Nov 2007 08:19:36 +0000"  >Here are my test results.&lt;br/&gt;
&lt;br/&gt;
I had to reduce the number of test nodes because I exactly saw what Ard just described. Currently all hits are path checked, hence the poor performance in any test run.&lt;br/&gt;
&lt;br/&gt;
&lt;a href=&quot;http://people.apache.org/~mreutegg/2007/11/JCR-1213/100k-test.html&quot;&gt;http://people.apache.org/~mreutegg/2007/11/JCR-1213/100k-test.html&lt;/a&gt;&lt;br/&gt;
&lt;br/&gt;
Initially the performance with the current code base is not that bad, but as soon as more DocIds across index segments are created the performance drops drastically. As you can see with both Ards and my patch the performance remains stable.</comment>
                    <comment id="12548680" author="mreutegg" created="Wed, 5 Dec 2007 14:20:59 +0000"  >Finally committed a mix of christophs and my patch. The performance characteristics are very similar to the attached patches.</comment>
                </comments>
                <issuelinks>
                        <issuelinktype id="10030">
                <name>Reference</name>
                                <outwardlinks description="relates to">
                            <issuelink>
            <issuekey id="12382333">JCR-1214</issuekey>
        </issuelink>
                    </outwardlinks>
                                                <inwardlinks description="is related to">
                            <issuelink>
            <issuekey id="12381438">JCR-1196</issuekey>
        </issuelink>
                    </inwardlinks>
                            </issuelinktype>
                    </issuelinks>
                <attachments>
                    <attachment id="12370391" name=" JCR-1213-ckiehl.txt" size="14987" author="ckiehl" created="Wed, 28 Nov 2007 08:26:18 +0000" />
                    <attachment id="12370290" name="JCR-1213-mreutegg.patch" size="20061" author="mreutegg" created="Tue, 27 Nov 2007 10:39:24 +0000" />
                    <attachment id="12370126" name="JCR-1213.patch" size="10691" author="aschrijvers" created="Fri, 23 Nov 2007 15:37:28 +0000" />
                    <attachment id="12370308" name="JCR1213Test.java" size="6729" author="mreutegg" created="Tue, 27 Nov 2007 14:18:39 +0000" />
                </attachments>
            <subtasks>
        </subtasks>
                <customfields>
                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                <customfieldname>Attachment count</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>4.0</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                <customfieldname>Date of First Response</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>Tue, 13 Nov 2007 09:13:05 +0000</customfieldvalue>

                </customfieldvalues>
            </customfield>
                                                                                                        <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Global Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>142579</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>190665</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                <customfieldname>Time in Status</customfieldname>
                <customfieldvalues>
                    
                </customfieldvalues>
            </customfield>
                            </customfields>
    </item>
</channel>
</rss>