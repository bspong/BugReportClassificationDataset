<!-- 
RSS generated by JIRA (5.2.8#851-sha1:3262fdc28b4bc8b23784e13eadc26a22399f5d88) at Sat Jul 27 05:52:12 UTC 2013

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/JCR-926/JCR-926.xml?field=key&field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>5.2.8</version>
        <build-number>851</build-number>
        <build-date>26-02-2013</build-date>
    </build-info>

<item>
            <title>[JCR-926] Global data store for binaries</title>
                <link>https://issues.apache.org/jira/browse/JCR-926</link>
                <project id="10591" key="JCR">Jackrabbit Content Repository</project>
                        <description>There are three main problems with the way Jackrabbit currently handles large binary values:&lt;br/&gt;
&lt;br/&gt;
1) Persisting a large binary value blocks access to the persistence layer for extended amounts of time (see &lt;a href=&quot;https://issues.apache.org/jira/browse/JCR-314&quot; title=&quot;Fine grained locking in SharedItemStateManager&quot;&gt;&lt;strike&gt;JCR-314&lt;/strike&gt;&lt;/a&gt;)&lt;br/&gt;
2) At least two copies of binary streams are made when saving them through the JCR API: one in the transient space, and one when persisting the value&lt;br/&gt;
3) Versioining and copy operations on nodes or subtrees that contain large binary values can quickly end up consuming excessive amounts of storage space.&lt;br/&gt;
&lt;br/&gt;
To solve these issues (and to get other nice benefits), I propose that we implement a global &amp;quot;data store&amp;quot; concept in the repository. A data store is an append-only set of binary values that uses short identifiers to identify and access the stored binary values. The data store would trivially fit the requirements of transient space and transaction handling due to the append-only nature. An explicit mark-and-sweep garbage collection process could be added to avoid concerns about storing garbage values.&lt;br/&gt;
&lt;br/&gt;
See the recent NGP value record discussion, especially [1], for more background on this idea.&lt;br/&gt;
&lt;br/&gt;
[1] &lt;a href=&quot;http://mail-archives.apache.org/mod_mbox/jackrabbit-dev/200705.mbox/%3c510143ac0705120919k37d48dc1jc7474b23c9f02cbd@mail.gmail.com%3e&quot;&gt;http://mail-archives.apache.org/mod_mbox/jackrabbit-dev/200705.mbox/%3c510143ac0705120919k37d48dc1jc7474b23c9f02cbd@mail.gmail.com%3e&lt;/a&gt;&lt;br/&gt;
</description>
                <environment></environment>
            <key id="12369478">JCR-926</key>
            <summary>Global data store for binaries</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/newfeature.png">New Feature</type>
                                <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                    <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png">Closed</status>
                    <resolution id="1">Fixed</resolution>
                                <assignee username="-1">Unassigned</assignee>
                                <reporter username="jukkaz">Jukka Zitting</reporter>
                        <labels>
                    </labels>
                <created>Wed, 16 May 2007 12:09:11 +0100</created>
                <updated>Tue, 15 Jan 2008 23:26:41 +0000</updated>
                    <resolved>Thu, 13 Sep 2007 15:32:18 +0100</resolved>
                                            <fixVersion>1.4</fixVersion>
                                <component>jackrabbit-core</component>
                        <due></due>
                    <votes>2</votes>
                        <watches>1</watches>
                                                    <comments>
                    <comment id="12496254" author="jukkaz" created="Wed, 16 May 2007 12:13:30 +0100"  >Attached (DataStore.patch) is a first draft of what such a data store could look like. The main interface is simply:&lt;br/&gt;
&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;public interface DataStore {&lt;br/&gt;
&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;DataRecord getRecord(DataIdentifier identifier) throws IOException;&lt;br/&gt;
&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;DataRecord addRecord(InputStream stream) throws IOException;&lt;br/&gt;
&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;}&lt;br/&gt;
&lt;br/&gt;
The patch contains a simple file-based implementation of this interface. See the javadocs in the patch for more details.&lt;br/&gt;
&lt;br/&gt;
I will proceed to propose a way to integrate this concept in the existing Jackrabbit core if there&amp;#39;s consensus that this approach is worth pursuing.</comment>
                    <comment id="12501891" author="jukkaz" created="Wed, 6 Jun 2007 11:29:42 +0100"  >Attached a prototype patch that integrates the data store concept in Jackrabbit. The integration is very ugly at this stage and the attached code is definitely not meant for inclusion as-is.&lt;br/&gt;
&lt;br/&gt;
For very rough performance testing I created a simple test application that creates a versionable folder with 100 files in it, each containing about 270kB of application/octet-stream data. Once populated, the entire folder was checked into the version store. The numbers, averaged over a couple of test runs, are: &lt;br/&gt;
&lt;br/&gt;
Current svn trunk:&lt;br/&gt;
&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;100 added files: 5625 milliseconds&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;checkin everything: 11094 milliseconds&lt;br/&gt;
&lt;br/&gt;
With this patch:&lt;br/&gt;
&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;100 added files: 2750 milliseconds&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;checkin everything: 1906 milliseconds&lt;br/&gt;
</comment>
                    <comment id="12501892" author="jukkaz" created="Wed, 6 Jun 2007 11:35:25 +0100"  >Note that the checkin performance boost will likely be even more impressive with bundle persistence. For this test I used the &amp;quot;old style&amp;quot; database persistence that is still the default configuration.</comment>
                    <comment id="12506141" author="tmueller" created="Tue, 19 Jun 2007 13:40:32 +0100"  >Hi,&lt;br/&gt;
&lt;br/&gt;
I wrote a small benchmark application to better understand the problem&lt;br/&gt;
&amp;#39;Upload of a large file will block other concurrent actions&amp;#39; as described here:&lt;br/&gt;
&lt;br/&gt;
&lt;a href=&quot;http://issues.apache.org/jira/browse/JCR-314&quot;&gt;http://issues.apache.org/jira/browse/JCR-314&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;http://www.mail-archive.com/users@jackrabbit.apache.org/msg02503.html&quot;&gt;http://www.mail-archive.com/users@jackrabbit.apache.org/msg02503.html&lt;/a&gt;&lt;br/&gt;
&lt;br/&gt;
However, in the current Jackrabbit, it looks like this problem is solved.&lt;br/&gt;
Here is what I tried:&lt;br/&gt;
- For 10 seconds, a new thread is added each second&lt;br/&gt;
- 2 threads write large files, the others just write simple nodes&lt;br/&gt;
- I made tests with small (8 KB) up to large (16 MB) files&lt;br/&gt;
&lt;br/&gt;
To compare the results, my application has a mode&lt;br/&gt;
where the file is not sent to Jackrabbit, instead it is written to disk &lt;br/&gt;
(RandomAccessFile). I wanted to find out how long the &amp;#39;simple&amp;#39; &lt;br/&gt;
threads are blocked by one thread writing a large files. The results are:&lt;br/&gt;
&lt;br/&gt;
- Storing the file outside the repository is about 30% faster&lt;br/&gt;
&amp;nbsp;&amp;nbsp;(but the reason might be the write buffer size or so).&lt;br/&gt;
- When a thread writes a large object, the other threads are _not_ blocked badly.&lt;br/&gt;
&amp;nbsp;&amp;nbsp;At least not more than if the file is stored on the same disk.&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&lt;br/&gt;
If you want to &amp;#39;not block others&amp;#39; when writing large objects, the only solution&lt;br/&gt;
I found is to store large objects on another hard drive. I have tested this as &lt;br/&gt;
well, and it completely solves the problem.&lt;br/&gt;
&lt;br/&gt;
Thomas&lt;br/&gt;
</comment>
                    <comment id="12506521" author="mreutegg" created="Wed, 20 Jun 2007 13:54:32 +0100"  >This may be due to caching on the LocalItemStateManager level. If you create a new session each time you read from the workspace or do random reads on a larger workspace the reading sessions will be blocked while the binary is written.&lt;br/&gt;
&lt;br/&gt;
I&amp;#39;ve committed a test case that illustrates the problem:&lt;br/&gt;
&lt;br/&gt;
&lt;a href=&quot;http://svn.apache.org/repos/asf/jackrabbit/trunk/jackrabbit-core/src/test/java/org/apache/jackrabbit/core/ReadWhileSaveTest.java&quot;&gt;http://svn.apache.org/repos/asf/jackrabbit/trunk/jackrabbit-core/src/test/java/org/apache/jackrabbit/core/ReadWhileSaveTest.java&lt;/a&gt;&lt;br/&gt;
&lt;br/&gt;
Using the default locking strategy in SharedItemState manager the read thread is able to read 127 times on my laptop. When using the fine-grained locking the number goes up to 372.</comment>
                    <comment id="12506522" author="mreutegg" created="Wed, 20 Jun 2007 13:56:07 +0100"  >I haven&amp;#39;t used the test case with the DataStore patch, but I expect that it will be similar to the number of reads for the fine-grained locking.</comment>
                    <comment id="12506676" author="jukkaz" created="Wed, 20 Jun 2007 22:11:33 +0100"  >I made a few modifications to ReadWhileSaveTest to better illustrate the problem. See the attached patch that instead of saving a number of 10MB files saves a single 300MB file. It also keeps track of how many times the root node is traversed while the 300MB file is being persisted.&lt;br/&gt;
&lt;br/&gt;
The raw output of a test run is below:&lt;br/&gt;
&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Wed Jun 20 23:41:17 EEST 2007 - setProperty() - 0&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Wed Jun 20 23:41:39 EEST 2007 - begin save() - 195&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Wed Jun 20 23:42:05 EEST 2007 - end save() - 197&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;numReads: 198&lt;br/&gt;
&lt;br/&gt;
Essentially:&lt;br/&gt;
&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;* setProperty(): 22 seconds, during which 195 root node traversals happened&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;* save():  26 seconds, during which 2 root node traversals happened&lt;br/&gt;
&lt;br/&gt;
The two traversals reported for save() most likely happened between the println() and save() statements.&lt;br/&gt;
&lt;br/&gt;
Observations:&lt;br/&gt;
&lt;br/&gt;
1) Currently we create one extra copy of the binary stream, the write performance would essentially be doubled simply by removing that extra copy. The stream passed to setProperty should be given directly to the DataStore implementation so no extra copies are needed.&lt;br/&gt;
&lt;br/&gt;
2) More alarmingly, this seems to indicate that the fine grained locking from &lt;a href=&quot;https://issues.apache.org/jira/browse/JCR-314&quot; title=&quot;Fine grained locking in SharedItemStateManager&quot;&gt;&lt;strike&gt;JCR-314&lt;/strike&gt;&lt;/a&gt; does not work as well as it should, i.e. a save() still blocks readers. Note that I explicitly added a save() call after the &amp;quot;stuff&amp;quot; node is added to make sure that the write should not affect nodes that are being read. I ran the test against latest svn trunk, revision 549230. &lt;br/&gt;
</comment>
                    <comment id="12506744" author="prios" created="Thu, 21 Jun 2007 03:34:39 +0100"  >I ran ReadWhileSaveTest test with the patch applied using the FineGrainedISMLocking many times, and the results are completely different from the former one, showing in each case that this locking strategy clearly improves concurrency.&lt;br/&gt;
&lt;br/&gt;
These are the output of two test runs:&lt;br/&gt;
&lt;br/&gt;
Wed Jun 20 19:03:54 PDT 2007 - setProperty() - 1&lt;br/&gt;
Wed Jun 20 19:04:14 PDT 2007 - begin save() - 186&lt;br/&gt;
Wed Jun 20 19:04:36 PDT 2007 - end save() - 402&lt;br/&gt;
numReads: 403&lt;br/&gt;
&lt;br/&gt;
Wed Jun 20 19:18:31 PDT 2007 - setProperty() - 1&lt;br/&gt;
Wed Jun 20 19:18:49 PDT 2007 - begin save() - 175&lt;br/&gt;
Wed Jun 20 19:19:09 PDT 2007 - end save() - 373&lt;br/&gt;
numReads: 373&lt;br/&gt;
&lt;br/&gt;
In all the runs I got similar results.&lt;br/&gt;
&lt;br/&gt;
Pablo</comment>
                    <comment id="12506803" author="jukkaz" created="Thu, 21 Jun 2007 09:50:54 +0100"  >Hmm, you&amp;#39;re correct. I assumed that FineGrainedISMLocking was already the default in latest svn trunk but it isn&amp;#39;t. After enabling it I see similar results as you do:&lt;br/&gt;
&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Thu Jun 21 11:44:29 EEST 2007 - setProperty() - 0&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Thu Jun 21 11:44:50 EEST 2007 - begin save() - 196&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Thu Jun 21 11:45:13 EEST 2007 - end save() - 405&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;numReads: 406&lt;br/&gt;
</comment>
                    <comment id="12506839" author="jukkaz" created="Thu, 21 Jun 2007 11:48:35 +0100"  >For the record, the same test run with DataStore2.patch applied:&lt;br/&gt;
&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Thu Jun 21 13:41:43 EEST 2007 - setProperty() - 0&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Thu Jun 21 13:41:54 EEST 2007 - begin save() - 81&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Thu Jun 21 13:41:57 EEST 2007 - end save() - 113&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;numReads: 113&lt;br/&gt;
&lt;br/&gt;
The total time is down from 44 to 14 seconds. :-)</comment>
                    <comment id="12506853" author="jukkaz" created="Thu, 21 Jun 2007 12:28:18 +0100"  >The above comment is probably not comparable with previous numbers, the setProperty() time should not change considerably change with the DataStore patch (in fact it should take a bit longer due to the SHA-1 calculation). To avoid things like disk caches to interfere with the test I increased the size of the test file to 3GB (I only have 1GB RAM).&lt;br/&gt;
&lt;br/&gt;
With DataStore2.patch and FineGrainedISMLocking the result is:&lt;br/&gt;
&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Thu Jun 21 13:51:09 EEST 2007 - setProperty() - 1&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Thu Jun 21 13:55:17 EEST 2007 - begin save() - 2338&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Thu Jun 21 13:55:18 EEST 2007 - end save() - 2352&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;numReads: 2353&lt;br/&gt;
&lt;br/&gt;
setProperty() = 248 seconds, save() = 1 second&lt;br/&gt;
&lt;br/&gt;
Without DataStore2.patch but with FineGrainedISMLocking the result is:&lt;br/&gt;
&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Thu Jun 21 14:08:33 EEST 2007 - setProperty() - 0&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Thu Jun 21 14:12:58 EEST 2007 - begin save() - 2419&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Thu Jun 21 14:17:03 EEST 2007 - end save() - 4766&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;numReads: 4816&lt;br/&gt;
&lt;br/&gt;
setProperty() = 265 seconds, save() = 245 seconds&lt;br/&gt;
&lt;br/&gt;
I guess the stream copy algorithm in FileDataStore is slightly faster than the one in BLOBFileValue, otherwise the numbers are pretty much as expected.</comment>
                    <comment id="12507172" author="tmueller" created="Fri, 22 Jun 2007 10:14:53 +0100"  >This is a patch to clean up InternalValue.internalValue():&lt;br/&gt;
&lt;br/&gt;
Before replacing the BLOBFileValue class with the new &amp;#39;Global Data Store&amp;#39; implementation, I wanted to clean up a few things in InternalValue. The method InternalValue.internalValue() was called a lot in the Jackrabbit code. It returns a java.lang.Object which was then cast to the required class. This has a few disadvantages:&lt;br/&gt;
&lt;br/&gt;
- Unnecessary casts in many places&lt;br/&gt;
- Hard to change the internal working of InternalValue, specially replace BLOBFileValue&lt;br/&gt;
- A few times, &amp;#39;instanceof&amp;#39; was used, making it hard to change BLOBFileValue&lt;br/&gt;
- For developers new to the Jackrabbit code (like me), it&amp;#39;s not always easy to understand what is going on in the code&lt;br/&gt;
- NodeIndexer used the java.lang.Object directly, assuming the implementation will always use Boolean, Long, Double, BLOBFileValue and so on objects.&lt;br/&gt;
&lt;br/&gt;
In this patch, I added specific getter methods to InternalValue, like done in the Value interface. Additionally, there are getPath (for PropertyType.PATH), getQName (for PropertyType.NAME), and getUUID (for PropertyType.REFERENCE).&lt;br/&gt;
&lt;br/&gt;
I had to make a few assertions, some of them were not 100% clear from the code, so could you please review them:&lt;br/&gt;
&lt;br/&gt;
- The &amp;#39;value&amp;#39; of InternalValue is never &amp;#39;null&amp;#39;. &lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;ValueConstraint was checking for &amp;#39;null&amp;#39;, but as far as I see &lt;br/&gt;
&amp;nbsp;&amp;nbsp;it is never really possible to have a &amp;#39;null&amp;#39; value.&lt;br/&gt;
- The type of QName.JCR_FROZENUUID is STRING (Object.toString() was used before).&lt;br/&gt;
- The type of QName.JCR_MIMETYPE is STRING&lt;br/&gt;
- The type of QName.JCR_ENCODING is STRING&lt;br/&gt;
- Currently, for types PropertyType.BINARY, the object is always &lt;br/&gt;
&amp;nbsp;&amp;nbsp;a BLOBFileValue (there was no other constructor for PropertyType.BINARY)&lt;br/&gt;
&lt;br/&gt;
NodeIndexer still has a few unnecessary type casts (addBinaryValue, addBinaryValue,...) but the methods are protected, and I was afraid to change them right now. I hope those can be changed soon to avoid a few unnecessary casts and conversions (Long, Double).&lt;br/&gt;
&lt;br/&gt;
There are no functional changes yet in this patch (as far as I see). But I think this patch is required, otherwise subsequent changes will be much harder.&lt;br/&gt;
&lt;br/&gt;
I didn&amp;#39;t remove InternalValue.internalValue so far, but set it to &amp;#39;deprecated&amp;#39;. I hope it can be removed in the near future.&lt;br/&gt;
&amp;nbsp;&lt;br/&gt;
Thomas&lt;br/&gt;
</comment>
                    <comment id="12507801" author="stefan@jira" created="Mon, 25 Jun 2007 09:01:49 +0100"  >&amp;gt; I had to make a few assertions, some of them were not 100% clear from the code, so could you please review them:&lt;br/&gt;
&amp;gt; &lt;br/&gt;
&amp;gt; - The &amp;#39;value&amp;#39; of InternalValue is never &amp;#39;null&amp;#39;.&lt;br/&gt;
&amp;gt;     ValueConstraint was checking for &amp;#39;null&amp;#39;, but as far as I see&lt;br/&gt;
&amp;gt;   it is never really possible to have a &amp;#39;null&amp;#39; value.&lt;br/&gt;
&amp;gt; - The type of QName.JCR_FROZENUUID is STRING (Object.toString() was used before).&lt;br/&gt;
&amp;gt; - The type of QName.JCR_MIMETYPE is STRING&lt;br/&gt;
&amp;gt; - The type of QName.JCR_ENCODING is STRING&lt;br/&gt;
&amp;gt; - Currently, for types PropertyType.BINARY, the object is always&lt;br/&gt;
&amp;gt;   a BLOBFileValue (there was no other constructor for PropertyType.BINARY)&lt;br/&gt;
&lt;br/&gt;
all the above assumptions are correct.</comment>
                    <comment id="12507875" author="jukkaz" created="Mon, 25 Jun 2007 14:30:16 +0100"  >Looks good, thanks! Committed internalValue.patch as-is in revision 550493.&lt;br/&gt;
&lt;br/&gt;
This change also makes it easier to switch to an InternalValue class hierarchy (as in InternalLongValue, etc.) later on if we want.&lt;br/&gt;
</comment>
                    <comment id="12508790" author="tmueller" created="Thu, 28 Jun 2007 11:44:09 +0100"  >Hi,&lt;br/&gt;
&lt;br/&gt;
This is a refactoring patch for GlobalDataStore. The patch introduces DataStore (almost) wherever it is required, but the behavior is not yet changed (the data store is disabled). This patch may break backwards compatibility.&lt;br/&gt;
&lt;br/&gt;
NodeImpl.internalCopyPropertyFrom: Never used, removed.&lt;br/&gt;
&lt;br/&gt;
ItemStateBinding.readState and writeState: Never used, removed.&lt;br/&gt;
&lt;br/&gt;
Deprecated class org.apache.jackrabbit.core.state.PMContext and org.apache.jackrabbit.core.state.util.Serializer: Removed. Adding a parameter would break backwards compatibility anyway.&lt;br/&gt;
&lt;br/&gt;
The parameter &amp;#39;DataStore store&amp;#39; was added to many constructors and methods. I don&amp;#39;t like it. Would there be a better way to do it? Idea: create a new class &amp;#39;RepositoryContext&amp;#39; with getNodeTypeRegistry(), maybe getNamespaceResolver(), getNamespaceRegistry(), and getDataStore(). Pass this object where appropriate.&lt;br/&gt;
&lt;br/&gt;
Sometimes BLOBs are used only for a short time. I renamed the method create(InputStream in) to createTemporary.&lt;br/&gt;
&lt;br/&gt;
BLOBFileValue is now an abstract class. The original implementation was renamed to &amp;#39;BLOBFileValueOld&amp;#39;. This is only a temporary class (until DataStore is done). There is also BLOBFileValueMemory for very small binary properties (a few hundres bytes), but currently not used.&lt;br/&gt;
&lt;br/&gt;
The DataStore parameter is still missing in InternalValue.valueOf (this method is never called for BINARY types), this will be changed.&lt;br/&gt;
&lt;br/&gt;
InternalValue: BOOLEAN_TRUE and BOOLEAN_FALSE is fixed now. &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
A few notes about the FileDataStore implementation:&lt;br/&gt;
&lt;br/&gt;
I didn&amp;#39;t change Jukka&amp;#39;s implementation so far, but I have a few ideas:&lt;br/&gt;
&lt;br/&gt;
Currently all files are stored in the same directory. However this is a problem for Windows XP (and may be other file systems). I would limit the number of files in the data store root directory to 1024. Afterwards, create subdirectories data1024-2047, data2048-3071,... with 1024 files each. When required, FileDataStore reads the directory list. If faster, one index file per directory could be created. &lt;br/&gt;
&lt;br/&gt;
The file name is currently the SHA-1 digest. I suggest to use SHA-256 (unless it is a lot slower or not available on some systems). Yes you can call me paranoid. SHA-1 could be broken in a few years.&lt;br/&gt;
&lt;br/&gt;
As the file name, I would use: &amp;lt;id&amp;gt;-&amp;lt;digest&amp;gt;.data. As the DataIdentifier, use &amp;lt;id&amp;gt;-&amp;lt;digest&amp;gt;. This would speed up finding files when reading, as (id / 1024) is the directory (direct lookup). Also this would allow to bundle data files in tar files. Tar file support would be priority 2. I would only bundle very small (&amp;lt; 4 KB) files in tar files anyway. Priority 3 would be compression (for text data mainly).&lt;br/&gt;
&lt;br/&gt;
There is no garbage collection at this time. This still needs to be implemented.&lt;br/&gt;
&lt;br/&gt;
Thomas&lt;br/&gt;
</comment>
                    <comment id="12508791" author="tmueller" created="Thu, 28 Jun 2007 11:46:31 +0100"  >I forgot to click on &amp;#39;Grant license to ASF for inclusion in ASF works&amp;#39;.</comment>
                    <comment id="12509586" author="tmueller" created="Mon, 2 Jul 2007 16:01:21 +0100"  >With this patch, both the old style &amp;#39;BLOBStore&amp;#39; and the new style &amp;#39;DataStore&amp;#39; implementations co-exist. The BLOBStore is used by default. To use the DataStore, set the System Property org.jackrabbit.useDataStore to &amp;#39;true&amp;#39; as in:&lt;br/&gt;
&lt;br/&gt;
java -Dorg.jackrabbit.useDataStore=true ...&lt;br/&gt;
&lt;br/&gt;
So this patch can be used to test the GlobalDataStore feature. All unit tests pass.&lt;br/&gt;
&lt;br/&gt;
There are still a few things missing: There is no garbage collection yet. Almost each blob creates two new subdirectories (this works, but is a bit slower, and means lots of directories; can be avoided maybe).&lt;br/&gt;
&lt;br/&gt;
The abstract class BLOBFileValue is now called BLOBValue (because, it is now not always a file). The old BLOBFileValue is now again named BLOBFileValue.&lt;br/&gt;
&lt;br/&gt;
New class Base64ReaderInputStream for BufferedStringValue to avoid creating a file when converting long Base64 strings to BINARY data. Actually the higher performance is just a side effect; the main reason to implement this was becuase the old constructor is based on a file resource and can&amp;#39;t be used with the DataStore.&lt;br/&gt;
</comment>
                    <comment id="12510515" author="prios" created="Thu, 5 Jul 2007 23:48:13 +0100"  >Which is the revision the last version of the binary data store patch should be applied to ?&lt;br/&gt;
&lt;br/&gt;
(I would like to have both the old style BLOBStore and the new style DataStore implementations co-exist and the clean up of the InternalValue.internalValue() method)&lt;br/&gt;
&lt;br/&gt;
The simplest steps that I found to apply the dataStore3.patch was:&lt;br/&gt;
- checkout revision 552445 (revision of the files modified by this patch)&lt;br/&gt;
- delete org.apache.jackrabbit.core.data package (already exists in revision 552445)&lt;br/&gt;
- make a copy of the file BLOBFileValue.java as BLOBValue.java (can&amp;#39;t find the file to patch at line 2659)&lt;br/&gt;
- apply dataStore3.patch&lt;br/&gt;
&lt;br/&gt;
Both with the data store feature disabled (org.jackrabbit.useDataStore=false) and with this feature enabled (org.jackrabbit.useDataStore=true) all TCK tests passed using maven (mvn test).&lt;br/&gt;
For some reasons I don&amp;#39;t know yet, running these tests with the data store enabled within Eclipse IDE, I occasionally got 46 errors and 10 failures.&lt;br/&gt;
&lt;br/&gt;
I would like to start contributing testing this feature.&lt;br/&gt;
&lt;br/&gt;
</comment>
                    <comment id="12510521" author="prios" created="Fri, 6 Jul 2007 00:29:06 +0100"  >I have a couple of questions about the data store.&lt;br/&gt;
&lt;br/&gt;
Given the append-only nature of this feature, when a node with a binary property is removed binary content remains in the data store. When do you expect to have a garbage collection process of binary content (files) in the file system ?&lt;br/&gt;
&lt;br/&gt;
Are you planning to provide a database-backed implementation of the data store ?&lt;br/&gt;
&lt;br/&gt;
Regards,&lt;br/&gt;
Pablo</comment>
                    <comment id="12510640" author="tmueller" created="Fri, 6 Jul 2007 10:44:26 +0100"  >This patch contains a background garbage collection implementation. The algorithm is:&lt;br/&gt;
&lt;br/&gt;
- Remember when the scan started&lt;br/&gt;
- Start an EventListener&lt;br/&gt;
- Tell the DataStore to update the last modification date of files that are read&lt;br/&gt;
&amp;nbsp;&amp;nbsp;(usually only storing files, or adding a link to an existing file&lt;br/&gt;
&amp;nbsp;&amp;nbsp;updates the modification date, but now during the GC also reading does)&lt;br/&gt;
- Recursively iterate through all nodes&lt;br/&gt;
- If the node contains binary properties, start reading them,&lt;br/&gt;
&amp;nbsp;&amp;nbsp;but close the input stream immediately. &lt;br/&gt;
&amp;nbsp;&amp;nbsp;This updates the modification date&lt;br/&gt;
- If new nodes are added, the EventListener does the same&lt;br/&gt;
&amp;nbsp;&amp;nbsp;(recurse through all added nodes).&lt;br/&gt;
&amp;nbsp;&amp;nbsp;Actually it would only be required to scan the moved nodes,&lt;br/&gt;
&amp;nbsp;&amp;nbsp;but not sure how to do that.&lt;br/&gt;
- The application needs to call &amp;#39;scan&amp;#39; for each workspace&lt;br/&gt;
&amp;nbsp;&amp;nbsp;(this is not done yet, not sure how to get the list of workspaces).&lt;br/&gt;
- When the scan is done, wait one second. This is for the EventListener&lt;br/&gt;
&amp;nbsp;&amp;nbsp;to catch up. How long do we have to wait for the observation listeners?&lt;br/&gt;
&amp;nbsp;&amp;nbsp;Is there a way to &amp;#39;force&amp;#39; Jackrabbit to call the observation listeners?&lt;br/&gt;
- Then, delete all data records that where not modified since GC scan started.&lt;br/&gt;
&lt;br/&gt;
To test the garbage collection, there is also a simple application (BlobGCTest.java). This is not yet a unit test, it is a standalone application. It creates a few nodes:&lt;br/&gt;
/node1&lt;br/&gt;
/node2&lt;br/&gt;
/node2/nodeWithBlob&lt;br/&gt;
/node2/nodeWithTemporaryBlob&lt;br/&gt;
&lt;br/&gt;
Then it deletes nodeWithTemporaryBlob. The file is still in the data store afterwards. Then the garbage collection is started. While the scan is running, after node1 was scanned but before node2, the /node2/nodeWithBlob is moved to /node1/nodeWithBlob. Usually, the garbage collection wouldn&amp;#39;t notice this (as the scan was past node1 already). But because of the EventListener, it scans the moved node as well (at the very end usually). The output is:&lt;br/&gt;
&lt;br/&gt;
scanning...&lt;br/&gt;
scanned: /node1&lt;br/&gt;
moved /node2/nodeWithBlob to /node1&lt;br/&gt;
scanned: /node2&lt;br/&gt;
identifiers:&lt;br/&gt;
&amp;nbsp;&amp;nbsp;17ec4a160f44f9467b4204aa20e5981d9508c4df&lt;br/&gt;
&amp;nbsp;&amp;nbsp;74b5b1b26f806661292b9add2e78f671cf06f432&lt;br/&gt;
stop scanning...&lt;br/&gt;
scanned: /node1/nodeWithBlob&lt;br/&gt;
deleting...&lt;br/&gt;
identifiers:&lt;br/&gt;
&amp;nbsp;&amp;nbsp;17ec4a160f44f9467b4204aa20e5981d9508c4df&lt;br/&gt;
&lt;br/&gt;
This is a patch for revision 553213 (actually the revision number is in the patch as well).&lt;br/&gt;
&lt;br/&gt;
To delete files early in the garbage collection scan, we could do this:&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;br/&gt;
A) If garbage collection was run before, see if there a file with the list of UUIDs (&amp;#39;uuids.txt&amp;#39;).&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;br/&gt;
B) If yes, and if the checksum is ok, read all those nodes first (if not so many).&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;This updates the modified date of all old files that are still in use.&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Afterwards, delete all files with an older modified date than the last scan!&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Newer files, and files that are read have a newer modification date.&lt;br/&gt;
&lt;br/&gt;
C) Delete the &amp;#39;uuids.txt&amp;#39; file (in any case).&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;br/&gt;
D) Iterate (recurse) through all nodes and properties like now.&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;If a node has a binary property, store the UUID of the node in the file (&amp;#39;uuids.txt&amp;#39;).&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Also store the time when the scan started.&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;br/&gt;
E) Checksum and close the file.&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;br/&gt;
F) Like now, delete files with an older modification date than this scan.&lt;br/&gt;
&lt;br/&gt;
We can&amp;#39;t use node path for this, UUIDs are required as nodes could be moved around.&lt;br/&gt;
&lt;br/&gt;
</comment>
                    <comment id="12510720" author="efranqueiro" created="Fri, 6 Jul 2007 17:07:48 +0100"  >Thomas, your patch references org.apache.jackrabbit.benchmark.RandomInputStream, wich is not included in the patch, and I couldn&amp;#39;t find it anywhere.&lt;br/&gt;
Regards </comment>
                    <comment id="12511387" author="tmueller" created="Tue, 10 Jul 2007 12:06:33 +0100"  >The garbage collection implementation has a few disadvantages, for example you can&amp;#39;t stop and restart it. I suggest to get the nodes directly from the persistence manager.  To do this, I suggest to add a new method to AbstractBundlePersistenceManager:&lt;br/&gt;
&lt;br/&gt;
protected synchronized NodeIdIterator getAllNodeIds(NodeId startWith, int maxCount)&lt;br/&gt;
&lt;br/&gt;
startWith can be null, in which case there is no lower limit.&lt;br/&gt;
If maxCount is 0 then all node ids are returned.&lt;br/&gt;
&lt;br/&gt;
Like this you can stop and restart it:&lt;br/&gt;
Day 1: getAllNodeIds(null, 1000);&lt;br/&gt;
&amp;nbsp;... iterate though all node ids&lt;br/&gt;
&amp;nbsp;... remember the last node id of this batch, for example 0x12345678&lt;br/&gt;
&lt;br/&gt;
Day 2: getAllNodeIds(0x12345678, 1000);&lt;br/&gt;
&amp;nbsp;... iterate though all node ids&lt;br/&gt;
&amp;nbsp;... remember the last node id of this batch,...&lt;br/&gt;
&lt;br/&gt;
New nodes are not a problem, as the modified date of a node is updated in this case.&lt;br/&gt;
AbstractBundlePersistenceManager.getAllNodeIds could be used for other features later on (for example, fast repository cloning, backup).&lt;br/&gt;
&lt;br/&gt;
Thomas</comment>
                    <comment id="12513847" author="tmueller" created="Thu, 19 Jul 2007 09:28:30 +0100"  >What needs to be done to commit this to Jackrabbit?&lt;br/&gt;
My patches get bigger and more complicated...</comment>
                    <comment id="12513854" author="jukkaz" created="Thu, 19 Jul 2007 09:50:11 +0100"  >I&amp;#39;m sorry I haven&amp;#39;t had the cycles lately to properly review the patches. Would it be possible to split them to smaller semi-independent pieces? For example we could commit the data store implementation independent of the integration to rest of the Jackrabbit core. </comment>
                    <comment id="12517917" author="tmueller" created="Mon, 6 Aug 2007 13:42:22 +0100"  >Hi,&lt;br/&gt;
&lt;br/&gt;
To help integrate the changes more quickly, I suggest to split the big patches into multiple smaller ones. Here is the addition of the garbage collector. This patch does not affect currently used code. &lt;br/&gt;
&lt;br/&gt;
Thomas</comment>
                    <comment id="12518389" author="tmueller" created="Wed, 8 Aug 2007 09:33:05 +0100"  >Hi,&lt;br/&gt;
&lt;br/&gt;
Is there anything I can do to help speed up integrating the global data store changes?&lt;br/&gt;
It&amp;#39;s a bit frustrating for me if I have to wait and can&amp;#39;t do anything.&lt;br/&gt;
&lt;br/&gt;
Thomas</comment>
                    <comment id="12522950" author="tmueller" created="Mon, 27 Aug 2007 09:31:15 +0100"  >Revision 570033: garbage collection implementation for the global data store</comment>
                    <comment id="12522953" author="tmueller" created="Mon, 27 Aug 2007 09:49:46 +0100"  >Revision 570040: garbage collection implementation for the global data store</comment>
                    <comment id="12523171" author="tmueller" created="Tue, 28 Aug 2007 08:00:55 +0100"  >Revision 570336: BLOBFileValue and InternalValue refactoring, improved GarbageCollector</comment>
                    <comment id="12523189" author="c_koell" created="Tue, 28 Aug 2007 09:37:16 +0100"  >Does the GlobalDataStore also prevent the BundleDBPersistenceManager to load the binary property automatically &lt;br/&gt;
when you get a node ? I have posted this a few weeks ago in the mailinglist an jukka told me that this problem will hopefully&lt;br/&gt;
be fixed with the GlobalDataStore.&lt;br/&gt;
&lt;br/&gt;
</comment>
                    <comment id="12523190" author="tmueller" created="Tue, 28 Aug 2007 09:43:17 +0100"  >&amp;gt; Does the GlobalDataStore also prevent the BundleDBPersistenceManager &lt;br/&gt;
&amp;gt; to load the binary property automatically when you get a node ?&lt;br/&gt;
&lt;br/&gt;
Yes. If &amp;#39;Global Data Store&amp;#39; is enabled, larger binary properties are be stored there and loaded from there. Only the DataIdentifier (a String) and small binaries (up to 1 KB or so, needs to be tested) will be stored in the persistence manager.&lt;br/&gt;
</comment>
                    <comment id="12523195" author="c_koell" created="Tue, 28 Aug 2007 09:53:28 +0100"  >thanks for the quick answer thomas.&lt;br/&gt;
&lt;br/&gt;
ok and where will the &amp;quot;datastore&amp;quot; be stored on the filesystem.&lt;br/&gt;
can i configure it because i think for data backup and recory process it&lt;br/&gt;
will be very interesting to save the files on a huge, fast filesystem. (SAN)</comment>
                    <comment id="12523201" author="tmueller" created="Tue, 28 Aug 2007 10:24:25 +0100"  >&amp;gt; where will the &amp;quot;datastore&amp;quot; be stored on the filesystem. &lt;br/&gt;
This will be a configuration option for the FileDataStore&lt;br/&gt;
</comment>
                    <comment id="12523229" author="tmueller" created="Tue, 28 Aug 2007 14:08:19 +0100"  >Revision 570407: add DataStore to constructors</comment>
                    <comment id="12523246" author="tmueller" created="Tue, 28 Aug 2007 15:17:14 +0100"  >Revision 570439: re-added useful methods</comment>
                    <comment id="12523508" author="tmueller" created="Wed, 29 Aug 2007 09:50:09 +0100"  >Revision 570439: renamed BLOBFileValue to BLOBValue, new abstract class BLOBFileValue</comment>
                    <comment id="12523807" author="tmueller" created="Thu, 30 Aug 2007 10:42:10 +0100"  >Revision 571094: global data store: new in-memory, data store, and temp file BLOB&lt;br/&gt;
The data store can now be tested, however it is disabled by default. &lt;br/&gt;
To enable, set the system property &amp;quot;org.jackrabbit.useDataStore&amp;quot; to &amp;quot;true&amp;quot;&lt;br/&gt;
before starting the application: java -Dorg.jackrabbit.useDataStore=true ...&lt;br/&gt;
(this does not work, not sure why: mvn -Dorg.jackrabbit.useDataStore=true ...)</comment>
                    <comment id="12523809" author="c_koell" created="Thu, 30 Aug 2007 10:58:51 +0100"  >hi thomas,&lt;br/&gt;
first ... great work !&lt;br/&gt;
can you explain how to configure the datastore or is this feature not yet implemented ?&lt;br/&gt;
i mean will the datastore be configureable in the workspace.xml  .. i think,so each workspace can have its own&lt;br/&gt;
datastore to define different backup solutions ..&lt;br/&gt;
thanks&lt;br/&gt;
claus&lt;br/&gt;
</comment>
                    <comment id="12523810" author="jukkaz" created="Thu, 30 Aug 2007 11:04:03 +0100"  >Nice work!&lt;br/&gt;
&lt;br/&gt;
&amp;gt; (this does not work, not sure why: mvn -Dorg.jackrabbit.useDataStore=true ...)&lt;br/&gt;
&lt;br/&gt;
Maven probably forks a separate JVM instance for running the test suite.</comment>
                    <comment id="12523814" author="tmueller" created="Thu, 30 Aug 2007 11:27:12 +0100"  >Hi,&lt;br/&gt;
&lt;br/&gt;
&amp;gt; great work !&lt;br/&gt;
Most of it was Jukkas work.&lt;br/&gt;
&lt;br/&gt;
&amp;gt; configure the datastore&lt;br/&gt;
That&amp;#39;s the next priority. Currently, you need to use system properties.&lt;br/&gt;
&lt;br/&gt;
&amp;gt; each workspace can have its own datastore&lt;br/&gt;
No, there is only one data store per repository. Technically it would be possible to store the files in the different workspaces, but in my view a lot of the benefit would be lost.&lt;br/&gt;
&lt;br/&gt;
&amp;gt; different backup solutions&lt;br/&gt;
Backup (online and incremental) is important. It is very easy to backup the data store: just copy all files. They are never modified, and only renamed from temp file to live file. Deleted only when no longer used (by the garbage collector). But I know only a few use cases: &amp;#39;backup everything&amp;#39;, &amp;#39;backup incrementally&amp;#39;, &amp;#39;backup with data compression&amp;#39;, &amp;#39;backup with encryption&amp;#39;, and &amp;#39;restore&amp;#39;. What other backup use cases / solutions do you have in mind?</comment>
                    <comment id="12523831" author="c_koell" created="Thu, 30 Aug 2007 12:43:38 +0100"  >ok great work to both of you :-)&lt;br/&gt;
I think only one datastore is not a good way.&lt;br/&gt;
we have jackrabbit running in a model 3 architecture with one repository and for each application one workspace.&lt;br/&gt;
the problem is not the backup solution, we would prefere backup incremential by third party solutions.&lt;br/&gt;
at the moment we define for each workspace different persistencemanagers to different db servers.&lt;br/&gt;
we want for each workspace &amp;quot;application&amp;quot; define different SAN storage places, because we must discount the&lt;br/&gt;
storage volume for each application. if we have only one datastore it is not possible to know how much&lt;br/&gt;
space each application consumes.&lt;br/&gt;
hope for a feature to define that.&lt;br/&gt;
&lt;br/&gt;
one thing at the end ... what do you mean with &lt;br/&gt;
&amp;gt; Deleted only when no longer used (by the garbage collector). &lt;br/&gt;
the files in the datastore are the permanent files or not ?&lt;br/&gt;
thanks&lt;br/&gt;
claus</comment>
                    <comment id="12523835" author="tmueller" created="Thu, 30 Aug 2007 12:57:47 +0100"  >Hi,&lt;br/&gt;
&lt;br/&gt;
&amp;gt; one repository and for each application one workspace.&lt;br/&gt;
&lt;br/&gt;
Why not one repository for each application? Like this you can limit the heap memory as well.&lt;br/&gt;
&lt;br/&gt;
&amp;gt; the files in the datastore are the permanent files&lt;br/&gt;
&lt;br/&gt;
If things get deleted, the space must eventually be reclaimed (unless you work for a hard drive company).&lt;br/&gt;
&lt;br/&gt;
Thomas</comment>
                    <comment id="12523848" author="c_koell" created="Thu, 30 Aug 2007 14:39:12 +0100"  >the heap is not the problem ... we have a lot ;-)&lt;br/&gt;
i think to use different workspaces is for us the better way ..&lt;br/&gt;
what are the benefits you would lost with a datastore per workspace ?&lt;br/&gt;
i see the datastore as enhancement for the persistencemanager because the other properties will be stored through the persistencemanager &lt;br/&gt;
per workspace and now we will put everything from all workspaces into one datastore ?&lt;br/&gt;
greets &lt;br/&gt;
claus</comment>
                    <comment id="12523852" author="jukkaz" created="Thu, 30 Aug 2007 14:59:26 +0100"  >A central idea of the *Global* Data Store is that its global to the repository, especially to drive down the costs of versioning and other cross-workspace operations.&lt;br/&gt;
&lt;br/&gt;
It would in principle be feasible to allow a workspace-specific data store to be configured, but that would make handling of cross-workspace operations considerably more complex. IMHO the benefits of workspace-local data stores wouldn&amp;#39;t be worth the added complexity.&lt;br/&gt;
&lt;br/&gt;
On a longer timescale I also believe Jackrabbit should be moving even more to centralized repository-global resource handling as that would for example help a lot in making things like versioning operations transactional.&lt;br/&gt;
&lt;br/&gt;
As for features like per-workspace quota or backups, I think those would be best achieved by implementing the features in Jackrabbit instead of relying on the underlying storage mechanism.</comment>
                    <comment id="12523853" author="tmueller" created="Thu, 30 Aug 2007 15:05:36 +0100"  >As far as I understand, one (important) use case is to use one workspace for &amp;#39;authoring&amp;#39; and another for &amp;#39;production&amp;#39;. The workspaces contain mostly the same data (maybe 90% is the same). Having a data store for each workspace would mean having to copy all large files. Having one data store saves you 50% of the space (for large objects). Also you can move data from one workspace to the other very quickly (because the files don&amp;#39;t have to be copied, only the identifiers). Also cloning of a workspace is very fast for the same reasons.&lt;br/&gt;
&lt;br/&gt;
&amp;gt; i think to use different workspaces is for us the better way .. &lt;br/&gt;
Do you know about blob store? If not you should try it out, because it sounds like this would be exactly what you need. The blob store already available.&lt;br/&gt;
</comment>
                    <comment id="12524012" author="c_koell" created="Fri, 31 Aug 2007 07:14:58 +0100"  >ok if you have a use case as you described i think a global datastore is the best way to make cross-workspace operations&lt;br/&gt;
more easy. you have only one file and no copies af same files.&lt;br/&gt;
if the road goes to a centralized repository a global datastore makes of course sense.&lt;br/&gt;
&lt;br/&gt;
in my case (and i think other has also a similarly use case) a per workspace datastore makes things easier&lt;br/&gt;
i am working for a government and the office employee get a lot of paper every day. they scan it and put it into jackrabbit.&lt;br/&gt;
now we must keep the documents based on the law up to 5-7 years with fast read access in jackrabbit. after that time we can archive it (slow access) and therefore&lt;br/&gt;
we want to store this documents not on a SAN storage (because its expensive) rather save it to a cheaper storage system (tape drive system)&lt;br/&gt;
we have planed to make this with moving the data from one workspace (SAN) to a other one (tape drive system)&lt;br/&gt;
with the global datastore is this not possible i think&lt;br/&gt;
&lt;br/&gt;
how would you solve such scenarios ?&lt;br/&gt;
greets&lt;br/&gt;
claus&lt;br/&gt;
&lt;br/&gt;
</comment>
                    <comment id="12524022" author="tmueller" created="Fri, 31 Aug 2007 08:34:01 +0100"  >Hi,&lt;br/&gt;
&lt;br/&gt;
Theoretically the data store could be split to different directories / hard drives. Content that is accessed more often could be moved to a faster disk, and less used data could eventually be moved to slower / cheaper disk. That would be an extension of the &amp;#39;memory hierarchy&amp;#39; (see also &lt;a href=&quot;http://en.wikipedia.org/wiki/Memory_hierarchy)&quot;&gt;http://en.wikipedia.org/wiki/Memory_hierarchy)&lt;/a&gt;. Of course this wouldn&amp;#39;t limit the space used per workspace, but would improve system performance if done right. Maybe we need to do that anyway in the near future to better support solid state disk. &lt;br/&gt;
&lt;br/&gt;
Workspace usage: I&amp;#39;m not sure what solution would be the best for your use case. Maybe this would better be discussed in a separate thread. See also &lt;a href=&quot;http://wiki.apache.org/jackrabbit/DavidsModel#head-ca639e0ee110b80e8277a50f9b9de092b5d86427&quot;&gt;http://wiki.apache.org/jackrabbit/DavidsModel#head-ca639e0ee110b80e8277a50f9b9de092b5d86427&lt;/a&gt;</comment>
                    <comment id="12524038" author="tmueller" created="Fri, 31 Aug 2007 09:28:17 +0100"  >Revision 571399: Follow Jackrabbit code style. Better do that now before it is too late, before re-formatting makes comparing version difficult</comment>
                    <comment id="12525395" author="tmueller" created="Thu, 6 Sep 2007 11:26:22 +0100"  >Revision 573209: Configuration is now supported. Still the system property &amp;#39;org.jackrabbit.useDataStore&amp;#39; is required to enable this feature, but now the data store class (and for the FileDataStore, the path) can be configured:&lt;br/&gt;
&lt;br/&gt;
&amp;lt;Repository&amp;gt;&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;lt;DataStore class=&amp;quot;org.apache.jackrabbit.core.data.FileDataStore&amp;quot;&amp;gt;&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;lt;param name=&amp;quot;path&amp;quot; value=&amp;quot;${rep.home}/repository&amp;quot;/&amp;gt;&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;lt;/DataStore&amp;gt;&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;....&lt;br/&gt;
&amp;lt;/Repository&amp;gt;&lt;br/&gt;
&lt;br/&gt;
The DataStore API was changed a bit to support this. The DataStore configuration is optional, if missing the system almost works as now. Almost, because the BLOBValue class is no longer used. The system property org.jackrabbit.useDataStore will be removed when this is tested. Also, the system property org.jackrabbit.minBlobFileSize will be integrated into DataStore. My idea is that each data store implementation (file system, database, S3?) can have a different &amp;#39;minimum size&amp;#39; depending on the overhead to store / load a value.&lt;br/&gt;
&lt;br/&gt;
By the way, the FileDataStore overhead (mainly calculating the SHA-1 digest) is quite low, smaller than 10%:&lt;br/&gt;
Writing and reading 5 files 100 KB each, average over 5 runs:&lt;br/&gt;
FileDataStore: 1390 ms, FileOutputStream: 1287 ms&lt;br/&gt;
</comment>
                    <comment id="12526412" author="tmueller" created="Tue, 11 Sep 2007 11:40:34 +0100"  >Revision 574543: The FileDataStore now supports the configuration option &amp;#39;minRecordLength&amp;#39; (default: 100). &lt;br/&gt;
&lt;br/&gt;
Missing unit tests have been added, the test code coverage is now OK. A bug has been fixed (when importing, a temp file was created but never stored in the data store).&lt;br/&gt;
&lt;br/&gt;
The setting &amp;#39;org.jackrabbit.useDataStore&amp;#39; can now be enabled in my view, I will do this in a day or two unless there is a problem. Then, the new classes BLOBInResource, BLOBInTempFile, BLOBInMemory are used instead of BLOBValue. The file data store is still only used when configured in repository.xml. Temp files are still created in some cases (for example importing).</comment>
                    <comment id="12526714" author="tmueller" created="Wed, 12 Sep 2007 10:06:59 +0100"  >Revision 15482: Remove unused methods&lt;br/&gt;
</comment>
                    <comment id="12526717" author="c_koell" created="Wed, 12 Sep 2007 10:11:06 +0100"  >hi thomas&lt;br/&gt;
&lt;br/&gt;
what do you think about migration steps for existing workspaces ?&lt;br/&gt;
&lt;br/&gt;
greets&lt;br/&gt;
claus&lt;br/&gt;
</comment>
                    <comment id="12526722" author="tmueller" created="Wed, 12 Sep 2007 10:29:22 +0100"  >Compatibility: the plan is to make this feature fully backward compatible. When the system property &amp;#39;org.jackrabbit.useDataStore&amp;#39; is enabled, and when FileDataStore is configured in repository.xml, old repositories can still be used. Only new binary objects are stored in the data store, and only when this is configured in repository.xml.&lt;br/&gt;
&lt;br/&gt;
Migration to data store: binary data that is currently in the blob store (or in the persistence manager) can be moved to the data store by cloning a workspace, or export / import.&lt;br/&gt;
&lt;br/&gt;
Migration away from the data store: currently, you need to export the data with the data store enabled / configured, and then import into a new repository without data store.</comment>
                    <comment id="12526725" author="tmueller" created="Wed, 12 Sep 2007 10:38:31 +0100"  >Migration from one data store type to another: Currently not required as there is only the file data store. A tool will be added when needed. The API required is already there: DataStore.getAllIdentifiers().</comment>
                    <comment id="12526907" author="pankaj.gupta" created="Wed, 12 Sep 2007 22:04:17 +0100"  >Currently clustering requires all blobs to be stored in the database to ensure transaction semantics. But in our application we would prefer to store blobs externally for performance reasons. I am assuming that with the global data store we would be able to that since blobs in the transient space would be stored separately.  Please let me know if this is correct as this will resolve a big issue that we are currently facing with Jackrabbit.&lt;br/&gt;
&lt;br/&gt;
Thanks,&lt;br/&gt;
Pankaj</comment>
                    <comment id="12526997" author="tmueller" created="Thu, 13 Sep 2007 07:49:57 +0100"  >&amp;gt; clustering - store blobs externally for performance reasons&lt;br/&gt;
&amp;gt; with the global data store we would be able to that &lt;br/&gt;
&lt;br/&gt;
Yes, clustering is supported. Entries are added as early as possible, and deleted only when they are not reachable (garbage collection). There is no &amp;#39;update&amp;#39; operation, only &amp;#39;add new entry&amp;#39;. Data is added before the transaction is committed. Additions are globally atomic, cluster nodes can share the same data store. Even different repositories can share the same store, as long as garbage collection is done correctly.&lt;br/&gt;
&lt;br/&gt;
Advantages: no duplicate entries (saves space; speeds up versioning, workspace cloning, node copy operations). Improved concurrency.&lt;br/&gt;
&lt;br/&gt;
Disadvantage: garbage collection is required. There are ideas how to efficiently do that (without having to scan through the whole repository).</comment>
                    <comment id="12527100" author="tmueller" created="Thu, 13 Sep 2007 14:23:38 +0100"  >Revision 575304: enabling the data store&lt;br/&gt;
&lt;br/&gt;
To use the FileDataStore, add this to your repository.xml after the &amp;lt;Repository&amp;gt; start tag:&lt;br/&gt;
&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;lt;DataStore class=&amp;quot;org.apache.jackrabbit.core.data.FileDataStore&amp;quot;/&amp;gt;&lt;br/&gt;
&lt;br/&gt;
The files will be stored under repository/datastore by default. For more information about the configuration, see FileDataStore.java</comment>
                    <comment id="12527117" author="jukkaz" created="Thu, 13 Sep 2007 15:25:48 +0100"  >Nice! Time to resolve this issue and file new issues for future fixes/enhancements?</comment>
                </comments>
                    <attachments>
                    <attachment id="12359067" name="DataStore2.patch" size="220874" author="jukkaz" created="Wed, 6 Jun 2007 11:29:42 +0100" />
                    <attachment id="12360941" name="dataStore3.patch" size="213143" author="tmueller" created="Mon, 2 Jul 2007 16:01:13 +0100" />
                    <attachment id="12361281" name="dataStore4.zip" size="34232" author="tmueller" created="Fri, 6 Jul 2007 10:44:26 +0100" />
                    <attachment id="12363242" name="dataStore5-garbageCollector.patch" size="17567" author="tmueller" created="Mon, 6 Aug 2007 13:42:22 +0100" />
                    <attachment id="12360722" name="dataStore.patch" size="187331" author="tmueller" created="Thu, 28 Jun 2007 11:44:09 +0100" />
                    <attachment id="12357458" name="DataStore.patch" size="31816" author="jukkaz" created="Wed, 16 May 2007 12:13:30 +0100" />
                    <attachment id="12360352" name="internalValue.patch" size="45107" author="tmueller" created="Fri, 22 Jun 2007 10:14:52 +0100" />
                    <attachment id="12360229" name="ReadWhileSaveTest.patch" size="3514" author="jukkaz" created="Wed, 20 Jun 2007 22:11:33 +0100" />
                </attachments>
            <subtasks>
        </subtasks>
                <customfields>
                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                <customfieldname>Attachment count</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>8.0</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                <customfieldname>Date of First Response</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>Tue, 19 Jun 2007 12:40:32 +0000</customfieldvalue>

                </customfieldvalues>
            </customfield>
                                                                                                        <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Global Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>142432</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>190027</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                <customfieldname>Time in Status</customfieldname>
                <customfieldvalues>
                    
                </customfieldvalues>
            </customfield>
                            </customfields>
    </item>
</channel>
</rss>