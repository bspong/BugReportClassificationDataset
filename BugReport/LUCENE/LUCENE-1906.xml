<!-- 
RSS generated by JIRA (5.2.8#851-sha1:3262fdc28b4bc8b23784e13eadc26a22399f5d88) at Tue Jul 16 13:35:19 UTC 2013

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/LUCENE-1906/LUCENE-1906.xml?field=key&field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>5.2.8</version>
        <build-number>851</build-number>
        <build-date>26-02-2013</build-date>
    </build-info>

<item>
            <title>[LUCENE-1906] Backwards problems with CharStream and Tokenizers with custom reset(Reader) method</title>
                <link>https://issues.apache.org/jira/browse/LUCENE-1906</link>
                <project id="12310110" key="LUCENE">Lucene - Core</project>
                        <description>&lt;p&gt;When reviewing the new CharStream code added to Tokenizers, I found a&lt;br/&gt;
serious problem with backwards compatibility and other Tokenizers, that do&lt;br/&gt;
not override reset(CharStream).&lt;/p&gt;

&lt;p&gt;The problem is, that e.g. CharTokenizer only overrides reset(Reader):&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void reset(Reader input) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
    &lt;span class=&quot;code-keyword&quot;&gt;super&lt;/span&gt;.reset(input);
    bufferIndex = 0;
    offset = 0;
    dataLen = 0;
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If you reset such a Tokenizer with another CharStream (not a Reader), this&lt;br/&gt;
method will never be called and breaking the whole Tokenizer.&lt;/p&gt;

&lt;p&gt;As CharStream extends Reader, I propose to remove this reset(CharStream&lt;br/&gt;
method) and simply do an instanceof check to detect if the supplied Reader&lt;br/&gt;
is no CharStream and wrap it. We could also remove the extra ctor (because&lt;br/&gt;
most Tokenizers have no support for passing CharStreams). If the ctor also&lt;br/&gt;
checks with instanceof and warps as needed the code is backwards compatible&lt;br/&gt;
and we do not need to add additional ctors in subclasses.&lt;/p&gt;

&lt;p&gt;As this instanceof check is always done in CharReader.get() why not remove&lt;br/&gt;
ctor(CharStream) and reset(CharStream) completely?&lt;/p&gt;

&lt;p&gt;Any thoughts?&lt;/p&gt;

&lt;p&gt;I would like to fix this somehow before RC4, I&apos;m, sorry &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</description>
                <environment></environment>
            <key id="12435329">LUCENE-1906</key>
            <summary>Backwards problems with CharStream and Tokenizers with custom reset(Reader) method</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.png">Blocker</priority>
                    <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png">Closed</status>
                    <resolution id="1">Fixed</resolution>
                                <assignee username="thetaphi">Uwe Schindler</assignee>
                                <reporter username="thetaphi">Uwe Schindler</reporter>
                        <labels>
                    </labels>
                <created>Thu, 10 Sep 2009 16:33:54 +0100</created>
                <updated>Fri, 25 Sep 2009 17:23:39 +0100</updated>
                    <resolved>Fri, 11 Sep 2009 07:15:33 +0100</resolved>
                            <version>2.9</version>
                                <fixVersion>2.9</fixVersion>
                                <component>modules/analysis</component>
                        <due></due>
                    <votes>0</votes>
                        <watches>0</watches>
                                                    <comments>
                    <comment id="12753664" author="thetaphi" created="Thu, 10 Sep 2009 16:42:51 +0100"  >&lt;p&gt;I will now check, if the change of the &quot;input&quot; member variable leads to backwards breaks (it was changed from Reader to CharStream)...&lt;/p&gt;</comment>
                    <comment id="12753666" author="yseeley@gmail.com" created="Thu, 10 Sep 2009 16:45:30 +0100"  >&lt;p&gt;+1, this looks like the best fix.&lt;/p&gt;</comment>
                    <comment id="12753679" author="mikemccand" created="Thu, 10 Sep 2009 17:07:28 +0100"  >&lt;p&gt;+1, good catch Uwe!&lt;/p&gt;</comment>
                    <comment id="12753687" author="markrmiller@gmail.com" created="Thu, 10 Sep 2009 17:26:49 +0100"  >&lt;p&gt;Ready Uwe?&lt;/p&gt;</comment>
                    <comment id="12753689" author="thetaphi" created="Thu, 10 Sep 2009 17:34:19 +0100"  >&lt;blockquote&gt;&lt;p&gt;I will now check, if the change of the &quot;input&quot; member variable leads to backwards breaks (it was changed from Reader to CharStream)...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;We also have a not-in-CHANGES.txt backwards break. We changed Reader to CharStream. When committing this change, also the backwards-branch was modified to use CharStream. I reverted this change (to get the state of a legacy Tokenizer) and wrote a Test, that called input.read() inside the Tokenizer. The test compiled correct in backwards and also run correct.&lt;/p&gt;

&lt;p&gt;In trunk, the test-tag failed:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    [junit] Testcase: testChangeToCharStream29(org.apache.lucene.analysis.TestTokenizer):       Caused an ERROR
    [junit] input
    [junit] java.lang.NoSuchFieldError: input
    [junit]     at org.apache.lucene.analysis.TestTokenizer$1.next(TestTokenizer.java:43)
    [junit]     at org.apache.lucene.analysis.TestTokenizer.testChangeToCharStream29(TestTokenizer.java:58)
    [junit]
    [junit]
    [junit] Test org.apache.lucene.analysis.TestTokenizer FAILED
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So somebody cannot use his old Tokenizers without recompiling (because Java is not able to respect the type change). After recompiling his classes it works.&lt;/p&gt;

&lt;p&gt;If we want to do this, we should clearly state this in CHANGES at the backwards-breaks.&lt;/p&gt;</comment>
                    <comment id="12753690" author="thetaphi" created="Thu, 10 Sep 2009 17:36:49 +0100"  >&lt;p&gt;Here is the patch for backwards-branch, that fails. It reverts the change from Reader to CharStream and adds a dummy Tokenizer in the test that compiles, but does not run in trunk.&lt;/p&gt;</comment>
                    <comment id="12753691" author="thetaphi" created="Thu, 10 Sep 2009 17:40:08 +0100"  >&lt;p&gt;Sorry, wrong patch, this one is correct. Other one was a even harder test by assigning a value.&lt;/p&gt;</comment>
                    <comment id="12753709" author="thetaphi" created="Thu, 10 Sep 2009 18:13:07 +0100"  >&lt;p&gt;One possibility to prevent this break would be the following:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;revert the CharStream to a Reader in Tokenizer (restore the old class).&lt;/li&gt;
	&lt;li&gt;add a method correctOffset(int) to Tokenizer that does:
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;protected&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; correctOffset(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; offset) {
  &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (input &lt;span class=&quot;code-keyword&quot;&gt;instanceof&lt;/span&gt; CharStream) &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; ((CharStream) input).correctOffset(offset);
  &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; offset;
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/li&gt;
	&lt;li&gt;Change the usage of correctOffset in all Tokenizers in core/contrib (only a few are affected)&lt;/li&gt;
	&lt;li&gt;revert the backwards-branch changes&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;In this case, the input of a Tokenizer stays always a j.io.Reader and the offset correction defaults to just nothing. If a custom Reader extends CharStream, the offset correction is automatically used. This is 100% backwards compatible (only some old Tokenizers not calling correctOffset() before passing to Token/OffsetAttribute would produce invalid offsets if used with CharStreams instead of Readers)&lt;/p&gt;</comment>
                    <comment id="12753713" author="markrmiller@gmail.com" created="Thu, 10 Sep 2009 18:27:18 +0100"  >&lt;p&gt;What about using an introspection cache again? Kind of nasty depending on how soon we could get rid of it.&lt;/p&gt;

&lt;p&gt;Personally, I think I&apos;d prefer a break to a solution that doesnt solve every case.&lt;/p&gt;</comment>
                    <comment id="12753715" author="rcmuir" created="Thu, 10 Sep 2009 18:29:11 +0100"  >&lt;blockquote&gt;&lt;p&gt;(only some old Tokenizers not calling correctOffset() before passing to Token/OffsetAttribute would produce invalid offsets if used with CharStreams instead of Readers)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;but don&apos;t you have this problem already? I like Uwe&apos;s approach.&lt;/p&gt;</comment>
                    <comment id="12753718" author="thetaphi" created="Thu, 10 Sep 2009 18:32:17 +0100"  >&lt;blockquote&gt;&lt;p&gt;What about using an introspection cache again? Kind of nasty depending on how soon we could get rid of it. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;A cache for what? I do not understand &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; The problem is the change of the member field.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;but don&apos;t you have this problem already? I like Uwe&apos;s approach.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Correct, this is always the problem with this change. The offsets are wrong if one legacy Tokenizer does not correct the offset (either through Tokenizer.correctOffset() or CharStream.correctOffset()).&lt;/p&gt;</comment>
                    <comment id="12753720" author="mikemccand" created="Thu, 10 Sep 2009 18:38:40 +0100"  >&lt;blockquote&gt;&lt;p&gt;We also have a not-in-CHANGES.txt backwards break.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Sigh, I forgot to also add an entry to &quot;Changes in back compat policy&quot;&lt;br/&gt;
when we made this change (in &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1466&quot; title=&quot;CharFilter - normalize characters before tokenizer&quot;&gt;&lt;del&gt;LUCENE-1466&lt;/del&gt;&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;We had decided at the time to make an exception to back-compat, ie&lt;br/&gt;
allow reader to become CharStream, but we can definitely revisit&lt;br/&gt;
that...&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;One possibility to prevent this break would be the following&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Adding an instanceof check in every correctOffset call makes me&lt;br/&gt;
nervous &amp;#8211; what&apos;s the performance cost?&lt;/p&gt;</comment>
                    <comment id="12753722" author="rcmuir" created="Thu, 10 Sep 2009 18:39:12 +0100"  >&lt;blockquote&gt;&lt;p&gt;Correct, this is always the problem with this change. The offsets are wrong if one legacy Tokenizer does not correct the offset (either through Tokenizer.correctOffset() or CharStream.correctOffset()).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;right, so your proposed fix would correct this issue (the back compat break), but it doesn&apos;t introduce any new issue.&lt;/p&gt;

&lt;p&gt;if you want to use CharFilter, then your tokenizer must call correctOffset() so the offsets will be correct.&lt;/p&gt;</comment>
                    <comment id="12753724" author="mikemccand" created="Thu, 10 Sep 2009 18:41:41 +0100"  >&lt;blockquote&gt;&lt;p&gt;Correct, this is always the problem with this change. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Right, we should separately fix this (so that all of our core/contrib tokenizers invoke correctOffset).&lt;/p&gt;</comment>
                    <comment id="12753725" author="markrmiller@gmail.com" created="Thu, 10 Sep 2009 18:42:08 +0100"  >&lt;blockquote&gt;&lt;p&gt;A cache for what? I do not understand  The problem is the change of the member field.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Sorry - I meant to say reflection. I mean check if the instance just overrides reset(Reader), and if so, call it with the CharReader from reset(Reader) (and cache the reflection results) - perhaps it gets more complicated though - I havn&apos;t thought on it - just throwing it out. I&apos;ve glossed over the code involved but I&apos;m still at a pretty high level with it, as I trust there is enough people that already know what they are doing in this area. I was never the kid in a group racing to have the math answer first &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Correct, this is always the problem with this change. The offsets are wrong if one legacy Tokenizer does not correct the offset (either through Tokenizer.correctOffset() or CharStream.correctOffset()).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Okay - I took it as - this is 100% backwards compatible, except for this exception where it is not. But if thats always been the case, it is back compat and it sounds fine to me - just got caught up in the wording.&lt;/p&gt;

&lt;p&gt;So if its good, lets ship it! It will take me a bit of time to ensure all the tests and package up, and transfer over again (man does all that maven stuff make transfer take forever - too many little files)&lt;/p&gt;</comment>
                    <comment id="12753727" author="thetaphi" created="Thu, 10 Sep 2009 18:45:00 +0100"  >&lt;p&gt;Here the patch for core. Contrib is unchanged.&lt;/p&gt;

&lt;p&gt;In principle just replace &quot;input.correctOffset(&quot; by &quot;correctOffset(&quot; everywhere. All core tests pass. The backwards branch must simply revert the commit of &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1466&quot; title=&quot;CharFilter - normalize characters before tokenizer&quot;&gt;&lt;del&gt;LUCENE-1466&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                    <comment id="12753733" author="mikemccand" created="Thu, 10 Sep 2009 18:58:54 +0100"  >&lt;p&gt;I&apos;m still nervous about inserting an instanceof check plus a cast in to every correctOffset call (which is called twice per token).&lt;/p&gt;

&lt;p&gt;For external code that accesses Tokenizer.input, a recompile is all that&apos;s required (which 2.9 already requires).  Subclasses that directly assign to input (if any) really should be calling reset instead.  I think breaking back compat here is OK?&lt;/p&gt;</comment>
                    <comment id="12753735" author="thetaphi" created="Thu, 10 Sep 2009 19:02:40 +0100"  >&lt;p&gt;&quot;instanceof&quot; is one of the operators directly implemented in the Java Bytecode as a separate instruction. It is fast and used everywhere. See various articles about it.&lt;/p&gt;</comment>
                    <comment id="12753737" author="rcmuir" created="Thu, 10 Sep 2009 19:06:28 +0100"  >&lt;p&gt;contrib changes.&lt;/p&gt;</comment>
                    <comment id="12753738" author="markrmiller@gmail.com" created="Thu, 10 Sep 2009 19:06:35 +0100"  >&lt;blockquote&gt;&lt;p&gt;I think breaking back compat here is OK?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I won&apos;t comment from a tech perspective, but in regards to this, that was my initial thought as well - if its just a recompile, we are saying 2.9 needs&lt;br/&gt;
to recompile anyway, else you might blow up - essentially is required as it is.&lt;/p&gt;</comment>
                    <comment id="12753742" author="yseeley@gmail.com" created="Thu, 10 Sep 2009 19:13:49 +0100"  >&lt;blockquote&gt;&lt;p&gt;&quot;instanceof&quot; is one of the operators directly implemented in the Java Bytecode as a separate instruction.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;My computer doesn&apos;t run bytecode ;-P&lt;br/&gt;
Yes, it&apos;s relatively fast, but it&apos;s per-token too.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;a recompile is all that&apos;s required (which 2.9 already requires)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Hmmm, I had missed that 2.9 required a recompile.  In that case it doesn&apos;t seem like there is any additional back compat breakage and thus the correct fix would be Uwe&apos;s first patch?&lt;/p&gt;</comment>
                    <comment id="12753746" author="markrmiller@gmail.com" created="Thu, 10 Sep 2009 19:17:26 +0100"  >&lt;blockquote&gt;&lt;p&gt;Hmmm, I had missed that 2.9 required a recompile. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Because it was never officially said one way or another, I was pretty loose about it:&lt;/p&gt;

&lt;p&gt;We recommend that you recompile your application with Lucene 2.9&lt;br/&gt;
rather than attempting to &quot;drop&quot; it in. This will alert you to any&lt;br/&gt;
issues you may have to fix if you are affected by one of the backward&lt;br/&gt;
compatibility breaks. As always, its a really good idea to thoroughly&lt;br/&gt;
read CHANGES.txt before upgrading. Also, remember that this is a&lt;br/&gt;
release candidate, and not the final Lucene 2.9 release.&lt;/p&gt;

&lt;p&gt;I should probably change it to required. I am saying, recompile or be&lt;br/&gt;
prepared for a random break. Thats got to be a euphemism for recompile required.&lt;/p&gt;</comment>
                    <comment id="12753750" author="thetaphi" created="Thu, 10 Sep 2009 19:22:59 +0100"  >&lt;blockquote&gt;&lt;p&gt;Yes, it&apos;s relatively fast, but it&apos;s per-token too.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It is once per token. But you do not need to wrap the input Reader using CharReader if you do not want to use CharFilters. If you wrap each call to Reader by CharReader you have a larger overhead (one additional method call per char read, if you tokenize using Reader.read()!).&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Hmmm, I had missed that 2.9 required a recompile. In that case it doesn&apos;t seem like there is any additional back compat breakage and thus the correct fix would be Uwe&apos;s first patch?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;A recompile is only needed is rare caces (if you override Scorers and so on). If you do not do any very-special Lucene usages, it works without recompiling. In my opinion, e.g. external language Tokenizer-Packages (as Michael Busch calls them) without source code would not work. This example is always brought by Michael.&lt;/p&gt;

&lt;p&gt;If we accept the break, the first patch is all we need to do (and move the CHANGES entry up to the bw-breaks).&lt;/p&gt;</comment>
                    <comment id="12753751" author="markrmiller@gmail.com" created="Thu, 10 Sep 2009 19:26:47 +0100"  >&lt;blockquote&gt;&lt;p&gt;In my opinion, e.g. external language Tokenizer-Packages (as Michael Busch calls them) without source code would not work. This example is always brought by Michael.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Excellent point. Hadn&apos;t seen it before or didn&apos;t remember it.&lt;/p&gt;</comment>
                    <comment id="12753762" author="mikemccand" created="Thu, 10 Sep 2009 19:45:39 +0100"  >&lt;blockquote&gt;&lt;p&gt;A recompile is only needed is rare caces (if you override Scorers and so on&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Or implement Searchable (an interface that we&apos;ve added methods to), or implemented Weight (an interface that we changed to an abstract class), or your own MergePolicy (IndexWriter instance now required to ctor).  I agree these ones are way-expert things.&lt;/p&gt;

&lt;blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;In my opinion, e.g. external language Tokenizer-Packages (as Michael Busch calls them) without source code would not work. This example is always brought by Michael.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Excellent point. Hadn&apos;t seen it before or didn&apos;t remember it.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;OK I agree, this does make me nervous, too.&lt;/p&gt;

&lt;p&gt;OK you&apos;ve convinced me Uwe: I think we should in fact restore input to be a Reader not a CharStream.  I think the potential performance hit is the lesser evil here.&lt;/p&gt;

&lt;p&gt;Maybe for 3.0 we can declare that this will become a CharStream?&lt;/p&gt;</comment>
                    <comment id="12753766" author="thetaphi" created="Thu, 10 Sep 2009 19:52:58 +0100"  >&lt;blockquote&gt;&lt;p&gt;Maybe for 3.0 we can declare that this will become a CharStream?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think the instanceof check is less evil than:&lt;/p&gt;

&lt;blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Yes, it&apos;s relatively fast, but it&apos;s per-token too.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It is once per token. But you do not need to wrap the input Reader using CharReader if you do not want to use CharFilters. If you wrap each call to Reader by CharReader you have a larger overhead (one additional method call per char read, if you tokenize using Reader.read()!).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think we should wait a while and think one night about it. Lets move RC4 to tomorrow morning.&lt;/p&gt;

&lt;p&gt;We have both possibilities, let&apos;s collect arguments +/-&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Excellent point. Hadn&apos;t seen it before or didn&apos;t remember it.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;He brought this up several times in the TokenStream discussion. This is why we mad this very fancy backwards layer that works with many special usages of TokenStreams like subclassing Token and so on (see extra BW Test). Hard stuff &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; And this because of this argument.&lt;/p&gt;</comment>
                    <comment id="12753810" author="thetaphi" created="Thu, 10 Sep 2009 21:47:54 +0100"  >&lt;p&gt;Here the updated patches for trunk (some missing occurences of CharReader-wrapping and so on) and backwards-branch (revert changes).&lt;/p&gt;

&lt;p&gt;The changes also show one posiible problem with current trunk: StandardTokenizer did not call super.reset(stream) which maybe user-provided tokenizers could also fail. Changing of public/protected member fields is a bad idea (and one reason to not have non-final public fields and use get/set methods instead).&lt;/p&gt;

&lt;p&gt;All test pass. Any other thoughts about this? Yonik? Mark? Robert? Mike? &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="12753830" author="rcmuir" created="Thu, 10 Sep 2009 22:35:50 +0100"  >&lt;p&gt;uwe, i like your patch.&lt;/p&gt;

&lt;p&gt;what was that StandardTokenizer setInput (that did not call super.reset) supposed to do ?&lt;/p&gt;</comment>
                    <comment id="12753834" author="thetaphi" created="Thu, 10 Sep 2009 22:42:04 +0100"  >&lt;p&gt;It was never used and seems to be a relict from a time when the jflex file created the tokenizer directly (???). It is package private and used nowhere, so no problem with deleting it. At least it should call reset(Reader) if we leave it there.&lt;/p&gt;</comment>
                    <comment id="12753875" author="markrmiller@gmail.com" created="Thu, 10 Sep 2009 23:49:04 +0100"  >&lt;p&gt;I say we go with it - &apos;instance of&apos; will have no practical effect from what I can tell with any micro benches. That, plus what I&apos;ve read has me not too worried.&lt;/p&gt;

&lt;p&gt;My vote is to go with with you have. We might as well wait till the morning at this point no matter what really - and that will give anyone else an opportunity to chime in.&lt;/p&gt;</comment>
                    <comment id="12753877" author="mikemccand" created="Thu, 10 Sep 2009 23:53:46 +0100"  >&lt;p&gt;Patch looks good Uwe!&lt;/p&gt;</comment>
                    <comment id="12753906" author="koji" created="Fri, 11 Sep 2009 00:56:35 +0100"  >&lt;p&gt;+1, patch looks good, thanks Uwe!&lt;/p&gt;</comment>
                    <comment id="12754017" author="thetaphi" created="Fri, 11 Sep 2009 07:13:21 +0100"  >&lt;p&gt;Some tweaks in JavaDocs. I committed this patch.&lt;/p&gt;</comment>
                    <comment id="12754018" author="thetaphi" created="Fri, 11 Sep 2009 07:15:33 +0100"  >&lt;p&gt;Committed revision: 813671&lt;/p&gt;

&lt;p&gt;There may be some changes needed in Solr (correctOffset in Tokenizer / CharStream-&amp;gt;Reader), should I open an issue?&lt;/p&gt;</comment>
                    <comment id="12754100" author="koji" created="Fri, 11 Sep 2009 12:53:39 +0100"  >&lt;blockquote&gt;&lt;p&gt;There may be some changes needed in Solr (correctOffset in Tokenizer / CharStream-&amp;gt;Reader), should I open an issue?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes, please.&lt;/p&gt;</comment>
                    <comment id="12754101" author="thetaphi" created="Fri, 11 Sep 2009 13:01:42 +0100"  >&lt;p&gt;It seems that Solr compiles with the new JAR files (there is only one compile error not related to this in PatternTokenizerFactory). Tests seem to work. Not tested thoroughly.&lt;/p&gt;

&lt;p&gt;There seem to be no custom analyzers using correctOffset at all in Solr.&lt;/p&gt;</comment>
                    <comment id="12754105" author="thetaphi" created="Fri, 11 Sep 2009 13:12:30 +0100"  >&lt;p&gt;I created an issue (&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-1423&quot; title=&quot;Lucene 2.9 RC4 may need some changes in Solr Analyzers using CharStream &amp;amp; others&quot;&gt;&lt;del&gt;SOLR-1423&lt;/del&gt;&lt;/a&gt;). Maybe there is nothing to do, I am not very familar with Solr. But it should be checked, that all Tokenizers correct their offsets (what some of them do not seem to do).&lt;/p&gt;</comment>
                </comments>
                <issuelinks>
                        <issuelinktype id="10030">
                <name>Reference</name>
                                                <inwardlinks description="is related to">
                            <issuelink>
            <issuekey id="12435422">SOLR-1423</issuekey>
        </issuelink>
                    </inwardlinks>
                            </issuelinktype>
                    </issuelinks>
                <attachments>
                    <attachment id="12419192" name="backwards-break.patch" size="3685" author="thetaphi" created="Thu, 10 Sep 2009 17:40:08 +0100" />
                    <attachment id="12419216" name="LUCENE-1906-bw.patch" size="6104" author="thetaphi" created="Thu, 10 Sep 2009 21:47:54 +0100" />
                    <attachment id="12419202" name="LUCENE-1906_contrib.patch" size="6281" author="rcmuir" created="Thu, 10 Sep 2009 19:06:28 +0100" />
                    <attachment id="12419275" name="LUCENE-1906.patch" size="22833" author="thetaphi" created="Fri, 11 Sep 2009 07:13:21 +0100" />
                    <attachment id="12419215" name="LUCENE-1906.patch" size="16042" author="thetaphi" created="Thu, 10 Sep 2009 21:47:54 +0100" />
                    <attachment id="12419199" name="LUCENE-1906.patch" size="7857" author="thetaphi" created="Thu, 10 Sep 2009 18:45:00 +0100" />
                    <attachment id="12419185" name="LUCENE-1906.patch" size="1914" author="thetaphi" created="Thu, 10 Sep 2009 16:42:09 +0100" />
                </attachments>
            <subtasks>
        </subtasks>
                <customfields>
                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                <customfieldname>Attachment count</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>7.0</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                <customfieldname>Date of First Response</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>Thu, 10 Sep 2009 15:45:30 +0000</customfieldvalue>

                </customfieldvalues>
            </customfield>
                                                                                                        <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Global Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>11861</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                <customfieldname>Lucene Fields</customfieldname>
                <customfieldvalues>
                        <customfieldvalue key="10121"><![CDATA[New]]></customfieldvalue>
    
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>25819</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                <customfieldname>Time in Status</customfieldname>
                <customfieldvalues>
                    
                </customfieldvalues>
            </customfield>
                            </customfields>
    </item>
</channel>
</rss>