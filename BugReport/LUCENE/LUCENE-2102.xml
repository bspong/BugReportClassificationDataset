<!-- 
RSS generated by JIRA (5.2.8#851-sha1:3262fdc28b4bc8b23784e13eadc26a22399f5d88) at Tue Jul 16 13:17:40 UTC 2013

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/LUCENE-2102/LUCENE-2102.xml?field=key&field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>5.2.8</version>
        <build-number>851</build-number>
        <build-date>26-02-2013</build-date>
    </build-info>

<item>
            <title>[LUCENE-2102] LowerCaseFilter for Turkish language</title>
                <link>https://issues.apache.org/jira/browse/LUCENE-2102</link>
                <project id="12310110" key="LUCENE">Lucene - Core</project>
                        <description>&lt;p&gt;java.lang.Character.toLowerCase() converts &apos;I&apos; to &apos;i&apos; however in Turkish alphabet lowercase of &apos;I&apos; is not &apos;i&apos;. It is LATIN SMALL LETTER DOTLESS I.&lt;/p&gt;
</description>
                <environment></environment>
            <key id="12442141">LUCENE-2102</key>
            <summary>LowerCaseFilter for Turkish language</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                    <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png">Closed</status>
                    <resolution id="1">Fixed</resolution>
                                <assignee username="simonw">Simon Willnauer</assignee>
                                <reporter username="iorixxx">Ahmet Arslan</reporter>
                        <labels>
                    </labels>
                <created>Tue, 1 Dec 2009 20:21:47 +0000</created>
                <updated>Fri, 10 May 2013 11:43:50 +0100</updated>
                    <resolved>Sat, 5 Dec 2009 12:47:06 +0000</resolved>
                            <version>3.0</version>
                                <fixVersion>4.0-ALPHA</fixVersion>
                                <component>modules/analysis</component>
                        <due></due>
                    <votes>0</votes>
                        <watches>0</watches>
                                                    <comments>
                    <comment id="12784403" author="iorixxx" created="Tue, 1 Dec 2009 20:29:36 +0000"  >&lt;p&gt;TurkishLowerCaseFilter that lowercases character &apos;I&apos; correctly is added.&lt;/p&gt;</comment>
                    <comment id="12784407" author="rcmuir" created="Tue, 1 Dec 2009 20:39:20 +0000"  >&lt;p&gt;Hi Ahmet, this patch is looking very nice, thank you!&lt;/p&gt;

&lt;p&gt;I have some minor suggestions:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;can we use hex notation (maybe also constants too) for the special case?&lt;/li&gt;
	&lt;li&gt;you can use assertTokenStreamContents here (it is in the base test case) to simplify your test, it works like assertAnalyzesTo but on tokenstream&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I will let others comment on where this belongs (maybe contrib?)&lt;br/&gt;
Wherever it is, I would like to use it in snowball contrib also.&lt;/p&gt;</comment>
                    <comment id="12784410" author="thetaphi" created="Tue, 1 Dec 2009 20:45:35 +0000"  >&lt;p&gt;Looks cool, it even uses the new CharUtils API.&lt;br/&gt;
+1 for using assertTokenStreamContents.&lt;/p&gt;</comment>
                    <comment id="12784414" author="rcmuir" created="Tue, 1 Dec 2009 20:50:49 +0000"  >&lt;p&gt;I have one comment, that this will not work correctly on text that is not NFC. This is because uppercase I with dot can be represented as \u0130 (as you handle it), but also decomposed as \u0049 + \u0307. There can also be stuff in between technically...&lt;/p&gt;

&lt;p&gt;after finding a regular I (\u0049) we could search ahead for COMBINING DOT ABOVE (ignoring any nonspacing marks and format and such along the way), and handle this differently.&lt;/p&gt;

&lt;p&gt;but non-NFC text doesn&apos;t work correctly throughout most of lucene&apos;s analysis components as it is now anyway, so I don&apos;t think we should worry about it right now. Maybe we could add a comment for the future though.&lt;/p&gt;</comment>
                    <comment id="12784418" author="thetaphi" created="Tue, 1 Dec 2009 20:56:44 +0000"  >&lt;p&gt;As this is a new lowercasefilter, shouldn&apos;t be the default matchVersion  completely removed? Other filters have deprecated the no-matchVersion filter and this one also. A new class should not have deprecated parts. -&amp;gt; remove&lt;/p&gt;</comment>
                    <comment id="12784421" author="dmsmith" created="Tue, 1 Dec 2009 21:00:02 +0000"  >&lt;blockquote&gt;&lt;p&gt;but non-NFC text doesn&apos;t work correctly throughout most of lucene&apos;s analysis components as it is now anyway, so I don&apos;t think we should worry about it right now. Maybe we could add a comment for the future though.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It might be good to note the NFC (NFKC?) requirement in the JavaDoc.&lt;/p&gt;

&lt;p&gt;Maybe its just me, but I think it is critical to normalize the input to Lucene for both indexing and searching. Unless a NFCNormalizingFilter is added to Lucene, I think it is the responsibility of the caller.&lt;/p&gt;</comment>
                    <comment id="12784423" author="dmsmith" created="Tue, 1 Dec 2009 21:03:27 +0000"  >&lt;p&gt;For new classes, would it be helpful to add @since to the class JavaDoc?&lt;/p&gt;</comment>
                    <comment id="12784424" author="rcmuir" created="Tue, 1 Dec 2009 21:03:39 +0000"  >&lt;blockquote&gt;&lt;p&gt;Maybe its just me, but I think it is critical to normalize the input to Lucene for both indexing and searching. Unless a NFCNormalizingFilter is added to Lucene, I think it is the responsibility of the caller.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;yeah I think its critical too.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;It might be good to note the NFC (NFKC?) requirement in the JavaDoc. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;yeah or maybe just a hint in the comments (because this is an exceptionally tricky case). &lt;br/&gt;
this same problem also applies to ASCIIFoldingFilter, pretty much all of the analyzers, etc too...&lt;/p&gt;</comment>
                    <comment id="12784428" author="rcmuir" created="Tue, 1 Dec 2009 21:07:25 +0000"  >&lt;blockquote&gt;&lt;p&gt;Unless a NFCNormalizingFilter is added to Lucene, I think it is the responsibility of the caller.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;btw DM, if you are interested, I inserted a long discussion about unicode normalization and how it interacts with Lucene tokenstreams in general in the javadoc header of ICUNormalizationFilter for &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1488&quot; title=&quot;multilingual analyzer based on icu&quot;&gt;&lt;del&gt;LUCENE-1488&lt;/del&gt;&lt;/a&gt;. (please comment over there if you have suggestions or thoughts on it)&lt;/p&gt;</comment>
                    <comment id="12784437" author="simonw" created="Tue, 1 Dec 2009 21:20:29 +0000"  >&lt;p&gt;There is no need to use CharacterUtils in here. You can use Character.codePointAt() directly. This is a new class and does not need to preserve any bw. compatibility. I agree with uwe, the Version should go away in this patch.&lt;/p&gt;

&lt;p&gt;Once more thing, this patch seems to be in core. I do not see any reason why this should be in core though. We should move it to contrib though as it serves such a specific usecase.&lt;/p&gt;
</comment>
                    <comment id="12784438" author="rcmuir" created="Tue, 1 Dec 2009 21:22:47 +0000"  >&lt;p&gt;Simon, I would rather see this in contrib also. &lt;/p&gt;

&lt;p&gt;Would there be opposition to making contrib/snowball depend upon contrib/analyzers so the SnowballAnalyzer can use this filter instead of lowercase filter for the Turkish case? (based upon Version, of course)?&lt;/p&gt;</comment>
                    <comment id="12784445" author="simonw" created="Tue, 1 Dec 2009 21:29:36 +0000"  >&lt;blockquote&gt;&lt;p&gt;Would there be opposition to making contrib/snowball depend upon contrib/analyzers so the SnowballAnalyzer can use this filter instead of lowercase filter for the Turkish case? (based upon Version, of course)?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;i think we can arrange something like that. Since we factored out Smart-cn the jar has reasonable size so this won&apos;t be an issue. maybe we should think about moving snowball into analyzers/snowball - just an idea.&lt;br/&gt;
Anyway, this is somewhat unrelated to this particular patch but still considerable.&lt;/p&gt;</comment>
                    <comment id="12784447" author="rcmuir" created="Tue, 1 Dec 2009 21:33:08 +0000"  >&lt;p&gt;I don&apos;t think its really unrelated, I think its a consideration towards where we put this.&lt;/p&gt;

&lt;p&gt;The turkish analyzer happens to be in contrib/snowball, and thats what really needs this for turkish search. (Although I agree this filter could be useful on its own)&lt;/p&gt;</comment>
                    <comment id="12784461" author="iorixxx" created="Tue, 1 Dec 2009 21:56:57 +0000"  >&lt;p&gt;assertTokenStreamContents, @since and hex constants are added.&lt;br/&gt;
deprecated constructor is removed.&lt;/p&gt;</comment>
                    <comment id="12784467" author="rcmuir" created="Tue, 1 Dec 2009 22:06:43 +0000"  >&lt;p&gt;Ahmet, hi I think you might have accidentally left the old (duplicate) test in there that does not use assertTokenStreamContents?&lt;/p&gt;</comment>
                    <comment id="12784469" author="iorixxx" created="Tue, 1 Dec 2009 22:10:26 +0000"  >&lt;p&gt;I kept the old test method and added a new one. Should i remove old one?&lt;/p&gt;</comment>
                    <comment id="12784471" author="rcmuir" created="Tue, 1 Dec 2009 22:16:17 +0000"  >&lt;p&gt;Ahmet, I think so. they both test the same functionality, but the second test is less code, and in my opinion, better. assertTokenStreamContents does some additional checks, it clears attributes in between, it calls .end(), things like that.&lt;/p&gt;</comment>
                    <comment id="12784472" author="thetaphi" created="Tue, 1 Dec 2009 22:18:05 +0000"  >&lt;p&gt;One othe possibility to resolve the problem in a completely different way: You could wrap a MappingCharFilter on top of the input reader in Analyzer and just add a replacement for this one char:&lt;br/&gt;
&lt;a href=&quot;http://lucene.apache.org/java/3_0_0/api/all/org/apache/lucene/analysis/MappingCharFilter.html&quot; class=&quot;external-link&quot;&gt;http://lucene.apache.org/java/3_0_0/api/all/org/apache/lucene/analysis/MappingCharFilter.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This would be a very easy fix without code duplication. You just change the input before tokenization. And its already in Lucene core, just plug it into the analyzer&apos;s tokenStream() or reusableTokenStream() method as a wrapper around the Reader param.&lt;/p&gt;

&lt;p&gt;This would be very easy also for the other analyzers having problem with seldom chars. It can also be used to remove chars at all or replace them by longer sequences like &#228; -&amp;gt; ae (for german).&lt;/p&gt;</comment>
                    <comment id="12784474" author="iorixxx" created="Tue, 1 Dec 2009 22:18:57 +0000"  >&lt;p&gt;test that does not use assertTokenStreamContents is removed.&lt;/p&gt;</comment>
                    <comment id="12784476" author="rcmuir" created="Tue, 1 Dec 2009 22:22:31 +0000"  >&lt;blockquote&gt;&lt;p&gt;One othe possibility to resolve the problem in a completely different way: You could wrap a MappingCharFilter on top of the input reader in Analyzer and just add a replacement for this one char:&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Uwe, but this is inflexible. If we want to make this filter support turkish lowercasing in the future for all of unicode, not just NFC composed form, we cannot do it with MappingCharFilter. Again I don&apos;t think we should fix this now, but in the future I think we might want to. &lt;/p&gt;</comment>
                    <comment id="12784478" author="thetaphi" created="Tue, 1 Dec 2009 22:27:15 +0000"  >&lt;p&gt;The patch&apos;s TurkishLowerCaseFilter is as unflexible as that. The idea is just a replacement for the current patch (and it is even a little bit more universal, because you can change the chars to map).&lt;/p&gt;</comment>
                    <comment id="12784479" author="rcmuir" created="Tue, 1 Dec 2009 22:28:00 +0000"  >&lt;blockquote&gt;&lt;p&gt;test that does not use assertTokenStreamContents is removed. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Thanks Ahmet, in my opinion this is good, we just have to figure out where to place it. &lt;/p&gt;

&lt;p&gt;My vote is for contrib/analyzers/common/tr for now.&lt;/p&gt;</comment>
                    <comment id="12784480" author="rcmuir" created="Tue, 1 Dec 2009 22:29:39 +0000"  >&lt;blockquote&gt;&lt;p&gt;The patch&apos;s TurkishLowerCaseFilter is as unflexible as that. The idea is just a replacement for the current patch (and it is even a little bit more universal, because you can change the chars to map).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Uwe this is not true. With a tokenfilter, I can use Version that will apply the logic i mentioned above:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;after finding a regular I (\u0049) we could search ahead for COMBINING DOT ABOVE (ignoring any nonspacing marks and format and such along the way), and handle this differently.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;you cannot do this with mappingchar filter, or rather, you could, but there would be millions of mappings for this one character. I could later patch this filter with Version and some lookahead based on unicode properties if i wanted to improve it.&lt;/p&gt;</comment>
                    <comment id="12784483" author="thetaphi" created="Tue, 1 Dec 2009 22:34:07 +0000"  >&lt;p&gt;if I replace this code from Ahmet&apos;s test&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; class TestTurkishLowerCaseFilter &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; BaseTokenStreamTestCase {

  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void testTurkishLowerCaseFilter() &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; Exception {
    TokenStream stream = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; WhitespaceTokenizer(
        &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; StringReader(&lt;span class=&quot;code-quote&quot;&gt;&quot;\u0130STANBUL \u0130ZM\u0130R ISPARTA&quot;&lt;/span&gt;));
    TokenStream filter = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; TurkishLowerCaseFilter(Version.LUCENE_30, stream);
	assertTokenStreamContents(filter, &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;[] {&lt;span class=&quot;code-quote&quot;&gt;&quot;istanbul&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;izmir&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;\u0131sparta&quot;&lt;/span&gt;,});      
  }

}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;by that, there is not even a new class or anything needed:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; class TestTurkishLowerCaseFilter &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; BaseTokenStreamTestCase {

  &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; NormalizeCharMap map = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; NormalizeCharMap();
  &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; {
   map.add(&lt;span class=&quot;code-quote&quot;&gt;&quot;\u0049&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;0x0131&quot;&lt;/span&gt;);
  }

  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void testTurkishLowerCaseFilter() &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; Exception {
    TokenStream stream = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; WhitespaceTokenizer(
        &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; MappingCharFilter(map,
        &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; StringReader(&lt;span class=&quot;code-quote&quot;&gt;&quot;\u0130STANBUL \u0130ZM\u0130R ISPARTA&quot;&lt;/span&gt;)));
    TokenStream filter = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; LowerCaseFilter(Version.LUCENE_30, stream);
	assertTokenStreamContents(filter, &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;[] {&lt;span class=&quot;code-quote&quot;&gt;&quot;istanbul&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;izmir&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;\u0131sparta&quot;&lt;/span&gt;,});      
  }

}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It just works.&lt;/p&gt;</comment>
                    <comment id="12784485" author="rcmuir" created="Tue, 1 Dec 2009 22:37:43 +0000"  >&lt;p&gt;Uwe I don&apos;t think you understand what I am saying.&lt;/p&gt;

&lt;p&gt;if my text is instead I&#775;STANBUL versus your &#304;STANBUL, it will not work.&lt;/p&gt;</comment>
                    <comment id="12784487" author="thetaphi" created="Tue, 1 Dec 2009 22:39:27 +0000"  >&lt;blockquote&gt;&lt;p&gt;Uwe this is not true. With a tokenfilter, I can use Version that will apply the logic i mentioned above&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I am talking about &lt;b&gt;this&lt;/b&gt; patch. Not any later version! I suggest to not apply this patch at all and for now tell the user to use above helper construct until we have ICU in core or whatever (sorry for the missing  \u, I do not want to edit again...)&lt;/p&gt;</comment>
                    <comment id="12784489" author="rcmuir" created="Tue, 1 Dec 2009 22:41:39 +0000"  >&lt;p&gt;Uwe, I am talking about this patch too. it is simple and can be extended to the future to handle such things.&lt;br/&gt;
your mappingcharfilter approach cannot, and I don&apos;t see us having ICU in core ever, even though I would love such a thing.&lt;/p&gt;

&lt;p&gt;Additionally, it will make it easier to fix SnowballAnalyzer, which is currently &lt;b&gt;broken for turkish language&lt;/b&gt; because it uses the wrong lowercase.&lt;/p&gt;</comment>
                    <comment id="12784496" author="thetaphi" created="Tue, 1 Dec 2009 22:51:58 +0000"  >&lt;p&gt;Robert: I understand your problem, but it affects LowerCaseFilter at all and is not special to the Turkish lower filter. If you have decomposed characters even LowerCaseFilter would fail for &lt;b&gt;all&lt;/b&gt; languages (even German if you compose &#228; out of a and two dots). In germany really nobody uses de-composed chars, I do not know how this is in Turkey, but the last time I was there, they just used the simpliest composed chars (like germans), they even have the umlauts which they use from the basic latin1 range. And for that this filter works and is a quick fix.&lt;/p&gt;

&lt;p&gt;But I give up now.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;EDIT&lt;/b&gt; Good night, I cannot hack my keys anymore &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; Sorry for heavy issue editing.&lt;/p&gt;</comment>
                    <comment id="12784499" author="rcmuir" created="Tue, 1 Dec 2009 22:56:45 +0000"  >&lt;p&gt;Uwe, it &lt;b&gt;is&lt;/b&gt; specific to the turkish case.&lt;br/&gt;
because for german, whether you have A, umlaut or A+umlaut as one character, it works regardless.&lt;br/&gt;
turkish is the only case where its more complex, because the casing of the character actually depends upon a diacritic that may not be composed, and may have other diacritics in between.&lt;/p&gt;

&lt;p&gt;this is what makes it such a bear to support in case folding:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;#      Note that the Turkic mappings do not maintain canonical equivalence without additional processing.
#      See the discussions of case mapping in the Unicode Standard for more information.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The problem is that context is required, and sometimes marks must actually be deleted for proper casing.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;# When lowercasing, remove dot_above in the sequence I + dot_above, which will turn into i.
# This matches the behavior of the canonically equivalent I-dot_above

0307; ; 0307; 0307; tr After_I; # COMBINING DOT ABOVE
0307; ; 0307; 0307; az After_I; # COMBINING DOT ABOVE

# When lowercasing, unless an I is before a dot_above, it turns into a dotless i.

0049; 0131; 0049; 0049; tr Not_Before_Dot; # LATIN CAPITAL LETTER I
0049; 0131; 0049; 0049; az Not_Before_Dot; # LATIN CAPITAL LETTER I
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;&lt;p&gt;but the last time I was there, they just used the simpliest composed chars (like germans).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This is why i recommended we not go crazy and only work on the composed form. But in the future we might want to correct this.&lt;br/&gt;
this is &lt;b&gt;impossible&lt;/b&gt; to do with mappingcharfilter, that is my only point.&lt;/p&gt;</comment>
                    <comment id="12784567" author="rcmuir" created="Wed, 2 Dec 2009 00:32:21 +0000"  >&lt;p&gt;attached is a slight modification, to support proper lowercasing for decomposed forms as well.&lt;br/&gt;
when an uppercase I is encountered, some lookahead is necessary (as long as characters are nonspacing marks they can be in between), to see if there is later a COMBINING_DOT_ABOVE.&lt;/p&gt;

&lt;p&gt;in this case, the uppercase I must be lowercased to a regular &apos;i&apos;, and this COMBINING_DOT_ABOVE later removed.&lt;/p&gt;</comment>
                    <comment id="12784570" author="rcmuir" created="Wed, 2 Dec 2009 00:42:58 +0000"  >&lt;p&gt;Hi Uwe, now are you ok with this being a TokenFilter? &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;Can we discuss where to put it, maybe contrib/analyzers under &quot;tr&quot; ?&lt;/p&gt;</comment>
                    <comment id="12784667" author="thetaphi" created="Wed, 2 Dec 2009 06:57:05 +0000"  >&lt;p&gt;Robert: Looks crazy but seems to work, great work! Small comments about the patch:&lt;br/&gt;
The int codepoint constants should be &lt;b&gt;static&lt;/b&gt; final not just final, termAtt should also be final &lt;span class=&quot;error&quot;&gt;&amp;#91;and optionally can be initialized directly in the declaration which I prefer, but that&amp;#39;s your turn&amp;#93;&lt;/span&gt;. In the test, the Version.LUCENE_CURRENT should be used (which has no effect on the tests, but maybe in future).&lt;/p&gt;</comment>
                    <comment id="12784673" author="rcmuir" created="Wed, 2 Dec 2009 07:08:30 +0000"  >&lt;p&gt;Uwe, it is kinda crazy. but I think worth the effort not to have such wierd behavior.&lt;/p&gt;

&lt;p&gt;I didn&apos;t optimize it yet in general either. In reality, on composed text this should not slow you down.&lt;br/&gt;
it should be one additional getType() check after any uppercase &quot;I&quot;. (its 2 right now, I will fix)&lt;br/&gt;
I&apos;ll also add in your suggestions (and move the patch to contrib/analyzers/tr for now), and upload a new patch.&lt;/p&gt;
</comment>
                    <comment id="12784685" author="rcmuir" created="Wed, 2 Dec 2009 07:31:03 +0000"  >&lt;p&gt;updated patch for contrib, with optimization i mentioned earlier, some cleanups from Uwe, and some more docs.&lt;/p&gt;</comment>
                    <comment id="12784690" author="rcmuir" created="Wed, 2 Dec 2009 07:43:08 +0000"  >&lt;p&gt;Sorry, new patch, forgot to change tests to LUCENE_CURRENT as Uwe mentioned.&lt;/p&gt;</comment>
                    <comment id="12784738" author="simonw" created="Wed, 2 Dec 2009 09:40:18 +0000"  >&lt;p&gt;Maybe I miss something but what is the reason to use Version in here. This is new code and it does not have to maintain any bw compatibility. There is also no need to use CharacterUtils you can use Character directly, can&apos;t you?!&lt;/p&gt;
</comment>
                    <comment id="12784743" author="thetaphi" created="Wed, 2 Dec 2009 09:49:19 +0000"  >&lt;p&gt;We should use version from the beginning of new tokenfilters to be prepared for the future. In this case the version could be ignored until we have a new version of this filter. But to be consistent with LowerCaseFilter I would prefer to also use the matchVersion to select the right utils class.&lt;/p&gt;</comment>
                    <comment id="12784748" author="simonw" created="Wed, 2 Dec 2009 10:04:00 +0000"  >&lt;blockquote&gt;&lt;p&gt;But to be consistent with LowerCaseFilter I would prefer to also use the matchVersion to select the right utils class.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I agree with the consistency ctor but I don&apos;t with the CharacterUtils. I do not see why a new class should yield buggy behavior in any case. If somebody uses Version &amp;lt; 3.1 this filter will not work correctly. We should prevent this in any case, another possibility would be enforcing a version &amp;gt;=3.1&lt;br/&gt;
Then I would be ok with it.&lt;/p&gt;</comment>
                    <comment id="12784750" author="simonw" created="Wed, 2 Dec 2009 10:13:02 +0000"  >&lt;p&gt;I think we should have a consistent behaviour for new classes taking version. It would make sense to have a method in Version like:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;enum&lt;/span&gt; Version {
...
 &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void ensureOnOrAfter(Version other){
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt;(!onOrAfter(other))
      &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; IllegalArgumentException(&lt;span class=&quot;code-quote&quot;&gt;&quot;Version &amp;lt; &quot;&lt;/span&gt; +&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.name() + &lt;span class=&quot;code-quote&quot;&gt;&quot; are not supported&quot;&lt;/span&gt;);
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;That enforces the version for new classes. This would also help to get rid of old behaviour in 4.0&lt;br/&gt;
We should open another issue for this I guess. I see many usecases where this could be very useful.&lt;/p&gt;

</comment>
                    <comment id="12784875" author="rcmuir" created="Wed, 2 Dec 2009 15:26:01 +0000"  >&lt;blockquote&gt;&lt;p&gt;If somebody uses Version &amp;lt; 3.1 this filter will not work correctly. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Simon, all the tests pass with Version &amp;lt; 3.1 (I tried LUCENE_20). So its just consistency with the other code.&lt;br/&gt;
I think we should do the same in general, just my opinion.&lt;/p&gt;

&lt;p&gt;For example, if I write a new analyzer in 3.1, I&apos;m just gonna take Version and pass it to my components.&lt;br/&gt;
Its true I do not even need Version. Maybe by 3.2 comes out there is only 1 thing affected by Version.&lt;br/&gt;
And yes, if its based on StandardTokenizer someone can set version LUCENE_24 and it will parse acronyms in an invalid way,&lt;br/&gt;
even though the analyzer wasn&apos;t around at the time of Lucene 2.4&lt;/p&gt;

&lt;p&gt;But this is easy and consistent, to just pass along version, we already do this in other places, I think its not worth changing.&lt;/p&gt;</comment>
                    <comment id="12784907" author="simonw" created="Wed, 2 Dec 2009 17:22:42 +0000"  >&lt;p&gt;Robert, I see your point. The root cause why this bugs me is that this TokenFilter changes his behavior (at least if you index deseret with this analyzer) &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; depending on the passed version. I don&apos;t think that new code should try do anything based on version. The Version ctor it totally ok for me in this case but we should really use Integer.CodePointAt() instead of CharacterUtil. Once I think about the mess ensureOnOrAfter would create throughout all the code I doubt it would to any good in the end.&lt;/p&gt;
</comment>
                    <comment id="12784926" author="rcmuir" created="Wed, 2 Dec 2009 17:34:36 +0000"  >&lt;blockquote&gt;&lt;p&gt;I don&apos;t think that new code should try do anything based on version.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;ok, I will change this. You are right, I would look at this problem differently if we didnt have CharacterUtil which makes it just so easy to support the old and new behavior.&lt;/p&gt;</comment>
                    <comment id="12784928" author="simonw" created="Wed, 2 Dec 2009 17:44:24 +0000"  >&lt;blockquote&gt;&lt;p&gt;ok, I will change this. You are right, I would look at this problem differently if we didnt have CharacterUtil which makes it just so easy to support the old and new behavior.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Actually, a unused Version argument is silly. If we have to add it in the future because of some change, you WANT to deprecate the ctor to make users aware of it. that is what deprecations are made for. I would not argue about consistency as not every TokenFilter has a Version ctor. (EdgeNGramTokenFilter for instance - this is just first coming to my mind). I would remove it completely! Use Character.codePointAt() and you are good to go.&lt;/p&gt;
</comment>
                    <comment id="12784930" author="rcmuir" created="Wed, 2 Dec 2009 17:46:05 +0000"  >&lt;p&gt;patch with Simon&apos;s suggestions.&lt;/p&gt;</comment>
                    <comment id="12784944" author="simonw" created="Wed, 2 Dec 2009 18:24:34 +0000"  >&lt;p&gt;Robert, this patch looks good! &lt;br/&gt;
Much cleaner now - version is not appropriate here!&lt;/p&gt;

&lt;p&gt;Thanks for updating.&lt;/p&gt;</comment>
                    <comment id="12784951" author="rcmuir" created="Wed, 2 Dec 2009 18:40:36 +0000"  >&lt;p&gt;trivial update with comment for the test and better example explaining what this is all about.&lt;/p&gt;</comment>
                    <comment id="12784956" author="simonw" created="Wed, 2 Dec 2009 18:48:35 +0000"  >&lt;p&gt;I will take over for Robert - go ahead and get automation done robert!&lt;/p&gt;</comment>
                    <comment id="12785253" author="simonw" created="Thu, 3 Dec 2009 10:31:38 +0000"  >&lt;p&gt;I plan to commit the latest patch until 12/06/09 if nobody objects.&lt;/p&gt;</comment>
                    <comment id="12785379" author="rcmuir" created="Thu, 3 Dec 2009 16:14:16 +0000"  >&lt;p&gt;Hello Simon, if this issue is resolved (so we do not forget), can we open a separate issue to fix the SnowballAnalyzer when using Turkish language?&lt;br/&gt;
I also think we should add some javadocs to the snowball stem filter that explain you need to use this filter beforehand for it to work.&lt;/p&gt;

&lt;p&gt;I already have some unit tests produced showing it doesn&apos;t work correctly with LowerCaseFilter and that it also does not handle uppercase.&lt;/p&gt;</comment>
                    <comment id="12786246" author="simonw" created="Fri, 4 Dec 2009 23:42:58 +0000"  >&lt;p&gt;I will commit this tomorrow if nobody objects.&lt;/p&gt;</comment>
                    <comment id="12786399" author="simonw" created="Sat, 5 Dec 2009 12:47:06 +0000"  >&lt;p&gt;Committed in revision 887535&lt;/p&gt;

&lt;p&gt;Thanks Ahmet / Robert!&lt;/p&gt;</comment>
                </comments>
                <issuelinks>
                        <issuelinktype id="10001">
                <name>dependent</name>
                                                <inwardlinks description="is depended upon by">
                            <issuelink>
            <issuekey id="12442546">LUCENE-2117</issuekey>
        </issuelink>
                    </inwardlinks>
                            </issuelinktype>
                    </issuelinks>
                <attachments>
                    <attachment id="12426693" name="LUCENE-2102.patch" size="10208" author="rcmuir" created="Wed, 2 Dec 2009 18:40:36 +0000" />
                    <attachment id="12426687" name="LUCENE-2102.patch" size="10076" author="rcmuir" created="Wed, 2 Dec 2009 17:46:05 +0000" />
                    <attachment id="12426640" name="LUCENE-2102.patch" size="10714" author="rcmuir" created="Wed, 2 Dec 2009 07:43:08 +0000" />
                    <attachment id="12426638" name="LUCENE-2102.patch" size="10641" author="rcmuir" created="Wed, 2 Dec 2009 07:31:03 +0000" />
                    <attachment id="12426605" name="LUCENE-2102.patch" size="7547" author="rcmuir" created="Wed, 2 Dec 2009 00:32:21 +0000" />
                    <attachment id="12426588" name="LUCENE-2102.patch" size="4799" author="iorixxx" created="Tue, 1 Dec 2009 22:18:57 +0000" />
                    <attachment id="12426583" name="LUCENE-2102.patch" size="5466" author="iorixxx" created="Tue, 1 Dec 2009 21:56:57 +0000" />
                    <attachment id="12426577" name="LUCENE-2102.patch" size="5093" author="iorixxx" created="Tue, 1 Dec 2009 20:29:35 +0000" />
                </attachments>
            <subtasks>
        </subtasks>
                <customfields>
                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                <customfieldname>Attachment count</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>8.0</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                <customfieldname>Date of First Response</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>Tue, 1 Dec 2009 20:39:20 +0000</customfieldvalue>

                </customfieldvalues>
            </customfield>
                                                                                                        <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Global Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>11677</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                <customfieldname>Lucene Fields</customfieldname>
                <customfieldvalues>
                        <customfieldvalue key="10121"><![CDATA[New]]></customfieldvalue>
    <customfieldvalue key="10120"><![CDATA[Patch Available]]></customfieldvalue>
    
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>25623</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                <customfieldname>Time in Status</customfieldname>
                <customfieldvalues>
                    
                </customfieldvalues>
            </customfield>
                            </customfields>
    </item>
</channel>
</rss>