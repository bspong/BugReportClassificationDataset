<!-- 
RSS generated by JIRA (5.2.8#851-sha1:3262fdc28b4bc8b23784e13eadc26a22399f5d88) at Tue Jul 16 13:31:44 UTC 2013

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/LUCENE-2958/LUCENE-2958.xml?field=key&field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>5.2.8</version>
        <build-number>851</build-number>
        <build-date>26-02-2013</build-date>
    </build-info>

<item>
            <title>[LUCENE-2958] WriteLineDocTask improvements</title>
                <link>https://issues.apache.org/jira/browse/LUCENE-2958</link>
                <project id="12310110" key="LUCENE">Lucene - Core</project>
                        <description>&lt;p&gt;Make WriteLineDocTask and LineDocSource more flexible/extendable:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;allow to emit lines also for empty docs (keep current behavior as default)&lt;/li&gt;
	&lt;li&gt;allow more/less/other fields&lt;/li&gt;
&lt;/ul&gt;
</description>
                <environment></environment>
            <key id="12501004">LUCENE-2958</key>
            <summary>WriteLineDocTask improvements</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                    <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png">Closed</status>
                    <resolution id="1">Fixed</resolution>
                                <assignee username="doronc">Doron Cohen</assignee>
                                <reporter username="doronc">Doron Cohen</reporter>
                        <labels>
                    </labels>
                <created>Thu, 10 Mar 2011 10:40:29 +0000</created>
                <updated>Fri, 3 Jun 2011 17:37:15 +0100</updated>
                    <resolved>Mon, 21 Mar 2011 15:34:46 +0000</resolved>
                                            <fixVersion>3.2</fixVersion>
                <fixVersion>4.0-ALPHA</fixVersion>
                                <component>modules/benchmark</component>
                        <due></due>
                    <votes>0</votes>
                        <watches>0</watches>
                                                    <comments>
                    <comment id="13005028" author="doronc" created="Thu, 10 Mar 2011 10:47:55 +0000"  >&lt;p&gt;Attached patch modifies LineDocSource and WriteLineDocTask to allow the described extensions. &lt;/p&gt;

&lt;p&gt;By default there are no modifications and behavior is as before.&lt;/p&gt;</comment>
                    <comment id="13005054" author="doronc" created="Thu, 10 Mar 2011 13:31:08 +0000"  >&lt;p&gt;Updated patch (for 3x):&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;from 3x root (previous patch was from benchmark by mistake)&lt;/li&gt;
	&lt;li&gt;fixed typos in javadoc&lt;/li&gt;
	&lt;li&gt;simplified loop over the fields in WriteLineDocTask&lt;/li&gt;
	&lt;li&gt;removed &lt;b&gt;volatile&lt;/b&gt; but added &lt;b&gt;final&lt;/b&gt; for &lt;b&gt;fields/ToWrite&lt;/b&gt;.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Without volatile one test was failing: TestPerfTasksLogic.testParallelDocMaker() but then I was unable to fail it again even after removing volatile. &lt;/p&gt;

&lt;p&gt;Once marking these fields &lt;b&gt;final&lt;/b&gt; definitely volatile is not required.&lt;/p&gt;

&lt;p&gt;But I don&apos;t understand why was it needed in the first place - ParallelTask in TaskSequence clones the tasks, and since WriteLineDocTask does not implement clone() all (parallel) tasks will have a reference to same array... which in fact can be copied into a local copy by the JVM for efficiency.. but since the clone must take place only after the constructor is done, the array is initialized already... If I could fail this again I would investigate it but now it always passes even without final/volatile. &lt;/p&gt;

&lt;p&gt;So keeping the final, as this is safe, but I don&apos;t like the voodooism of it and if anyone has a better explanation it would be appreciated.&lt;/p&gt;</comment>
                    <comment id="13005169" author="mikemccand" created="Thu, 10 Mar 2011 17:13:27 +0000"  >&lt;p&gt;It&apos;s great to make line file docs more extensible!  Maybe, we should&lt;br/&gt;
put the field names as a header line?  Then the source can get the&lt;br/&gt;
field names from there?&lt;/p&gt;

&lt;p&gt;feilds is mis-spelled&lt;/p&gt;

&lt;p&gt;The cutover to splitting by regex (vs prior split-by-char) makes me&lt;br/&gt;
nervous.  Have you tested perf hit?  Or, can we go back to just using&lt;br/&gt;
a char sep?  We also make a String[] when we didn&apos;t before.  If we&lt;br/&gt;
really want to stick w/ regex then we should at least pre-compile to&lt;br/&gt;
a Pattern then use the split method on that?&lt;/p&gt;</comment>
                    <comment id="13005190" author="doronc" created="Thu, 10 Mar 2011 17:33:47 +0000"  >&lt;p&gt;Thanks for reviewing Mike!&lt;/p&gt;

&lt;p&gt;No I didn&apos;t perf the perf task change.. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; I will look at this again. &lt;/p&gt;

&lt;p&gt;Nice catch about the feild name.&lt;/p&gt;

&lt;p&gt;As for putting the field names in the file - let&apos;s see how this would work&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;We need a matching pair: LineDocWriter and LineDocSource, both should expect the same fields in same order/&lt;/li&gt;
	&lt;li&gt;In addition, DocData has some fixed field names: ID, Body, Name, Date, Title, and a flexible Properties which can include anything else.&lt;/li&gt;
	&lt;li&gt;If we move to put the field names in the header line as you suggest, that would make a single line-doc-source for any lineDocWriter which is nice.&lt;/li&gt;
	&lt;li&gt;It would require to modify DocData so that all fields would be maintained in props )except for ID which would be still mandatory).&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I like it, except perhaps for performance... &lt;br/&gt;
What do you think? Is this what you have in mind?&lt;/p&gt;</comment>
                    <comment id="13005218" author="mikemccand" created="Thu, 10 Mar 2011 18:14:33 +0000"  >&lt;p&gt;That&apos;s exactly what I had in mind!&lt;/p&gt;

&lt;p&gt;I think for LineDocWriter we&apos;d have to tell it up front what fields (in what order) it should write.&lt;/p&gt;

&lt;p&gt;But then LineDocSource should be generic... though we&apos;d still have to set up the Fields properly for indexing (ie some are stored, some are not tokenized, etc.).&lt;/p&gt;</comment>
                    <comment id="13005259" author="shaie" created="Thu, 10 Mar 2011 19:11:07 +0000"  >&lt;blockquote&gt;&lt;p&gt;though we&apos;d still have to set up the Fields properly for indexing (ie some are stored, some are not tokenized, etc.)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don&apos;t think that matters? I.e., LineDocSource returns DocData, it&apos;s the DocMaker which creates the actual Lucene Field and Document instances. So all LDS needs to know is the name of the field.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;If we really want to stick w/ regex then we should at least pre-compile to a Pattern then use the split method on that?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I agree. String.split compiles a Pattern inside, so we&apos;d better pre-compile that pattern once, and then you pattern.split().&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Or, can we go back to just using a char sep? We also make a String[] when we didn&apos;t before.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That&apos;s a good point Mike. But the alternative (splitting on char &apos;the old way&apos;) is not any better either, because you don&apos;t know in advance how many fields you expect, so you&apos;d have to create a List or something to store them.&lt;/p&gt;

&lt;p&gt;I guess what we should be considering is super-duper optimized code vs. a nice readable one. String.split[] is easily understood, keeps the code compact and clear. Searching for SEP (the old code) is more complicated, especially when you want to handle a general case. We&apos;ll be searching for SEP both ways, so the only difference is whether an array is allocated or not.&lt;/p&gt;

&lt;p&gt;Maybe instead of doing the split ourselves, we can have a getDocData(String line), which will be implemented by default to search for TITLE, DATE and BODY, using the optimized code, and can be overridden by others to parse line differently? That way we don&apos;t impose any specific splitting behavior on everyone, but we lose the potential generality of LineDocSource.&lt;/p&gt;

&lt;p&gt;Is that array alloc() really critical?&lt;/p&gt;

&lt;p&gt;About writing the field names in the file &amp;#8211; that&apos;s a nice idea, but complicates DocData. We&apos;d need to change it to store a Map&amp;lt;String,String&amp;gt; (or Properties) of name-value pairs. That will affect the performance of creating DocData, as well as constructing a Document out of it.&lt;/p&gt;

&lt;p&gt;If we&apos;re willing to sacrifice some optimization here, we can do nice things. But if we want to insist on having the most optimized code, I don&apos;t think we can do much ... probably the best option is to have WLDT and LDS optimized for what they are today, and let users extend to write/read more fields. We can pass them the &apos;line&apos; and let them split it however they want.&lt;/p&gt;</comment>
                    <comment id="13005286" author="mikemccand" created="Thu, 10 Mar 2011 19:47:51 +0000"  >&lt;blockquote&gt;&lt;p&gt;I don&apos;t think that matters? I.e., LineDocSource returns DocData, it&apos;s the DocMaker which creates the actual Lucene Field and Document instances. So all LDS needs to know is the name of the field.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;OK, that&apos;s nice.  So a simple string&amp;lt;SEP&amp;gt;string&amp;lt;SEP&amp;gt;... header could define the field names.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Is that array alloc() really critical?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Probably fairly minor, but, this is a death-by-a-thousand-cuts situation?  Ie, these changes only make our index throughput tests slower; hopefully by a tiny amount, but it&apos;ll add up over time.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Maybe instead of doing the split ourselves, we can have a getDocData(String line), which will be implemented by default to search for TITLE, DATE and BODY, using the optimized code, and can be overridden by others to parse line differently?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think that&apos;s good?&lt;/p&gt;

&lt;p&gt;Or, if we do the header idea... then a given usage need not override getDocData?  Like it&apos;s generic at that point?&lt;/p&gt;</comment>
                    <comment id="13005502" author="shaie" created="Fri, 11 Mar 2011 05:44:12 +0000"  >&lt;p&gt;If we do the header idea, then we&apos;ll need to move to a more generic DocData. So instead of doing docData.title = title, you&apos;ll need to do docData.set(&quot;title&quot;, title), which under the hood will store that pair in a Map or Properties. Similarly for &apos;getter&apos;. That also has some implications on perf.&lt;/p&gt;

&lt;p&gt;What is better - generality or optimized code for the common Lucene tasks and let users extend for their own purposes?&lt;/p&gt;

&lt;p&gt;If we want to have the most optimized code, then let&apos;s pass the line entirely to an overridable method. Lucene will offer an optimized way of tokenizing the current fields, while the user will have to either provide his own optimized way (for his fields), or decide that he can risk some cycles in favor of simpler code (e.g., calling line.split()).&lt;/p&gt;</comment>
                    <comment id="13005607" author="mikemccand" created="Fri, 11 Mar 2011 11:37:14 +0000"  >&lt;blockquote&gt;&lt;p&gt;If we do the header idea, then we&apos;ll need to move to a more generic DocData. So instead of doing docData.title = title, you&apos;ll need to do docData.set(&quot;title&quot;, title), which under the hood will store that pair in a Map or Properties. Similarly for &apos;getter&apos;. That also has some implications on perf.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Hmm, true.&lt;/p&gt;

&lt;p&gt;Really, it would be better if LineDocSource could directly set Field values.  Then, up front on parsing the header it could make a Field[], and then when parsing the line it&apos;d just set these Field values.  &lt;/p&gt;

&lt;p&gt;But that&apos;s a much larger change... so I think until then we should just pass the full String line to eg a processLine method?  And the default optimized one breaks it into the fixed name/date/body fields.&lt;/p&gt;</comment>
                    <comment id="13005612" author="shaie" created="Fri, 11 Mar 2011 12:03:58 +0000"  >&lt;blockquote&gt;&lt;p&gt;Really, it would be better if LineDocSource could directly set Field values.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That will break the separation we have today &amp;#8211; ContentSource returns DocData which is not a Lucene Document, and DocMaker creates a Document out of it. Remember that we were in this design before &amp;#8211; DocMaker was responsible for both parsing the content and creating a Document out of it. The current design is much more flexible.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;until then we should just pass the full String line to eg a processLine method&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I agree. Either processLine or getDocData or whatever, but something which receives a line and returns DocData.&lt;/p&gt;</comment>
                    <comment id="13005647" author="mikemccand" created="Fri, 11 Mar 2011 14:17:10 +0000"  >&lt;p&gt;So the separation we have today of DocData from DocMaker allows what flexibility?  Is it just so that we can pull multiple docs from a single DocData?  EG the line file could have massive docs, but we want to index tiny docs, so DocMaker can split them up?&lt;/p&gt;

&lt;p&gt;I agree that&apos;s useful... but it does result in somewhat synthetic docs.  EG 20 docs in a row will have the same title and date (and any other properties).  If you are eval&apos;ing a standard corpus, presumably you don&apos;t do this doc splitting, right?&lt;/p&gt;

&lt;p&gt;The flexibility can only cost us performance (though maybe it&apos;s not so much of a hit).&lt;/p&gt;</comment>
                    <comment id="13005653" author="shaie" created="Fri, 11 Mar 2011 14:29:14 +0000"  >&lt;p&gt;No, the flexibility is in the ability to have a TrecContentSource emitting the TREC documents, and multiple DocMakers that consume them and build Lucene documents out of them.&lt;/p&gt;

&lt;p&gt;For example, one DocMaker can decide to split each doc into N tiny docs. Another can choose to add facets to it. Yet another can do complex analysis on it and produce richer documents.&lt;/p&gt;

&lt;p&gt;Before that, you&apos;d have to write a DocMaker for every such combination. E.g., if you wanted to add facets, you&apos;d need to write a DocMaker per source of data with the same impl.&lt;/p&gt;

&lt;p&gt;DocData as an intermediary object is not expensive, considering it&apos;s only bin over some already allocated Strings. And we reuse it always, so you don&apos;t even allocate it more than once ...&lt;/p&gt;

&lt;p&gt;I would hate to lose that flexibility.&lt;/p&gt;</comment>
                    <comment id="13005908" author="doronc" created="Sat, 12 Mar 2011 00:01:58 +0000"  >&lt;p&gt;Hi, thanks Mike and Shai for the review and great comments.&lt;/p&gt;

&lt;p&gt;Attaching an updated patch.&lt;/p&gt;

&lt;p&gt;Now WriteLineDocTask writes the fields as a header line to the result file. &lt;/p&gt;

&lt;p&gt;It always does this - perhaps a property to disable the header will be useful for allowing previous behavior (no header).&lt;/p&gt;

&lt;p&gt;There are quite a few involved changes to LineDocSource:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;replaced line.split(SEP) by original recurring search for SEP.&lt;/li&gt;
	&lt;li&gt;Method fillDocData(doc,fields[]) was changed to take a line String instead of the array of fields.&lt;/li&gt;
	&lt;li&gt;That method was wrapped in a new interface: DocDataFiller for which there are now two implementations:
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;SimpleDocDataFiller is used when there is no header line in the input file. It is implementing the original logic before this change. This allows to continue using existing line-doc-files which have no header line.&lt;/li&gt;
		&lt;li&gt;HeaderDocDataFiller is used when there exists a header line in the input file. Its implementation populates both fixed fields and flexible properties of DocData:
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;At construction of the filler a mapping is created from the field position in the header line to a setter method of docData. That mapping is not by reflection, nor by a HashMap - simply an int[] posToM where if posToM&lt;span class=&quot;error&quot;&gt;&amp;#91;3&amp;#93;&lt;/span&gt; = 1, later, when handling the field no. 3 in the line, the method fillDate3() will be called, and it will, in turn, call docData.setDate(), through a switch statement. If there&apos;s no mapping to a DocData setter, its properties object will be populated. So, this is quite general, with some performance overhead, though less than reflection I think (I did not measure this).&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;An extension point for overriding the filler creation is through two new methods:
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;createDocDataFiller() for the case of no header line&lt;/li&gt;
		&lt;li&gt;createDocDataFiller(String[] header) when a header line is found in the input&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;Note that filler creation is done once, when reading the first line of the input file.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Some tests were fixed to account for the existence (or absence) of a header line.&lt;/p&gt;

&lt;p&gt;I think more tests are required, but you can get the idea how this code will work.&lt;/p&gt;

&lt;p&gt;Bottom line, LineDocSource is more general now, but the code became more complex.&lt;/p&gt;

&lt;p&gt;I have mixed feelings about this - preferring simple code, but the added functionality is appealing.&lt;/p&gt;</comment>
                    <comment id="13006145" author="shaie" created="Sun, 13 Mar 2011 06:33:08 +0000"  >&lt;p&gt;I haven&apos;t reviewed the patch yet, but I must say that from your description it sounds like LineDocSource has become very complicated. I&apos;d prefer to keep things simple. Before this issue, LDS read a line and split it into 3 fields. Now we think it should be extend-able, such that users can read lines and tokenize them differently (for e.g. supporting more fields). I think that for that, a getDocData/processLine extension point is enough.&lt;/p&gt;

&lt;p&gt;After all, users can write their own WLDT and LDS, they don&apos;t have to use ours. The purpose here is to keep the common logic in those two classes (writing/reading lines to multiple in/output formats), only allow these classes to be somewhat more flexible.&lt;/p&gt;

&lt;p&gt;Therefore I think that the header line may not be that useful eventually. It seems to only complicate matters. Most people (judging by the fact that it hasn&apos;t come up as an issue yet) are either happy w/ the current capabilities, or wrote their own matching pair to support more fields. So let&apos;s keep the current impl as optimized as it was before, but allow for a simple extension point?&lt;/p&gt;</comment>
                    <comment id="13006211" author="doronc" created="Sun, 13 Mar 2011 15:40:43 +0000"  >&lt;blockquote&gt;&lt;p&gt;So let&apos;s keep the current impl as optimized as it was before, but allow for a simple extension point?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I believe the original case in LineDocSource is as optimized as it was before.&lt;/p&gt;

&lt;p&gt;If you take a look at the inner class SimpleDocDataFiller - it has exactly the same logic as before.&lt;/p&gt;

&lt;p&gt;The more general logic - the one in HeaderDocDataFiller which processes any header line for you - is more complex, and perhaps somewhat less efficient - but only slightly I believe, as the additional cost is a switch statement per field.&lt;/p&gt;

&lt;p&gt;But please do not review this code just yet - I&apos;m in a middle of improving it:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;By default LineDocSource should use the SimpleDocDataFiller not only when there&apos;s no header line in the file (this part is covered already), but also when the header line is the same as the default one (the default coming from WriteLineDocTask).&lt;/li&gt;
	&lt;li&gt;selecting the DocDataFiller to use should be possible through a property - as is the spirit of this package.&lt;/li&gt;
	&lt;li&gt;DocDataFiller should better be named DocDataLineReader.&lt;/li&gt;
	&lt;li&gt;DocDataLineReader inner methods like fillDate2() should be inlined (i.e. removed)&lt;/li&gt;
	&lt;li&gt;HeaderDocDataLineReader should switch on an enum rather than on ints.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;These changes would make LineDocSource more efficient and more readable.&lt;br/&gt;
I feel that the added functionality is worth the additional complexity in the code,&lt;br/&gt;
And, for those wishing to save the extra cycles of the general HeaderDocDataLineReader, it is possible to implement a custom one and pass its name as the (new) property docdata.line.reader.&lt;/p&gt;

&lt;p&gt;I am working on an updated patch...&lt;/p&gt;</comment>
                    <comment id="13006251" author="shaie" created="Sun, 13 Mar 2011 19:01:04 +0000"  >&lt;p&gt;A thought &amp;#8211; how about we do the following:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;LineDocSource remains basically as it is today, with a getDocData(String line) extendable method for whoever wants&lt;/li&gt;
	&lt;li&gt;Instead of introducing those Fillers, you create a HeaderLineDocSource which assumes the first line read is the header line, and parses the following ones as appropriate. It will create LDS extending getDocData.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;This will not introduce a Filler in LDS, and those who don&apos;t care about it don&apos;t need to know about it at all. Also, it will showcase the &apos;extendability&apos; of LDS.&lt;/p&gt;

&lt;p&gt;Will that be simpler?&lt;/p&gt;</comment>
                    <comment id="13006266" author="doronc" created="Sun, 13 Mar 2011 19:57:04 +0000"  >&lt;blockquote&gt;&lt;p&gt;Will that be simpler?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;It will be simpler, I admit, but it will harder to manage:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;when re-reading the input file (with repeat=true) special treatment of the header line is needed. And cannot assume that the header line exists, because there are 1-line files out there without this line, which, is possible, I would not like to force recreating, and it is possible.&lt;/li&gt;
	&lt;li&gt;the simple LDS as today handles no header line. As such, if there is one, it will wrongly treat it as a regular line. But I would like it to be able to handle both old files (with no header) and new files, with the header. Mmmm,,, e could for that write the header only if it differs from the default header. Perhaps this will work.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I&apos;ll take a look at that again, meanwhile attaching updated patch with the two inner DocDataLineReader&apos;s.&lt;/p&gt;</comment>
                    <comment id="13006269" author="doronc" created="Sun, 13 Mar 2011 20:17:14 +0000"  >&lt;p&gt;Rethinking this suggestion, I am afraid it will easily lead users to errors/mistakes - users would have to be aware: &lt;/p&gt;

&lt;p&gt;&quot;did I create that file with a header? Mmm... so I must use the source which handles the header, and that file is with the default settings, so it needs the simple reader, but man, did I set it to create the header anyhow... I don&apos;t remember, I&apos;ll recreate the file...&quot; &lt;/p&gt;

&lt;p&gt;Maybe some users will remember such things, but I know that I will not remember, and a line-reader that handles correctly all inputs out-of-the-box is much more convenient... which is what I liked in the header suggestion.&lt;/p&gt;</comment>
                    <comment id="13006377" author="mikemccand" created="Mon, 14 Mar 2011 10:37:55 +0000"  >&lt;blockquote&gt;&lt;p&gt;For example, one DocMaker can decide to split each doc into N tiny docs. Another can choose to add facets to it. Yet another can do complex analysis on it and produce richer documents.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I like the flexibility to &quot;enrich&quot; the docs produced by the source&lt;br/&gt;
(set up facets, semantic extraction, etc.) but the ability to split up&lt;br/&gt;
docs is... dangerous, I think.&lt;/p&gt;

&lt;p&gt;Ie, it feels to me like DocData should in fact just be a Document. The&lt;br/&gt;
two-step process we have now (fill fields in a DocData, then,&lt;br/&gt;
separately ask this DocData to make one or more Docments) feels&lt;br/&gt;
wrong.&lt;/p&gt;

&lt;p&gt;Splitting a big doc into N smaller docs can&apos;t be done well.  It&apos;s&lt;br/&gt;
synthetic data (eg 20 docs in a row will have same title/data) and so&lt;br/&gt;
you&apos;ll draw synthetic conclusions.&lt;/p&gt;

&lt;p&gt;The enrichment can &quot;simply&quot; be a Document processing pipeline that&lt;br/&gt;
runs after the source document was produced from the line file.  EG,&lt;br/&gt;
UIMA.&lt;/p&gt;

&lt;p&gt;When we run perf tests w/ luceneutil, we do in fact do this split, but&lt;br/&gt;
then we shuffle the resulting line file so that you don&apos;t see 20 docs&lt;br/&gt;
w/ same title in a row which skews eg compression results since a&lt;br/&gt;
given term foo in its title will have 20 adjacent docIDs assigned and&lt;br/&gt;
thus be unnaturally easy to compress.  Likewise for the date field,&lt;br/&gt;
which makes the NRQ performance unnaturally good.&lt;/p&gt;

&lt;p&gt;If you want to chop docs up really you do it as a pre-processing step&lt;br/&gt;
in building your line file...&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Before that, you&apos;d have to write a DocMaker for every such combination. E.g., if you wanted to add facets, you&apos;d need to write a DocMaker per source of data with the same impl.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;But, if LineDocSource returned a Document, can&apos;t you take that&lt;br/&gt;
Document and run with it?  We&apos;d still have a single class that pulls&lt;br/&gt;
Document from a line file, just different &quot;Document processors&quot; that&lt;br/&gt;
run after it.&lt;/p&gt;

&lt;p&gt;I&apos;m still not really seeing why DocData is needed, except for the&lt;br/&gt;
somewhat dangerous split-up-docs case.&lt;/p&gt;

&lt;p&gt;But we don&apos;t need to change/fix this, today...&lt;/p&gt;</comment>
                    <comment id="13006378" author="mikemccand" created="Mon, 14 Mar 2011 10:39:38 +0000"  >&lt;p&gt;Patch looks great!  Some small things:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;I think we should throw an exc if any of the field names contain&lt;br/&gt;
    the SEP char?&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Can we name it &quot;parseLine&quot; instead of &quot;readLine&quot;?  Ie, the line&lt;br/&gt;
    has already been read (from the file); what remains is to parse it&lt;br/&gt;
    (and, as a side effect, change DocData to reflect that parsing).&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Typo: sedDocData -&amp;gt; setDocData (in HeaderDocDataLineReader).&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I do think we should move to all line files having the field header&lt;br/&gt;
line (w/ back compat handled for existing line files out there).  The&lt;br/&gt;
approach in the patch looks great &amp;#8211; the &lt;span class=&quot;error&quot;&gt;&amp;#91;common&amp;#93;&lt;/span&gt; fixed case of just&lt;br/&gt;
title/date/body that we have today is specialized and should still be&lt;br/&gt;
fast (SimpleDocDataLineReader).&lt;/p&gt;</comment>
                    <comment id="13006380" author="doronc" created="Mon, 14 Mar 2011 10:55:35 +0000"  >&lt;p&gt;Thanks for reviewing Mike!&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I think we should throw an exc if any of the field names contain the SEP char?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Right, good catch!&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Can we name it &quot;parseLine&quot;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes, I like it better, readLine() felt wrong, parseLine it will be.&lt;br/&gt;
Also the inner class should better be called LineParser (rather than DocDataLineReader).&lt;/p&gt;

&lt;p&gt;I&apos;ll patch these - and fix the typo - totogether with more tests...&lt;/p&gt;</comment>
                    <comment id="13008982" author="doronc" created="Sun, 20 Mar 2011 22:54:55 +0000"  >&lt;p&gt;Updated patch, tests added for better coverage, and added a Changes entry.&lt;/p&gt;</comment>
                    <comment id="13009123" author="doronc" created="Mon, 21 Mar 2011 13:30:52 +0000"  >&lt;p&gt;Hmmm, while reviewing again before committing I noticed that the HeaderLineParser constructor never assigns FieldName.PROP in posToF. I intended to do this but forgot. Indeed, emma shows that Properties handling in LineDocSource is not tested. So I enhanced LineDocSourceTest to also test for nonstandard fields and for properties. The test failes as expected, and the fix was trivial.&lt;/p&gt;

&lt;p&gt;Attaching updated patch, planning to commit this shortly.&lt;/p&gt;</comment>
                    <comment id="13009178" author="doronc" created="Mon, 21 Mar 2011 15:34:46 +0000"  >&lt;p&gt;Committed:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;r1083789 - 3x&lt;/li&gt;
	&lt;li&gt;r1083812 - 3x undo added unused imports&lt;/li&gt;
	&lt;li&gt;r1083816 - trunk&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Thanks Shai and Mike for reviewing and suggestions!&lt;/p&gt;</comment>
                    <comment id="13043492" author="rcmuir" created="Fri, 3 Jun 2011 17:37:15 +0100"  >&lt;p&gt;Bulk closing for 3.2&lt;/p&gt;</comment>
                </comments>
                    <attachments>
                    <attachment id="12474175" name="LUCENE-2958.patch" size="36047" author="doronc" created="Mon, 21 Mar 2011 13:30:52 +0000" />
                    <attachment id="12474135" name="LUCENE-2958.patch" size="33567" author="doronc" created="Sun, 20 Mar 2011 22:54:55 +0000" />
                    <attachment id="12473515" name="LUCENE-2958.patch" size="22095" author="doronc" created="Sun, 13 Mar 2011 19:57:04 +0000" />
                    <attachment id="12473447" name="LUCENE-2958.patch" size="19117" author="doronc" created="Sat, 12 Mar 2011 00:01:58 +0000" />
                    <attachment id="12473260" name="LUCENE-2958.patch" size="6022" author="doronc" created="Thu, 10 Mar 2011 13:31:08 +0000" />
                    <attachment id="12473254" name="LUCENE-2958.patch" size="5993" author="doronc" created="Thu, 10 Mar 2011 10:47:55 +0000" />
                </attachments>
            <subtasks>
        </subtasks>
                <customfields>
                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                <customfieldname>Attachment count</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>6.0</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                <customfieldname>Date of First Response</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>Thu, 10 Mar 2011 17:13:27 +0000</customfieldvalue>

                </customfieldvalues>
            </customfield>
                                                                                                        <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Global Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>10918</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                <customfieldname>Lucene Fields</customfieldname>
                <customfieldvalues>
                        <customfieldvalue key="10121"><![CDATA[New]]></customfieldvalue>
    
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>24734</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                <customfieldname>Time in Status</customfieldname>
                <customfieldvalues>
                    
                </customfieldvalues>
            </customfield>
                            </customfields>
    </item>
</channel>
</rss>