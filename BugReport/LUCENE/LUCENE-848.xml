<!-- 
RSS generated by JIRA (5.2.8#851-sha1:3262fdc28b4bc8b23784e13eadc26a22399f5d88) at Tue Jul 16 13:32:23 UTC 2013

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/LUCENE-848/LUCENE-848.xml?field=key&field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>5.2.8</version>
        <build-number>851</build-number>
        <build-date>26-02-2013</build-date>
    </build-info>

<item>
            <title>[LUCENE-848] Add supported for Wikipedia English as a corpus in the benchmarker stuff</title>
                <link>https://issues.apache.org/jira/browse/LUCENE-848</link>
                <project id="12310110" key="LUCENE">Lucene - Core</project>
                        <description>&lt;p&gt;Add support for using Wikipedia for benchmarking.&lt;/p&gt;</description>
                <environment></environment>
            <key id="12365750">LUCENE-848</key>
            <summary>Add supported for Wikipedia English as a corpus in the benchmarker stuff</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/newfeature.png">New Feature</type>
                                <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                    <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                    <resolution id="1">Fixed</resolution>
                                <assignee username="gsingers">Grant Ingersoll</assignee>
                                <reporter username="steven_parkes">Steven Parkes</reporter>
                        <labels>
                    </labels>
                <created>Sun, 25 Mar 2007 19:02:05 +0100</created>
                <updated>Sun, 8 Jul 2007 18:55:32 +0100</updated>
                    <resolved>Sun, 8 Jul 2007 18:55:32 +0100</resolved>
                                                            <component>modules/benchmark</component>
                        <due></due>
                    <votes>1</votes>
                        <watches>1</watches>
                                                    <comments>
                    <comment id="12483961" author="steven_parkes" created="Sun, 25 Mar 2007 19:02:56 +0100"  >&lt;p&gt;Sorry; it&apos;s not a major thing.&lt;/p&gt;</comment>
                    <comment id="12483971" author="karl.wettin" created="Sun, 25 Mar 2007 20:06:48 +0100"  >&lt;p&gt;There is some code in &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-826&quot; title=&quot;Language detector&quot;&gt;&lt;del&gt;LUCENE-826&lt;/del&gt;&lt;/a&gt;. Here is a newer version.&lt;/p&gt;</comment>
                    <comment id="12484930" author="steven_parkes" created="Wed, 28 Mar 2007 18:08:37 +0100"  >&lt;p&gt;Can&apos;t leave the typo in the title. It&apos;s bugging me.&lt;/p&gt;

&lt;p&gt;Karl, it looks like your stuff grabs individual articles, right? I&apos;m gong to have it download the bzip2 snapshots they provide (and that they prefer you use, if you&apos;re getting much).&lt;/p&gt;

&lt;p&gt;Question (for Doron and anyone else): the file is xml and it&apos;s big, so DOM isn&apos;t going to work. I could still use something SAX based but since the format is so tightly controlled, I&apos;m thinking regular expressions would be sufficient and have less dependences. Anyone have opinions on this? &lt;/p&gt;</comment>
                    <comment id="12486837" author="karl.wettin" created="Thu, 5 Apr 2007 03:24:30 +0100"  >&lt;p&gt;&amp;gt; Karl, it looks like your stuff grabs individual articles, right? I&apos;m gong to have it download the bzip2 snapshots they provide (and that they prefer you use, if you&apos;re getting much). &lt;/p&gt;

&lt;p&gt;They also supply the rendered HTML every now and then. It should be enough to change the URL pattern to &lt;a href=&quot;file:///tmp/wikipedia/&quot; class=&quot;external-link&quot;&gt;file:///tmp/wikipedia/&lt;/a&gt;. I was considering porting the MediaWiki BNF as a tokenizer, but found it much simpler to just parse the HTML.&lt;/p&gt;</comment>
                    <comment id="12487592" author="steven_parkes" created="Mon, 9 Apr 2007 19:28:42 +0100"  >&lt;p&gt;This patch is a first cut a wikipedia benchmark support. It downloads the current english pages from the Wikipedia download site ... which, of course, is actually not there right now. I&apos;m not quite sure what&apos;s up, but you can find the files at &lt;a href=&quot;http://download.wikimedia.org/enwiki/20070402/&quot; class=&quot;external-link&quot;&gt;http://download.wikimedia.org/enwiki/20070402/&lt;/a&gt; right now if you want to play.&lt;/p&gt;

&lt;p&gt;It adds ExtractWikipedia.java, which uses Xerces-J to grab the individual articles. It writes the articles in the same format as the Reuters stuff, so a generecised ReutersDocMaker, DirDocMaker, works.&lt;/p&gt;

&lt;p&gt;The current size of the download file is 2.1G bzip2&apos;d. It&apos;s supposed to contain about 1.2M documents but I came out with 2 or 3, I think, so there maybe &quot;extra&quot; files in there. (Some entries are links and I tried to get rid of those, but I may have missed a particular coding or case).&lt;/p&gt;

&lt;p&gt;For the first pass, I copied the Reuters steps of decompressing and parsing. This creates big temporary files. Moreover, it creates a big directory tree in the end. (The extractor uses a fixed number of documents per directory and grows the depth of the tree logarithmically, a lot like Lucene segments).&lt;/p&gt;

&lt;p&gt;It&apos;s not clear how this preprocessing-to-a-directory-tree compares to on the fly decompression, which would require less disk seeks on the input during indexing. May try that at some point ...&lt;/p&gt;</comment>
                    <comment id="12487600" author="steven_parkes" created="Mon, 9 Apr 2007 19:51:35 +0100"  >&lt;p&gt;By the way, that&apos;s a rough patch. I&apos;m cleaning it up as I use it to test 847.&lt;/p&gt;

&lt;p&gt;Also, I was going to add support to the algorithm format for setting max field length ...&lt;/p&gt;</comment>
                    <comment id="12487608" author="doronc" created="Mon, 9 Apr 2007 20:10:11 +0100"  >&lt;p&gt;&amp;gt; Also, I was going to add support to the algorithm format for setting max field length ... &lt;/p&gt;

&lt;p&gt;If this means extending the algorithm language, it would be simpler to just base on a property here - in the alg file set that property - &quot;max.field.length=20000&quot; - and then in OpenIndexTask read that new property (see how merge.factor property is read) and set it on the index. &lt;/p&gt;</comment>
                    <comment id="12487609" author="steven_parkes" created="Mon, 9 Apr 2007 20:17:33 +0100"  >&lt;p&gt;That&apos;s what I meant (and did).&lt;/p&gt;

&lt;p&gt;If it&apos;s okay, I&apos;ll bundle it into 848. &lt;/p&gt;
</comment>
                    <comment id="12487617" author="doronc" created="Mon, 9 Apr 2007 20:36:46 +0100"  >&lt;p&gt;Seems okay to me (since it&apos;s all in the benchmark).&lt;/p&gt;</comment>
                    <comment id="12489238" author="steven_parkes" created="Mon, 16 Apr 2007 22:23:29 +0100"  >&lt;p&gt;Update of the previous patch. Used Doron&apos;s suggestion for variable name. Cleaned up a little (reverted the eol style on build.txt so the diff makes sense; see &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-864&quot; title=&quot;contrib/benchmark files need eol-style set&quot;&gt;&lt;del&gt;LUCENE-864&lt;/del&gt;&lt;/a&gt; to for fixing the eol-styles in contrib/benchmark.&lt;/p&gt;

&lt;p&gt;Right now the test algorithm is wikipedia.alg but I think the idea is to create specific benchmarks, so maybe this should be something like ingest-enwiki meaning a test of ingest rate against wikipedia.&lt;/p&gt;</comment>
                    <comment id="12489283" author="steven_parkes" created="Tue, 17 Apr 2007 03:10:41 +0100"  >&lt;p&gt;Blah. This patch doesn&apos;t work quite right with 1.4. My intention was/is to use xerces to do the xml parsing but the setup doesn&apos;t work quite right under 1.4 which has some crimson stuff in rt.jar that I don&apos;t (yet) understand.&lt;/p&gt;</comment>
                    <comment id="12489498" author="steven_parkes" created="Tue, 17 Apr 2007 19:27:47 +0100"  >&lt;p&gt;Okay, I&apos;ve tested this patch against 1.4, 1.5, and 1.6. I&apos;ve added the xerces lib since we&apos;re including other required support jars in lib.&lt;/p&gt;</comment>
                    <comment id="12489499" author="steven_parkes" created="Tue, 17 Apr 2007 19:30:47 +0100"  >&lt;p&gt;Here&apos;s the version of xerces that I used, to go in contrib/benchmark/lib (svn diff seems to eat binary files).&lt;/p&gt;</comment>
                    <comment id="12489888" author="steven_parkes" created="Wed, 18 Apr 2007 22:33:53 +0100"  >&lt;p&gt;Upgrade to Xerces 2. Xerces 1 passes the sanity check, but fails for wikipedia, evidently because of &amp;gt;2G files.&lt;/p&gt;

&lt;p&gt;In addition to patch, requires xerces.jar and xml-apis.jar.&lt;/p&gt;</comment>
                    <comment id="12489891" author="steven_parkes" created="Wed, 18 Apr 2007 22:38:31 +0100"  >&lt;p&gt;Now I see the button for attach multiple files. Oh, well.&lt;/p&gt;

&lt;p&gt;Anyway, both jars go in contrib/benchmark/lib.&lt;/p&gt;</comment>
                    <comment id="12490757" author="gsingers" created="Mon, 23 Apr 2007 00:13:44 +0100"  >&lt;p&gt;Steven, is this ready to go in your opinion?  If so, I will take a look at it and try to add it this week.&lt;/p&gt;
</comment>
                    <comment id="12491080" author="steven_parkes" created="Mon, 23 Apr 2007 23:00:36 +0100"  >&lt;p&gt;yeah; think so; it worked for my benchmarking stuff on a couple of systems; might have some things others discover, but that&apos;s always true&lt;/p&gt;</comment>
                    <comment id="12491387" author="gsingers" created="Tue, 24 Apr 2007 19:17:11 +0100"  >&lt;p&gt;Hi Steven,&lt;/p&gt;

&lt;p&gt;Do you know what version of Xerces and xml-apis these are?  I can add the version onto them when I check them in.&lt;/p&gt;</comment>
                    <comment id="12491389" author="gsingers" created="Tue, 24 Apr 2007 19:24:42 +0100"  >&lt;p&gt;I&apos;m getting:&lt;br/&gt;
 Getting: &lt;a href=&quot;http://download.wikimedia.org/enwiki/latest/enwiki-latest-pages-articles.xml.bz2&quot; class=&quot;external-link&quot;&gt;http://download.wikimedia.org/enwiki/latest/enwiki-latest-pages-articles.xml.bz2&lt;/a&gt;&lt;br/&gt;
      &lt;span class=&quot;error&quot;&gt;&amp;#91;get&amp;#93;&lt;/span&gt; To: /Users/grantingersoll/projects/lucene/Lucene-Trunk/contrib/benchmark/temp/enwiki-latest-pages-articles.xml.bz2&lt;br/&gt;
      &lt;span class=&quot;error&quot;&gt;&amp;#91;get&amp;#93;&lt;/span&gt; Error opening connection java.io.FileNotFoundException: &lt;a href=&quot;http://download.wikimedia.org/enwiki/latest/enwiki-latest-pages-articles.xml.bz2&quot; class=&quot;external-link&quot;&gt;http://download.wikimedia.org/enwiki/latest/enwiki-latest-pages-articles.xml.bz2&lt;/a&gt;&lt;br/&gt;
      &lt;span class=&quot;error&quot;&gt;&amp;#91;get&amp;#93;&lt;/span&gt; Error opening connection java.io.FileNotFoundException: &lt;a href=&quot;http://download.wikimedia.org/enwiki/latest/enwiki-latest-pages-articles.xml.bz2&quot; class=&quot;external-link&quot;&gt;http://download.wikimedia.org/enwiki/latest/enwiki-latest-pages-articles.xml.bz2&lt;/a&gt;&lt;br/&gt;
      &lt;span class=&quot;error&quot;&gt;&amp;#91;get&amp;#93;&lt;/span&gt; Error opening connection java.io.FileNotFoundException: &lt;a href=&quot;http://download.wikimedia.org/enwiki/latest/enwiki-latest-pages-articles.xml.bz2&quot; class=&quot;external-link&quot;&gt;http://download.wikimedia.org/enwiki/latest/enwiki-latest-pages-articles.xml.bz2&lt;/a&gt;&lt;br/&gt;
      &lt;span class=&quot;error&quot;&gt;&amp;#91;get&amp;#93;&lt;/span&gt; Can&apos;t get &lt;a href=&quot;http://download.wikimedia.org/enwiki/latest/enwiki-latest-pages-articles.xml.bz2&quot; class=&quot;external-link&quot;&gt;http://download.wikimedia.org/enwiki/latest/enwiki-latest-pages-articles.xml.bz2&lt;/a&gt; to &amp;lt;mydir&amp;gt;/contrib/benchmark/temp/enwiki-latest-pages-articles.xml.bz2&lt;/p&gt;
</comment>
                    <comment id="12491393" author="steven_parkes" created="Tue, 24 Apr 2007 19:28:28 +0100"  >&lt;p&gt;Both jars are from xerces-2.9.0.&lt;/p&gt;</comment>
                    <comment id="12491394" author="doronc" created="Tue, 24 Apr 2007 19:32:40 +0100"  >&lt;p&gt;I haven&apos;t tried this patch yet - hesitated/thinking it must take very long to download the huge start-up data (is this correct?)...   anyhow I was wondering abut the new jars - whether we should try to make xcerses and xml-apis jars &quot;ext-jars&quot;, i.e. downloaded from somewhere (where?) only when attempting to use this package.  Otherwise this is adding ~2.5MB to the checkout/dev-pack - do others consider this an issue at all?&lt;/p&gt;</comment>
                    <comment id="12491396" author="steven_parkes" created="Tue, 24 Apr 2007 19:43:32 +0100"  >&lt;p&gt;Yeah, it takes a while to download.&lt;/p&gt;

&lt;p&gt;I added the jars since that&apos;s what we&apos;ve been doing elsewhere. In fact, xerces is in gdata-server too. Personally, the size isn&apos;t an issue for me; don&apos;t know about others.  What might be difficult, though, is trying to share the two since that would mean coordinating contrib projects, and I don&apos;t know anything about the gdata server. I can tell you that if you want to support both 1.4 and 1.5 on something as big wikipedia, there is sensitivity to the xerces revision. &lt;/p&gt;

&lt;p&gt;Sorry about the download problem, Grant. I actually documented that in a readme ... hat I can no longer find. I would swear I put it in the patch but obviously I didn&apos;t becuase it&apos;s not there. Now I have to go find it.&lt;/p&gt;

&lt;p&gt;The short answer is you want to download  &lt;a href=&quot;http://download.wikimedia.org/enwiki/20070402/enwiki-20070402-pages-articles.xml.bz2&quot; class=&quot;external-link&quot;&gt;http://download.wikimedia.org/enwiki/20070402/enwiki-20070402-pages-articles.xml.bz2&lt;/a&gt;. The wikipedia download site isn&apos;t always clean, doesn&apos;t have files where they &quot;should&quot; be. It was when I first started this, but isn&apos;t now.&lt;/p&gt;</comment>
                    <comment id="12491397" author="gsingers" created="Tue, 24 Apr 2007 19:45:16 +0100"  >&lt;p&gt;+1  Not a big deal to go get the files via an ANT task.  Of course,  &lt;br/&gt;
this could stir the whole maven/ivy debate once again &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;The other question is whether there are common libraries sprinkled  &lt;br/&gt;
throughout contrib that it might make sense to create a contrib/lib   &lt;br/&gt;
Of course, then you would have to figure out what versions to  &lt;br/&gt;
support, etc.  Aaah, Maven, just put it in the POM...  &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;




&lt;p&gt;--------------------------&lt;br/&gt;
Grant Ingersoll&lt;br/&gt;
Center for Natural Language Processing&lt;br/&gt;
&lt;a href=&quot;http://www.cnlp.org&quot; class=&quot;external-link&quot;&gt;http://www.cnlp.org&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Read the Lucene Java FAQ at &lt;a href=&quot;http://wiki.apache.org/jakarta-lucene/&quot; class=&quot;external-link&quot;&gt;http://wiki.apache.org/jakarta-lucene/&lt;/a&gt; &lt;br/&gt;
LuceneFAQ&lt;/p&gt;

</comment>
                    <comment id="12491404" author="steven_parkes" created="Tue, 24 Apr 2007 20:02:05 +0100"  >&lt;p&gt;Here&apos;s the patch with the README.&lt;/p&gt;

&lt;p&gt;By the way, there&apos;s also a .rsync-filter in the patch. I never described that. If you use rsync, there&apos;s an option where it will look for these filter files and not rsync files/directories as spec&apos;d in the file.&lt;/p&gt;

&lt;p&gt;Since I sometime rsync working copies around to test on different machines, and since I don&apos;t want to try to copy around wikipedia  (or the other datasets), I &quot;spec&quot; those out.&lt;/p&gt;

&lt;p&gt;Without the appropriate rsync option, the files are ignored, so I would think this would be a good thing to have ...&lt;/p&gt;</comment>
                    <comment id="12491616" author="mikemccand" created="Wed, 25 Apr 2007 12:59:01 +0100"  >&lt;p&gt;Friendly reminder: the latest patch looks like it still has some cancerous whitespace in it!&lt;/p&gt;</comment>
                    <comment id="12492374" author="steven_parkes" created="Fri, 27 Apr 2007 20:13:52 +0100"  >&lt;p&gt;Well, here&apos;s a version with less whitespace.&lt;/p&gt;

&lt;p&gt;But, I have to admit, removing it turned out to be more difficult than I thought it would be. I may have gone too far. It&apos;s hard for me to judge &quot;benign&quot;  (&quot;as long as it doesn&apos;t hurt readability&quot;) for obvious reasons.&lt;/p&gt;</comment>
                    <comment id="12492460" author="mikemccand" created="Sat, 28 Apr 2007 10:43:38 +0100"  >&lt;p&gt;Alas I fear you did not go quite far enough; there&apos;s still lots of&lt;br/&gt;
extra whitespace around ()&apos;s and []&apos;s.&lt;/p&gt;

&lt;p&gt;For example I think source like this:&lt;/p&gt;

&lt;p&gt;  if ( qualified.equals( &quot;title&quot; ) ) {&lt;/p&gt;

&lt;p&gt;should look like this instead:&lt;/p&gt;

&lt;p&gt;  if (qualified.equals(&quot;title&quot;)) {&lt;/p&gt;</comment>
                    <comment id="12492756" author="steven_parkes" created="Mon, 30 Apr 2007 20:04:54 +0100"  >&lt;p&gt;Ath. That would be because I was thinking vertically, not horizontally.&lt;/p&gt;

&lt;p&gt;Would this be reasonably normative?&lt;br/&gt;
&lt;a href=&quot;http://java.sun.com/docs/codeconv/html/CodeConventions.doc7.html#475&quot; class=&quot;external-link&quot;&gt;http://java.sun.com/docs/codeconv/html/CodeConventions.doc7.html#475&lt;/a&gt;&lt;/p&gt;</comment>
                    <comment id="12492761" author="steven_parkes" created="Mon, 30 Apr 2007 20:16:54 +0100"  >&lt;p&gt;Close to &lt;a href=&quot;http://java.sun.com/docs/codeconv/html/CodeConventions.doc7.html#475&quot; class=&quot;external-link&quot;&gt;http://java.sun.com/docs/codeconv/html/CodeConventions.doc7.html#475&lt;/a&gt;. Within normal Lucene differences, I believe.&lt;/p&gt;</comment>
                    <comment id="12492763" author="mikemccand" created="Mon, 30 Apr 2007 20:21:47 +0100"  >&lt;p&gt;Ahhh, that looks great Steve.  Thanks.&lt;/p&gt;</comment>
                    <comment id="12492764" author="cutting" created="Mon, 30 Apr 2007 20:23:36 +0100"  >&lt;p&gt;Yes, the standard for Lucene Java (as specified in &lt;a href=&quot;http://wiki.apache.org/jakarta-lucene/HowToContribute&quot; class=&quot;external-link&quot;&gt;http://wiki.apache.org/jakarta-lucene/HowToContribute&lt;/a&gt;) is Sun&apos;s except 2-space indentation.&lt;/p&gt;</comment>
                    <comment id="12500893" author="michaelbusch" created="Sat, 2 Jun 2007 01:39:49 +0100"  >&lt;p&gt;I&apos;m not familiar with this patch but looking at the recent comments it looks ready to commit?&lt;/p&gt;</comment>
                    <comment id="12500896" author="steven_parkes" created="Sat, 2 Jun 2007 02:04:16 +0100"  >&lt;p&gt;Grant was looking at hosting a copy of the dataset on zones so that we&apos;d have a fixed dataset which would enable more repeatable experiments. If that happened, we could update code/readme to point there rather than fetching things from wikipedia, where things are always changing (and not always there).&lt;/p&gt;</comment>
                    <comment id="12500901" author="michaelbusch" created="Sat, 2 Jun 2007 02:40:40 +0100"  >&lt;p&gt;OK I see, that makes sense. I think we can clear the fix version here?&lt;/p&gt;</comment>
                    <comment id="12500902" author="hossman" created="Sat, 2 Jun 2007 02:50:35 +0100"  >&lt;p&gt;is there any reason not to host these on lucene.apache.org instead of the zone?&lt;/p&gt;

&lt;p&gt;I ask this assuming the barrier is setting up a webserver on the zone to host the file and not any remainining legal issues since those seem to have been ok&apos;d...&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.nabble.com/Fwd%3A-Wikipedia-content%2C-GNU-Free-Documentation-License-and-Apache-p10182964.html&quot; class=&quot;external-link&quot;&gt;http://www.nabble.com/Fwd%3A-Wikipedia-content%2C-GNU-Free-Documentation-License-and-Apache-p10182964.html&lt;/a&gt;&lt;/p&gt;</comment>
                    <comment id="12500903" author="steven_parkes" created="Sat, 2 Jun 2007 03:12:14 +0100"  >&lt;p&gt;I&apos;ll leave the hosting site to others; I don&apos;t know enough about apache infra.&lt;/p&gt;

&lt;p&gt;If the hosting got decided before 2.2 got cut, that&apos;d be great, but I certainly don&apos;t think it&apos;s worth holding up the release for.&lt;/p&gt;</comment>
                    <comment id="12500922" author="michaelbusch" created="Sat, 2 Jun 2007 07:24:37 +0100"  >&lt;p&gt;Alright. Clearing the fix version to not block 2.2. &lt;/p&gt;</comment>
                    <comment id="12500939" author="gsingers" created="Sat, 2 Jun 2007 11:57:16 +0100"  >&lt;p&gt;I think the zone is the preferred place, since that is for developer  &lt;br/&gt;
resources.  Since this isn&apos;t in the main line of testing, it probably  &lt;br/&gt;
won&apos;t be downloaded all that much.&lt;/p&gt;

&lt;p&gt;Steven, do we have a final version that you can point me at that you  &lt;br/&gt;
want hosted?&lt;/p&gt;



&lt;p&gt;--------------------------&lt;br/&gt;
Grant Ingersoll&lt;br/&gt;
Center for Natural Language Processing&lt;br/&gt;
&lt;a href=&quot;http://www.cnlp.org/tech/lucene.asp&quot; class=&quot;external-link&quot;&gt;http://www.cnlp.org/tech/lucene.asp&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Read the Lucene Java FAQ at &lt;a href=&quot;http://wiki.apache.org/jakarta-lucene/&quot; class=&quot;external-link&quot;&gt;http://wiki.apache.org/jakarta-lucene/&lt;/a&gt; &lt;br/&gt;
LuceneFAQ&lt;/p&gt;

</comment>
                    <comment id="12501344" author="steven_parkes" created="Mon, 4 Jun 2007 21:18:11 +0100"  >&lt;p&gt;It looks like the latest successful dump is&lt;br/&gt;
&lt;a href=&quot;http://download.wikimedia.org/enwiki/20070527/enwiki-20070527-pages-articles.xml.bz2&quot; class=&quot;external-link&quot;&gt;http://download.wikimedia.org/enwiki/20070527/enwiki-20070527-pages-articles.xml.bz2&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;If you copy it whereever, I&apos;ll fetch it from there and test it.&lt;/p&gt;</comment>
                    <comment id="12501760" author="gsingers" created="Wed, 6 Jun 2007 02:21:29 +0100"  >&lt;p&gt;OK, I applied the patch and am testing this.  I updated the build file to point to &lt;a href=&quot;http://people.apache.org/~gsingers/wikipedia/enwiki-20070527-pages-articles.xml.bz2&quot; class=&quot;external-link&quot;&gt;http://people.apache.org/~gsingers/wikipedia/enwiki-20070527-pages-articles.xml.bz2&lt;/a&gt;&lt;/p&gt;</comment>
                    <comment id="12508318" author="gsingers" created="Tue, 26 Jun 2007 21:46:27 +0100"  >&lt;p&gt;I am getting the following when I apply this patch:&lt;br/&gt;
Exception in thread &quot;main&quot; java.lang.RuntimeException: org.xml.sax.SAXParseException: Element type &quot;Pat&quot; must be followed by either attribute specifications, &quot;&amp;gt;&quot; or &quot;/&amp;gt;&quot;.&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.lucene.benchmark.utils.ExtractWikipedia.extract(ExtractWikipedia.java:184)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.lucene.benchmark.utils.ExtractWikipedia.main(ExtractWikipedia.java:199)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt; Caused by: org.xml.sax.SAXParseException: Element type &quot;Pat&quot; must be followed by either attribute specifications, &quot;&amp;gt;&quot; or &quot;/&amp;gt;&quot;.&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.xerces.framework.XMLParser.reportError(XMLParser.java:1213)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.xerces.framework.XMLDocumentScanner.reportFatalXMLError(XMLDocumentScanner.java:579)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.xerces.framework.XMLDocumentScanner.abortMarkup(XMLDocumentScanner.java:628)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.xerces.framework.XMLDocumentScanner.scanElement(XMLDocumentScanner.java:1800)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.xerces.framework.XMLDocumentScanner$ContentDispatcher.dispatch(XMLDocumentScanner.java:1182)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.xerces.framework.XMLDocumentScanner.parseSome(XMLDocumentScanner.java:381)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.xerces.framework.XMLParser.parse(XMLParser.java:1098)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.lucene.benchmark.utils.ExtractWikipedia.extract(ExtractWikipedia.java:181)&lt;/p&gt;</comment>
                    <comment id="12508327" author="steven_parkes" created="Tue, 26 Jun 2007 22:05:34 +0100"  >&lt;p&gt;Let me see if I can replicate.&lt;/p&gt;

&lt;p&gt;Can you do a sha1sum on your enwiki-20070527-pages-articles.xml.bz2 so I can be sure my copy is valid?&lt;/p&gt;

&lt;p&gt;Mine&apos;s 263f94e857882e4a379ac60372201467e343db50&lt;/p&gt;</comment>
                    <comment id="12508652" author="gsingers" created="Wed, 27 Jun 2007 22:11:10 +0100"  >&lt;p&gt;OK, I downloaded a fresh copy.  sha1sum on the bz2 file yields: 76402fed3b6f6583aa283db5dbbba83abbf65d74&lt;br/&gt;
when downloaded from &lt;a href=&quot;http://people.apache.org/~gsingers/wikipedia/enwiki-20070527-pages-articles.xml.bz2&quot; class=&quot;external-link&quot;&gt;http://people.apache.org/~gsingers/wikipedia/enwiki-20070527-pages-articles.xml.bz2&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ls -l yields:&lt;br/&gt;
...  1778897799 ... enwiki-20070527-pages-articles.xml&lt;br/&gt;
...   477278208 ... enwiki-20070527-pages-articles.xml.bz2&lt;/p&gt;


&lt;p&gt;Now my error is&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt; Exception in thread &quot;main&quot; java.lang.RuntimeException: org.xml.sax.SAXParseException: Attribute name &quot;Td&quot; must be followed by the &apos;=&apos; character.&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.lucene.benchmark.utils.ExtractWikipedia.extract(ExtractWikipedia.java:184)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.lucene.benchmark.utils.ExtractWikipedia.main(ExtractWikipedia.java:199)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt; Caused by: org.xml.sax.SAXParseException: Attribute name &quot;Td&quot; must be followed by the &apos;=&apos; character.&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.xerces.framework.XMLParser.reportError(XMLParser.java:1213)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.xerces.framework.XMLDocumentScanner.reportFatalXMLError(XMLDocumentScanner.java:598)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.xerces.framework.XMLDocumentScanner.abortMarkup(XMLDocumentScanner.java:636)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.xerces.framework.XMLDocumentScanner.scanElement(XMLDocumentScanner.java:1761)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.xerces.framework.XMLDocumentScanner$ContentDispatcher.dispatch(XMLDocumentScanner.java:1182)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.xerces.framework.XMLDocumentScanner.parseSome(XMLDocumentScanner.java:381)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.xerces.framework.XMLParser.parse(XMLParser.java:1098)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.lucene.benchmark.utils.ExtractWikipedia.extract(ExtractWikipedia.java:181)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     ... 1 more&lt;/p&gt;</comment>
                    <comment id="12508661" author="steven_parkes" created="Wed, 27 Jun 2007 22:24:54 +0100"  >&lt;p&gt;Actually, I just noticed wikimedia provides the md5 hashes. I was able to validate my copy.&lt;/p&gt;

&lt;p&gt;I don&apos;t actually remember if I got my copy from wikimedia or from p.a.o.&lt;/p&gt;

&lt;p&gt;The copy in your ls -l looks bad, both from the sha1sum and from the size. Looks like your file is truncated: the file length is 455M (if 477278208  is the size in bytes) and the real file is 2686431976 (2.6G) bytes.&lt;/p&gt;

&lt;p&gt;Can you check the file on p.a.o, both the size and the md5 hash? The latter should be&lt;br/&gt;
fc24229da9af033cbb55b9867a950431&lt;br/&gt;
(&lt;a href=&quot;http://download.wikimedia.org/enwiki/20070527/enwiki-20070527-md5sums.txt&quot; class=&quot;external-link&quot;&gt;http://download.wikimedia.org/enwiki/20070527/enwiki-20070527-md5sums.txt&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;I should be able to launch a test of the unzip/extract tonight. It takes a while.&lt;/p&gt;</comment>
                    <comment id="12508675" author="gsingers" created="Wed, 27 Jun 2007 23:37:26 +0100"  >&lt;p&gt;Weird, this is the info on p.a.o:&lt;br/&gt;
... 2686431976 May 30 02:17 enwiki-20070527-pages-articles.xml.bz2&lt;/p&gt;

&lt;p&gt;So, I don&apos;t know what is up w/ my download.  I am surprised it  &lt;br/&gt;
uncompressed.  p.a.o. doesn&apos;t have sha1sum&lt;/p&gt;

&lt;p&gt;Anyway, I am trying to download using wget and it lists the file size  &lt;br/&gt;
at 2.5G, so hopefully this will download.&lt;/p&gt;



&lt;p&gt;--------------------------&lt;br/&gt;
Grant Ingersoll&lt;br/&gt;
Center for Natural Language Processing&lt;br/&gt;
&lt;a href=&quot;http://www.cnlp.org/tech/lucene.asp&quot; class=&quot;external-link&quot;&gt;http://www.cnlp.org/tech/lucene.asp&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Read the Lucene Java FAQ at &lt;a href=&quot;http://wiki.apache.org/lucene-java/LuceneFAQ&quot; class=&quot;external-link&quot;&gt;http://wiki.apache.org/lucene-java/LuceneFAQ&lt;/a&gt;&lt;/p&gt;

</comment>
                    <comment id="12508805" author="gsingers" created="Thu, 28 Jun 2007 12:52:06 +0100"  >&lt;p&gt;OK, looks like that one went through, using wget.  I think I will commit as there must have been something screwed up on my network side.&lt;/p&gt;</comment>
                    <comment id="12508830" author="gsingers" created="Thu, 28 Jun 2007 14:32:33 +0100"  >&lt;p&gt;I take back my promise to commit, I am getting (after processing 189500 docs):&lt;br/&gt;
 &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt; Error: cannot execute the algorithm! term out of order (&quot;docid:disrs&quot;.compareTo(&quot;docname:disregardle&lt;br/&gt;
                                                                                                                &amp;amp;*Ar&quot;) &amp;lt;= 0)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt; org.apache.lucene.index.CorruptIndexException: term out of order (&quot;docid:disrs&quot;.compareTo(&quot;docname:disregardle&lt;br/&gt;
                                                                                                                          &amp;amp;*Ar&quot;) &amp;lt;= 0)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.lucene.index.TermInfosWriter.add(TermInfosWriter.java:102)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.lucene.index.SegmentMerger.mergeTermInfo(SegmentMerger.java:332)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.lucene.index.SegmentMerger.mergeTermInfos(SegmentMerger.java:297)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.lucene.index.SegmentMerger.mergeTerms(SegmentMerger.java:261)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.lucene.index.SegmentMerger.merge(SegmentMerger.java:98)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.lucene.index.IndexWriter.mergeSegments(IndexWriter.java:1883)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.lucene.index.IndexWriter.maybeMergeSegments(IndexWriter.java:1811)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.lucene.index.IndexWriter.flushRamSegments(IndexWriter.java:1742)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.lucene.index.IndexWriter.flushRamSegments(IndexWriter.java:1733)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.lucene.index.IndexWriter.maybeFlushRamSegments(IndexWriter.java:1727)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.lucene.index.IndexWriter.addDocument(IndexWriter.java:1004)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.lucene.index.IndexWriter.addDocument(IndexWriter.java:983)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.lucene.benchmark.byTask.tasks.AddDocTask.doLogic(AddDocTask.java:74)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.lucene.benchmark.byTask.tasks.PerfTask.runAndMaybeStats(PerfTask.java:83)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.lucene.benchmark.byTask.tasks.TaskSequence.doSerialTasks(TaskSequence.java:107)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.lucene.benchmark.byTask.tasks.TaskSequence.doLogic(TaskSequence.java:93)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.lucene.benchmark.byTask.tasks.PerfTask.runAndMaybeStats(PerfTask.java:90)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.lucene.benchmark.byTask.tasks.TaskSequence.doSerialTasks(TaskSequence.java:107)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.lucene.benchmark.byTask.tasks.TaskSequence.doLogic(TaskSequence.java:93)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.lucene.benchmark.byTask.tasks.PerfTask.runAndMaybeStats(PerfTask.java:90)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.lucene.benchmark.byTask.tasks.TaskSequence.doSerialTasks(TaskSequence.java:107)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.lucene.benchmark.byTask.tasks.TaskSequence.doLogic(TaskSequence.java:93)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.lucene.benchmark.byTask.tasks.PerfTask.runAndMaybeStats(PerfTask.java:90)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.lucene.benchmark.byTask.tasks.TaskSequence.doSerialTasks(TaskSequence.java:107)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.lucene.benchmark.byTask.tasks.TaskSequence.doLogic(TaskSequence.java:93)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.lucene.benchmark.byTask.utils.Algorithm.execute(Algorithm.java:228)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.lucene.benchmark.byTask.Benchmark.execute(Benchmark.java:72)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt;     at org.apache.lucene.benchmark.byTask.Benchmark.main(Benchmark.java:108)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt; ####################&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt; ###  D O N E !!! ###&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt; ####################&lt;/p&gt;


&lt;p&gt;Can you reproduce this?  It seems like an actual issue with core.&lt;/p&gt;</comment>
                    <comment id="12508833" author="steven_parkes" created="Thu, 28 Jun 2007 15:05:08 +0100"  >&lt;p&gt;Trying to reproduce now.&lt;/p&gt;

&lt;p&gt;Something that came up while restarting the fetch/decompress/etc. was the number of files this procedure creates. It&apos;s a lot: one for each article. I used the existing benchmark code for doing this stuff but perhaps it&apos;s not a good idea on this scale? For one thing, it kinda kills ant since ant wants to do a walk of subtrees for some of its tasks. Either we need to exclude the work and temp directories from ant&apos;s walks and/or we should come up with something better than one file per article.&lt;/p&gt;

&lt;p&gt;I think Mike mentioned not doing the one file per article. I&apos;ll try to look at that ...&lt;/p&gt;</comment>
                    <comment id="12508922" author="doronc" created="Thu, 28 Jun 2007 20:46:52 +0100"  >&lt;p&gt;Steven wrote:&lt;br/&gt;
&amp;gt; I think Mike mentioned not doing the one file per article. I&apos;ll try to look at that ...&lt;/p&gt;

&lt;p&gt;Perhaps also (re) consider the &quot;compress and add on-the-fly&quot; approach, similar to what TrecDocmaker is doing?&lt;/p&gt;

&lt;p&gt;Grant wrote:&lt;br/&gt;
&amp;gt; I take back my promise to commit, I am getting (after processing 189500 docs): &lt;br/&gt;
&amp;gt;    &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt; Error: cannot execute the algorithm! term out of order (&quot;docid:disrs&quot;.compareTo(&quot;docname:disregardle &lt;br/&gt;
&amp;gt;                                                                                                                &amp;amp;*Ar&quot;) &amp;lt;= 0) &lt;br/&gt;
&amp;gt;   &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt; org.apache.lucene.index.CorruptIndexException: term out of order (&quot;docid:disrs&quot;.compareTo(&quot;docname:disregardle &lt;br/&gt;
&amp;gt;                                                                                                                         &amp;amp;*Ar&quot;) &amp;lt;= 0) &lt;/p&gt;

&lt;p&gt;Just to verify that it is not a benchmark issue, could you also post here the executed algorithm (as printed, or, if not printed, the actual file)...?&lt;/p&gt;</comment>
                    <comment id="12509288" author="mikemccand" created="Sat, 30 Jun 2007 13:50:00 +0100"  >&lt;p&gt;&amp;gt; I think Mike mentioned not doing the one file per article. I&apos;ll try to look at that ... &lt;/p&gt;

&lt;p&gt;I&apos;m actually &lt;span class=&quot;error&quot;&gt;&amp;#91;slowly&amp;#93;&lt;/span&gt; working through a patch to contrib/benchmark&lt;br/&gt;
that adds a LineDocMaker that will open a single file and make one&lt;br/&gt;
document per line.  (This is the follow-through on &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-843&quot; title=&quot;improve how IndexWriter uses RAM to buffer added documents&quot;&gt;&lt;del&gt;LUCENE-843&lt;/del&gt;&lt;/a&gt; to merge&lt;br/&gt;
in the benchmarking tool that I used there, into contib/benchmark).&lt;br/&gt;
This is in order to do tests that aren&apos;t affected by the time to&lt;br/&gt;
decompress files/walk trees/open new files/etc. to build their&lt;br/&gt;
documents.&lt;/p&gt;

&lt;p&gt;I will also include in the patch some way to run an existing DocMaker,&lt;br/&gt;
pull its documents, and store them into a single line file.  It&apos;s&lt;br/&gt;
probably still worthwhile to have a DocMaker that can read the single&lt;br/&gt;
wikipedia XML file and produce documents directly from that to save&lt;br/&gt;
creating file-per-document in a large dir tree.&lt;/p&gt;</comment>
                    <comment id="12509289" author="mikemccand" created="Sat, 30 Jun 2007 13:51:43 +0100"  >&lt;p&gt;Just to add another datapoint: I&apos;ve been using the wikipedia snapshot just before 05/27 (I think it was 04/22 or so but I can&apos;t access the download site right now to confirm) without any issues.&lt;/p&gt;</comment>
                    <comment id="12509292" author="gsingers" created="Sat, 30 Jun 2007 14:46:30 +0100"  >&lt;p&gt;Here&apos;s a patch to just the build.xml that downloads from people.a.o&lt;/p&gt;

&lt;p&gt;You still need all the other stuff (libs, patches) to make this work.&lt;/p&gt;</comment>
                    <comment id="12509347" author="gsingers" created="Sun, 1 Jul 2007 02:58:54 +0100"  >&lt;p&gt;OK, I reran it and it went fine.  Not sure what happened, but maybe just a hiccup on my machine.&lt;/p&gt;

&lt;p&gt;I am going to commit.&lt;/p&gt;</comment>
                    <comment id="12509349" author="gsingers" created="Sun, 1 Jul 2007 03:21:28 +0100"  >&lt;p&gt;Committed.&lt;/p&gt;</comment>
                    <comment id="12509473" author="mikemccand" created="Mon, 2 Jul 2007 01:39:41 +0100"  >&lt;p&gt;I think somehow the wrong version (1.4.4) of Xerces was committed and&lt;br/&gt;
named as lib/xerces-2.9.0.jar.&lt;/p&gt;

&lt;p&gt;I&apos;m hitting what I think is the same issue Steven is referring to&lt;br/&gt;
above (&lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-848#action_1248988&quot; class=&quot;external-link&quot;&gt;https://issues.apache.org/jira/browse/LUCENE-848#action_1248988&lt;/a&gt;),&lt;br/&gt;
this exception after ~350K docs:&lt;/p&gt;

&lt;p&gt;Exception in thread &quot;main&quot; java.lang.RuntimeException: java.lang.RuntimeException: Internal Error: fPreviousChunk == NULL&lt;br/&gt;
	at org.apache.lucene.benchmark.utils.ExtractWikipedia.extract(ExtractWikipedia.java:184)&lt;br/&gt;
	at org.apache.lucene.benchmark.utils.ExtractWikipedia.main(ExtractWikipedia.java:199)&lt;br/&gt;
Caused by: java.lang.RuntimeException: Internal Error: fPreviousChunk == NULL&lt;br/&gt;
	at org.apache.xerces.framework.XMLParser.parse(XMLParser.java:1111)&lt;br/&gt;
	at org.apache.lucene.benchmark.utils.ExtractWikipedia.extract(ExtractWikipedia.java:181)&lt;br/&gt;
	... 1 more&lt;/p&gt;

&lt;p&gt;I downloaded 1.4.4 of xerces.jar and &quot;cmp&quot; says it&apos;s the same file&lt;br/&gt;
that&apos;s now checked in as lib/xerces-2.9.0.jar.  When I download xerces&lt;br/&gt;
2.9.0 myself and overwrite this one in lib, the extraction finishes&lt;br/&gt;
without errors.&lt;/p&gt;</comment>
                    <comment id="12509474" author="gsingers" created="Mon, 2 Jul 2007 01:58:06 +0100"  >&lt;p&gt;OK, go ahead and commit it.&lt;/p&gt;



&lt;p&gt;--------------------------&lt;br/&gt;
Grant Ingersoll&lt;br/&gt;
Center for Natural Language Processing&lt;br/&gt;
&lt;a href=&quot;http://www.cnlp.org/tech/lucene.asp&quot; class=&quot;external-link&quot;&gt;http://www.cnlp.org/tech/lucene.asp&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Read the Lucene Java FAQ at &lt;a href=&quot;http://wiki.apache.org/lucene-java/LuceneFAQ&quot; class=&quot;external-link&quot;&gt;http://wiki.apache.org/lucene-java/LuceneFAQ&lt;/a&gt;&lt;/p&gt;

</comment>
                    <comment id="12510988" author="gsingers" created="Sun, 8 Jul 2007 18:55:32 +0100"  >&lt;p&gt;This has been committed&lt;/p&gt;</comment>
                </comments>
                <issuelinks>
                        <issuelinktype id="10030">
                <name>Reference</name>
                                <outwardlinks description="relates to">
                            <issuelink>
            <issuekey id="12372263">LUCENE-940</issuekey>
        </issuelink>
                    </outwardlinks>
                                            </issuelinktype>
                    </issuelinks>
                <attachments>
                    <attachment id="12360866" name="LUCENE-848-build.patch" size="4534" author="gsingers" created="Sat, 30 Jun 2007 14:46:29 +0100" />
                    <attachment id="12356535" name="LUCENE-848.txt" size="23841" author="steven_parkes" created="Mon, 30 Apr 2007 20:16:54 +0100" />
                    <attachment id="12356432" name="LUCENE-848.txt" size="24068" author="steven_parkes" created="Fri, 27 Apr 2007 20:13:52 +0100" />
                    <attachment id="12356173" name="LUCENE-848.txt" size="24244" author="steven_parkes" created="Tue, 24 Apr 2007 20:02:05 +0100" />
                    <attachment id="12355791" name="LUCENE-848.txt" size="22619" author="steven_parkes" created="Wed, 18 Apr 2007 22:33:53 +0100" />
                    <attachment id="12355708" name="LUCENE-848.txt" size="22856" author="steven_parkes" created="Tue, 17 Apr 2007 19:27:47 +0100" />
                    <attachment id="12355646" name="LUCENE-848.txt" size="21209" author="steven_parkes" created="Mon, 16 Apr 2007 22:23:29 +0100" />
                    <attachment id="12355182" name="LUCENE-848.txt" size="19108" author="steven_parkes" created="Mon, 9 Apr 2007 19:28:42 +0100" />
                    <attachment id="12354172" name="WikipediaHarvester.java" size="6692" author="karl.wettin" created="Sun, 25 Mar 2007 20:06:48 +0100" />
                    <attachment id="12355793" name="xerces.jar" size="1812019" author="steven_parkes" created="Wed, 18 Apr 2007 22:36:43 +0100" />
                    <attachment id="12355709" name="xerces.jar" size="691157" author="steven_parkes" created="Tue, 17 Apr 2007 19:30:47 +0100" />
                    <attachment id="12355794" name="xml-apis.jar" size="194354" author="steven_parkes" created="Wed, 18 Apr 2007 22:38:31 +0100" />
                </attachments>
            <subtasks>
        </subtasks>
                <customfields>
                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                <customfieldname>Attachment count</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>12.0</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                <customfieldname>Date of First Response</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>Sun, 25 Mar 2007 19:06:48 +0000</customfieldvalue>

                </customfieldvalues>
            </customfield>
                                                                                                        <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Global Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>12893</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                <customfieldname>Lucene Fields</customfieldname>
                <customfieldvalues>
                        <customfieldvalue key="10120"><![CDATA[Patch Available]]></customfieldvalue>
    
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>26881</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                <customfieldname>Time in Status</customfieldname>
                <customfieldvalues>
                    
                </customfieldvalues>
            </customfield>
                            </customfields>
    </item>
</channel>
</rss>