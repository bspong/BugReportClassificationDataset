<!-- 
RSS generated by JIRA (5.2.8#851-sha1:3262fdc28b4bc8b23784e13eadc26a22399f5d88) at Tue Jul 16 13:33:45 UTC 2013

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/LUCENE-1043/LUCENE-1043.xml?field=key&field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>5.2.8</version>
        <build-number>851</build-number>
        <build-date>26-02-2013</build-date>
    </build-info>

<item>
            <title>[LUCENE-1043] Speedup merging of stored fields when field mapping &quot;matches&quot;</title>
                <link>https://issues.apache.org/jira/browse/LUCENE-1043</link>
                <project id="12310110" key="LUCENE">Lucene - Core</project>
                        <description>&lt;p&gt;Robert Engels suggested the following idea, here:&lt;/p&gt;

&lt;p&gt;  &lt;a href=&quot;http://www.gossamer-threads.com/lists/lucene/java-dev/54217&quot; class=&quot;external-link&quot;&gt;http://www.gossamer-threads.com/lists/lucene/java-dev/54217&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;When merging in the stored fields from a segment, if the field name -&amp;gt;&lt;br/&gt;
number mapping is identical then we can simply bulk copy the entire&lt;br/&gt;
entry for the document rather than re-interpreting and then re-writing&lt;br/&gt;
the actual stored fields.&lt;/p&gt;

&lt;p&gt;I&apos;ve pulled the code from the above thread and got it working on the&lt;br/&gt;
current trunk.&lt;/p&gt;</description>
                <environment></environment>
            <key id="12381726">LUCENE-1043</key>
            <summary>Speedup merging of stored fields when field mapping &quot;matches&quot;</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                    <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png">Closed</status>
                    <resolution id="1">Fixed</resolution>
                                <assignee username="mikemccand">Michael McCandless</assignee>
                                <reporter username="mikemccand">Michael McCandless</reporter>
                        <labels>
                    </labels>
                <created>Fri, 2 Nov 2007 18:29:15 +0000</created>
                <updated>Fri, 25 Jan 2008 03:24:08 +0000</updated>
                    <resolved>Thu, 8 Nov 2007 11:08:10 +0000</resolved>
                            <version>2.2</version>
                                <fixVersion>2.3</fixVersion>
                                <component>core/index</component>
                        <due></due>
                    <votes>0</votes>
                        <watches>0</watches>
                                                    <comments>
                    <comment id="12539660" author="mikemccand" created="Fri, 2 Nov 2007 18:30:02 +0000"  >&lt;p&gt;Initial patch.  All tests pass.&lt;/p&gt;</comment>
                    <comment id="12539675" author="yseeley@gmail.com" created="Fri, 2 Nov 2007 19:13:56 +0000"  >&lt;p&gt;You&apos;re fast!&lt;/p&gt;

&lt;p&gt;Future optimizations could include bulk copying multiple documents at once (all ranges between deleted docs).  The speedup would probably be greatest for small docs, but I&apos;m not sure if it would be worth it or not.&lt;/p&gt;

&lt;p&gt;More controversial:  maybe even expand the number of docs that can be bulk copied by  not bothering removing deleted docs if it&apos;s some very small number (unless it&apos;s an optimize).  This is probably not worth it.&lt;/p&gt;</comment>
                    <comment id="12539682" author="mikemccand" created="Fri, 2 Nov 2007 19:39:46 +0000"  >&lt;blockquote&gt;
&lt;p&gt;Future optimizations could include bulk copying multiple documents at once (all ranges between deleted docs). The speedup would probably be greatest for small docs, but I&apos;m not sure if it would be worth it or not.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Ooh, I like that idea!  I&apos;ll explore that.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;More controversial: maybe even expand the number of docs that can be bulk copied by not bothering removing deleted docs if it&apos;s some very small number (unless it&apos;s an optimize). This is probably not worth it.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That&apos;s a neat idea too but I agree likely not worth it.&lt;/p&gt;

&lt;p&gt;Another idea: we can &lt;b&gt;almost&lt;/b&gt; just concatenate the posting lists&lt;br/&gt;
(frq/prx) for each term, because they are &quot;delta coded&quot; (we write the&lt;br/&gt;
delta between docIDs).  The only catch is you have to &quot;stitch up&quot; the&lt;br/&gt;
boundary: you have to read the docID from the start of the next&lt;br/&gt;
segment, write the delta-code, then you can copy the remaining bytes.&lt;br/&gt;
I think this could be a big win especially when merging larger&lt;br/&gt;
segments.&lt;/p&gt;</comment>
                    <comment id="12539686" author="rengels@ix.netcom.com" created="Fri, 2 Nov 2007 19:48:47 +0000"  >&lt;p&gt;You have to be careful with the bulk copy because you will need to also copy the offsets from the source, sticking them up, and then write them in bulk.&lt;/p&gt;

&lt;p&gt;With large enough input and output buffers I am not sure the bulk copy will make that large a difference.&lt;/p&gt;</comment>
                    <comment id="12539688" author="yseeley@gmail.com" created="Fri, 2 Nov 2007 19:57:07 +0000"  >&lt;p&gt;re bulk copying: Ideally, read a group of docs into a buffer big enough that it triggers the IndexInput to read directly into it, and write directly from it.  The field index needs to be done int by int, but it&apos;s just adding a constant to all of them and probably isn&apos;t worth optimizing (trying to not fully encode/decode).... just loop over them ahead of time, fixing them up.  The total size of the stored fields to write is simply the difference between the indicies (need to slightly special case the end of the index of course...)&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Another idea: we can almost just concatenate the posting lists&lt;br/&gt;
(frq/prx) for each term, because they are &quot;delta coded&quot; (we write the&lt;br/&gt;
delta between docIDs)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Nice!  new JIRA issue?&lt;/p&gt;</comment>
                    <comment id="12539696" author="rengels@ix.netcom.com" created="Fri, 2 Nov 2007 20:38:04 +0000"  >&lt;p&gt;When bulk copying the documents, I think you need to:&lt;/p&gt;

&lt;p&gt;read array of long from index (8 * (ndocs+1)) in long&lt;span class=&quot;error&quot;&gt;&amp;#91;ndocs+1&amp;#93;&lt;/span&gt; offsets;&lt;br/&gt;
calculate length = offset&lt;span class=&quot;error&quot;&gt;&amp;#91;ndocs&amp;#93;&lt;/span&gt;-offset&lt;span class=&quot;error&quot;&gt;&amp;#91;0&amp;#93;&lt;/span&gt;;&lt;br/&gt;
read bytes of length from document file&lt;br/&gt;
startoffset = current output document stream position&lt;br/&gt;
write bytes to output document&lt;br/&gt;
modify offset[] adding startoffset-offset&lt;span class=&quot;error&quot;&gt;&amp;#91;0&amp;#93;&lt;/span&gt; to each entry&lt;br/&gt;
write offset[] in bulk to index output&lt;/p&gt;</comment>
                    <comment id="12539907" author="mikemccand" created="Sat, 3 Nov 2007 09:36:41 +0000"  >&lt;blockquote&gt;
&lt;p&gt;Nice!  new JIRA issue?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes, though I need to mull it over some ... I think it would require a&lt;br/&gt;
change to the index file format to have each term record the last&lt;br/&gt;
docID in its posting list, which then increases the size of the&lt;br/&gt;
index.  Maybe we could do it only when the posting list is long.  So&lt;br/&gt;
there are tricky tradeoffs....&lt;/p&gt;</comment>
                    <comment id="12540228" author="mikemccand" created="Mon, 5 Nov 2007 18:01:55 +0000"  >&lt;p&gt;Attached new rev of the patch, using the bulk copy approach instead.&lt;/p&gt;

&lt;p&gt;I changed the approach slightly: I allocate an array to store the&lt;br/&gt;
length (in bytes) of each docs&apos;s stored fields, but then I do a low&lt;br/&gt;
level byte copy (added IndexOutput.copyBytes) from the FieldsReader&apos;s&lt;br/&gt;
fieldsStream to the FieldWriter&apos;s fieldsStream.&lt;/p&gt;

&lt;p&gt;All tests pass.  I plan to commit in a day or two.&lt;/p&gt;</comment>
                    <comment id="12541024" author="mikemccand" created="Thu, 8 Nov 2007 11:08:10 +0000"  >&lt;p&gt;I just committed this.  Thanks Robert!&lt;/p&gt;</comment>
                </comments>
                    <attachments>
                    <attachment id="12368892" name="LUCENE-1043.patch" size="7875" author="mikemccand" created="Fri, 2 Nov 2007 18:30:02 +0000" />
                    <attachment id="12368987" name="LUCENE-1043.take2.patch" size="12757" author="mikemccand" created="Mon, 5 Nov 2007 18:01:55 +0000" />
                </attachments>
            <subtasks>
        </subtasks>
                <customfields>
                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                <customfieldname>Attachment count</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>2.0</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                <customfieldname>Date of First Response</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>Fri, 2 Nov 2007 19:13:56 +0000</customfieldvalue>

                </customfieldvalues>
            </customfield>
                                                                                                        <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Global Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>12702</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                <customfieldname>Lucene Fields</customfieldname>
                <customfieldvalues>
                        <customfieldvalue key="10121"><![CDATA[New]]></customfieldvalue>
    
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>26686</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                <customfieldname>Time in Status</customfieldname>
                <customfieldvalues>
                    
                </customfieldvalues>
            </customfield>
                            </customfields>
    </item>
</channel>
</rss>