<!-- 
RSS generated by JIRA (5.2.8#851-sha1:3262fdc28b4bc8b23784e13eadc26a22399f5d88) at Tue Jul 16 13:24:06 UTC 2013

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/LUCENE-565/LUCENE-565.xml?field=key&field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>5.2.8</version>
        <build-number>851</build-number>
        <build-date>26-02-2013</build-date>
    </build-info>

<item>
            <title>[LUCENE-565] Supporting deleteDocuments in IndexWriter (Code and Performance Results Provided)</title>
                <link>https://issues.apache.org/jira/browse/LUCENE-565</link>
                <project id="12310110" key="LUCENE">Lucene - Core</project>
                        <description>&lt;p&gt;Today, applications have to open/close an IndexWriter and open/close an&lt;br/&gt;
IndexReader directly or indirectly (via IndexModifier) in order to handle a&lt;br/&gt;
mix of inserts and deletes. This performs well when inserts and deletes&lt;br/&gt;
come in fairly large batches. However, the performance can degrade&lt;br/&gt;
dramatically when inserts and deletes are interleaved in small batches.&lt;br/&gt;
This is because the ramDirectory is flushed to disk whenever an IndexWriter&lt;br/&gt;
is closed, causing a lot of small segments to be created on disk, which&lt;br/&gt;
eventually need to be merged.&lt;/p&gt;

&lt;p&gt;We would like to propose a small API change to eliminate this problem. We&lt;br/&gt;
are aware that this kind change has come up in discusions before. See&lt;br/&gt;
&lt;a href=&quot;http://www.gossamer-threads.com/lists/lucene/java-dev/23049?search_string=indexwriter%20delete;#23049&quot; class=&quot;external-link&quot;&gt;http://www.gossamer-threads.com/lists/lucene/java-dev/23049?search_string=indexwriter%20delete;#23049&lt;/a&gt;&lt;br/&gt;
. The difference this time is that we have implemented the change and&lt;br/&gt;
tested its performance, as described below.&lt;/p&gt;

&lt;p&gt;API Changes&lt;br/&gt;
-----------&lt;br/&gt;
We propose adding a &quot;deleteDocuments(Term term)&quot; method to IndexWriter.&lt;br/&gt;
Using this method, inserts and deletes can be interleaved using the same&lt;br/&gt;
IndexWriter.&lt;/p&gt;

&lt;p&gt;Note that, with this change it would be very easy to add another method to&lt;br/&gt;
IndexWriter for updating documents, allowing applications to avoid a&lt;br/&gt;
separate delete and insert to update a document.&lt;/p&gt;

&lt;p&gt;Also note that this change can co-exist with the existing APIs for deleting&lt;br/&gt;
documents using an IndexReader. But if our proposal is accepted, we think&lt;br/&gt;
those APIs should probably be deprecated.&lt;/p&gt;

&lt;p&gt;Coding Changes&lt;br/&gt;
--------------&lt;br/&gt;
Coding changes are localized to IndexWriter. Internally, the new&lt;br/&gt;
deleteDocuments() method works by buffering the terms to be deleted.&lt;br/&gt;
Deletes are deferred until the ramDirectory is flushed to disk, either&lt;br/&gt;
because it becomes full or because the IndexWriter is closed. Using Java&lt;br/&gt;
synchronization, care is taken to ensure that an interleaved sequence of&lt;br/&gt;
inserts and deletes for the same document are properly serialized.&lt;/p&gt;

&lt;p&gt;We have attached a modified version of IndexWriter in Release 1.9.1 with&lt;br/&gt;
these changes. Only a few hundred lines of coding changes are needed. All&lt;br/&gt;
changes are commented by &quot;CHANGE&quot;. We have also attached a modified version&lt;br/&gt;
of an example from Chapter 2.2 of Lucene in Action.&lt;/p&gt;

&lt;p&gt;Performance Results&lt;br/&gt;
-------------------&lt;br/&gt;
To test the performance our proposed changes, we ran some experiments using&lt;br/&gt;
the TREC WT 10G dataset. The experiments were run on a dual 2.4 Ghz Intel&lt;br/&gt;
Xeon server running Linux. The disk storage was configured as RAID0 array&lt;br/&gt;
with 5 drives. Before indexes were built, the input documents were parsed&lt;br/&gt;
to remove the HTML from them (i.e., only the text was indexed). This was&lt;br/&gt;
done to minimize the impact of parsing on performance. A simple&lt;br/&gt;
WhitespaceAnalyzer was used during index build.&lt;/p&gt;

&lt;p&gt;We experimented with three workloads:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Insert only. 1.6M documents were inserted and the final&lt;br/&gt;
    index size was 2.3GB.&lt;/li&gt;
	&lt;li&gt;Insert/delete (big batches). The same documents were&lt;br/&gt;
    inserted, but 25% were deleted. 1000 documents were&lt;br/&gt;
    deleted for every 4000 inserted.&lt;/li&gt;
	&lt;li&gt;Insert/delete (small batches). In this case, 5 documents&lt;br/&gt;
    were deleted for every 20 inserted.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;                                current       current          new&lt;br/&gt;
Workload                      IndexWriter  IndexModifier   IndexWriter&lt;br/&gt;
-----------------------------------------------------------------------&lt;br/&gt;
Insert only                     116 min       119 min        116 min&lt;br/&gt;
Insert/delete (big batches)       &amp;#8211;          135 min        125 min&lt;br/&gt;
Insert/delete (small batches)     &amp;#8211;          338 min        134 min&lt;/p&gt;

&lt;p&gt;As the experiments show, with the proposed changes, the performance&lt;br/&gt;
improved by 60% when inserts and deletes were interleaved in small batches.&lt;/p&gt;


&lt;p&gt;Regards,&lt;br/&gt;
Ning&lt;/p&gt;


&lt;p&gt;Ning Li&lt;br/&gt;
Search Technologies&lt;br/&gt;
IBM Almaden Research Center&lt;br/&gt;
650 Harry Road&lt;br/&gt;
San Jose, CA 95120&lt;/p&gt;</description>
                <environment></environment>
            <key id="12333383">LUCENE-565</key>
            <summary>Supporting deleteDocuments in IndexWriter (Code and Performance Results Provided)</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                    <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png">Closed</status>
                    <resolution id="1">Fixed</resolution>
                                <assignee username="mikemccand">Michael McCandless</assignee>
                                <reporter username="ningli">Ning Li</reporter>
                        <labels>
                    </labels>
                <created>Tue, 9 May 2006 07:39:35 +0100</created>
                <updated>Tue, 27 Feb 2007 18:10:33 +0000</updated>
                    <resolved>Tue, 13 Feb 2007 10:56:09 +0000</resolved>
                                            <fixVersion>2.1</fixVersion>
                                <component>core/index</component>
                        <due></due>
                    <votes>8</votes>
                        <watches>7</watches>
                                                    <comments>
                    <comment id="12378557" author="cutting" created="Tue, 9 May 2006 10:24:34 +0100"  >&lt;p&gt;Can you please attach diffs rather than complete files?  The diffs should not not contain CHANGE comments.  To generate diffs, check Lucene out of Subversion, make your changes, then, from the Lucene trunk, run something like &apos;svn diff &amp;gt; my.patch&apos;.  New files should first be added with &apos;svn add&apos; so that they&apos;re included in the diff.  Thanks!&lt;/p&gt;
</comment>
                    <comment id="12378673" author="ningli" created="Wed, 10 May 2006 01:52:39 +0100"  >&lt;p&gt;Here is the diff file of IndexWriter.java.&lt;/p&gt;</comment>
                    <comment id="12419396" author="otis" created="Thu, 6 Jul 2006 11:25:15 +0100"  >&lt;p&gt;I took a look at the patch and it looks good to me (anyone else had a look)?&lt;br/&gt;
Unfortunately, I couldn&apos;t get the patch to apply &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;$ patch -F3 &amp;lt; IndexWriter.patch&lt;br/&gt;
(Stripping trailing CRs from patch.)&lt;br/&gt;
patching file IndexWriter.java&lt;br/&gt;
Hunk #1 succeeded at 58 with fuzz 1.&lt;br/&gt;
Hunk #2 succeeded at 112 (offset 2 lines).&lt;br/&gt;
Hunk #4 succeeded at 504 (offset 33 lines).&lt;br/&gt;
Hunk #6 succeeded at 605 with fuzz 2 (offset 57 lines).&lt;br/&gt;
missing header for unified diff at line 259 of patch&lt;br/&gt;
(Stripping trailing CRs from patch.)&lt;br/&gt;
can&apos;t find file to patch at input line 259&lt;br/&gt;
Perhaps you should have used the -p or --strip option?&lt;br/&gt;
The text leading up to this was:&lt;br/&gt;
...&lt;br/&gt;
...&lt;br/&gt;
...&lt;br/&gt;
File to patch: IndexWriter.java&lt;br/&gt;
patching file IndexWriter.java&lt;br/&gt;
Hunk #1 FAILED at 802.&lt;br/&gt;
Hunk #2 succeeded at 745 with fuzz 2 (offset -131 lines).&lt;br/&gt;
1 out of 2 hunks FAILED &amp;#8211; saving rejects to file IndexWriter.java.rej&lt;/p&gt;


&lt;p&gt;Would it be possible for you to regenerate the patch against IndexWriter in HEAD?&lt;/p&gt;

&lt;p&gt;Also, I noticed ^Ms in the patch, but I can take care of those easily (dos2unix).&lt;/p&gt;

&lt;p&gt;Finally, I noticed in 2-3 places that the simple logging via &quot;infoStream&quot; variable was removed, for example:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (infoStream != null) infoStream.print(&quot;merging segments&quot;);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Perhaps this was just an oversight?&lt;/p&gt;

&lt;p&gt;Looking forward to the new patch. Thanks!&lt;/p&gt;</comment>
                    <comment id="12419580" author="ningli" created="Fri, 7 Jul 2006 02:46:45 +0100"  >&lt;p&gt;For an overview of my changes, I&apos;ll repeat some of what I said in&lt;br/&gt;
my earlier e-mail (see &lt;a href=&quot;http://www.gossamer-threads.com/lists/lucene/java-dev/35143&quot; class=&quot;external-link&quot;&gt;http://www.gossamer-threads.com/lists/lucene/java-dev/35143&lt;/a&gt;),&lt;br/&gt;
then add more detail about specific coding changes.&lt;/p&gt;

&lt;p&gt;Overview&lt;br/&gt;
--------&lt;br/&gt;
Today, applications have to open/close an IndexWriter and&lt;br/&gt;
open/close an IndexReader directly or indirectly (via IndexModifier)&lt;br/&gt;
in order to handle a mix of inserts and deletes. This performs well&lt;br/&gt;
when inserts and deletes come in fairly large batches. However, the&lt;br/&gt;
performance can degrade dramatically when inserts and deletes are&lt;br/&gt;
interleaved in small batches. This is because the ramDirectory is&lt;br/&gt;
flushed to disk whenever an IndexWriter is closed, causing a lot of&lt;br/&gt;
small segments to be created on disk, which eventually need to be&lt;br/&gt;
merged.&lt;/p&gt;

&lt;p&gt;API Changes&lt;br/&gt;
-----------&lt;br/&gt;
We propose adding a &quot;deleteDocuments(Term term)&quot; method to&lt;br/&gt;
IndexWriter. Using this method, inserts and deletes can be&lt;br/&gt;
interleaved using the same IndexWriter.&lt;/p&gt;

&lt;p&gt;Coding Changes&lt;br/&gt;
--------------&lt;br/&gt;
Coding changes are localized to IndexWriter. Internally, the new&lt;br/&gt;
deleteDocuments() method works by buffering the terms to be deleted.&lt;br/&gt;
Deletes are deferred until the ramDirectory is flushed to disk,&lt;br/&gt;
either because it becomes full or because the IndexWriter is closed.&lt;br/&gt;
Using Java synchronization, care is taken to ensure that an&lt;br/&gt;
interleaved sequence of inserts and deletes for the same document&lt;br/&gt;
are properly serialized. &lt;/p&gt;

&lt;p&gt;For simplicity of explanation, let&apos;s assume the index resides in a&lt;br/&gt;
disk-based directory.&lt;/p&gt;

&lt;p&gt;Changes to the IndexWriter variables:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;segmentInfos used to store the info of all segments (on disk&lt;br/&gt;
    or in ram). Now it only stores the info of segments on disk.&lt;/li&gt;
	&lt;li&gt;ramSegmentInfos is a new variable which stores the info of just&lt;br/&gt;
    ram segments.&lt;/li&gt;
	&lt;li&gt;bufferedDeleteTerms is a new variable which buffers delete terms&lt;br/&gt;
    before they are applied.&lt;/li&gt;
	&lt;li&gt;maxBufferedDeleteTerms is similar to maxBufferedDocs. It controls&lt;br/&gt;
    the max number of delete terms that can be buffered before they&lt;br/&gt;
    must be flushed to disk.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Changes to IndexWriter methods:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;addDocument()&lt;br/&gt;
    The info of the new ram segment is added to ramSegmentInfos.&lt;/li&gt;
	&lt;li&gt;deleteDocuments(), batchDeleteDocuments()&lt;br/&gt;
    The terms are added to bufferedDeleteTerms. bufferedDeleteTerms&lt;br/&gt;
    also records the current number of documents buffered in ram, so&lt;br/&gt;
    the delete terms can be applied to ram segments as well as&lt;br/&gt;
    the segments on disk.&lt;/li&gt;
	&lt;li&gt;flushRamSegments()&lt;br/&gt;
    Step 1: Apply buffered delete terms to all the segments on disk.&lt;br/&gt;
    Step 2: Merge all the ram segments into one segment on disk.&lt;br/&gt;
    Step 3: Apply buffered delete terms to the new segment appropriately,&lt;br/&gt;
            so that a delete term is only applied to the documents&lt;br/&gt;
            buffered before it, but not to those buffered after it.&lt;br/&gt;
    Step 4: Clean up and commit the change to the index (both the new&lt;br/&gt;
            segment and the .del files if it applies).&lt;/li&gt;
	&lt;li&gt;maybeMergeSegments()&lt;br/&gt;
    Before, a flush would be triggered only if enough documents were&lt;br/&gt;
    buffered. Now a flush is triggered if enough documents are&lt;br/&gt;
    buffered OR if enough delete terms are buffered.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12419605" author="otis" created="Fri, 7 Jul 2006 05:31:58 +0100"  >&lt;p&gt;Thanks for all the information about coding changes, that makes it easier to understand the diff.&lt;br/&gt;
Ideally this will become comments in the new diff, which I can commit.&lt;/p&gt;

&lt;p&gt;Yonik mentioned this in email.  It does sound like a better place for this might be in a higher level class.  IndexWriter would really not be just a writer/appender once delete functionality is added to it, even if it&apos;s the IndexReaders behind the scenes doing the work.  So if you are going to be redoing the patch, consider this.&lt;/p&gt;

&lt;p&gt;Perhaps IndexModifier methods should be deprecated and it should get a new/your API?&lt;/p&gt;</comment>
                    <comment id="12419942" author="ningli" created="Mon, 10 Jul 2006 11:38:37 +0100"  >&lt;p&gt;Hi Otis,&lt;/p&gt;

&lt;p&gt;I&apos;ve attached two patch files:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;IndexWriter.July09.patch is an updated version of the old patch.&lt;/li&gt;
	&lt;li&gt;NewIndexModifier.July09.patch makes minimal changes to IndexWriter and puts new functionalities in a new class called NewIndexModifier. I didn&apos;t name it IndexModifier because the two are unrelated and I don&apos;t want a diff of the two.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;All unit test succeeded except the following one:&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; Testcase: testIndex(org.apache.lucene.index.TestIndexModifier):	FAILED&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; expected:&amp;lt;3&amp;gt; but was:&amp;lt;4&amp;gt;&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; junit.framework.AssertionFailedError: expected:&amp;lt;3&amp;gt; but was:&amp;lt;4&amp;gt;&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;junit&amp;#93;&lt;/span&gt; 	at org.apache.lucene.index.TestIndexModifier.testIndex(TestIndexModifier.java:67)&lt;/p&gt;

&lt;p&gt;However, the unit test has a problem, not the patch: IndexWriter&apos;s docCount() does not tell the actual number of documents in an index, only IndexReader&apos;s numDocs() does. For example, in a similar test below, where 10 documents are added, then 1 deleted, then 2 added, the last call to docCount() returns 12, not 11, with or without the patch.&lt;/p&gt;

&lt;p&gt;  public void testIndexSimple() throws IOException {&lt;br/&gt;
    Directory ramDir = new RAMDirectory();&lt;br/&gt;
    IndexModifier i = new IndexModifier(ramDir, new StandardAnalyzer(), true);&lt;br/&gt;
    // add 10 documents initially&lt;br/&gt;
    for (int count = 0; count &amp;lt; 10; count++) &lt;/p&gt;
{
       i.addDocument(getDoc());
    }
&lt;p&gt;    i.flush();&lt;br/&gt;
    i.optimize();&lt;br/&gt;
    assertEquals(10, i.docCount());&lt;br/&gt;
    i.deleteDocument(0);&lt;br/&gt;
    i.flush();&lt;br/&gt;
    assertEquals(9, i.docCount());&lt;br/&gt;
    i.addDocument(getDoc());&lt;br/&gt;
    i.addDocument(getDoc());&lt;br/&gt;
    i.flush();&lt;br/&gt;
    assertEquals(12, i.docCount());&lt;br/&gt;
  }&lt;/p&gt;

&lt;p&gt;The reason for the docCount() difference in the unit test (which does not affect the correctness of the patch) is that flushRamSegments() in the patch merges all and only the segments in ram and write to disk, whereas the original flushRamSegments() merges not only the segments in ram but &lt;b&gt;sometimes&lt;/b&gt; also one segment from disk (see in that function the comment &quot;// add one FS segment?&quot;).&lt;/p&gt;

&lt;p&gt;Regards,&lt;br/&gt;
Ning&lt;/p&gt;</comment>
                    <comment id="12422007" author="ningli" created="Wed, 19 Jul 2006 01:32:20 +0100"  >&lt;p&gt;Hopefully, third time&apos;s a charm. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;I rewrote IndexWriter in such a way that semantically it&apos;s the same as before, but it provides extension points so that delete-by-term, delete-by-query, and more functionalities can be easily supported in a subclass. NewIndexModifier is such a subclass that supports delete-by-term.&lt;/p&gt;

&lt;p&gt;Here is an overview of the changes:&lt;/p&gt;

&lt;p&gt;Changes to IndexWriter&lt;br/&gt;
Changes to IndexWriter variables:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;segmentInfos used to store the info of all segments (on disk or in ram). Now it&lt;br/&gt;
    only stores the info of segments on disk.&lt;/li&gt;
	&lt;li&gt;ramSegmentInfos is a new variable which stores the info of just ram segments.&lt;br/&gt;
Changes to IndexWriter methods:&lt;/li&gt;
	&lt;li&gt;addDocument()&lt;br/&gt;
    The info of the new ram segment is added to ramSegmentInfos.&lt;/li&gt;
	&lt;li&gt;maybeMergeSegments()&lt;br/&gt;
    toFlushRamSegments() is called at the beginning to decide whether a flush should take place.&lt;/li&gt;
	&lt;li&gt;flushRamSegments()&lt;br/&gt;
    doAfterFlushRamSegments() is called after all ram segments are merged and flushed to disk.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;NewIndexModifier&lt;br/&gt;
New variables:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;bufferedDeleteTerms is a new variable which buffers delete terms&lt;br/&gt;
    before they are applied.&lt;/li&gt;
	&lt;li&gt;maxBufferedDeleteTerms is similar to maxBufferedDocs. It controls&lt;br/&gt;
    the max number of delete terms that can be buffered before they&lt;br/&gt;
    must be flushed to disk.&lt;br/&gt;
Overloaded/new methods:&lt;/li&gt;
	&lt;li&gt;deleteDocuments(), batchDeleteDocuments()&lt;br/&gt;
    The terms are added to bufferedDeleteTerms. bufferedDeleteTerms&lt;br/&gt;
    also records the current number of documents buffered in ram,&lt;br/&gt;
    so the delete terms can be applied to ram segments as well as&lt;br/&gt;
    the segments on disk.&lt;/li&gt;
	&lt;li&gt;toFlushRamSegments()&lt;br/&gt;
    In IndexWriter, a flush would be triggered only if enough documents were&lt;br/&gt;
    buffered. Now a flush is triggered if enough documents are&lt;br/&gt;
    buffered OR if enough delete terms are buffered.&lt;/li&gt;
	&lt;li&gt;doAfterlushRamSegments()&lt;br/&gt;
    Step 1: Apply buffered delete terms to all the segments on disk.&lt;br/&gt;
    Step 2: Apply buffered delete terms to the new segment appropriately,&lt;br/&gt;
            so that a delete term is only applied to the documents&lt;br/&gt;
            buffered before it, but not to those buffered after it.&lt;br/&gt;
    Step 3: Clean up the buffered delete terms.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12428035" author="doronc" created="Tue, 15 Aug 2006 05:19:35 +0100"  >&lt;p&gt;I tried out this patch (July18), and have a few comments...&lt;/p&gt;

&lt;p&gt;First, it is nice to be able to add/remove documents with no need to care for switching between readers and writers, and without worrying for performance issues as result of that switching. I did not test for performance yet.&lt;/p&gt;

&lt;p&gt;This post is quite long, so here is an outline...&lt;br/&gt;
(1) Compile error in test code&lt;br/&gt;
(2) Failing tests - is this patch actually fixing a bug in current flushRamSegments()?&lt;br/&gt;
(3) Additional tests I ran&lt;br/&gt;
(4) Javadocs remarks&lt;br/&gt;
(5) deleteDocument(int doc) not implemented&lt;br/&gt;
(6) flush() not implemented&lt;br/&gt;
(7) Method name - batchDeleteDocuments(Term[]) &lt;br/&gt;
(8) Class name and placement + What&apos;s Next for this patch&lt;/p&gt;

&lt;p&gt;------------ (1) Compile error in test code &lt;br/&gt;
The new TestWriterDelete does not reflect recent name change from IndexWriter to NewIndexModifier. Easily fixed by renaming accordingly in that file.&lt;/p&gt;

&lt;p&gt;------------ (2) Failing tests - does this patch also fix a bug in current flushRamSegments()?&lt;br/&gt;
&quot;ant test&quot; has one failure: TestIndexModifier.testIndex().&lt;br/&gt;
This is the same issue that Ning described above. However I think it exposes a bug in current flushRamSegments(): when an index with 1 segment on disk that has 2 documents, one of which is deleted, and 1 segment in memory, is closed, this method decides to merge - prematurely - the two segments into one. This wrong behavior (if I understand things correctly) is - by &quot;mistake&quot; - causing TestIndexModifier.testIndex() to pass in the current implementation of flushRamSegments(). But this comes with the cost of too many merges. If one is interleaving adds and deletes this bug would become costly. I will post a separate question on this to the dev forum, to discuss if this is indeed a bug.&lt;/p&gt;

&lt;p&gt;------------ (3) Additional tests I ran &lt;br/&gt;
I wanted to verify that all existing functions (well, at least tested ones..) are working with the new class (NewIndexModifier). So I temporarily renamed the existing IndexWriter to IndexWriter0, and renamed NewIndexModifier to IndexWriter (now extending IndexWriter0). For compiling, now, also had to temporarily modify args from IndexWriter to IndexWriter0 in 3 classes - DocumentWriter, SegmentMerger, and also from NewIndexModifier to IndexWriter in the new TestWriteDelete. (Note again: these modifications are temporary, just for the sake of testing this new class as if it was the new IndexWriter, which it is not.) Now all the tests were using the new class instead of the original IndexWriter. &lt;/p&gt;

&lt;p&gt;All tests passed, except for TestIndexModifier.testIndex() - this is the same failure as above - so, no problem detected in new class.&lt;/p&gt;

&lt;p&gt;------------ (4) Javadocs Remarks&lt;br/&gt;
Current Javadocs for the new class focus on changes to the implementation. I think this description of implementation changes should be made regular Java comments (for developers), and instead should add a shorter javadoc that describes the API for users, and the implications on behavior as result of buffering deletes.&lt;/p&gt;

&lt;p&gt;------------ (5) deleteDocument(int doc) not implemented&lt;br/&gt;
Original IndexModifier has a delete(int docs), the new class doesn&apos;t. At first this seems ok, since internal doc IDs are not accessible through index writer (unlike index reader). But IndexModifier also does not provide access to doc-ids. So why was delete-by-id enabled in IndexModifier? Perhaps there&apos;s a good reason for it, that I fail to see - if so, it should probably be added to the new class as well. Adding this is required if the new class would eventually replace the implementation of current index modifier.&lt;/p&gt;

&lt;p&gt;------------ (6) flush() not implemented&lt;br/&gt;
Original IndexModifier has a flush(int docs) method, allowing to commit any pending changes. I think it would be nice to have this feature here as well, for forcing any pending changes (without caller having to modify the max-bufferred value). This would allow more control when using this class. Again, adding this is required if the new class would eventually replace the implementation of current index modifier.&lt;/p&gt;

&lt;p&gt;------------ (7) Method name - batchDeleteDocuments(Term[]) &lt;br/&gt;
I would prefer it to be called deleteDocuments(Term[]), and let Java decide which method to call. Main reason is developers would expect that methods with similar semantics are named similarly, especially when using IDEs like Eclipse, where users type &quot;i.del&quot; and the IDE lets them select from all the methods that start with &quot;del&quot;.&lt;/p&gt;

&lt;p&gt;------------ (8) Class name and placement + What&apos;s Next for this patch&lt;br/&gt;
Performance test should be added for this new class. Also, I did not code review the actual code changes to IndexWriter and the code of NewIndexModifier itself.&lt;/p&gt;

&lt;p&gt;It seems to me that this class would be very useful for users, either as a new class or if it replaces the current implementation of IndexModifier. Latter would be possible only if the 2 missing methods mentioned above are added. In this case, the &quot;immediate delete&quot; behavior of current IndexModifier should be possible to achieve by users, by setting maxBefferedDeleteTerms to 1.&lt;/p&gt;

&lt;p&gt;One disadvantage of this class vs. current IndexModifier is the ability to add access to further methods of IndexReader. With current IndexModifier this is very simple (though not always efficient) - just follow code template in existing methods, i.e. close writer/reader and open reader/writer as required. With the new class, exposing further methods of IndexReader would be more of a challenge. Perhaps having a multiReader on all segment readers can do. I am not sure to what extent this should be a consideration, so just bringing it up. &lt;/p&gt;

&lt;p&gt;So, If this class replaces IndexModifier - fine. If not, how about calling it BufferredIndexWriter?&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Doron&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12429780" author="jasonhusong" created="Tue, 22 Aug 2006 20:00:37 +0100"  >&lt;p&gt;I tested just the IndexWriter from this code base, it does not seem to work.  NewIndexModifier does work.  I simply used IndexWriter to create several documents and then search for them.  Nothing came back even though it seems something was written to disk.&lt;/p&gt;</comment>
                    <comment id="12430128" author="ninglili" created="Wed, 23 Aug 2006 23:42:08 +0100"  >&lt;p&gt;&amp;gt; Yes I am including this patch as it is very useful for increasing&lt;br/&gt;
&amp;gt; the efficiency of updates as you described.  I will be conducting&lt;br/&gt;
&amp;gt; more tests and will post any results.  Yes a patch for IndexWriter&lt;br/&gt;
&amp;gt; will be useful so that the entirety of this build will work.&lt;br/&gt;
&amp;gt; Thanks!&lt;/p&gt;

&lt;p&gt;I&apos;ve attached a patch that works with the current code. The&lt;br/&gt;
implementation of IndexWriter and NewIndexModifier is the same as&lt;br/&gt;
the last patch. I removed the &quot;singleDocSegmentsCount&quot; optimization&lt;br/&gt;
from this patch since my IndexWriter checks singleDocSegmentsCount&lt;br/&gt;
by simply calling ramSegmentInfos.size().&lt;/p&gt;

&lt;p&gt;This patch had evolved with the help of many good discussions&lt;br/&gt;
(thanks!) since it came out in May. Here is the current state of&lt;br/&gt;
the patch:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;This patch aims at enabling users to do inserts and general&lt;br/&gt;
    deletes (delete-by-term, and later delete-by-query) without&lt;br/&gt;
    switching between writers and readers.&lt;/li&gt;
	&lt;li&gt;The goal is achieved by rewritting IndexWriter in such a way&lt;br/&gt;
    that semantically it&apos;s the same as before, but it provides&lt;br/&gt;
    extension points so that delete-by-term, delete-by-query, and&lt;br/&gt;
    more functionalities can be easily supported in a subclass.&lt;/li&gt;
	&lt;li&gt;NewIndexModifier extends IndexWriter and supports delete-by-term&lt;br/&gt;
    by simply overriding two methods: toFlushRamSegment() which&lt;br/&gt;
    decides if a flush should happen, and doAfterFlushRamSegments()&lt;br/&gt;
    which does proper work after a flush is done.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Suggestions are welcome! Especially those that may help it get&lt;br/&gt;
committed. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="12430130" author="ninglili" created="Wed, 23 Aug 2006 23:43:58 +0100"  >&lt;p&gt;Doron, thank you very much for the review! I want to briefly comment&lt;br/&gt;
on one of your comments:&lt;/p&gt;

&lt;p&gt;&amp;gt; (5) deleteDocument(int doc) not implemented&lt;/p&gt;

&lt;p&gt;I deliberately left that one out. This is because document ids are&lt;br/&gt;
changing as documents are deleted and segments are merged. Users&lt;br/&gt;
don&apos;t know exactly when segments are merged thus ids are changed&lt;br/&gt;
when using IndexModifier. Thus I don&apos;t think it should be supported&lt;br/&gt;
in IndexModifier at all.&lt;/p&gt;</comment>
                    <comment id="12430361" author="jasonhusong" created="Fri, 25 Aug 2006 00:42:37 +0100"  >&lt;p&gt;This IndexWriter seems to work.  Thanks.  Great work!&lt;/p&gt;</comment>
                    <comment id="12430679" author="doronc" created="Sat, 26 Aug 2006 02:21:29 +0100"  >&lt;p&gt;I ran a performance test for interleaved adds and removes - and compared between IndexModifier and NewIndexModifier. &lt;/p&gt;

&lt;p&gt;Few setups were tested, with a few combinations of &quot;consecutive adds before a delete takes place&quot;, maxBufferredDocs, and &quot;number of total test iterations&quot;, where each iteration does the conseutive adds and then does the deletes.&lt;/p&gt;

&lt;p&gt;Each setup ran in this order - orig indexModifier, new one, orig, new one, and the best time out of the two runs was used.&lt;/p&gt;

&lt;p&gt;Results indicate that NewIndexModifier is far faster for most setups. &lt;/p&gt;

&lt;p&gt;Attached is the performance test, the performance results, and the log of the run. The performance test is written as a Junit test, and it fails in case the original IndexModfier is faster than the new one by more than 1 second (smaller than 1 sec difference is considered noise). &lt;/p&gt;

&lt;p&gt;Test was run on XP (SP1) with IBM JDK 1.5.&lt;/p&gt;

&lt;p&gt;Test was first failing with &quot;access denied&quot; errors due to what seems to be an XP issue. So in order to run this test on XP (and probably other Windows platforms) the patch from &lt;a href=&quot;http://issues.apache.org/jira/browse/LUCENE-665&quot; class=&quot;external-link&quot;&gt;http://issues.apache.org/jira/browse/LUCENE-665&lt;/a&gt; should be applied first.&lt;/p&gt;

&lt;p&gt;It is interesting to notice that in addition to preformance gain, NewIndexModifier seems less sensitive to &quot;access denied&quot; XP problems, because it closes/reopens readers and writers less frequently, and indeed, at least in my runs, these errors had to be bypassed (by the &quot;retry&quot; patch) only for the current index-modifier. &lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Doron&lt;/li&gt;
&lt;/ul&gt;

</comment>
                    <comment id="12431342" author="jasonhusong" created="Tue, 29 Aug 2006 20:55:25 +0100"  >&lt;p&gt;It seems this writer works, but then some mysterious happens to the index and the searcher can no longer read it.  I am using this in conjunction with Solr.  The index files look ok, however a search will return nothing.  I have seen this repeatedly over about 1 weeks time.&lt;/p&gt;</comment>
                    <comment id="12431354" author="doronc" created="Tue, 29 Aug 2006 21:20:37 +0100"  >&lt;p&gt;Is it that results that were returned are suddenly (say after updates) not returned anymore (indicating something bad happened to existing index)?&lt;/p&gt;

&lt;p&gt;Or is it that the search does not reflect recent changes? &lt;/p&gt;

&lt;p&gt;I don&apos;t remember how often Solr closes and re-opens the writer/modifier...  with this patch a delete does not immediately cause a &quot;flush to disk&quot; - so flushes are controlled by closing the NewIndexModifier (and re-opening, since there no flush() method) and by the limits for max-bufferred-docs and max-bufferred-deletes. If this seems relevant to your case, what limits are in effect?&lt;/p&gt;</comment>
                    <comment id="12431400" author="jasonhusong" created="Tue, 29 Aug 2006 23:48:22 +0100"  >&lt;p&gt;I started to flush the deletes after making them, which opens a new NewIndexModifier afterwards.  I still see the same thing.  I am starting off by deleting all documents by matching on a Term that all of them have.  Commit (reopen), then perform a batch addDocuments.  Then when a search is executed nothing is returned, and after an optimize the index goes down to 1K.  Seems like some peculiarity in NewIndexModifier.  Seems like the new documents are deleted even after they are added.  &lt;/p&gt;</comment>
                    <comment id="12431419" author="doronc" created="Wed, 30 Aug 2006 01:16:21 +0100"  >&lt;p&gt;Just to make sure on the scenario - are you - &lt;br/&gt;
(1) using NewIndexModifier at all, or &lt;br/&gt;
(2) just letting Solr use this IndexWriter (with the code changes introduced to ebable NewIndexModifier) instead of the Lucene&apos;s svn-head (or cetrain release) IndexModifier. &lt;/p&gt;

&lt;p&gt;As is, Solr would not use NewIndexModifier or IndexModifier at all. &lt;/p&gt;

&lt;p&gt;For case (2) above the bufferred deletes logic is not in effect at all. &lt;/p&gt;

&lt;p&gt;I wonder if it possibe to re-create this with a simple Lucene stand-alone (test) program rather than with Solr - it would be easier to analyze.&lt;/p&gt;</comment>
                    <comment id="12431423" author="jasonhusong" created="Wed, 30 Aug 2006 01:19:55 +0100"  >&lt;p&gt;Good points... I&apos;ve actually used both NewIndexModifier and the parent.  I&apos;ve tried writing a new UpdateHandler, and incorporating the new IndexWriter into DirectUpdateHandler2.  I will create a non-Solr reproduction of the issue.  I guess it has something to do with ths doc ids being reused and so the new documents that are added are also marked as deleted as the number of documents would match almost exactly after the rebuild.  I am not an expert in regards to that aspect of Lucene.&lt;/p&gt;</comment>
                    <comment id="12431475" author="jasonhusong" created="Wed, 30 Aug 2006 06:40:27 +0100"  >&lt;p&gt;Having trouble reproducing this.  Probably something in the other code.  Thanks for the help and the patch, I feel more confident in it now.  &lt;/p&gt;</comment>
                    <comment id="12431757" author="jasonhusong" created="Thu, 31 Aug 2006 01:24:24 +0100"  >&lt;p&gt;I figured out the problem, the Solr DirectUpdateHandler2 expects to delete only a certain number of documents specifically the oldest first in some cases by using TermDocs and deleting by the doc id.  NewIndexModifier deletes at the level of the SegmentReader however.  Any good way to do this?&lt;/p&gt;</comment>
                    <comment id="12432046" author="doronc" created="Fri, 1 Sep 2006 06:11:43 +0100"  >&lt;p&gt;Updated performance test results - perf-test-res2.JPG - in avarage, the new code is  &lt;b&gt;9&lt;/b&gt;  times faster!&lt;/p&gt;

&lt;p&gt;What have changed? - in previous test I forgot to set max-buffered-deletes. &lt;/p&gt;

&lt;p&gt;After fixing so, I removed the test cases with max-buffer of 5,000 and up, because they consumed too much memory, and added more practical (I think) cases of 2000 and 3000. &lt;/p&gt;

&lt;p&gt;Here is a textual summary of the data in the attached image:&lt;/p&gt;

&lt;p&gt;max buf add/del         10          10       100      1000     2000      3000&lt;br/&gt;
iterations                       1          10        100       100      200          300&lt;br/&gt;
adds/iteration             10          10         10          10       10              10&lt;br/&gt;
dels/iteration                 5            5           5            5        5                  5&lt;br/&gt;
orig time (sec)           0.13      0.86        9.57      8.88    22.74      44.01&lt;br/&gt;
new  time (sec)          0.20      0.95       1.74      1.30    2.16          3.08&lt;br/&gt;
Improvement (sec)    -0.07    -0.09      7.83      7.58    20.58      40.94&lt;br/&gt;
Improvement  (%)     -55%     -11%      82%      85%      90%      93%&lt;/p&gt;

&lt;p&gt;Note: for the first two cases new code is slower by 11% and 55%, but this is a very short test case, - the absolute difference here is less than 100ms, comparing to the other cases, where the difference is measured in seconds and 10&apos;s of seconds.&lt;/p&gt;</comment>
                    <comment id="12432155" author="yseeley@gmail.com" created="Fri, 1 Sep 2006 15:57:55 +0100"  >&lt;p&gt;&amp;gt; the new code is &lt;b&gt;9&lt;/b&gt; times faster! &lt;/p&gt;

&lt;p&gt;That&apos;s a bit apples-and-oranges &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  I don&apos;t think people use IndexModifier when they need performance... they buffer things and do them in batches.&lt;/p&gt;

&lt;p&gt;IMO, performance of &lt;b&gt;existing&lt;/b&gt; code using IndexWriter is more important, and what I would be interested in.  Say indexing 10000 documents to a RamDirectory with default settings (no deletes at all).  I haven&apos;t had a chance to review the new code, so I don&apos;t know if it&apos;s something to worry about or not.&lt;/p&gt;
</comment>
                    <comment id="12432164" author="yseeley@gmail.com" created="Fri, 1 Sep 2006 16:34:11 +0100"  >&lt;p&gt;I believe this patch probably also changes the merge behavior.&lt;br/&gt;
I think we need to discuss what exactly the new merge behavior is, if it&apos;s OK, what we think the index invariants should be (no more than x segments of y size, etc), and I&apos;d like to see some code to test those invariants.&lt;/p&gt;

&lt;p&gt;Keep in mind the difficulty of getting the last IndexWriter patch correct (and that was a very minor patch to keep track of the number of buffered docs!)&lt;/p&gt;</comment>
                    <comment id="12432216" author="doronc" created="Fri, 1 Sep 2006 20:49:21 +0100"  >&lt;p&gt;I agree - I also suspected it might change the merge behavior (and also had reflections from the repeated trials to have that simple Indexwriter buffered-docs patch correct...&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;. &lt;/p&gt;

&lt;p&gt;Guess I just wanted to get a feeling if there is interest to include this patch before I delve into it too much - and the perf test was meant to see for my self if it really helps. I was a bit surprised that it speeds 9 times in an interleaving add/delete scenario. Guess this by itself now justifies delving into this patch, analyzing merge behavior as you suggest - will do - I think idealy should try this patch not to modify the merge behavior.&lt;/p&gt;

&lt;p&gt;About the test - l was trying to test what I thought is a realistic use scenario (max-buf, etc.) - I have a fixed version of the perf test that is easier to modify for different scenarios - can upload it here if there is interest.&lt;/p&gt;
</comment>
                    <comment id="12433463" author="ninglili" created="Fri, 8 Sep 2006 18:55:36 +0100"  >&lt;p&gt;This patch features the new more robust merge policy. Reference on the new policy is at &lt;a href=&quot;http://www.gossamer-threads.com/lists/lucene/java-dev/35147&quot; class=&quot;external-link&quot;&gt;http://www.gossamer-threads.com/lists/lucene/java-dev/35147&lt;/a&gt;&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;The patch passes all the tests except that one in TestIndexModifier (see an earlier comment on this issue).&lt;/li&gt;
	&lt;li&gt;Since the test itself has a problem, it is fixed (one line change) and the patch passes the fixed test.&lt;/li&gt;
	&lt;li&gt;A new test call TestIndexWriterMergePolicy is included which shows the robustness of the new merge policy.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;The following is a detailed description of the new merge policy and its properties.&lt;/p&gt;

&lt;p&gt; Overview of merge policy:&lt;/p&gt;

&lt;p&gt; A flush is triggered either by close() or by the number of ram segments&lt;br/&gt;
 reaching maxBufferedDocs. After a disk segment is created by the flush,&lt;br/&gt;
 further merges may be triggered.&lt;/p&gt;

&lt;p&gt; LowerBound and upperBound set the limits on the doc count of a segment&lt;br/&gt;
 which may be merged. Initially, lowerBound is set to 0 and upperBound&lt;br/&gt;
 to maxBufferedDocs. Starting from the rightmost* segment whose doc count&lt;br/&gt;
 &amp;gt; lowerBound and &amp;lt;= upperBound, count the number of consecutive segments&lt;br/&gt;
 whose doc count &amp;lt;= upperBound.&lt;/p&gt;

&lt;p&gt; Case 1: number of worthy segments &amp;lt; mergeFactor, no merge, done.&lt;br/&gt;
 Case 2: number of worthy segments == mergeFactor, merge these segments.&lt;br/&gt;
         If the doc count of the merged segment &amp;lt;= upperBound, done.&lt;br/&gt;
         Otherwise, set lowerBound to upperBound, and multiply upperBound&lt;br/&gt;
         by mergeFactor, go through the process again.&lt;br/&gt;
 Case 3: number of worthy segments &amp;gt; mergeFactor (in the case mergeFactor&lt;br/&gt;
         M changes), merge the leftmost* M segments. If the doc count of&lt;br/&gt;
         the merged segment &amp;lt;= upperBound, consider the merged segment for&lt;br/&gt;
         further merges on this same level. Merge the now leftmost* M&lt;br/&gt;
         segments, and so on, until number of worthy segments &amp;lt; mergeFactor.&lt;br/&gt;
         If the doc count of all the merged segments &amp;lt;= upperBound, done.&lt;br/&gt;
         Otherwise, set lowerBound to upperBound, and multiply upperBound&lt;br/&gt;
         by mergeFactor, go through the process again.&lt;br/&gt;
 Note that case 2 can be considerd as a special case of case 3.&lt;/p&gt;

&lt;p&gt; This merge policy guarantees two invariants if M does not change and&lt;br/&gt;
 segment doc count is not reaching maxMergeDocs:&lt;br/&gt;
 B for maxBufferedDocs, f&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/thumbs_down.gif&quot; height=&quot;19&quot; width=&quot;19&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; defined as ceil(log_M(ceil(n/B)))&lt;br/&gt;
      1: If i (left*) and i+1 (right*) are two consecutive segments of doc&lt;br/&gt;
         counts x and y, then f&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/error.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &amp;gt;= f&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/thumbs_up.gif&quot; height=&quot;19&quot; width=&quot;19&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;.&lt;br/&gt;
      2: The number of committed segments on the same level (f&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/thumbs_down.gif&quot; height=&quot;19&quot; width=&quot;19&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;) &amp;lt;= M.&lt;/p&gt;</comment>
                    <comment id="12434041" author="yseeley@gmail.com" created="Tue, 12 Sep 2006 03:27:45 +0100"  >&lt;p&gt;Thanks for separating out the new merge policy Ning!  I&apos;m reviewing the patch now...&lt;br/&gt;
Assuming everything looks good (it does so far), I&apos;m inclined to commit it.  I&apos;m just giving a heads up to other lucene developers as this is a change in behavior to core lucene.&lt;/p&gt;

&lt;p&gt;I think the new merge policy is a positive change because:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;flushing all ram segments separately from disk segments allows more efficient implementations of combination reader/writers (like buffered deletes) because docids won&apos;t change from the flush alone (a merge is needed to change ids)&lt;/li&gt;
	&lt;li&gt;flushing all buffered docs together leaves more optimization possibilities... something other than single-doc segments could be used to buffer in-mem docs in the future.&lt;/li&gt;
	&lt;li&gt;increases indexing performance in the presence of deleted documents or partially full segments (merges are minimized while the number of segments are maximized).&lt;/li&gt;
	&lt;li&gt;fixes worst-case behavior that can cause the number of segments to grow too large (way more than mergefactor)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Are there any concerns?&lt;/p&gt;</comment>
                    <comment id="12434751" author="yseeley@gmail.com" created="Thu, 14 Sep 2006 18:50:06 +0100"  >&lt;p&gt;I also did a quick indexing performance test w/ Solr:&lt;/p&gt;

&lt;p&gt;maxBufferedDocs=100, mergeFactor=4, did 100K random overwriting adds in batches of 75 (75 docs added, dups deleted).&lt;br/&gt;
It was 12% faster with this new merge policy.&lt;/p&gt;</comment>
                    <comment id="12436585" author="ninglili" created="Thu, 21 Sep 2006 18:15:15 +0100"  >&lt;p&gt;This is to update the delete-support patch after the commit of the new merge policy.&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Very few changes to IndexWriter.&lt;/li&gt;
	&lt;li&gt;The patch passes all tests.&lt;/li&gt;
	&lt;li&gt;A new test call TestNewIndexModifierDelete is added to show different scenarios when using delete methods in NewIndexModifier.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12447657" author="ningli@us.ibm.com" created="Tue, 7 Nov 2006 06:22:40 +0000"  >
&lt;p&gt;   [[ Old comment, sent by email on Thu, 6 Jul 2006 07:53:35 -0700 ]]&lt;/p&gt;

&lt;p&gt;Hi Otis,&lt;/p&gt;

&lt;p&gt;I will regenerate the patch and add more comments. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;Regards,&lt;br/&gt;
Ning&lt;/p&gt;





&lt;p&gt;             &quot;Otis Gospodnetic                                             &lt;br/&gt;
             (JIRA)&quot;                                                       &lt;br/&gt;
             &amp;lt;jira@apache.org&amp;gt;                                          To &lt;br/&gt;
                                       ningli@almaden.ibm.com              &lt;br/&gt;
             07/05/2006 11:25                                           cc &lt;br/&gt;
             PM                                                            &lt;br/&gt;
                                                                   Subject &lt;br/&gt;
                                       &lt;span class=&quot;error&quot;&gt;&amp;#91;jira&amp;#93;&lt;/span&gt; Commented: (&lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-565&quot; title=&quot;Supporting deleteDocuments in IndexWriter (Code and Performance Results Provided)&quot;&gt;&lt;del&gt;LUCENE-565&lt;/del&gt;&lt;/a&gt;)      &lt;br/&gt;
                                       Supporting deleteDocuments in       &lt;br/&gt;
                                       IndexWriter (Code and Performance   &lt;br/&gt;
                                       Results Provided)                   &lt;/p&gt;










&lt;p&gt;    [&lt;br/&gt;
&lt;a href=&quot;http://issues.apache.org/jira/browse/LUCENE-565?page=comments#action_12419396&quot; class=&quot;external-link&quot;&gt;http://issues.apache.org/jira/browse/LUCENE-565?page=comments#action_12419396&lt;/a&gt;&lt;br/&gt;
 ]&lt;/p&gt;

&lt;p&gt;Otis Gospodnetic commented on &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-565&quot; title=&quot;Supporting deleteDocuments in IndexWriter (Code and Performance Results Provided)&quot;&gt;&lt;del&gt;LUCENE-565&lt;/del&gt;&lt;/a&gt;:&lt;br/&gt;
-----------------------------------------&lt;/p&gt;

&lt;p&gt;I took a look at the patch and it looks good to me (anyone else had a&lt;br/&gt;
look)?&lt;br/&gt;
Unfortunately, I couldn&apos;t get the patch to apply &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;$ patch -F3 &amp;lt; IndexWriter.patch&lt;br/&gt;
(Stripping trailing CRs from patch.)&lt;br/&gt;
patching file IndexWriter.java&lt;br/&gt;
Hunk #1 succeeded at 58 with fuzz 1.&lt;br/&gt;
Hunk #2 succeeded at 112 (offset 2 lines).&lt;br/&gt;
Hunk #4 succeeded at 504 (offset 33 lines).&lt;br/&gt;
Hunk #6 succeeded at 605 with fuzz 2 (offset 57 lines).&lt;br/&gt;
missing header for unified diff at line 259 of patch&lt;br/&gt;
(Stripping trailing CRs from patch.)&lt;br/&gt;
can&apos;t find file to patch at input line 259&lt;br/&gt;
Perhaps you should have used the -p or --strip option?&lt;br/&gt;
The text leading up to this was:&lt;br/&gt;
...&lt;br/&gt;
...&lt;br/&gt;
...&lt;br/&gt;
File to patch: IndexWriter.java&lt;br/&gt;
patching file IndexWriter.java&lt;br/&gt;
Hunk #1 FAILED at 802.&lt;br/&gt;
Hunk #2 succeeded at 745 with fuzz 2 (offset -131 lines).&lt;br/&gt;
1 out of 2 hunks FAILED &amp;#8211; saving rejects to file IndexWriter.java.rej&lt;/p&gt;


&lt;p&gt;Would it be possible for you to regenerate the patch against IndexWriter in&lt;br/&gt;
HEAD?&lt;/p&gt;

&lt;p&gt;Also, I noticed ^Ms in the patch, but I can take care of those easily&lt;br/&gt;
(dos2unix).&lt;/p&gt;

&lt;p&gt;Finally, I noticed in 2-3 places that the simple logging via &quot;infoStream&quot;&lt;br/&gt;
variable was removed, for example:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (infoStream != null) infoStream.print(&quot;merging segments&quot;);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Perhaps this was just an oversight?&lt;/p&gt;

&lt;p&gt;Looking forward to the new patch. Thanks!&lt;/p&gt;

&lt;p&gt;Provided)&lt;br/&gt;
---------------------------------------------------------------------------------&lt;/p&gt;


&lt;p&gt;a&lt;br/&gt;
IndexWriter&lt;br/&gt;
&lt;a href=&quot;http://www.gossamer-threads.com/lists/lucene/java-dev/23049?search_string=indexwriter%20delete;#23049&quot; class=&quot;external-link&quot;&gt;http://www.gossamer-threads.com/lists/lucene/java-dev/23049?search_string=indexwriter%20delete;#23049&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;to&lt;br/&gt;
deleting&lt;br/&gt;
version&lt;br/&gt;
using&lt;br/&gt;
batches.&lt;/p&gt;

&lt;p&gt;&amp;#8211;&lt;br/&gt;
This message is automatically generated by JIRA.&lt;br/&gt;
-&lt;br/&gt;
If you think it was sent incorrectly contact one of the administrators:&lt;br/&gt;
   &lt;a href=&quot;http://issues.apache.org/jira/secure/Administrators.jspa&quot; class=&quot;external-link&quot;&gt;http://issues.apache.org/jira/secure/Administrators.jspa&lt;/a&gt;&lt;br/&gt;
-&lt;br/&gt;
For more information on JIRA, see:&lt;br/&gt;
   &lt;a href=&quot;http://www.atlassian.com/software/jira&quot; class=&quot;external-link&quot;&gt;http://www.atlassian.com/software/jira&lt;/a&gt;&lt;/p&gt;</comment>
                    <comment id="12452039" author="ningli" created="Wed, 22 Nov 2006 20:28:50 +0000"  >&lt;p&gt;With the recent commits to IndexWriter, this patch no longer applies cleanly. The 5 votes for this issue encourages&lt;br/&gt;
me to submit yet another patch. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; But before I do that, I&apos;d like to briefly describe the design again and welcome all&lt;br/&gt;
suggestions that help improve it and help get it committed. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;With the new merge policy committed, the change to IndexWriter is minimal: three zero-or-one-line functions are&lt;br/&gt;
added and used.&lt;br/&gt;
  1 timeToFlushRam(): return true if number of ram segments &amp;gt;= maxBufferedDocs and used in maybeFlushRamSegments()&lt;br/&gt;
  2 anythingToFlushRam(): return true if number of ram segments &amp;gt; 0 and used in flushRamSegments()&lt;br/&gt;
  3 doAfterFlushRamSegments(): do nothing and called in mergeSegments() if the merge is on ram segments&lt;/p&gt;

&lt;p&gt;The new IndexModifier is a subclass of IndexWriter and only overwrites the three functions described above.&lt;br/&gt;
  1 timeToFlushRam(): return true if number of ram segments &amp;gt;= maxBufferedDocs OR if number of buffered&lt;br/&gt;
     deletes &amp;gt;= maxBufferedDeletes&lt;br/&gt;
  2 anythingToFlushRam(): return true if number of ram segments &amp;gt; 0 OR if number of buffered deletes &amp;gt; 0&lt;br/&gt;
  3 doAfterFlushRamSegments(): properly flush buffered deletes&lt;/p&gt;

&lt;p&gt;The new IndexModifier supports all APIs from the current IndexModifier except one: deleteDocument(int doc).&lt;br/&gt;
I had commented on this before:  &quot;I deliberately left that one out. This is because document ids are changing&lt;br/&gt;
as documents are deleted and segments are merged. Users don&apos;t know exactly when segments are merged&lt;br/&gt;
thus ids are changed when using IndexModifier.&quot;&lt;/p&gt;

&lt;p&gt;This behaviour is true for both the new IndexModifier and the current IndexModifier. If this is preventing this&lt;br/&gt;
patch from getting accepted, I&apos;m willing to add this, but I will detail this in the Java doc so users of this function&lt;br/&gt;
are aware of this behaviour.&lt;/p&gt;</comment>
                    <comment id="12456887" author="michaelbusch" created="Fri, 8 Dec 2006 15:50:04 +0000"  >&lt;p&gt;What are the reasons to not add the NewIndexModifier to Lucene? This issue has already 6 votes, so it seems to be very popular amongst users (there is only one issue that has more votes). I can say that I&apos;m using it for a couple of months already, it works flawlessly and made my life a lot easier &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;/p&gt;

&lt;p&gt;I think the main objections were that too many changes to IndexWriter were made in the earliest versions of this patch, but with the new merge policy committed, most of the new code is in the new class NewIndexModifier whereas the changes to IndexWriter are minimal. &lt;/p&gt;

&lt;p&gt;So I would like to encourage committer(s) to take another look, I think this would be a nice feature for the next Lucene release.&lt;/p&gt;</comment>
                    <comment id="12457582" author="yseeley@gmail.com" created="Tue, 12 Dec 2006 05:20:41 +0000"  >&lt;p&gt;Lack of committer time... I&apos;ve been busy enough that I&apos;ve shied away from complexity and gravitated toward issues that I can handle in a single bite.  I&apos;m on PTO until the end of the year, so I expect my time to be more compressed.&lt;/p&gt;

&lt;p&gt;To minimize the number of reader open/closes on large persistent segments, I think the ability to apply deletes only before a merge is important.  That might add a 4th method: doBeforeMerge()&lt;/p&gt;

&lt;p&gt;It would be nice to not have to continually open and close readers on segments that aren&apos;t involved in a merge.  Is there a way to do this?&lt;/p&gt;

&lt;p&gt;Ning, please do produce another patch to the latest trunk (but you might want to wait until after &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-702&quot; title=&quot;Disk full during addIndexes(Directory[]) can corrupt index&quot;&gt;&lt;del&gt;LUCENE-702&lt;/del&gt;&lt;/a&gt; is sorted out.&lt;/p&gt;</comment>
                    <comment id="12457758" author="yseeley@gmail.com" created="Tue, 12 Dec 2006 15:10:01 +0000"  >&lt;p&gt;&amp;gt; It would be nice to not have to continually open and close readers on segments&lt;br/&gt;
&amp;gt;  that aren&apos;t involved in a merge. Is there a way to do this? &lt;/p&gt;

&lt;p&gt;Hmmm, and what about segments that are involved in a merge?&lt;br/&gt;
I assume it&apos;s a different reader that is used for deleting docs than used for merging, but it doesn&apos;t have to be...&lt;/p&gt;

&lt;p&gt;If SegmentInfos had a cached reader, that seems like it would solve both problems.&lt;br/&gt;
I haven&apos;t thought about it enough to figure out how doable it is though.&lt;/p&gt;</comment>
                    <comment id="12457764" author="mikemccand" created="Tue, 12 Dec 2006 15:17:53 +0000"  >&lt;p&gt;&amp;gt; If SegmentInfos had a cached reader, that seems like it would solve both problems.&lt;br/&gt;
&amp;gt; I haven&apos;t thought about it enough to figure out how doable it is though.&lt;/p&gt;

&lt;p&gt;Good idea!  I think this could also be used by reopen (&lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-743&quot; title=&quot;IndexReader.reopen()&quot;&gt;&lt;del&gt;LUCENE-743&lt;/del&gt;&lt;/a&gt; ) to re-use readers.&lt;/p&gt;</comment>
                    <comment id="12457789" author="yseeley@gmail.com" created="Tue, 12 Dec 2006 16:44:55 +0000"  >&lt;p&gt;&amp;gt; Good idea! I think this could also be used by reopen (&lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-743&quot; title=&quot;IndexReader.reopen()&quot;&gt;&lt;del&gt;LUCENE-743&lt;/del&gt;&lt;/a&gt; ) to re-use readers.&lt;/p&gt;

&lt;p&gt;Yes, although  reopen() needs more support than what would be needed for this though (namely reference counting).&lt;br/&gt;
One thing to probably watch out for is to avoid making the single-doc ram segments more expensive.&lt;/p&gt;</comment>
                    <comment id="12457833" author="yseeley@gmail.com" created="Tue, 12 Dec 2006 18:36:02 +0000"  >&lt;p&gt;On 12/12/06, Ning Li &amp;lt;ning.li.li@gmail.com&amp;gt; wrote:&lt;br/&gt;
&amp;gt; &amp;gt; To minimize the number of reader open/closes on large persistent segments, I think the ability to apply deletes only before a merge is important.  That might add a 4th method: doBeforeMerge()&lt;br/&gt;
&amp;gt; &lt;br/&gt;
&amp;gt; I&apos;m not sure I get this. Buffered deletes are only applied(flushed)&lt;br/&gt;
&amp;gt; during ram flush. No buffered deletes are applied in the merges of&lt;br/&gt;
&amp;gt; on-disk segments.&lt;/p&gt;

&lt;p&gt;What is important is to be able to apply deletes before any ids change.&lt;br/&gt;
You could do it after every new lowest-level segment is written to the index (the flush), &lt;b&gt;or&lt;/b&gt; you could choose to do it before a merge of the lowest level on-disk segments.  If none of the lowest level segments have deletes, you could even defer the deletes until after all the lowest-level segments have been merged.  This makes the deletes more efficient since it goes from O(mergeFactor * log(maxBufferedDocs)) to O(log(mergeFactor*maxBufferedDocs))&lt;/p&gt;

&lt;p&gt;If we can&apos;t reuse IndexReaders, this becomes more important.&lt;/p&gt;

&lt;p&gt;One could perhaps choose to defer deletes until a segment with deleted docs is involved in a merge.&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; It would be nice to not have to continually open and close readers on segments that aren&apos;t involved in a merge.  Is there a way to do this?&lt;br/&gt;
&amp;gt; &amp;gt; If SegmentInfos had a cached reader, that seems like it would solve both problems.&lt;br/&gt;
&amp;gt; &amp;gt; I haven&apos;t thought about it enough to figure out how doable it is though.&lt;br/&gt;
&amp;gt; &lt;br/&gt;
&amp;gt; This is a good idea! One concern, however, is that caching readers&lt;br/&gt;
&amp;gt; will cause a larger memory footprint. Is it acceptable?&lt;/p&gt;

&lt;p&gt;As I said, I haven&apos;t had time to think about it at all, but at the lowest level of reuse, it wouldn&apos;t increase the footprint at all in the event that deletes are deferred until a merge:&lt;/p&gt;

&lt;p&gt;The specific scenario I&apos;m thinking of is instead of&lt;br/&gt;
  doAfterFlushRamSegments()&lt;br/&gt;
    open readers&lt;br/&gt;
    delete docs&lt;br/&gt;
    close readers&lt;br/&gt;
  segmentMerger()&lt;br/&gt;
    open readers&lt;br/&gt;
    merge segments&lt;br/&gt;
    close readers&lt;/p&gt;

&lt;p&gt;It would be:&lt;br/&gt;
  doAfterFlushRamSegments()&lt;br/&gt;
    open readers&lt;br/&gt;
    delete docs&lt;br/&gt;
  segmentMerger()&lt;br/&gt;
    merge segments&lt;br/&gt;
    close readers&lt;/p&gt;

&lt;p&gt;This cutting out an additional open-close cycle.&lt;br/&gt;
You are right that other forms of reader caching could increase the footprint, but it&apos;s nice to have the option of trading some memory for performance.&lt;/p&gt;

&lt;p&gt;Yet another strategy a subclass of IndexWriter could choose is to only apply deletes to segments actually involved in a merge.  Then the bigger segments in the index wouldn&apos;t continually have an reader opened and closed on them.... it could all be deferred until a close, or until there are too many deletes buffered.&lt;/p&gt;

&lt;p&gt;Of course NewIndexModifier doesn&apos;t have to impliment all these options to start with, but it would be nice if the extension hooks in IndexWriter could support them.&lt;/p&gt;

&lt;p&gt;Whew, this is why I was slow to get involved in this again &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="12457865" author="ningli" created="Tue, 12 Dec 2006 20:30:55 +0000"  >&lt;p&gt;&amp;gt; &lt;b&gt;or&lt;/b&gt; you could choose to do it before a merge of the lowest level on-disk&lt;br/&gt;
&amp;gt; segments.  If none of the lowest level segments have deletes, you could&lt;br/&gt;
&amp;gt; even defer the deletes until after all the lowest-level segments have been&lt;br/&gt;
&amp;gt; merged.  This makes the deletes more efficient since it goes from&lt;br/&gt;
&amp;gt; O(mergeFactor * log(maxBufferedDocs)) to O(log(mergeFactor*maxBufferedDocs))&lt;/p&gt;

&lt;p&gt;I don&apos;t think I like this semantics, though. With the semantics in the patch,&lt;br/&gt;
an update can be easily supported. With this semantics, an insert is flushed&lt;br/&gt;
yet a delete before the insert may or may not have been flushed.&lt;/p&gt;

&lt;p&gt;&amp;gt; You are right that other forms of reader caching could increase the footprint,&lt;br/&gt;
&amp;gt; but it&apos;s nice to have the option of trading some memory for performance.&lt;/p&gt;

&lt;p&gt;Agree. It&apos;d be nice to cache all readers... &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;Thanks again for your comments. Enjoy your PTO!&lt;/p&gt;</comment>
                    <comment id="12457885" author="yseeley@gmail.com" created="Tue, 12 Dec 2006 21:29:38 +0000"  >&lt;p&gt;Hmmm, I see your point... If deletes are deferred, a different reader could go and open the index and see the additions but not the deletions.&lt;/p&gt;

&lt;p&gt;Can the same thing happen with your patch (with a smaller window), or are deletes applied between writing the new segment and writing the new segments file that references it?  (hard to tell from current diff in isolation)&lt;/p&gt;

&lt;p&gt;Anyway, it&apos;s less of a problem if opening a new reader is coordinated with the writing.  That still does leave the crash scenario though.&lt;/p&gt;</comment>
                    <comment id="12458158" author="ningli" created="Wed, 13 Dec 2006 15:34:00 +0000"  >&lt;p&gt;&amp;gt; Can the same thing happen with your patch (with a smaller window), or are deletes applied between writing the new segment and writing the new segments file that references it?  (hard to tell from current diff in isolation)&lt;/p&gt;

&lt;p&gt;No, it does not happen with the patch, no matter what the window size is.&lt;br/&gt;
This is because results of flushing ram - both inserts and deletes - are committed in the same transaction.&lt;/p&gt;</comment>
                    <comment id="12458170" author="yseeley@gmail.com" created="Wed, 13 Dec 2006 16:01:22 +0000"  >&lt;p&gt;&amp;gt; both inserts and deletes - are committed in the same transaction.&lt;/p&gt;

&lt;p&gt;OK, cool.  I agree that&apos;s the ideal default behavior.&lt;/p&gt;</comment>
                    <comment id="12458174" author="yseeley@gmail.com" created="Wed, 13 Dec 2006 16:07:15 +0000"  >&lt;p&gt;Minor question... in the places that you use Vector, is there a reason you aren&apos;t using ArrayList?&lt;br/&gt;
And in methods that pass a Vector, that could be changed to a List .&lt;/p&gt;</comment>
                    <comment id="12458205" author="ningli" created="Wed, 13 Dec 2006 17:34:49 +0000"  >&lt;p&gt;&amp;gt; Minor question... in the places that you use Vector, is there a reason you aren&apos;t using ArrayList? &lt;br/&gt;
&amp;gt; And in methods that pass a Vector, that could be changed to a List . &lt;/p&gt;

&lt;p&gt;ArrayList and List can be used, respectively.&lt;/p&gt;</comment>
                    <comment id="12459482" author="paul.elschot@xs4all.nl" created="Mon, 18 Dec 2006 22:18:48 +0000"  >&lt;p&gt;I&apos;d like to give this a try over the upcoming holidays.&lt;br/&gt;
Would it be possible to post a single patch?&lt;br/&gt;
A single patch can be made by locally svn add&apos;ing all new files&lt;br/&gt;
and then doing an svn diff on all files involved from the top directory.&lt;/p&gt;

&lt;p&gt;Regards,&lt;br/&gt;
Paul Elschot&lt;/p&gt;</comment>
                    <comment id="12459490" author="ningli" created="Mon, 18 Dec 2006 22:59:31 +0000"  >&lt;p&gt;Many versions of the patch were submitted as new code was committed to IndexWriter.java. For each version, all changes made were included in a single patch file.&lt;/p&gt;

&lt;p&gt;I removed all but the latest version of the patch. Even this one is outdated by the commit of &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-701&quot; title=&quot;Lock-less commits&quot;&gt;&lt;del&gt;LUCENE-701&lt;/del&gt;&lt;/a&gt; (lock-less commits). I was waiting for the commit of &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-702&quot; title=&quot;Disk full during addIndexes(Directory[]) can corrupt index&quot;&gt;&lt;del&gt;LUCENE-702&lt;/del&gt;&lt;/a&gt; before submitting another patch. &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-702&quot; title=&quot;Disk full during addIndexes(Directory[]) can corrupt index&quot;&gt;&lt;del&gt;LUCENE-702&lt;/del&gt;&lt;/a&gt; was committed this morning. So I&apos;ll submit an up-to-date patch over the holidays.&lt;/p&gt;

&lt;p&gt;On 12/18/06, Paul Elschot (JIRA) &amp;lt;jira@apache.org&amp;gt; wrote:&lt;br/&gt;
&amp;gt; I&apos;d like to give this a try over the upcoming holidays. &lt;/p&gt;

&lt;p&gt;That&apos;s great! We can discuss/compare the designs then. Or, we can discuss/compare the designs before submitting new patches.&lt;/p&gt;</comment>
                    <comment id="12459506" author="ningli" created="Tue, 19 Dec 2006 00:47:40 +0000"  >&lt;p&gt;Here is the design overview. Minor changes were made because of lock-less commits.&lt;/p&gt;

&lt;p&gt;In the current IndexWriter, newly added documents are buffered in ram in the form of one-doc segments.&lt;br/&gt;
When a flush is triggered, all ram documents are merged into a single segment and written to disk.&lt;br/&gt;
Further merges of disk segments may be triggered.&lt;/p&gt;

&lt;p&gt;NewIndexModifier extends IndexWriter and supports document deletion in addition to document addition.&lt;br/&gt;
NewIndexModifier not only buffers newly added documents in ram, but also buffers deletes in ram.&lt;br/&gt;
The following describes what happens when a flush is triggered:&lt;/p&gt;

&lt;p&gt;  1 merge ram documents into one segment and written to disk&lt;br/&gt;
    do not commit - segmentInfos is updated in memory, but not written to disk&lt;/p&gt;

&lt;p&gt;  2 for each disk segment to which a delete may apply&lt;br/&gt;
      open reader&lt;br/&gt;
      delete docs*, write new .delN file (* Care is taken to ensure that an interleaved sequence of&lt;br/&gt;
        inserts and deletes for the same document are properly serialized.)&lt;br/&gt;
      close reader, but do not commit - segmentInfos is updated in memory, but not written to disk&lt;/p&gt;

&lt;p&gt;  3 commit - write new segments_N to disk&lt;/p&gt;

&lt;p&gt;Further merges for disk segments work the same as before.&lt;/p&gt;


&lt;p&gt;As an option, we can cache readers to minimize the number of reader opens/closes. In other words,&lt;br/&gt;
we can trade memory for better performance. The design would be modified as follows:&lt;/p&gt;

&lt;p&gt;  1 same as above&lt;/p&gt;

&lt;p&gt;  2 for each disk segment to which a delete may apply&lt;br/&gt;
      open reader and cache it if not already opened/cached&lt;br/&gt;
      delete docs*, write new .delN file&lt;/p&gt;

&lt;p&gt;  3 commit - write new segments_N to disk&lt;/p&gt;

&lt;p&gt;The logic for disk segment merge changes accordingly: open reader if not already opened/cached;&lt;br/&gt;
after a merge is complete, close readers for the segments that have been merged.&lt;/p&gt;</comment>
                    <comment id="12466189" author="jkassis" created="Sat, 20 Jan 2007 00:33:06 +0000"  >&lt;p&gt;Happy New Year everyone. I&apos;m personally very excited about this improvement to Lucene. It really begins to open Lucene up to service highly mutable data, important for the application I&apos;m developing. Following the thread, it looks like quite a few people have favorably reviewed the patch. Perhaps it&apos;s time for a blessing and commit? &lt;/p&gt;</comment>
                    <comment id="12467733" author="ningli" created="Fri, 26 Jan 2007 03:26:49 +0000"  >&lt;p&gt;The patch is updated because of the code committed to IndexWriter since the last patch. The high-level design is the same as before. See comments on 18/Dec/06.&lt;/p&gt;

&lt;p&gt;Care has been taken to make sure if writer/modifier tries to commit but hits disk full that writer/modifier remains consistent and usable. A test case is added to TestNewIndexModifierDelete to test this.&lt;/p&gt;

&lt;p&gt;All tests pass.&lt;/p&gt;</comment>
                    <comment id="12468012" author="mikemccand" created="Sat, 27 Jan 2007 12:06:56 +0000"  >
&lt;p&gt;Thanks for redoing the patch Ning!  I like the added test case for&lt;br/&gt;
disk full.&lt;/p&gt;

&lt;p&gt;I&apos;ve reviewed this and it looks great.  I fixed a few small typos and&lt;br/&gt;
whitespace issues (looks like a line-wrapper had jumped in at some&lt;br/&gt;
point) and attached NewIndexModifier.Jan2007.take2.patch&lt;/p&gt;

&lt;p&gt;I think this is the only issue holding up a Lucene 2.1 release (so&lt;br/&gt;
far?).  Yonik (or anyone) do you have any objections / questions about&lt;br/&gt;
this patch?  It&apos;s basically unchanged from before, just modified to&lt;br/&gt;
accommodate recent fixes to IndexWriter.&lt;/p&gt;</comment>
                    <comment id="12468371" author="yseeley@gmail.com" created="Mon, 29 Jan 2007 19:03:39 +0000"  >&lt;p&gt;I just reviewed this, and it looks good to me.&lt;br/&gt;
I like how you managed to enable parallel analysis in updateDocument() too.&lt;/p&gt;</comment>
                    <comment id="12468617" author="michaelbusch" created="Tue, 30 Jan 2007 13:57:02 +0000"  >&lt;p&gt;I tried the new patch out and everything looks good to me. One comment though: The public method NewIndexModifier.flush() just calls the public method flushRamSegments(). It might be confusing to have two public methods that do exactly the same?&lt;/p&gt;

&lt;p&gt;Besides this minor question I&apos;m all for committing this patch. &lt;/p&gt;</comment>
                    <comment id="12468640" author="mikemccand" created="Tue, 30 Jan 2007 15:17:38 +0000"  >&lt;p&gt;The flush() was added to better match the current IndexModifier, based&lt;br/&gt;
on feedback (bullet 6) above:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-565#action_12428035&quot; class=&quot;external-link&quot;&gt;https://issues.apache.org/jira/browse/LUCENE-565#action_12428035&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Actually, back when that feedback was given, flushRamSegments() was&lt;br/&gt;
still private.  I agree it&apos;s awkward now to have two separate methods&lt;br/&gt;
that do the same thing.&lt;/p&gt;

&lt;p&gt;But, I prefer &quot;flush&quot; over &quot;flushRamSegments&quot; because flush() is more&lt;br/&gt;
generic so it reveals less about how the IndexWriter makes use of its&lt;br/&gt;
RAM and leaves freedom in the future to have more interesting use of&lt;br/&gt;
RAM (like KinoSearch as one example).&lt;/p&gt;

&lt;p&gt;So I think the right fix would be to add a public IndexWriter.flush()&lt;br/&gt;
that just calls flushRamSegments, and then make flushRamSegments&lt;br/&gt;
private again, then remove the flush() method from NewIndexModifier?&lt;br/&gt;
(The public flushRamSegments() has not yet been released so making it&lt;br/&gt;
private again before we release 2.1 is OK).&lt;/p&gt;

&lt;p&gt;Any objections to this approach?  I will re-work the last patch &amp;amp;&lt;br/&gt;
attach it.&lt;/p&gt;</comment>
                    <comment id="12468687" author="michaelbusch" created="Tue, 30 Jan 2007 16:59:38 +0000"  >&lt;p&gt;Thanks for the explanation, Mike. I&apos;d prefer flush() too and the changes you suggest look good to me!&lt;/p&gt;</comment>
                    <comment id="12468714" author="mikemccand" created="Tue, 30 Jan 2007 17:55:31 +0000"  >&lt;p&gt;OK I&apos;ve attached NewIndexModifier.Jan2007.take3.patch with that approach.&lt;/p&gt;

&lt;p&gt;I plan on committing this in the next day or two if there are no more questions/feedback....&lt;/p&gt;

&lt;p&gt;Thank you Ning for this great addition, and for persisting through this long process!&lt;/p&gt;</comment>
                    <comment id="12469408" author="mikemccand" created="Thu, 1 Feb 2007 10:58:01 +0000"  >&lt;p&gt;I just committed this.&lt;/p&gt;

&lt;p&gt;Thank you Ning.  Keep the patches coming!&lt;/p&gt;</comment>
                    <comment id="12471844" author="mikemccand" created="Fri, 9 Feb 2007 22:05:57 +0000"  >&lt;p&gt;Reopening based on recent discussions on java-dev:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;http://www.gossamer-threads.com/lists/lucene/java-dev/45099&quot; class=&quot;external-link&quot;&gt;http://www.gossamer-threads.com/lists/lucene/java-dev/45099&lt;/a&gt;&lt;/p&gt;</comment>
                    <comment id="12471980" author="mikemccand" created="Sat, 10 Feb 2007 10:07:44 +0000"  >&lt;p&gt;OK I moved NewIndexModifier&apos;s methods into IndexWriter and did some&lt;br/&gt;
small refactoring, tightening up protections, fixed javadocs,&lt;br/&gt;
indentation, etc.  NewIndexModifier is now removed.&lt;/p&gt;

&lt;p&gt;I like this solution much better!&lt;/p&gt;

&lt;p&gt;I also increased the default number of deleted terms before a flush is&lt;br/&gt;
triggered from 10 to 1000.  These buffered terms use very little&lt;br/&gt;
memory so I think it makes sense to have a larger default?&lt;/p&gt;

&lt;p&gt;So, this adds these public methods to IndexWriter:&lt;/p&gt;

&lt;p&gt;  public void updateDocument(Term term, Document doc, Analyzer analyzer)&lt;br/&gt;
  public void updateDocument(Term term, Document doc)&lt;br/&gt;
  public synchronized void deleteDocuments(Term[] terms)&lt;br/&gt;
  public synchronized void deleteDocuments(Term term)&lt;br/&gt;
  public void setMaxBufferedDeleteTerms(int maxBufferedDeleteTerms)&lt;br/&gt;
  public int getMaxBufferedDeleteTerms()&lt;/p&gt;

&lt;p&gt;And this public field:&lt;/p&gt;

&lt;p&gt;  public final static int DEFAULT_MAX_BUFFERED_DELETE_TERMS = 10;&lt;/p&gt;


&lt;p&gt;On the extensions points, we had previously added these 4:&lt;/p&gt;

&lt;p&gt;  protected void doAfterFlushRamSegments(boolean flushedRamSegments)&lt;br/&gt;
  protected boolean timeToFlushRam()&lt;br/&gt;
  protected boolean anythingToFlushRam()&lt;br/&gt;
  protected boolean onlyRamDocsToFlush()&lt;/p&gt;

&lt;p&gt;I would propose that instead we add only the first one above, but&lt;br/&gt;
rename it to &quot;doAfterFlush()&quot;.  This is basically a callback that a&lt;br/&gt;
subclass could use to do its own thing after a flush but before a&lt;br/&gt;
commit.&lt;/p&gt;

&lt;p&gt;But then I don&apos;t think we should add any of the others.  The&lt;br/&gt;
&quot;timeToFlushRam()&quot; callback isn&apos;t really needed now that we have a&lt;br/&gt;
public &quot;flush()&quot; method.  And the other two are very specific to how&lt;br/&gt;
IndexWriter implements RAM buffering/flushing and so unless/until we&lt;br/&gt;
can think of a use case that needs these I&apos;m inclined to not include&lt;br/&gt;
them?&lt;/p&gt;

&lt;p&gt;Yonik, is there something in Solr that would need these last 2&lt;br/&gt;
callbacks?&lt;/p&gt;

&lt;p&gt;I&apos;ve attached the patch (&lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-565&quot; title=&quot;Supporting deleteDocuments in IndexWriter (Code and Performance Results Provided)&quot;&gt;&lt;del&gt;LUCENE-565&lt;/del&gt;&lt;/a&gt;.Feb2007.patch) with these&lt;br/&gt;
changes!&lt;/p&gt;</comment>
                    <comment id="12472499" author="yseeley@gmail.com" created="Tue, 13 Feb 2007 01:53:24 +0000"  >&lt;p&gt;OK I moved NewIndexModifier&apos;s methods into IndexWriter and did some&lt;br/&gt;
small refactoring, tightening up protections, &lt;/p&gt;

&lt;p&gt;&amp;gt; I would propose that instead we add only the first one above, but rename it to &quot;doAfterFlush()&quot;. &lt;/p&gt;

&lt;p&gt;Yes, that sounds fine.&lt;/p&gt;

&lt;p&gt;The problem is that we wouldn&apos;t be able to take advantage of the hook because of the &quot;tightening up protections&quot;.  Access to the segments is key.&lt;/p&gt;

&lt;p&gt;+  private SegmentInfos segmentInfos = new SegmentInfos();       // the segments&lt;br/&gt;
+  private SegmentInfos ramSegmentInfos = new SegmentInfos();    // the segments in ramDirectory&lt;br/&gt;
+  final private SegmentInfo buildSingleDocSegment(Document doc, Analyzer analyzer)&lt;/p&gt;

&lt;p&gt;So instead of changing these to private, how about package protected?&lt;/p&gt;
</comment>
                    <comment id="12472610" author="mikemccand" created="Tue, 13 Feb 2007 10:26:11 +0000"  >&lt;p&gt;OK, got it.  I will change those 3 to package protection and then commit.  Thanks Yonik.&lt;/p&gt;</comment>
                    <comment id="12476258" author="mikemccand" created="Tue, 27 Feb 2007 18:10:33 +0000"  >&lt;p&gt;Closing all issues that were resolved for 2.1.&lt;/p&gt;</comment>
                </comments>
                <issuelinks>
                        <issuelinktype id="10020">
                <name>Cloners</name>
                                <outwardlinks description="is cloned as">
                            <issuelink>
            <issuekey id="12349945">LUCENE-672</issuekey>
        </issuelink>
                    </outwardlinks>
                                            </issuelinktype>
                    </issuelinks>
                <attachments>
                    <attachment id="12350827" name="LUCENE-565.Feb2007.patch" size="60951" author="mikemccand" created="Sat, 10 Feb 2007 10:07:44 +0000" />
                    <attachment id="12349660" name="NewIndexModifier.Jan2007.patch" size="33527" author="ningli" created="Fri, 26 Jan 2007 03:26:49 +0000" />
                    <attachment id="12349726" name="NewIndexModifier.Jan2007.take2.patch" size="33539" author="mikemccand" created="Sat, 27 Jan 2007 12:06:56 +0000" />
                    <attachment id="12349944" name="NewIndexModifier.Jan2007.take3.patch" size="33813" author="mikemccand" created="Tue, 30 Jan 2007 17:55:31 +0000" />
                    <attachment id="12341314" name="NewIndexModifier.Sept21.patch" size="18826" author="ninglili" created="Thu, 21 Sep 2006 18:15:15 +0100" />
                    <attachment id="12339629" name="perfres.log" size="3136" author="doronc" created="Sat, 26 Aug 2006 02:21:29 +0100" />
                    <attachment id="12340014" name="perf-test-res2.JPG" size="105531" author="doronc" created="Fri, 1 Sep 2006 06:11:43 +0100" />
                    <attachment id="12339628" name="perf-test-res.JPG" size="74953" author="doronc" created="Sat, 26 Aug 2006 02:21:29 +0100" />
                    <attachment id="12339627" name="TestBufferedDeletesPerf.java" size="10172" author="doronc" created="Sat, 26 Aug 2006 02:21:29 +0100" />
                </attachments>
            <subtasks>
        </subtasks>
                <customfields>
                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                <customfieldname>Attachment count</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>9.0</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                <customfieldname>Date of First Response</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>Tue, 9 May 2006 09:24:34 +0000</customfieldvalue>

                </customfieldvalues>
            </customfield>
                                                                                                        <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Global Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>13185</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                <customfieldname>Lucene Fields</customfieldname>
                <customfieldvalues>
                        <customfieldvalue key="10120"><![CDATA[Patch Available]]></customfieldvalue>
    
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>27162</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                <customfieldname>Time in Status</customfieldname>
                <customfieldvalues>
                    
                </customfieldvalues>
            </customfield>
                            </customfields>
    </item>
</channel>
</rss>