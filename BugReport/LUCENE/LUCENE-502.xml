<!-- 
RSS generated by JIRA (5.2.8#851-sha1:3262fdc28b4bc8b23784e13eadc26a22399f5d88) at Tue Jul 16 13:03:51 UTC 2013

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/LUCENE-502/LUCENE-502.xml?field=key&field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>5.2.8</version>
        <build-number>851</build-number>
        <build-date>26-02-2013</build-date>
    </build-info>

<item>
            <title>[LUCENE-502] TermScorer caches values unnecessarily</title>
                <link>https://issues.apache.org/jira/browse/LUCENE-502</link>
                <project id="12310110" key="LUCENE">Lucene - Core</project>
                        <description>&lt;p&gt;TermScorer aggressively caches the doc and freq of 32 documents at a time for each term scored.  When querying for a lot of terms, this causes a lot of garbage to be created that&apos;s unnecessary.  The SegmentTermDocs from which it retrieves its information doesn&apos;t have any optimizations for bulk loading, and it&apos;s unnecessary.&lt;/p&gt;

&lt;p&gt;In addition, it has a SCORE_CACHE, that&apos;s of limited benefit.  It&apos;s caching the result of a sqrt that should be placed in DefaultSimilarity, and if you&apos;re only scoring a few documents that contain those terms, there&apos;s no need to precalculate the SQRT, especially on modern VMs.&lt;/p&gt;

&lt;p&gt;Enclosed is a patch that replaces TermScorer with a version that does not cache the docs or feqs.  In the case of a lot of queries, that saves 196 bytes/term, the unnecessary disk IO, and extra SQRTs which adds up.&lt;/p&gt;</description>
                <environment></environment>
            <key id="12329573">LUCENE-502</key>
            <summary>TermScorer caches values unnecessarily</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                    <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png">Closed</status>
                    <resolution id="1">Fixed</resolution>
                                <assignee username="-1">Unassigned</assignee>
                                <reporter username="tamm">Steven Tamm</reporter>
                        <labels>
                    </labels>
                <created>Wed, 1 Mar 2006 11:32:52 +0000</created>
                <updated>Fri, 10 May 2013 11:43:23 +0100</updated>
                    <resolved>Fri, 15 Jul 2011 04:00:22 +0100</resolved>
                            <version>1.9</version>
                                <fixVersion>4.0-ALPHA</fixVersion>
                                <component>core/search</component>
                        <due></due>
                    <votes>1</votes>
                        <watches>2</watches>
                                                    <comments>
                    <comment id="12368221" author="tamm" created="Wed, 1 Mar 2006 14:33:33 +0000"  >&lt;p&gt;Here&apos;s the patch&lt;/p&gt;

&lt;p&gt;Sorry about my lack of proofreading, I saved right as I was leaving work.  &lt;/p&gt;

&lt;p&gt;The main point is that the look ahead caching done by TermScorer is unnecessary.  It is only of benefit if you are scoring in a given locality (i.e. query doc 0, then 30, then 10, then 3, etc).  Nearly all use cases are sequential: the use of seek vs. next() is fine because the underlying BufferedIndexInput has an efficient seek function for sequential access.  &lt;/p&gt;

&lt;p&gt;Here&apos;s an HPROF run from a set of sequential wildcard searches (with many terms per search).  Since this never performs sequential access on documents, the &quot;cache&quot; is completely unnecessary. &lt;/p&gt;

&lt;p&gt;          percent          live          alloc&apos;ed  stack class&lt;br/&gt;
 rank   self  accum     bytes objs     bytes  objs trace name&lt;br/&gt;
   29  0.79% 58.64%   1029312 7148   1801296 12509 387945 float[]&lt;br/&gt;
   30  0.79% 59.43%   1029312 7148   1801296 12509 387944 int[]&lt;br/&gt;
   31  0.79% 60.23%   1029312 7148   1801296 12509 387943 int[]&lt;/p&gt;

&lt;p&gt;TRACE 387943:&lt;br/&gt;
	org.apache.lucene.search.TermScorer.&amp;lt;init&amp;gt;(TermScorer.java:30)&lt;br/&gt;
	org.apache.lucene.search.TermQuery$TermWeight.scorer(TermQuery.java:64)&lt;br/&gt;
	org.apache.lucene.search.BooleanQuery$BooleanWeight.scorer(BooleanQuery.java:165)&lt;br/&gt;
	org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:158)&lt;br/&gt;
TRACE 387944:&lt;br/&gt;
	org.apache.lucene.search.TermScorer.&amp;lt;init&amp;gt;(TermScorer.java:31)&lt;br/&gt;
	org.apache.lucene.search.TermQuery$TermWeight.scorer(TermQuery.java:64)&lt;br/&gt;
	org.apache.lucene.search.BooleanQuery$BooleanWeight.scorer(BooleanQuery.java:165)&lt;br/&gt;
	org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:158)&lt;br/&gt;
TRACE 387945:&lt;br/&gt;
	org.apache.lucene.search.TermScorer.&amp;lt;init&amp;gt;(TermScorer.java:36)&lt;br/&gt;
	org.apache.lucene.search.TermQuery$TermWeight.scorer(TermQuery.java:64)&lt;br/&gt;
	org.apache.lucene.search.BooleanQuery$BooleanWeight.scorer(BooleanQuery.java:165)&lt;br/&gt;
	org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:158)&lt;/p&gt;
</comment>
                    <comment id="12368768" author="tamm" created="Sat, 4 Mar 2006 02:59:48 +0000"  >&lt;p&gt;If you&apos;re using a WildcardTermEnum, this optimization saves a ton.  We usually do wildcard searches which retrieve 50-5000 terms.  Since each one of these corresponds to a new TermScorer, removing the caching saves a lot.  For a query that has 1800 terms, it saves 800K/query, plus it&apos;s also quicker by about 15%.&lt;/p&gt;

&lt;p&gt;Don&apos;t double buffer.&lt;/p&gt;</comment>
                    <comment id="12368770" author="cutting" created="Sat, 4 Mar 2006 03:11:40 +0000"  >&lt;p&gt;It is not clear to me that your uses are typical uses.  These optimizations were added because they made big improvements.  They were not premature.  In some cases JVM&apos;s may have evolved so that some of them are no longer required.  But some of them may still make significant improvements for lots of users.  We really need a benchmark suite to better understand the effects of things like this...&lt;/p&gt;</comment>
                    <comment id="12368775" author="tamm" created="Sat, 4 Mar 2006 03:57:47 +0000"  >&lt;p&gt;The main point is this:  When you are using TermScorer to score one document, it is doing a lot of extra work.  It&apos;s reading 31 extra documents from the disk and calculating the weight factors for 31 documents.   The question is how does the caching help when you have multiple documents.  My analysis is that (with a modern VM) it helps you only if the docFreq of a term is 16-31 and you are using a ConjunctiveScorer (i.e. not Wildcard searches).  I would imagine this is a use case that is not uncommon.  Anyone using Wildcard searches will have &lt;b&gt;immediate&lt;/b&gt; benefit from installing this patch.&lt;/p&gt;

&lt;p&gt;So I&apos;m going to analyze this from the &quot;amount of work to do&quot; perspective.&lt;br/&gt;
TermScorer.next():  If you are calling TermScorer.next() there is no real difference.  SegmentTermDocs.read(int[], float[]) is no different from calling SegmentTermDocs.next() 32 times.  The change in the patch switches TermScorer.next() to always calling next on the underlying SegmentTermDocs.  The only cost I&apos;m removing is the caching and I&apos;m not adding any new ones.  Therefore there&apos;s no change, with the exception of adding the cache for use in skipTo().&lt;/p&gt;

&lt;p&gt;TermScorer.skipTo():  The only case where my patch is worse is if the frequency of the term is greater than the skip interval (i.e &amp;gt;= 16 documents per term).  In this case, if you are retrieving more than 16 documents (but less than 32), you can avoid accessing the skipStream entirely.  If you are retrieving more than 32 documents, then you need to access the skipStream anyway, and since both of the underlying IndexInput&apos;s are cached, repositioning the freqStream will be only pointer manipulation.&lt;/p&gt;

&lt;p&gt;TermScorer.score():&lt;br/&gt;
&quot;In some cases JVM&apos;s may have evolved so that some of them are no longer required.&quot;  I can imagine that the scoreCache made a lot of sense in JDK 1.1 when the cost of Math.sqrt would be high.  However, if the TermScorer is only going to be used for a single document, this is obviously wrong.   Like I said before, caching DefaultSimilarity.tf(int) inside DefaultSimilarity would end up inlined by the HotSpot compiler, but Math.sqrt is inlined into a processor trap, so it&apos;s not a big deal.&lt;/p&gt;

&lt;p&gt;I want other people to test this and tell me any problems with it.  Whether or not you accept the patches into are less important to me than providing them to other people that have similar performance problems.  Perhaps I should have created a parallel structure to TermScorer that you can use when you have a low hit/term ratio. &lt;/p&gt;</comment>
                    <comment id="12368782" author="cutting" created="Sat, 4 Mar 2006 04:52:24 +0000"  >&lt;p&gt;&amp;gt; The question is how does the caching help when you have multiple documents.  My analysis is that (with a modern VM) it helps you only if the docFreq of a term is 16-31 and you are using a ConjunctiveScorer (i.e. not Wildcard searches).&lt;/p&gt;

&lt;p&gt;The conjunctive scorer does not call score(HitCollector,int).  This is only called in a few cases anymore.  It can help a lot with a single-term query for a very common term, or for disjunctive queries involving very common terms, although BooleanScorer2 no longer uses it in this case.  That&apos;s too bad.  If all clauses to a query are optional, then the old BooleanScorer was faster.  But it didn&apos;t always return documents in order...  So it indeed may be time to retire this method.&lt;/p&gt;

&lt;p&gt;&amp;gt;SegmentTermDocs.read(int[], int[]) is no different from calling SegmentTermDocs.next() 32 times.&lt;/p&gt;

&lt;p&gt;If that were the case, then then termDocs(int[], int[]) method would never have been added!  Benchmarking showed this to be much faster.   There&apos;s also optimized C++ code that implements this method in src/gcj.  In C++, with a memory-mapped index, the i/o completely inlines.  When I last benchmarked this in GCJ, it was twice as fast as anything HotSpot could do.&lt;/p&gt;

&lt;p&gt;But without score(HitCollector,int), TermDocs.read(int[], int[]) will never be called.  Sigh.&lt;/p&gt;

&lt;p&gt;As for the scoreCache, this is certainly useful for terms that occur in thousands of documents, and useless for terms that occur only once.  Perhaps we should have two TermScorer implementations, one for common terms and one for rare terms, and have TermWeight select which to use.&lt;/p&gt;</comment>
                    <comment id="12368784" author="tamm" created="Sat, 4 Mar 2006 05:10:21 +0000"  >&lt;p&gt;&amp;gt; The conjunctive scorer does not call score(HitCollector,int).  This is only called in a few cases anymore. &lt;br/&gt;
However, in your comments to &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-505&quot; title=&quot;MultiReader.norm() takes up too much memory: norms byte[] should be made into an Object&quot;&gt;&lt;del&gt;LUCENE-505&lt;/del&gt;&lt;/a&gt; you said this: &quot;For example, in TermScorer.score(HitCollector, int), Lucene&apos;s innermost loop, you change two array accesses into a call to an interface. That could make a substantial difference.&quot;  Which is true?   Or, as it seems likely, TermScorer was optimized for a case that is no longer valid (i.e. ConjunctiveScorer).&lt;/p&gt;

&lt;p&gt;&amp;gt; If that were the case, then then termDocs(int[], int[]) method would never have been added!&lt;br/&gt;
This hasn&apos;t been true for at least 3 years.  Inlining by hand is not necessary anymore with hotspot (I don&apos;t know about gcj).  Run a benchmark on JDK 1.5 to prove this to yourself.&lt;/p&gt;

&lt;p&gt;In short, we should have two TermScorer implementations.  One for low documents/term, and one for high documents/term.&lt;/p&gt;</comment>
                    <comment id="12368792" author="paul.elschot@xs4all.nl" created="Sat, 4 Mar 2006 05:54:26 +0000"  >&lt;p&gt;&amp;gt;&amp;gt; The question is how does the caching help when you have multiple documents. My analysis is that (with a modern VM) it helps you only if the docFreq of a term is 16-31 and you are using a ConjunctiveScorer (i.e. not Wildcard searches). &lt;/p&gt;

&lt;p&gt;&amp;gt; The conjunctive scorer does not call score(HitCollector,int). This is only called in a few cases anymore. It can help a lot with a single-term query for a very common term, or for disjunctive queries involving very common terms, although BooleanScorer2 no longer uses it in this case. That&apos;s too bad. If all clauses to a query are optional, then the old BooleanScorer was faster. But it didn&apos;t always return documents in order... So it indeed may be time to retire this method. &lt;/p&gt;

&lt;p&gt;With BooleanScorer2 It is quite possible to use different versions of DisjunctionScorer:&lt;br/&gt;
one for query top level that does not need skipTo(), and one for lower level that allows&lt;br/&gt;
skipTo(). The top level one can be implemented just like the &quot;old&quot; BooleanScorer.&lt;/p&gt;

&lt;p&gt;Iirc the method to implement such different behaviour are already in place (for scoring a range of documents),&lt;br/&gt;
it only needs to be implemented for DisjunctionScorer, and the top level BooleanScorer2 should then&lt;br/&gt;
use it when appropriate.&lt;/p&gt;

&lt;p&gt;Regards,&lt;br/&gt;
Paul Elschot&lt;/p&gt;</comment>
                    <comment id="12368797" author="cutting" created="Sat, 4 Mar 2006 06:27:32 +0000"  >&lt;p&gt;&amp;gt;  Which is true? Or, as it seems likely, TermScorer was optimized for a case that is no longer valid (i.e. ConjunctiveScorer). &lt;/p&gt;

&lt;p&gt;No, it was optimized for BooleanScorer&apos;s &lt;b&gt;disjunctive&lt;/b&gt; scoring algorithm, which is no longer used by default, but is faster than BooleanScorer2&apos;s disjunctive scoring algorithm.  This applies to a very common type of query: classic vector-space searches.  So this optimization may not be leveraged much in the current codebase, but that does not mean that it is no longer valid.  But it may slow other sorts of searches, like your wildcards.  The challenge is not just how to figure out how to make your application as fast as possible, but how to do this without making other&apos;s and future applications slower.&lt;/p&gt;

&lt;p&gt;&amp;gt; In short, we should have two TermScorer implementations. One for low documents/term, and one for high documents/term.&lt;/p&gt;

&lt;p&gt;Yes, I think that would be useful.  Classically, total query processing time is dominated by common terms, so that&apos;s an important case to optimize.  But It seems that with wildcard queries over smaller collections that these optimizations become costly.  So two implementations seems like it would make everyone happy.&lt;/p&gt;</comment>
                    <comment id="12647173" author="markrmiller@gmail.com" created="Thu, 13 Nov 2008 03:43:42 +0000"  >&lt;p&gt;Are we interested in this optimization?&lt;/p&gt;

&lt;p&gt;Here is an attempted patch. &lt;/p&gt;

&lt;p&gt;Two issues:&lt;/p&gt;

&lt;p&gt;1. Seems it might be better to try and use IDF to determine which scorer to use (TermScorer or LowFreqTermScorer) rather than doc freq so that doc freq doesn&apos;t need to be accessed twice.&lt;/p&gt;

&lt;p&gt;2. I don&apos;t know at what &apos;level&apos; the LowFreqTermScorer should be cut out for the TermScorer. Some benching may help.&lt;/p&gt;</comment>
                    <comment id="12986981" author="rcmuir" created="Wed, 26 Jan 2011 12:29:23 +0000"  >&lt;p&gt;Can we close this one?&lt;/p&gt;

&lt;p&gt;It seems it was geared towards multitermqueries, but these are using different codepaths these days (e.g. Filter rewrite).&lt;br/&gt;
I think as this issue stands though, I would be against changing the defaults...&lt;/p&gt;

&lt;p&gt;(separately: in &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-2392&quot; title=&quot;Enable flexible scoring&quot;&gt;&lt;del&gt;LUCENE-2392&lt;/del&gt;&lt;/a&gt;, you can control this in your Similarity yourself)&lt;/p&gt;</comment>
                    <comment id="13065687" author="rcmuir" created="Fri, 15 Jul 2011 04:00:22 +0100"  >&lt;p&gt;In trunk, there is no longer a score cache in TermScorer because this is just an optimization for the TF/IDF scoring formula.&lt;/p&gt;

&lt;p&gt;Instead this optimization is in TFIDFSimilarity, if you want or don&apos;t want similar pre-computations in your scoring you can adjust this by plugging in your own Similarity.&lt;/p&gt;</comment>
                </comments>
                    <attachments>
                    <attachment id="12393836" name="LUCENE-502.patch" size="5872" author="markrmiller@gmail.com" created="Thu, 13 Nov 2008 03:44:20 +0000" />
                    <attachment id="12323543" name="TermScorer.patch" size="6159" author="tamm" created="Wed, 1 Mar 2006 14:33:33 +0000" />
                </attachments>
            <subtasks>
        </subtasks>
                <customfields>
                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                <customfieldname>Attachment count</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>2.0</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                <customfieldname>Date of First Response</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>Sat, 4 Mar 2006 03:11:40 +0000</customfieldvalue>

                </customfieldvalues>
            </customfield>
                                                                                                        <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Global Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>13248</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>27225</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                <customfieldname>Time in Status</customfieldname>
                <customfieldvalues>
                    
                </customfieldvalues>
            </customfield>
                            </customfields>
    </item>
</channel>
</rss>