<!-- 
RSS generated by JIRA (5.2.8#851-sha1:3262fdc28b4bc8b23784e13eadc26a22399f5d88) at Tue Jul 16 13:11:45 UTC 2013

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/LUCENE-1794/LUCENE-1794.xml?field=key&field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>5.2.8</version>
        <build-number>851</build-number>
        <build-date>26-02-2013</build-date>
    </build-info>

<item>
            <title>[LUCENE-1794] implement reusableTokenStream for all contrib analyzers</title>
                <link>https://issues.apache.org/jira/browse/LUCENE-1794</link>
                <project id="12310110" key="LUCENE">Lucene - Core</project>
                        <description>&lt;p&gt;most contrib analyzers do not have an impl for reusableTokenStream&lt;/p&gt;

&lt;p&gt;regardless of how expensive the back compat reflection is for indexing speed, I think we should do this to mitigate any performance costs. hey, overall it might even be an improvement!&lt;/p&gt;

&lt;p&gt;the back compat code for non-final analyzers is already in place so this is easy money in my opinion.&lt;/p&gt;</description>
                <environment></environment>
            <key id="12432638">LUCENE-1794</key>
            <summary>implement reusableTokenStream for all contrib analyzers</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                    <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png">Closed</status>
                    <resolution id="1">Fixed</resolution>
                                <assignee username="rcmuir">Robert Muir</assignee>
                                <reporter username="rcmuir">Robert Muir</reporter>
                        <labels>
                    </labels>
                <created>Sun, 9 Aug 2009 22:20:08 +0100</created>
                <updated>Mon, 16 May 2011 19:15:28 +0100</updated>
                    <resolved>Wed, 19 Aug 2009 12:58:36 +0100</resolved>
                                            <fixVersion>2.9</fixVersion>
                                <component>modules/analysis</component>
                        <due></due>
                    <votes>0</votes>
                        <watches>0</watches>
                                                    <comments>
                    <comment id="12741274" author="rcmuir" created="Mon, 10 Aug 2009 12:51:35 +0100"  >&lt;p&gt;reusableTokenStream + tests for the contrib analyzers. only a few are non-final and require the back compat code.&lt;/p&gt;</comment>
                    <comment id="12741305" author="rcmuir" created="Mon, 10 Aug 2009 14:03:34 +0100"  >&lt;p&gt;no code changes, but improve the reusableTokenStream tests for cn and smartcn to also test offsets, testing that reset() is working correctly.&lt;/p&gt;</comment>
                    <comment id="12741306" author="rcmuir" created="Mon, 10 Aug 2009 14:14:07 +0100"  >&lt;p&gt;I moved this to 2.9, if there are concerns please feel free to change this, but I think it is ready.&lt;/p&gt;</comment>
                    <comment id="12741319" author="shaie" created="Mon, 10 Aug 2009 14:49:39 +0100"  >&lt;p&gt;Robert - wouldn&apos;t it make sense to pull SavedStreams (maybe call it ReusableStreams?) up to Analyzer, and have all the extensions use it? I couldn&apos;t help but notice that this code is duplicated in all the Analyzers.&lt;/p&gt;

&lt;p&gt;Also, and I don&apos;t know if it&apos;s a matter for a different issue - the fact that reusableTokenStream accepts a field name is misleading. On one hand, it makes you think you can ask for a.rts(&quot;a) and a.rts(&quot;b&quot;) safely, but on the other it is documented to be not that safe (i.e., don&apos;t call this method if you need more than one token stream from an analyzer at the same time).&lt;/p&gt;

&lt;p&gt;I don&apos;t know how to solve it best - I&apos;d like to have a tokenStream method that accepts the field name, and that I can get a reused token stream, for that field name. But I also would like to have a method that I can call &quot;get a reusable token stream&quot; and &quot;I don&apos;t care which field it is&quot;. So maybe have two variants:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;reusableTokenStream(Reader reader)&lt;/li&gt;
	&lt;li&gt;reusableTokenStream(String field, Reader reader)&lt;br/&gt;
This is kind of related to &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1678&quot; title=&quot;Deprecate Analyzer.tokenStream&quot;&gt;&lt;del&gt;LUCENE-1678&lt;/del&gt;&lt;/a&gt;, as I think we&apos;d like tokenStream to return a reused one, but maybe having a tokenStream which always returns a new one, and a reusableTokenStream (w/o a field) which reuses a stream (maybe the &apos;default&apos; stream), would be good.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;What do you think?&lt;/p&gt;</comment>
                    <comment id="12741334" author="rcmuir" created="Mon, 10 Aug 2009 15:09:54 +0100"  >&lt;blockquote&gt;
&lt;p&gt;Robert - wouldn&apos;t it make sense to pull SavedStreams (maybe call it ReusableStreams?) up to Analyzer, and have all the extensions use it? I couldn&apos;t help but notice that this code is duplicated in all the Analyzers. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Shai, it would be great if somehow this could be factored. its not complete duplication: different things need to happen here: for example Thai and Smart Chinese have filters that keep state and require a reset(). But i don&apos;t know, seems like it could be factored into Analyzer and reset() called on both tokenizer and filters... &lt;/p&gt;

&lt;p&gt;I am trying to imagine a situation where refactoring this kind of thing would prevent some flexibility, but i think if tokenstreams keep state in some wierd way they should implement reset() for this purpose.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Also, and I don&apos;t know if it&apos;s a matter for a different issue - the fact that reusableTokenStream accepts a field name is misleading.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;probably to support PerFieldAnalyzerWrapper is my first thought. how would PerFieldAnalyzerWrapper work correctly if field is not supplied???&lt;/p&gt;</comment>
                    <comment id="12741337" author="thetaphi" created="Mon, 10 Aug 2009 15:16:01 +0100"  >&lt;blockquote&gt;
&lt;p&gt;different things need to happen here: for example Thai and Smart Chinese have filters that keep state and require a reset(). But i don&apos;t know, seems like it could be factored into Analyzer and reset() called on both tokenizer and filters... &lt;/p&gt;

&lt;p&gt;I am trying to imagine a situation where refactoring this kind of thing would prevent some flexibility, but i think if tokenstreams keep state in some wierd way they should implement reset() for this purpose.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;reset() is always called by IndexWriter before consuming the TokenStream; end() is called as last operation on the TokenStream.&lt;/p&gt;

&lt;p&gt;And each TokenFilter should for sure pass the call also to the input TokenStream... The default impl does this.&lt;/p&gt;</comment>
                    <comment id="12741339" author="rcmuir" created="Mon, 10 Aug 2009 15:21:58 +0100"  >&lt;blockquote&gt;
&lt;p&gt;reset() is always called by IndexWriter before consuming the TokenStream; end() is called as last operation on the TokenStream.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Uwe, this may be the case for IndexWriter, but if I do not explicitly call it like so in ThaiAnalyzer, then ThaiWordFilter&apos;s reset() is not invoked:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;  streams.source.reset(reader);
  streams.result.reset(); // reset the ThaiWordFilter&apos;s state &amp;lt;-- right here
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;By calling reset I can ensure it happens regardless of what is consuming the tokenstream... (such as my tests!) maybe this is overkill?&lt;/p&gt;</comment>
                    <comment id="12741386" author="shaie" created="Mon, 10 Aug 2009 16:50:46 +0100"  >&lt;p&gt;I actually meant to pull the class SavedStreams up to Analyzer, and leave the rest of the logic in each Analyzer impl (I don&apos;t think there can be a default impl for all). SavedStreams have a Tokenizer and TokenFilter, which is what every reusable token stream needs.&lt;/p&gt;

&lt;p&gt;As for PerFieldAnalyzerWrapper --&amp;gt; it will still have a reusableTS(field) version to call. But when you call this method, you guarantee you reuse a TS for that field only.&lt;/p&gt;

&lt;p&gt;But if IW needs to call this method for every field it parses, then it can only call reusableTokenStream(field), and therefore I wonder how that optimization work ...&lt;/p&gt;</comment>
                    <comment id="12741418" author="rcmuir" created="Mon, 10 Aug 2009 17:41:50 +0100"  >&lt;p&gt;Shai: I see what you are saying wrt SavedStreams... &lt;br/&gt;
but in my opinion the biggest problem with the current setup is that it feels fragile... forcing me to create separate tests for reusableTS() to ensure its doing what TS() does.&lt;/p&gt;

&lt;p&gt;If you can think of a better way to implement this patch, i&apos;d love to hear it because I&apos;m not thrilled with what I had to do either, I just didnt see a better way.&lt;br/&gt;
but really its implemented the same way the core analyzers (Standard/Simple/Stop) are done.&lt;/p&gt;</comment>
                    <comment id="12741601" author="rcmuir" created="Mon, 10 Aug 2009 23:39:58 +0100"  >&lt;p&gt;I am thinking of expanding this patch to include reset() impls for state-keeping tokenizers/filters that do not currently have an analyzer...&lt;br/&gt;
not really part of this issue but it presents an issue for someone trying to create a custom analyzer (with reusableTS) based on these components.&lt;/p&gt;</comment>
                    <comment id="12741804" author="yseeley@gmail.com" created="Tue, 11 Aug 2009 11:59:11 +0100"  >&lt;blockquote&gt;&lt;p&gt;I am thinking of expanding this patch to include reset() impls for state-keeping tokenizers/filters that do not currently have an analyzer...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;+1&lt;/p&gt;

&lt;p&gt;In the past we&apos;ve always encouraged people to create their own analyzers by plugging together the provided filters - we should keep this simple to do.&lt;/p&gt;

&lt;p&gt;Now the problem:  TokenStream.reset() has different semantics than what we are using it for here.  CachingTokenFilter uses it to start the replay of the last string of tokens it saw (definitely bad for reuse).&lt;/p&gt;

&lt;p&gt;So.... do we redefine reset()?  Something like CachingTokenFilter is very special case, and I don&apos;t feel like it should have it&apos;s own method.  There are other ways it could be implemented now anyway.&lt;/p&gt;
</comment>
                    <comment id="12741805" author="rcmuir" created="Tue, 11 Aug 2009 12:08:17 +0100"  >&lt;blockquote&gt;
&lt;p&gt;Now the problem: TokenStream.reset() has different semantics than what we are using it for here. CachingTokenFilter uses it to start the replay of the last string of tokens it saw (definitely bad for reuse).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Hmm, I have not looked at CachingTokenFilter, sounds like an issue there.&lt;br/&gt;
In this case I was referring to state-keeping tokenizers/filters without reset() impls in contrib: Ngram, shingles, things like that.&lt;br/&gt;
I looked at the core tokenstreams and most of those seemed to properly support it... I guess we have one exception&lt;/p&gt;</comment>
                    <comment id="12741810" author="yseeley@gmail.com" created="Tue, 11 Aug 2009 12:29:22 +0100"  >&lt;p&gt;For something like CachingTokenFilter to work, the implementation of all other TokenFilters.reset() is still what we want - &quot;get rid of your state because we are starting over&quot;.  So it&apos;s really only the caching-type filters that have a semantic clash... (i.e. does reset() mean replay what I&apos;ve seen before, or does reset mean start over with new input) and perhaps we can start off by saying &quot;don&apos;t use these in conjunction with reusable token streams&quot;.&lt;/p&gt;</comment>
                    <comment id="12741813" author="rcmuir" created="Tue, 11 Aug 2009 12:36:57 +0100"  >&lt;p&gt;yonik, I see your point. &lt;/p&gt;

&lt;p&gt;&quot;get rid of your state because we are starting over&quot; just happens to equal &quot;Resets this stream to the beginning.&quot; 90% of the time,&lt;br/&gt;
but sometimes these things are different...&lt;/p&gt;

&lt;p&gt;I would really like to see it easier to have reusableStreams in the future, both for a person writing a custom analyzer and in an &quot;automatic&quot; case like TokenizerChain&lt;/p&gt;</comment>
                    <comment id="12741830" author="rcmuir" created="Tue, 11 Aug 2009 13:01:31 +0100"  >&lt;p&gt;add reset() impls for ngram/* and compound/*. These still need tests, and still a few more to be done.&lt;/p&gt;</comment>
                    <comment id="12741835" author="dmsmith555" created="Tue, 11 Aug 2009 13:34:13 +0100"  >&lt;p&gt;If CachingTokenFilter.reset() means rewind, then how does one reset it?&lt;/p&gt;

&lt;p&gt;Without that, it is not reusable.&lt;/p&gt;

&lt;p&gt;When I did the prior token/filter changes, IIRC, some were not reusable. Maybe reset needs to be documented that for reuse, the common case, it means reset (or no-op) and otherwise means rewind. And then document which classes are not reusable.&lt;/p&gt;

&lt;p&gt;Or should these single use classes be made reusable? This would argue for a rewind() method. IMHO it is a bug that reset does not follow the contract.  &lt;/p&gt;</comment>
                    <comment id="12741837" author="markrmiller@gmail.com" created="Tue, 11 Aug 2009 13:43:34 +0100"  >&lt;blockquote&gt;&lt;p&gt;This would argue for a rewind() method.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Is that a crazy idea? It almost seems like we should have reset,  requiring an impl now, and add rewind, making it optional as reset used to be?&lt;/p&gt;

&lt;p&gt;Barring the back compat issues, isn&apos;t that how this should be setup?&lt;/p&gt;</comment>
                    <comment id="12741839" author="rcmuir" created="Tue, 11 Aug 2009 13:53:40 +0100"  >&lt;p&gt;personally I like this idea. CachingTokenFilter is not final though, so you are right back compat will need some thought, but it makes sense.&lt;/p&gt;</comment>
                    <comment id="12741848" author="yseeley@gmail.com" created="Tue, 11 Aug 2009 14:02:28 +0100"  >&lt;p&gt;I don&apos;t think we need a rewind() at all on TokenStream - it&apos;s too special-case.&lt;/p&gt;</comment>
                    <comment id="12741849" author="markrmiller@gmail.com" created="Tue, 11 Aug 2009 14:05:41 +0100"  >&lt;p&gt;So what do you propose  ? You would just cast to CachingTokenFilter if you want rewind?&lt;/p&gt;

&lt;p&gt;I&apos;ve never really been a fan of these methods that are optionally implemented ... and you must know the type if you know it can rewind.&lt;/p&gt;

&lt;p&gt;So what about making reset required (and work the same across all TokenStreams) and adding rewind to CachingTokenFilter then?&lt;/p&gt;</comment>
                    <comment id="12741856" author="markrmiller@gmail.com" created="Tue, 11 Aug 2009 14:21:10 +0100"  >&lt;p&gt;Or even a Rewindable interface that can implemented if a TokenStream supports Rewind?&lt;/p&gt;

&lt;p&gt;Then, if you really needed it, you could use InstanceOf to check for support.&lt;/p&gt;</comment>
                    <comment id="12741859" author="yseeley@gmail.com" created="Tue, 11 Aug 2009 14:23:32 +0100"  >&lt;p&gt;It depends on the use case for CachingTokenFilter.&lt;br/&gt;
When it&apos;s used in places like QueryParser.getFieldQuery(), the consumer creates the CachingTokenFilter and can rewind it too.&lt;/p&gt;

&lt;p&gt;If one has managed to use the same instance more than once in the same document, other tricks could be used such as resetting to the beginning after false is returned from incrementToken() or implementing rewind in end().  Seems like either would work.&lt;/p&gt;

&lt;p&gt;But in reality, the concept of CachingTokenFilter isn&apos;t really compatible with the concept of reuse at all... so I don&apos;t think we necessarily need to do anything except document that it&apos;s not reusable.  Adding rewind() to TokenStream won&apos;t solve this semantic problem.&lt;/p&gt;</comment>
                    <comment id="12742652" author="rcmuir" created="Thu, 13 Aug 2009 00:35:24 +0100"  >&lt;p&gt;add reusable/reset impls for shingles, snowball, and memory/synonym.&lt;br/&gt;
memory/synonym had no previous tests afaik.&lt;br/&gt;
tests are still needed for compound,ngram, and shingles reset()&lt;br/&gt;
memory/PatternAnalyzer still does not use reusableTS&lt;br/&gt;
and there are two wrappers: shingle/ShingleAnalyzerWrapper and query/QueryAutoStopWordAnalyzer that should be fixed and tested.&lt;/p&gt;

&lt;p&gt;unfortunately something came up at work, so I may be slow on this, if you want to jump in, please help!&lt;br/&gt;
and let me know what you are tackling, I will do my best to work this issue late night to get it resolved.&lt;/p&gt;</comment>
                    <comment id="12742798" author="rcmuir" created="Thu, 13 Aug 2009 12:19:30 +0100"  >&lt;p&gt;with ShingleAnalyzerWrapper and tests, plan to do QueryAutoStopWord the same way... off to work&lt;/p&gt;</comment>
                    <comment id="12742974" author="shaie" created="Thu, 13 Aug 2009 22:18:29 +0100"  >&lt;p&gt;Robert, what I meant about pulling SavedStreams up to Analyzer (few comments above) was to do something like this:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
class Analyzer {
  &lt;span class=&quot;code-keyword&quot;&gt;protected&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; class Streams {
    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; Tokenizer tokenizer;
    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; TokenStream tokenStream;
  }
  ...
}

class MyAnalyzer &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; Analyzer {
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; reusableTokenStream() {
    Streams streams = getPrevTS();
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (streams == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
      streams = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Streams();
      streams.tokenizer = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Tokenizer();
      streams.tokenStream = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; TokenStream();
      setPrevTS(streams);
   } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
      streams.tokenizer.reset(reader);
      streams.tokenStream.reset();
   }
   &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; streams.tokenStream;
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This will just save the declaration of SavedStreams or Streams in all sub-classes. In addition we can do the following:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;Define reset(String, Reader) on Streams, so that everyone just calls streams.reset(), instead of resetting tokenizer and tokenStream. Streams will do that internally.&lt;/li&gt;
	&lt;li&gt;Define a protected abstract getTokenizer() on Analyzer that all Analyzers implement. (due to back-compat, this can throw UOE - let&apos;s leave it for now).&lt;/li&gt;
	&lt;li&gt;Have Analyzer&apos;s reusableTokenStream look like the following:
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; TokenStream reusableTokenStream(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; field, Reader reader) {
  Streams streams = getPreviousTokenStream();
  &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (streams == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
    streams = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Streams();
    streams.tokenizer = getTokenizer(field, reader);
    streams.tokenStream = tokenStream();
    setPrevTS(streams);
  } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
    streams.reset(field, reader);
  }
  &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; streams.tokenStream;
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;And that can be even more simplified, by having Streams define a ctor which accepts Tokenizer and TokenStream. We can also instead of doing &quot;new Streams()&quot; call a method newStreams() so that sublcasses can override if they want to provide a different Streams impl. Not a must, and we might even consider the whole thing final (Streams, reusableTokenStream ? etc.)&lt;/p&gt;

&lt;p&gt;That will save some code in that patch I believe. What do you think?&lt;/p&gt;

&lt;p&gt;I haven&apos;t touched the back-compat issues yet - let&apos;s discuss the idea first.&lt;/p&gt;</comment>
                    <comment id="12742978" author="shaie" created="Thu, 13 Aug 2009 22:22:44 +0100"  >&lt;p&gt;Also Robert, I&apos;ve looked at the patch and I see that you don&apos;t call reset() on streams.result, just on source. I think you should call that on streams.result too. You do it in TestSynonymTokenFilter.&lt;/p&gt;

&lt;p&gt;If we go w/ my proposal above, such issues will not happen, since there will be only one copy of reusableTokenStreams (at least for the majority of analyzers).&lt;/p&gt;</comment>
                    <comment id="12742984" author="rcmuir" created="Thu, 13 Aug 2009 22:34:19 +0100"  >&lt;p&gt;Shai, first of all let me address your first comment... for the saved streams thing.&lt;/p&gt;

&lt;p&gt;one issue would be how to implement AnalyzerWrappers with that? with the existing functionality I am able to make this work. See my impl for ShingleAnalyzerWrapper for an example.&lt;/p&gt;

&lt;p&gt;your second comment, I only call reset() on streams.result when there is a state-keeping TokenFilter on that chain. it is not necessary to invoke it if reset() is a no-op...&lt;/p&gt;</comment>
                    <comment id="12742988" author="rcmuir" created="Thu, 13 Aug 2009 22:47:52 +0100"  >&lt;p&gt;Shai thinking about this some more, as long as the behavior could be overridden for the extreme case&lt;br/&gt;
i think it would make some sense to somehow have a &apos;default&apos; implementation (what you are proposing does make sense)&lt;br/&gt;
and it could be overridden in the strange cases if the thing is non-final.&lt;/p&gt;

&lt;p&gt;but now my problem child is memory/PatternAnalyzer, its source of tokens is not a Tokenizer.&lt;br/&gt;
So the getTokenizer() method does not make sense in that case... (I guess it could throw UOE there but it starts to sound like we are dancing around the problem)&lt;/p&gt;</comment>
                    <comment id="12742994" author="shaie" created="Thu, 13 Aug 2009 22:58:57 +0100"  >&lt;blockquote&gt;&lt;p&gt;I only call reset() on streams.result when there is a state-keeping TokenFilter on that chain. it is not necessary to invoke it if reset() is a no-op...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;What if one of those streams will become state-keeper some day? I don&apos;t think that calling reset() and have it done nothing will be expensive, no?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;but now my problem child is memory/PatternAnalyzer, its source of tokens is not a Tokenizer.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It could just override reusableTokenStream and do what it wants, no?&lt;/p&gt;

&lt;p&gt;I must admit that I still have in mind the current TokenStream and Analyzer API. Therefore my suggestion may not be 100% compatible w/ AttributeSource and the new stuff. But my gut feeling tells me there has to be a way to remove all those unnecessary impls in all Analyzers. The following default impl seems too obvious than to say we cannot do it:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;protected&lt;/span&gt; TokenStream internalTokenStream() {
  &lt;span class=&quot;code-comment&quot;&gt;// &lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt; something
&lt;/span&gt;}

&lt;span class=&quot;code-keyword&quot;&gt;protected&lt;/span&gt; Tokenizer getTokenizer() {
  &lt;span class=&quot;code-comment&quot;&gt;// &lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt; something
&lt;/span&gt;}

&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; TokenStream tokenStream() {
  TokenStream result = getTokenizer();
  result = internalTokenStream(result);
  &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; result;
}

&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; TokenStream reusableTokenStream() {
  Streams streams = getPrevTS();
  &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (streams == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
    streams = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Streams();
    streams.tokenizer = getTokenizer();
    streams.tokenStream = internalTokenStream(streams.tokenizer);
    setPrevTS(streams);
  } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
    streams.reset();
  } 
  &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; streams.tokenStream;
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I&apos;ll try to impl it tomorrow, using the new API and see how it goes.&lt;/p&gt;</comment>
                    <comment id="12743000" author="rcmuir" created="Thu, 13 Aug 2009 23:15:02 +0100"  >&lt;blockquote&gt;
&lt;p&gt;What if one of those streams will become state-keeper some day? I don&apos;t think that calling reset() and have it done nothing will be expensive, no?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;it could also become completely incompatible with reuse in some way, (example: CachingTokenFilter). in that case reset will not help either &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;It could just override reusableTokenStream and do what it wants, no?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Oh, definitely, my concern was what should getTokenizer() do in that case? I guess as long as getTokenizer() is not public and is documented as optional operation, then I would not have a problem with this case...&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I&apos;ll try to impl it tomorrow, using the new API and see how it goes.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;please do, I think its a great idea! I am just bringing up the ridiculous cases in contrib, as long as its flexible enough that things can be overridden in those cases, it could save a lot of heartache and maintenance hassle.&lt;/p&gt;

&lt;p&gt;do you have any ideas on the back compat issues?&lt;/p&gt;</comment>
                    <comment id="12743183" author="shaie" created="Fri, 14 Aug 2009 13:12:47 +0100"  >&lt;p&gt;We only need getTokenizer because TokenStream.reset() does not accept a Reader. If we could introduce such method on TokenStream, we wouldn&apos;t need to refer to Tokenizer directly.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;do you have any ideas on the back compat issues?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Well it&apos;s a bit trickier ... today we call reusableTokenStream in our indexing code, and either get a new instance, or a reused instance. We cannot change Analyzer&apos;s default behavior, which returns a new instance (unless we&apos;re willing to break back-compat), because Analyzers that did not override reusableTokenStream, may break if we start reusing the instance by default (for example if they add two fields to a document w/ reusableTokenStream called twice).&lt;/p&gt;

&lt;p&gt;Also, deprecate reusableTokenStream and define a new one (say reuseTokenStream), and move to use it is not good either, since we want its default impl to reuse the token stream, and impls that did not override it may break.&lt;/p&gt;

&lt;p&gt;So how about if we create a new abstract ReusingAnalyzer which impls reusableTokenStream to always reuse it. And we add Streams to Analyzer as a protected static class. That way, Analyzers that don&apos;t care about reuse, can still extend Analyzer. Analyzers which care about reuse and are fine w/ ReusingAnalyzer&apos;s impl, can move to extend it. And Analyzers that care about reuse but want their reuse to be done differently can choose to extend ReusingAnalyzer, or Analyzer.&lt;/p&gt;

&lt;p&gt;Back-compat wise, we&apos;re safe since:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;Existing Lucene Analyzers that reuse can be changed to extend ReusingAnalyzer.&lt;/li&gt;
	&lt;li&gt;Existing Analyzers (outside Lucene code) either override or not reusableTokenStream, and therefore won&apos;t break.&lt;/li&gt;
	&lt;li&gt;Our indexing code will still call reusableTokenStream, no change here.&lt;/li&gt;
	&lt;li&gt;Any code out there which traverses an Analyzer by calling reusableTokenStream does not need to change anything.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;I think that&apos;d work?&lt;/p&gt;</comment>
                    <comment id="12743187" author="rcmuir" created="Fri, 14 Aug 2009 13:22:13 +0100"  >&lt;p&gt;Shai, works for me.&lt;/p&gt;

&lt;p&gt;i will keep working on this patch, but if you get ReusingAnalyzer together, i can easily move 95% of the code to it &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
it is doing the tests that take forever anyway and they will not change.&lt;/p&gt;

&lt;p&gt;thank you!&lt;/p&gt;</comment>
                    <comment id="12743343" author="rcmuir" created="Fri, 14 Aug 2009 19:27:07 +0100"  >&lt;p&gt;the tests will not pass for upcoming patch unless &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1801&quot; title=&quot;Tokenizers (which are the source of Tokens) should call AttributeSource.clearAttributes() first&quot;&gt;&lt;del&gt;LUCENE-1801&lt;/del&gt;&lt;/a&gt; is applied first.&lt;/p&gt;

&lt;p&gt;this is because i test that if you interrupt a shinglefilter, the type is correct (and it is currently not being cleared correctly).&lt;/p&gt;</comment>
                    <comment id="12743345" author="rcmuir" created="Fri, 14 Aug 2009 19:30:01 +0100"  >&lt;p&gt;rest of the analyzers and tests, except memory/PatternAnalyzer. The design of the tokenstreams used by this analyzer does not support reusableTS and it will need to be redesigned to make this happen.&lt;/p&gt;
</comment>
                    <comment id="12743721" author="yseeley@gmail.com" created="Sat, 15 Aug 2009 15:46:08 +0100"  >&lt;p&gt;Patch looks good - do you plan on committing soon Robert?&lt;/p&gt;</comment>
                    <comment id="12743727" author="rcmuir" created="Sat, 15 Aug 2009 16:37:12 +0100"  >&lt;p&gt;Yonik, thanks for reviewing it. &lt;br/&gt;
I wanted to wait a bit and see if Shai wanted to give a crack at ReusingAnalyzer, but we could do that as a separate issue and then refactor code to use it?&lt;/p&gt;</comment>
                    <comment id="12743728" author="yseeley@gmail.com" created="Sat, 15 Aug 2009 16:43:25 +0100"  >&lt;p&gt;Yes, I think we should just commit this now - the most important part is that people can create their own reusable tokenstreams from Lucene&apos;s tokenizers and token filters.  Making an easier to use ReusingAnalyzer can be a separate issue.&lt;/p&gt;</comment>
                    <comment id="12743730" author="rcmuir" created="Sat, 15 Aug 2009 16:53:11 +0100"  >&lt;p&gt;Yonik, ok, I will look over the patch again, but I plan on committing this tonight or tomorrow if nothing comes up.&lt;/p&gt;</comment>
                    <comment id="12743757" author="shaie" created="Sat, 15 Aug 2009 20:55:35 +0100"  >&lt;p&gt;Apologies for the late post, I had a busy weekend. Attached patch includes ReusingAnalyzer, Streams in Analyzer and javadocs.&lt;/p&gt;

&lt;p&gt;Robert, please have a look. I think extending it should be fairly straightforward and we can probably finish the integration in a couple of days. However if you discover it isn&apos;t the case, we can separate it into a different issue.&lt;/p&gt;

&lt;p&gt;Also, I did not include a note in CHANGES. Once you&apos;re done merging it into the larger patch, I can help w/ the javadocs and CHANGES if required.&lt;/p&gt;</comment>
                    <comment id="12743763" author="yseeley@gmail.com" created="Sat, 15 Aug 2009 21:13:33 +0100"  >&lt;p&gt;Perhaps the Streams class should be part of ReusingAnalyzer and not Analyzer?  It&apos;s a specific implementation of a reusable token stream, not part of the Analyzer interface.&lt;/p&gt;</comment>
                    <comment id="12743770" author="shaie" created="Sat, 15 Aug 2009 21:42:31 +0100"  >&lt;p&gt;Well ... it&apos;s true and false at the same time. On one hand, I think Analyzer should impl reusableTokenStream just like ReusingAnalyzer, but we can&apos;t do that because of back-compat. On the other hand, Streams does belong to ReusingAnalyzer because it makes use of it.&lt;/p&gt;

&lt;p&gt;What I thought was that maybe someone would want to make use of Streams w/o extending Analyzer. And ... we may want to constraint setPreviousTokenStream to Streams, or TokenStream or a generic type of thing, to avoid casting and be more type-safe.&lt;/p&gt;

&lt;p&gt;I wonder if we&apos;ll stay w/ Analyzer.reusableTS as it is forever, or will we break it one day to be like ReusingAnalyzer (and by that deprecate ReusingAnalyzer?).&lt;/p&gt;

&lt;p&gt;I guess that if we think for the long term that ReusingAnalyzer will stay, and hence most Analyzers will actually be ReusingAnalyzer extension, then I&apos;m ok w/ moving Streams into ReusingAnalyzer. But keeping it in Analyzer will allow us in the future to constrain prevTokenStream to be of that type and not a generic Object.&lt;/p&gt;</comment>
                    <comment id="12743774" author="rcmuir" created="Sat, 15 Aug 2009 22:21:40 +0100"  >&lt;p&gt;Shai, I will take a look at your patch as soon as I am at a real computer. thanks for your work in advance, we maybe should put it on another issue though just to keep the scope of this one reasonably contained.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;And ... we may want to constraint setPreviousTokenStream to Streams, or TokenStream or a generic type of thing, to avoid casting and be more type-safe.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;see QueryAutoStopWordAnalyzer in my patch for a counter-example to this. in this case, it is a Set, because it is dependent upon field.&lt;/p&gt;</comment>
                    <comment id="12743776" author="yseeley@gmail.com" created="Sat, 15 Aug 2009 22:49:20 +0100"  >&lt;p&gt;In general, we should strive to treat our base abstract classes like interfaces, with the ability to provide default implementations to avoid back compatibility breaks (while avoiding adding members or non-overrideable methods).  One could make the case that the ClosableThreadLocal should not be in Analyzer either, but it&apos;s been there long enough now, it would break back compat to move it.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;What I thought was that maybe someone would want to make use of Streams w/o extending Analyzer.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;They still can - ReusableAnalyzer.Streams.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;But keeping it in Analyzer will allow us in the future to constrain prevTokenStream to be of that type and not a generic Object.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Doesn&apos;t seem like we should force all tokenstreams to be reusable, or constrain the exact form of how a reusable token stream is obtained.&lt;/p&gt;</comment>
                    <comment id="12743778" author="shaie" created="Sat, 15 Aug 2009 23:03:18 +0100"  >&lt;p&gt;I guess you&apos;re both right. I thought that one day we&apos;ll cancel ReusingAnalyzer and pull it up to Analyzer, but it looks like ReusingAnalyzer makes sense to stay, and so we can move Streams to it.&lt;/p&gt;

&lt;p&gt;Robert, if possible, I&apos;d like to get this one in as part of this issue. The reason is that you already modified all Analyzers to impl reusableTokenStream. I&apos;m afraid that if we&apos;ll do it in another issue, some Analyzers will be skipped over. If you want, I can apply this to your patch and post pack an updated one tomorrow.&lt;/p&gt;</comment>
                    <comment id="12743786" author="markrmiller@gmail.com" created="Sun, 16 Aug 2009 00:28:04 +0100"  >&lt;p&gt;To not break back compat, everything has got to work even if they don&apos;t yet move from the deprecated method.&lt;/p&gt;
</comment>
                    <comment id="12743788" author="rcmuir" created="Sun, 16 Aug 2009 00:47:00 +0100"  >&lt;blockquote&gt;
&lt;p&gt;Robert, if possible, I&apos;d like to get this one in as part of this issue. The reason is that you already modified all Analyzers to impl reusableTokenStream. I&apos;m afraid that if we&apos;ll do it in another issue, some Analyzers will be skipped over. If you want, I can apply this to your patch and post pack an updated one tomorrow.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Shai, this is a valid concern. But also lets not forget analyzers that already implement reusableTS that are not a part of this patch (yet should be changed to extend ReusingAnalyzer)... examples include collation/* analyzers/fa, etc.&lt;/p&gt;

&lt;p&gt;But even before this I think we should make sure everyone is happy with ReusingAnalyzer itself... this is the only reason I think it might merit another issue... this patch is already a little unwieldy because I crept the scope to include reset(Reader) and reset() methods for tokenstreams that keep state...&lt;/p&gt;</comment>
                    <comment id="12743791" author="yseeley@gmail.com" created="Sun, 16 Aug 2009 01:24:48 +0100"  >&lt;blockquote&gt;&lt;p&gt;But even before this I think we should make sure everyone is happy with ReusingAnalyzer itself... this is the only reason I think it might merit another issue&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;+1&lt;/p&gt;

&lt;p&gt;The ReusingAnalyzer brings up other issues of protocol - right now consumers like lucene indexing call reset() on the stream, but I see the prototype ReusingAnalyzer also calling reset() on the stream.&lt;/p&gt;</comment>
                    <comment id="12743816" author="shaie" created="Sun, 16 Aug 2009 07:17:16 +0100"  >&lt;blockquote&gt;&lt;p&gt;right now consumers like lucene indexing call reset() on the stream, but I see the prototype ReusingAnalyzer also calling reset() on the stream.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don&apos;t think that&apos;s a new problem - I simply coded what I think most Analyzers that do impl reusableTS do. And if there are reusableTS impls that don&apos;t call reset() on purpose, then we shouldn&apos;t call it.&lt;/p&gt;

&lt;p&gt;Therefore, I think that we should change our code to not call reset(). I don&apos;t think there&apos;s a reusableTS impl which does not call reset(), because it relies on the consumer to do it (nobody guarantees that anyway). We should simply note that on reusableTS javadoc (e.g., something like &quot;return an already reset token stream&quot;). I don&apos;t mind doing that in a separate issue if that&apos;s what you prefer.&lt;/p&gt;</comment>
                    <comment id="12743830" author="rcmuir" created="Sun, 16 Aug 2009 12:34:18 +0100"  >&lt;p&gt;i would like to commit this as is later today and we create a separate issue for improving reusability:  ReusingAnalyzer, figure out who calls reset(), that sort of thing? &lt;/p&gt;</comment>
                    <comment id="12743831" author="shaie" created="Sun, 16 Aug 2009 12:38:15 +0100"  >&lt;p&gt;Works for me. +1&lt;/p&gt;</comment>
                    <comment id="12743839" author="rcmuir" created="Sun, 16 Aug 2009 13:42:51 +0100"  >&lt;p&gt;Committed revision 804680.&lt;/p&gt;</comment>
                    <comment id="12744494" author="rcmuir" created="Tue, 18 Aug 2009 14:17:19 +0100"  >&lt;p&gt;there is a small backwards compatibility problem here.&lt;br/&gt;
some of the analyzers, such as GermanAnalyzer, have a setStemExclusionTable method.&lt;/p&gt;

&lt;p&gt;with reusableTS, if someone changes the Stem Exclusion table, it will not take effect instantly like it did before.&lt;br/&gt;
so for these, if someone changes it, we should blow away saved streams I think: setPreviousTokenStream(null)&lt;/p&gt;

&lt;p&gt;patch and tests coming.&lt;/p&gt;</comment>
                    <comment id="12744519" author="rcmuir" created="Tue, 18 Aug 2009 15:22:38 +0100"  >&lt;p&gt;fix + tests for br, de, fr, and nl analyzers.&lt;/p&gt;</comment>
                    <comment id="12744546" author="rcmuir" created="Tue, 18 Aug 2009 16:19:04 +0100"  >&lt;p&gt;i plan to commit this fix at the end of the day if nobody objects to it.&lt;/p&gt;</comment>
                    <comment id="12744783" author="michaelbusch" created="Wed, 19 Aug 2009 00:47:39 +0100"  >&lt;p&gt;Patch looks good!&lt;/p&gt;</comment>
                    <comment id="12744789" author="rcmuir" created="Wed, 19 Aug 2009 01:00:56 +0100"  >&lt;p&gt;Michael, thanks for the review. &lt;/p&gt;

&lt;p&gt;But I am looking over all the analyzers again one last time, and I think i found another devious one:&lt;br/&gt;
CzechAnalyzer has a loadStopWords() method which is not a utility method, it replaces the stoptable.&lt;/p&gt;

&lt;p&gt;So I will go thru these again (very slowly), and upload another patch.&lt;/p&gt;

&lt;p&gt;Sorry for missing these the first time.&lt;/p&gt;</comment>
                    <comment id="12744823" author="rcmuir" created="Wed, 19 Aug 2009 02:07:28 +0100"  >&lt;p&gt;null out saved streams in the case someone calls CzechAnalyzer loadStopWords(),&lt;br/&gt;
so that new stopwords are applied immediately with reusableTS.&lt;/p&gt;</comment>
                    <comment id="12745017" author="rcmuir" created="Wed, 19 Aug 2009 12:58:36 +0100"  >&lt;p&gt;Committed revision 805766.&lt;/p&gt;</comment>
                </comments>
                <issuelinks>
                        <issuelinktype id="10032">
                <name>Blocker</name>
                                                <inwardlinks description="is blocked by">
                            <issuelink>
            <issuekey id="12432803">LUCENE-1801</issuekey>
        </issuelink>
                    </inwardlinks>
                            </issuelinktype>
                    </issuelinks>
                <attachments>
                    <attachment id="12416940" name="LUCENE-1794_fix2.txt" size="15653" author="rcmuir" created="Wed, 19 Aug 2009 02:07:28 +0100" />
                    <attachment id="12416879" name="LUCENE-1794_fix.patch" size="11081" author="rcmuir" created="Tue, 18 Aug 2009 15:22:38 +0100" />
                    <attachment id="12416586" name="LUCENE-1794.patch" size="98465" author="rcmuir" created="Fri, 14 Aug 2009 19:30:01 +0100" />
                    <attachment id="12416426" name="LUCENE-1794.patch" size="83456" author="rcmuir" created="Thu, 13 Aug 2009 12:19:30 +0100" />
                    <attachment id="12416376" name="LUCENE-1794.patch" size="75541" author="rcmuir" created="Thu, 13 Aug 2009 00:35:24 +0100" />
                    <attachment id="12416191" name="LUCENE-1794.patch" size="61226" author="rcmuir" created="Tue, 11 Aug 2009 13:01:31 +0100" />
                    <attachment id="12416058" name="LUCENE-1794.patch" size="58005" author="rcmuir" created="Mon, 10 Aug 2009 14:03:34 +0100" />
                    <attachment id="12416047" name="LUCENE-1794.patch" size="57364" author="rcmuir" created="Mon, 10 Aug 2009 12:51:34 +0100" />
                    <attachment id="12416670" name="LUCENE-1794-reusing-analyzer.patch" size="5802" author="shaie" created="Sat, 15 Aug 2009 20:55:35 +0100" />
                </attachments>
            <subtasks>
        </subtasks>
                <customfields>
                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                <customfieldname>Attachment count</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>9.0</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                <customfieldname>Date of First Response</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>Mon, 10 Aug 2009 13:49:39 +0000</customfieldvalue>

                </customfieldvalues>
            </customfield>
                                                                                                        <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Global Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>11968</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                <customfieldname>Lucene Fields</customfieldname>
                <customfieldvalues>
                        <customfieldvalue key="10121"><![CDATA[New]]></customfieldvalue>
    
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>25932</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                <customfieldname>Time in Status</customfieldname>
                <customfieldvalues>
                    
                </customfieldvalues>
            </customfield>
                            </customfields>
    </item>
</channel>
</rss>