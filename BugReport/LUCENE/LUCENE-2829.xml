<!-- 
RSS generated by JIRA (5.2.8#851-sha1:3262fdc28b4bc8b23784e13eadc26a22399f5d88) at Tue Jul 16 13:31:42 UTC 2013

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/LUCENE-2829/LUCENE-2829.xml?field=key&field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>5.2.8</version>
        <build-number>851</build-number>
        <build-date>26-02-2013</build-date>
    </build-info>

<item>
            <title>[LUCENE-2829] improve termquery &quot;pk lookup&quot; performance</title>
                <link>https://issues.apache.org/jira/browse/LUCENE-2829</link>
                <project id="12310110" key="LUCENE">Lucene - Core</project>
                        <description>&lt;p&gt;For things that are like primary keys and don&apos;t exist in some segments (worst case is primary/unique key that only exists in 1)&lt;br/&gt;
we do wasted seeks.&lt;/p&gt;

&lt;p&gt;While &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-2694&quot; title=&quot;MTQ rewrite + weight/scorer init should be single pass&quot;&gt;&lt;del&gt;LUCENE-2694&lt;/del&gt;&lt;/a&gt; tries to solve some of this issue with TermState, I&apos;m concerned we could every backport that to 3.1 for example.&lt;/p&gt;

&lt;p&gt;This is a simpler solution here just to solve this one problem in termquery... we could just revert it in trunk when we resolve &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-2694&quot; title=&quot;MTQ rewrite + weight/scorer init should be single pass&quot;&gt;&lt;del&gt;LUCENE-2694&lt;/del&gt;&lt;/a&gt;,&lt;br/&gt;
but I don&apos;t think we should leave things as they are in 3.x&lt;/p&gt;</description>
                <environment></environment>
            <key id="12493802">LUCENE-2829</key>
            <summary>improve termquery &quot;pk lookup&quot; performance</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                    <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png">Closed</status>
                    <resolution id="1">Fixed</resolution>
                                <assignee username="mikemccand">Michael McCandless</assignee>
                                <reporter username="rcmuir">Robert Muir</reporter>
                        <labels>
                    </labels>
                <created>Tue, 21 Dec 2010 20:35:42 +0000</created>
                <updated>Wed, 30 Mar 2011 16:49:52 +0100</updated>
                    <resolved>Mon, 10 Jan 2011 21:25:51 +0000</resolved>
                                            <fixVersion>3.1</fixVersion>
                                <component>core/search</component>
                        <due></due>
                    <votes>0</votes>
                        <watches>1</watches>
                                                    <comments>
                    <comment id="12973868" author="rcmuir" created="Tue, 21 Dec 2010 20:37:45 +0000"  >&lt;p&gt;quickly hacked up patch, &lt;/p&gt;

&lt;p&gt;for the IndexSearcher case, we sum up docFreq ourselves, along the way saving the hashcodes&lt;br/&gt;
of the readers where the term exists into a set.&lt;/p&gt;

&lt;p&gt;if this list exists (IndexSearcher case), the scorer then checks the reader&apos;s hashcode against this list...&lt;br/&gt;
if we get a collision, worst case we do a wasted seek. but we don&apos;t have to keep any hairy references&lt;br/&gt;
to readers or anything.&lt;/p&gt;</comment>
                    <comment id="12973869" author="mikemccand" created="Tue, 21 Dec 2010 20:43:07 +0000"  >&lt;p&gt;I made a random PK lookup tester (committed to luceneutil), to lookup by docid (unique key) from the luceneutil index.&lt;/p&gt;

&lt;p&gt;Pre-patch it&apos;s 53 usec per lookup and with this patch it&apos;s 31 usec &amp;#8211; ~42% faster!&lt;/p&gt;</comment>
                    <comment id="12973877" author="rcmuir" created="Tue, 21 Dec 2010 20:47:13 +0000"  >&lt;p&gt;right, we just have to not do stupid things like hash hashcodes to make it faster for when the data is hot...&lt;br/&gt;
but as a start this is safe, hopefully we could do something non-invasive (and backportable) to make it faster.&lt;/p&gt;
</comment>
                    <comment id="12973882" author="hossman" created="Tue, 21 Dec 2010 20:54:10 +0000"  >&lt;p&gt;The patch is over my head, but providing a super optimized solution to the &quot;primary key&quot; type lookup problem definitely seems worthwhile &amp;#8211; it has me wondering if a &quot;PrimaryKeyQuery&quot; that works like TermQuery bug quits collecting as soon as it finds one matching document would be a good idea?&lt;/p&gt;</comment>
                    <comment id="12973889" author="rcmuir" created="Tue, 21 Dec 2010 21:12:07 +0000"  >&lt;p&gt;Hoss Man, well I think if you surely know its a PK field you can definitely do something better, starting with a custom collector that does something like what you mentioned, with no PQ at all etc.&lt;/p&gt;

&lt;p&gt;But in this case, though i categorized it as PK, the general problem is this:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;in lots of cases we do redundant seeks, like to get the docFreq, then to get the DocsEnum&lt;/li&gt;
	&lt;li&gt;in most cases the term dictionary cache helps here because the 2nd time (e.g. getting DocsEnum) is cached.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Here&apos;s the problem with &quot;PK&quot; or &quot;PK-ish&quot; (low freq terms like what wildcards/fuzzies/range queries hit too):&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;our cache doesn&apos;t cache &quot;negative&quot; hits, the fact that a term &lt;b&gt;doesnt&lt;/b&gt; exist in some segment.&lt;/li&gt;
	&lt;li&gt;For example in the PK case, if there are 15 segments we always get at most 1 cache hit and&lt;br/&gt;
at least 14 misses when getting the DocsEnum, so we do at least 14 wasted seeks always.&lt;/li&gt;
	&lt;li&gt;For other low frequency terms that don&apos;t exist in all segments (very precise dates or what have you)&lt;br/&gt;
the same idea applies, just to a lesser extent: the PK is the worst.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12973890" author="mikemccand" created="Tue, 21 Dec 2010 21:15:24 +0000"  >&lt;p&gt;I think a cleaner interface may be for the Weight.scorer method to receive the ord of the sub reader in the parent?&lt;/p&gt;

&lt;p&gt;This way TermWeight doesn&apos;t need a hash / ReaderView &amp;#8211; it can use just an array.&lt;/p&gt;

&lt;p&gt;We could also make it a struct/class, that contain parent, sub, and ord.  This way TermWeight (and others) could assert they are not invoked on a different parent reader.&lt;/p&gt;</comment>
                    <comment id="12973892" author="rcmuir" created="Tue, 21 Dec 2010 21:22:29 +0000"  >&lt;blockquote&gt;&lt;p&gt;I think a cleaner interface may be for the Weight.scorer method to receive the ord of the sub reader in the parent?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes, ideally with the actual df in there. This would save the third seek in the bulkpostings branch.&lt;/p&gt;

&lt;p&gt;But at the same time, i&apos;m worried/don&apos;t want this issue to evolve into TermState (&lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-2694&quot; title=&quot;MTQ rewrite + weight/scorer init should be single pass&quot;&gt;&lt;del&gt;LUCENE-2694&lt;/del&gt;&lt;/a&gt;). I wasn&apos;t thinking &lt;br/&gt;
that this was any kind of end-solution but just an approach we could take that would work against 3.1&lt;/p&gt;</comment>
                    <comment id="12973902" author="mikemccand" created="Tue, 21 Dec 2010 21:27:48 +0000"  >&lt;blockquote&gt;&lt;p&gt;but just an approach we could take that would work against 3.1&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Well it&apos;s already a 42% speedup so it seems very worthwhile already.&lt;/p&gt;

&lt;p&gt;But, then, passing a struct (parent/sub/ord) is a fairly small change, and, if it &quot;matches&quot; the change we will make on &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-2694&quot; title=&quot;MTQ rewrite + weight/scorer init should be single pass&quot;&gt;&lt;del&gt;LUCENE-2694&lt;/del&gt;&lt;/a&gt;, then that&apos;s great.&lt;/p&gt;</comment>
                    <comment id="12973908" author="rcmuir" created="Tue, 21 Dec 2010 21:35:11 +0000"  >&lt;blockquote&gt;&lt;p&gt;But, then, passing a struct (parent/sub/ord) is a fairly small change, and, if it &quot;matches&quot; the change we will make on &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-2694&quot; title=&quot;MTQ rewrite + weight/scorer init should be single pass&quot;&gt;&lt;del&gt;LUCENE-2694&lt;/del&gt;&lt;/a&gt;, then that&apos;s great.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Ok, that might be a good approach, to fix the it this way in &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-2694&quot; title=&quot;MTQ rewrite + weight/scorer init should be single pass&quot;&gt;&lt;del&gt;LUCENE-2694&lt;/del&gt;&lt;/a&gt; (or actually, preferably add the parent/sub/ord in its own issue!), &lt;br/&gt;
but in 3.1 we could use the struct to avoid wasted seeks on PK terms... &lt;/p&gt;

&lt;p&gt;Seems like backporting the entire termstate thing could be a little tricky/risky for 3.1, with not much to gain there except&lt;br/&gt;
PK lookups anyway, since the multitermqueries there tend to be slow (dominated by term comparison) and don&apos;t even work&lt;br/&gt;
per-segment anyway.&lt;/p&gt;</comment>
                    <comment id="12974212" author="yseeley@gmail.com" created="Wed, 22 Dec 2010 14:23:29 +0000"  >&lt;p&gt;Why not keep the TermState cache and use it for all queries except MTQ, while using a different mechanism for MTQ to avoid trashing the cache?&lt;/p&gt;

&lt;p&gt;The cache has a number of advantages that may never be duplicated in a different type of API, including&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;actually cache frequently used terms across different requests&lt;/li&gt;
	&lt;li&gt;cache terms reused in the same request.  term proximity boosting is an example:   +united +states &quot;united states&quot;^10&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;edit: and as robert previously pointed out, if we cached misses as well, then we could avoid needless seeks on segments that don&apos;t contain the term.&lt;/p&gt;</comment>
                    <comment id="12974223" author="rcmuir" created="Wed, 22 Dec 2010 14:46:19 +0000"  >&lt;blockquote&gt;&lt;p&gt;edit: and as robert previously pointed out, if we cached misses as well, then we could avoid needless seeks on segments that don&apos;t contain the term.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;True, this is a good idea, just a little tricker:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;In trunk, we have TermsEnum.seek(BytesRef text, boolean useCache), defaulting to true.&lt;/li&gt;
	&lt;li&gt;FilteredTermsEnum passes false here, so the multitermqueries don&apos;t populate the cache with&lt;br/&gt;
  garbage while enumerating (eg foo*),  only explicitly at the end with cacheTerm() (per-segment) &lt;br/&gt;
  for the ones that were actually accepted. They sum up their docFreq themselves to prevent the &lt;br/&gt;
  first wasted seek in TermQuery. &lt;/li&gt;
	&lt;li&gt;So this solution would make MTQ worse, as it would cause them to trash the caches in the&lt;br/&gt;
  second wasted seek (the docsenum) where they do not today, with negative entries for the &lt;br/&gt;
  segments where the term doesn&apos;t exist. Today they do this wasted seek, but they don&apos;t &lt;br/&gt;
  trash the cache here. The only solution to prevent that is the PerReaderTermState &lt;br/&gt;
  (or something equally complicated).&lt;/li&gt;
	&lt;li&gt;We would have to look at other places where negative entries would hurt, for example&lt;br/&gt;
  rebuilding spellcheck indexes uses this &apos;termExists()&apos; method implemented with docFreq. &lt;br/&gt;
  So we would have to likely change spellcheck&apos;s code to use a TermsEnum and &lt;br/&gt;
  seek(term, false)... using a termsenum in parallel with the spellcheck dictionary would &lt;br/&gt;
  obviously be more efficient for the index-based spellcheck case (forget about caching)&lt;br/&gt;
  versus docFreq()&apos;ing every term... &lt;b&gt;but&lt;/b&gt; we cannot assume the spellcheck &quot;Dictionary&quot; &lt;br/&gt;
  is actually in term order, (imagine the File-based dictionary case), so we can&apos;t &lt;br/&gt;
  implement this today.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;On 3.x i think its slightly less complicated as there is already a hack in the cache to &lt;br/&gt;
prevent sequential termsenums from trashing it (e.g. foo*), and pretty much all the MTQs &lt;br/&gt;
just enumerate sequentially anyway... (except NRQ which doesn&apos;t enum many terms &lt;br/&gt;
anyway, likely not a problem).&lt;/p&gt;

&lt;p&gt;But we would have to at least fix the spellcheck case there too I think.&lt;/p&gt;

&lt;p&gt;Not saying I don&apos;t like your idea... just saying there&apos;s more work to do it.&lt;/p&gt;</comment>
                    <comment id="12974229" author="rcmuir" created="Wed, 22 Dec 2010 14:58:54 +0000"  >&lt;p&gt;On further thought Yonik, your idea is really completely unrelated.&lt;/p&gt;

&lt;p&gt;We shouldn&apos;t be seeking to terms/relying upon the terms dictionary cache &lt;br/&gt;
internally when we don&apos;t need to...&lt;/p&gt;

&lt;p&gt;whether or not its populated with negative entries for the more general case is unrelated,&lt;br/&gt;
even if we go that route we shouldn&apos;t be lazy and rely upon that.&lt;/p&gt;</comment>
                    <comment id="12974262" author="mikemccand" created="Wed, 22 Dec 2010 16:25:34 +0000"  >&lt;blockquote&gt;&lt;p&gt;The cache has a number of advantages that may never be duplicated in a different type of API&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;+1 &amp;#8211; I agree we should keep the TermState cache.  It has benefits outside of re-use win a single query.&lt;/p&gt;

&lt;p&gt;But allowing term-lookup-intensive clients like MTQ  to do their own caching (ie pulling the TermState from the enum) is also important.  I think we need both.&lt;/p&gt;

&lt;p&gt;On caching misses... that makes me nervous.  If there are apps out there that do alot of checking for terms that don&apos;t exist that can destroy the cache.&lt;/p&gt;

&lt;p&gt;The cache is a great safety net but I think our core queries should be good consumers, when possible, and hold their own TermState.&lt;/p&gt;</comment>
                    <comment id="12974274" author="earwin" created="Wed, 22 Dec 2010 16:46:33 +0000"  >&lt;p&gt;Term lookup misses can be alleviated by a simple Bloom Filter.&lt;br/&gt;
No caching misses required, helps both PK and near-PK queries.&lt;/p&gt;</comment>
                    <comment id="12974310" author="rcmuir" created="Wed, 22 Dec 2010 18:08:45 +0000"  >&lt;p&gt;Bloom filters and negative caches are nice, but please open separate issues!&lt;br/&gt;
I am starting to feel like its mandatory to refactor the entirety of lucene to make a single incremental improvement.&lt;/p&gt;

&lt;p&gt;So, I&apos;d like to proceed with this issue as-is, to make TermWeight explicitly do less seeks.&lt;/p&gt;</comment>
                    <comment id="12974350" author="earwin" created="Wed, 22 Dec 2010 19:35:55 +0000"  >&lt;p&gt;Nobody halts your progress, we&apos;re merely discussing.&lt;/p&gt;

&lt;p&gt;I, on the other hand, have a feeling that Lucene is overflowing with &quot;single incremental improvements&quot; aka &quot;hacks&quot;, as they are easier and faster to implement than trying to get a bigger picture, and, yes, rebuilding everything &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
For example, better term dict code will make this issue (somewhat hackish, admit it?) irrelevant. Whether we implement bloom filters, or just guarantee to keep the whole term dict in memory with reasonable lookup routine (eg. as FST).&lt;/p&gt;

&lt;p&gt;Having said that, I reiterate, I&apos;m not here to stop you or turn this issue into something else.&lt;/p&gt;</comment>
                    <comment id="12974354" author="rcmuir" created="Wed, 22 Dec 2010 19:43:48 +0000"  >&lt;blockquote&gt;&lt;p&gt;For example, better term dict code will make this issue (somewhat hackish, admit it?) irrelevant. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Right, it is hackish, but what is a worse hack is wasted seeks in our next 3.1 release because we can&apos;t&lt;br/&gt;
keep scope under control and fix small problems without rewriting everything, which means less &lt;br/&gt;
gets backported to our stable branch.&lt;/p&gt;

&lt;p&gt;Anyway, I&apos;m just gonna mark this won&apos;t fix so I don&apos;t have to deal with it anymore.&lt;/p&gt;</comment>
                    <comment id="12977353" author="mikemccand" created="Tue, 4 Jan 2011 17:20:24 +0000"  >&lt;p&gt;I think we should commit this, and if/when &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-2694&quot; title=&quot;MTQ rewrite + weight/scorer init should be single pass&quot;&gt;&lt;del&gt;LUCENE-2694&lt;/del&gt;&lt;/a&gt; and/or &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-2831&quot; title=&quot;Revise Weight#scorer &amp;amp; Filter#getDocIdSet API to pass Readers context&quot;&gt;&lt;del&gt;LUCENE-2831&lt;/del&gt;&lt;/a&gt; are committed to 3.x, we can revisit it.&lt;/p&gt;</comment>
                    <comment id="12978415" author="mikemccand" created="Thu, 6 Jan 2011 17:28:52 +0000"  >&lt;p&gt;I ported this patch to 3.x, and fix a few tests that were illegally passing top readers to Weight.scorer.  There&apos;s still a couple nocommits, but I think it&apos;s close.&lt;/p&gt;</comment>
                    <comment id="12979192" author="mikemccand" created="Sat, 8 Jan 2011 19:59:31 +0000"  >&lt;p&gt;New patch.  I added VirtualMethods to Sim to make sure Sim subclasses that don&apos;t override idfExplain that takes docFreq are still called.&lt;/p&gt;</comment>
                    <comment id="13013283" author="gsingers" created="Wed, 30 Mar 2011 16:49:52 +0100"  >&lt;p&gt;Bulk close for 3.1&lt;/p&gt;</comment>
                </comments>
                    <attachments>
                    <attachment id="12467805" name="LUCENE-2829.patch" size="16868" author="mikemccand" created="Sat, 8 Jan 2011 19:59:31 +0000" />
                    <attachment id="12467646" name="LUCENE-2829.patch" size="14763" author="mikemccand" created="Thu, 6 Jan 2011 17:28:52 +0000" />
                    <attachment id="12466757" name="LUCENE-2829.patch" size="2178" author="rcmuir" created="Tue, 21 Dec 2010 20:37:45 +0000" />
                </attachments>
            <subtasks>
        </subtasks>
                <customfields>
                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                <customfieldname>Attachment count</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>3.0</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                <customfieldname>Date of First Response</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>Tue, 21 Dec 2010 20:43:07 +0000</customfieldvalue>

                </customfieldvalues>
            </customfield>
                                                                                                        <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Global Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>11031</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                <customfieldname>Lucene Fields</customfieldname>
                <customfieldvalues>
                        <customfieldvalue key="10121"><![CDATA[New]]></customfieldvalue>
    <customfieldvalue key="10120"><![CDATA[Patch Available]]></customfieldvalue>
    
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>24863</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                <customfieldname>Time in Status</customfieldname>
                <customfieldvalues>
                    
                </customfieldvalues>
            </customfield>
                            </customfields>
    </item>
</channel>
</rss>