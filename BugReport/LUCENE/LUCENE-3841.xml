<!-- 
RSS generated by JIRA (5.2.8#851-sha1:3262fdc28b4bc8b23784e13eadc26a22399f5d88) at Tue Jul 16 13:08:53 UTC 2013

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/LUCENE-3841/LUCENE-3841.xml?field=key&field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>5.2.8</version>
        <build-number>851</build-number>
        <build-date>26-02-2013</build-date>
    </build-info>

<item>
            <title>[LUCENE-3841] CloseableThreadLocal does not work well with Tomcat thread pooling</title>
                <link>https://issues.apache.org/jira/browse/LUCENE-3841</link>
                <project id="12310110" key="LUCENE">Lucene - Core</project>
                        <description>&lt;p&gt;We tracked down a large memory leak (effectively a leak anyway) caused&lt;br/&gt;
by how Analyzer users CloseableThreadLocal.&lt;br/&gt;
CloseableThreadLocal.hardRefs holds references to Thread objects as&lt;br/&gt;
keys.  The problem is that it only frees these references in the set()&lt;br/&gt;
method, and SnowballAnalyzer will only call set() when it is used by a&lt;br/&gt;
NEW thread.&lt;/p&gt;

&lt;p&gt;The problem scenario is as follows:&lt;/p&gt;

&lt;p&gt;The server experiences a spike in usage (say by robots or whatever)&lt;br/&gt;
and many threads are created and referenced by&lt;br/&gt;
CloseableThreadLocal.hardRefs.  The server quiesces and lets many of&lt;br/&gt;
these threads expire normally.  Now we have a smaller, but adequate&lt;br/&gt;
thread pool.  So CloseableThreadLocal.set() may not be called by&lt;br/&gt;
SnowBallAnalyzer (via Analyzer) for a &lt;em&gt;long&lt;/em&gt; time.  The purge code is&lt;br/&gt;
never called, and these threads along with their thread local storage&lt;br/&gt;
(lucene related or not) is never cleaned up.&lt;/p&gt;

&lt;p&gt;I think calling the purge code in both get() and set() would have&lt;br/&gt;
avoided this problem, but is potentially expensive.  Perhaps using &lt;br/&gt;
WeakHashMap instead of HashMap may also have helped.  WeakHashMap &lt;br/&gt;
purges on get() and set().  So this might be an efficient way to&lt;br/&gt;
clean up threads in get(), while set() might do the more expensive&lt;br/&gt;
Map.keySet() iteration.&lt;/p&gt;

&lt;p&gt;Our current work around is to not share SnowBallAnalyzer instances&lt;br/&gt;
among HTTP searcher threads.  We open and close one on every request.&lt;/p&gt;

&lt;p&gt;Thanks,&lt;br/&gt;
Matt&lt;/p&gt;</description>
                <environment>&lt;p&gt;Lucene/Tika/Snowball running in a Tomcat web application&lt;/p&gt;</environment>
            <key id="12545007">LUCENE-3841</key>
            <summary>CloseableThreadLocal does not work well with Tomcat thread pooling</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                    <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png">Closed</status>
                    <resolution id="1">Fixed</resolution>
                                <assignee username="mikemccand">Michael McCandless</assignee>
                                <reporter username="mbellew">Matthew Bellew</reporter>
                        <labels>
                    </labels>
                <created>Fri, 2 Mar 2012 23:56:03 +0000</created>
                <updated>Fri, 10 May 2013 11:44:05 +0100</updated>
                    <resolved>Wed, 14 Mar 2012 15:43:39 +0000</resolved>
                            <version>3.5</version>
                                <fixVersion>3.6</fixVersion>
                <fixVersion>4.0-ALPHA</fixVersion>
                                <component>core/other</component>
                        <due></due>
                    <votes>0</votes>
                        <watches>1</watches>
                                                    <comments>
                    <comment id="13221629" author="eksdev" created="Sat, 3 Mar 2012 16:31:10 +0000"  >&lt;p&gt;This is indeed a problem. Recently we moved to solr on tomcat and we hit it, slightly different form. &lt;/p&gt;

&lt;p&gt;The nature of the problem is in high thread churn on tomcat, and when combined with expensive analyzers it wracks gc() havoc (&lt;b&gt;even without stale ClosableThreadLocals from this issue&lt;/b&gt;). We are attacking this problem currently by reducing maxThreads and increasing minSpareThreads (also reducing time to forced thread renew). The goal is to increase life-time of threads, and to contain them to reasonable limits. I would appreciate any tips into this direction.&lt;/p&gt;

&lt;p&gt;The problem with this strategy is if some cheep requests, not really related to your search saturate smallish thread pool... I am looking for a way to define separate thread pools for search/update requests and one for the rest as it does not make sense to have 100 search threads searching lucene on dual core box. Not really experienced with tomcat... &lt;/p&gt;

&lt;p&gt;Of course, keeping Analyzer creation cheep helps(e.g. make expensive, background structures thread-safe that can be shared and only thin analyzer using them). But this is not always easy.&lt;/p&gt;

&lt;p&gt;Just sharing experience here, maybe someone finds it helpful. Hints always welcome &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;


</comment>
                    <comment id="13227049" author="mikemccand" created="Sun, 11 Mar 2012 14:00:37 +0000"  >&lt;p&gt;I think it should be safe to use a WeakHashMap for the hardRefs instead of HashMap?&lt;/p&gt;

&lt;p&gt;This way, if a thread has finished and its Thread object is otherwise GCable, the entries in hardRefs should be cleared... though, it&apos;s not clear to me precisely when they will be cleared.  If it&apos;s only on future access to the WeakHashMap (get or set), which seems likely because I think WeakHashMap uses a WeakReference for the keys and therefore won&apos;t really remove an entry util it&apos;s later &quot;touched&quot;, then again only on set will the object be cleared and we haven&apos;t really improved the situation.&lt;/p&gt;

&lt;p&gt;Matthew, did you try that change, and, did it improve the scenario above?&lt;/p&gt;

&lt;p&gt;Failing that, I think we have to purge it get... maybe we can amortize it (every Nth get, where N is a factor of how many entries are in the map...).&lt;/p&gt;

&lt;p&gt;Also: I don&apos;t think PagedBytes should use CloseableThreadLocal... I think it should just new byte[].&lt;/p&gt;

&lt;p&gt;Separately: maybe SnowballAnalyzer is too heavy...?  Does it have some static data that ought to be loaded once and shared across analyzers... but isn&apos;t today?&lt;/p&gt;</comment>
                    <comment id="13227055" author="rcmuir" created="Sun, 11 Mar 2012 14:24:12 +0000"  >&lt;blockquote&gt;
&lt;p&gt;Separately: maybe SnowballAnalyzer is too heavy...? Does it have some static data that ought to be loaded once and shared across analyzers... but isn&apos;t today?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think the analyzers are going to be heavy.&lt;/p&gt;

&lt;p&gt;If we start going down the path of trying to speed up their instantiation time, then I vote to remove reusable tokenstreams completely.&lt;/p&gt;

&lt;p&gt;That is: i don&apos;t think we should suffer the &apos;worst of both worlds&apos;. either we go thru all the effort to make things reusable, or we dont&lt;br/&gt;
and instead worry about instantiation time, etc.&lt;/p&gt;</comment>
                    <comment id="13227099" author="mikemccand" created="Sun, 11 Mar 2012 17:17:27 +0000"  >&lt;p&gt;Patch.&lt;/p&gt;

&lt;p&gt;I cutover to WeakHashMap for the hard refs, and now purge periodically&lt;br/&gt;
from both set and get.  The purge frequency is 20X the number of&lt;br/&gt;
threads in the map, so that the amortized cost remains linear.&lt;/p&gt;

&lt;p&gt;I also stopped using CTL in PagedBytes, and added some additional&lt;br/&gt;
tests for it.&lt;/p&gt;
</comment>
                    <comment id="13227100" author="mikemccand" created="Sun, 11 Mar 2012 17:21:55 +0000"  >&lt;blockquote&gt;
&lt;p&gt;I think the analyzers are going to be heavy.&lt;/p&gt;

&lt;p&gt;If we start going down the path of trying to speed up their instantiation time, then I vote to remove reusable tokenstreams completely.&lt;/p&gt;

&lt;p&gt;That is: i don&apos;t think we should suffer the &apos;worst of both worlds&apos;. either we go thru all the effort to make things reusable, or we dont&lt;br/&gt;
 and instead worry about instantiation time, etc.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Sorry, you&apos;re right: it&apos;s fine for the Analyzer to be heavy/slow to&lt;br/&gt;
init/etc., as long as the TokenStreams then share static state.&lt;/p&gt;

&lt;p&gt;So, what I meant is: are the TokenStreams returned from&lt;br/&gt;
SnowballAnalyzer somehow not sharing static stuff...?  Or, why would&lt;br/&gt;
they be so heavy...?&lt;/p&gt;
</comment>
                    <comment id="13229267" author="mikemccand" created="Wed, 14 Mar 2012 15:43:40 +0000"  >&lt;p&gt;Thanks Matthew!&lt;/p&gt;</comment>
                </comments>
                    <attachments>
                    <attachment id="12517898" name="LUCENE-3841.patch" size="10539" author="mikemccand" created="Sun, 11 Mar 2012 17:17:27 +0000" />
                </attachments>
            <subtasks>
        </subtasks>
                <customfields>
                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                <customfieldname>Attachment count</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>1.0</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                <customfieldname>Date of First Response</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>Sat, 3 Mar 2012 16:31:10 +0000</customfieldvalue>

                </customfieldvalues>
            </customfield>
                                                                                                        <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Global Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>230194</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                <customfieldname>Lucene Fields</customfieldname>
                <customfieldvalues>
                        <customfieldvalue key="10121"><![CDATA[New]]></customfieldvalue>
    
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>23858</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                <customfieldname>Time in Status</customfieldname>
                <customfieldvalues>
                    
                </customfieldvalues>
            </customfield>
                            </customfields>
    </item>
</channel>
</rss>