<!-- 
RSS generated by JIRA (5.2.8#851-sha1:3262fdc28b4bc8b23784e13eadc26a22399f5d88) at Tue Jul 16 13:02:07 UTC 2013

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/LUCENE-1461/LUCENE-1461.xml?field=key&field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>5.2.8</version>
        <build-number>851</build-number>
        <build-date>26-02-2013</build-date>
    </build-info>

<item>
            <title>[LUCENE-1461] Cached filter for a single term field</title>
                <link>https://issues.apache.org/jira/browse/LUCENE-1461</link>
                <project id="12310110" key="LUCENE">Lucene - Core</project>
                        <description>&lt;p&gt;These classes implement inexpensive range filtering over a field containing a single term. They do this by building an integer array of term numbers (storing the term-&amp;gt;number mapping in a TreeMap) and then implementing a fast integer comparison based DocSetIdIterator.&lt;/p&gt;

&lt;p&gt;This code is currently being used to do age range filtering, but could also be used to do other date filtering or in any application where there need to be multiple filters based on the same single term field. I have an untested implementation of single term filtering and have considered but not yet implemented term set filtering (useful for location based searches) as well. &lt;/p&gt;

&lt;p&gt;The code here is fairly rough; it works but lacks javadocs and toString() and hashCode() methods etc. I&apos;m posting it here to discover if there is other interest in this feature; I don&apos;t mind fixing it up but would hate to go to the effort if it&apos;s not going to make it into Lucene.&lt;/p&gt;
</description>
                <environment></environment>
            <key id="12408791">LUCENE-1461</key>
            <summary>Cached filter for a single term field</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/newfeature.png">New Feature</type>
                                <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                    <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png">Closed</status>
                    <resolution id="1">Fixed</resolution>
                                <assignee username="thetaphi">Uwe Schindler</assignee>
                                <reporter username="tsturge">Tim Sturge</reporter>
                        <labels>
                    </labels>
                <created>Wed, 19 Nov 2008 01:13:03 +0000</created>
                <updated>Tue, 30 Jun 2009 12:18:17 +0100</updated>
                    <resolved>Tue, 30 Jun 2009 12:18:17 +0100</resolved>
                                            <fixVersion>2.9</fixVersion>
                                        <due></due>
                    <votes>1</votes>
                        <watches>1</watches>
                                                    <comments>
                    <comment id="12648862" author="tsturge" created="Wed, 19 Nov 2008 01:17:30 +0000"  >&lt;p&gt;Base code which builds the integer array.&lt;/p&gt;</comment>
                    <comment id="12648863" author="tsturge" created="Wed, 19 Nov 2008 01:19:14 +0000"  >&lt;p&gt;Constructs a virtual RangeFilter on top of an already existing DisjointMultiFilter. Note that the RangeFilter costs almost nothing once the DisjointMultiFilter already exists. &lt;/p&gt;</comment>
                    <comment id="12648869" author="tsturge" created="Wed, 19 Nov 2008 01:26:36 +0000"  >&lt;p&gt;Here&apos;s some benchmark data to demonstrate the utility. Results on a 45M document index:&lt;/p&gt;

&lt;p&gt;Firstly without an age constraint as a baseline:&lt;/p&gt;

&lt;p&gt;Query &quot;+name:tim&quot; &lt;br/&gt;
startup: 0 &lt;br/&gt;
Hits: 15089&lt;br/&gt;
first query: 1004&lt;br/&gt;
100 queries: 132 (1.32 msec per query)&lt;/p&gt;

&lt;p&gt;Now with a cached filter. This is ideal from a speed standpoint but as with most range based queries there are too many possible start/end combinations to cache all the filters.&lt;/p&gt;

&lt;p&gt;Query &quot;+name:tim age:&lt;span class=&quot;error&quot;&gt;&amp;#91;18 TO 35&amp;#93;&lt;/span&gt;&quot; (ConstantScoreQuery on cached RangeFilter)&lt;br/&gt;
startup: 3&lt;br/&gt;
Hits: 11156&lt;br/&gt;
first query: 1830&lt;br/&gt;
100 queries: 287 (2.87 msec per query)&lt;/p&gt;

&lt;p&gt;Now with an uncached filter. This is awful.&lt;/p&gt;

&lt;p&gt;Query &quot;+name:tim age:&lt;span class=&quot;error&quot;&gt;&amp;#91;18 TO 35&amp;#93;&lt;/span&gt;&quot; (uncached ConstantScoreRangeQuery)&lt;br/&gt;
startup: 3&lt;br/&gt;
Hits: 11156&lt;br/&gt;
first query: 1665&lt;br/&gt;
100 queries: 51862 (yes, 518 msec per query, 200x slower)&lt;/p&gt;

&lt;p&gt;A RangeQuery is slightly better but still bad (and has a different result set)&lt;/p&gt;

&lt;p&gt;Query &quot;+name:tim age:&lt;span class=&quot;error&quot;&gt;&amp;#91;18 TO 35&amp;#93;&lt;/span&gt;&quot; (uncached RangeQuery)&lt;br/&gt;
startup: 0&lt;br/&gt;
Hits: 10147&lt;br/&gt;
first query: 1517&lt;br/&gt;
100 queries: 27157 (271 msec is 100x slower than the filter)&lt;/p&gt;

&lt;p&gt;Now with the prebuilt column stride filter:&lt;/p&gt;

&lt;p&gt;Query &quot;+name:tim age:&lt;span class=&quot;error&quot;&gt;&amp;#91;18 TO 35&amp;#93;&lt;/span&gt;&quot; (ConstantScoreQuery on prebuilt column stride filter)&lt;br/&gt;
startup: 2811&lt;br/&gt;
Hits: 11156&lt;br/&gt;
first query: 1395&lt;br/&gt;
100 queries: 441 (back down to 4.41msec per query)&lt;/p&gt;

&lt;p&gt;This is less than 2x slower than the dedicated bitset and more than 50x faster than the range boolean query.&lt;/p&gt;
</comment>
                    <comment id="12649143" author="paul.elschot@xs4all.nl" created="Wed, 19 Nov 2008 19:31:53 +0000"  >&lt;p&gt;This is a nice tradeoff: reduced space (the equivalent of 32 bit set range filters) for increased time (less than 2x slower) against any number of range filters on a single term field.&lt;/p&gt;</comment>
                    <comment id="12649195" author="tsturge" created="Wed, 19 Nov 2008 22:43:17 +0000"  >&lt;p&gt;Thanks Paul.&lt;/p&gt;

&lt;p&gt;This solved a nasty performance itch with the system we are building at hi5. &lt;/p&gt;

&lt;p&gt;I&apos;m looking into whether using a byte[] or short[] makes sense when there are less total terms (it will certainly save space, don&apos;t know about performance). &lt;/p&gt;

&lt;p&gt;The other thing I wonder is whether you can use this for a set based query (for example a set of location grid-blocks). What I need there is a very fast java integer set (hopefully much faster than java.util.HashSet&amp;lt;Integer&amp;gt;)&lt;/p&gt;
</comment>
                    <comment id="12649298" author="paul.elschot@xs4all.nl" created="Thu, 20 Nov 2008 08:05:55 +0000"  >&lt;p&gt;For fields that have no more distinct values than fit into a short (2^16 at best, 65536), using a short[] would make sense I think. As the number of distinct field values can simply be counted in this context, it would make sense to simply replace the int[] by a short[] in that case. But it would only help to reduce space, and only a factor two.&lt;/p&gt;

&lt;p&gt;For a set based query, the problem boils down to doing integer set membership in the iterator. For small sets, binary search should be fine. For larger ones an OpenBitSet would be preferable, but in this context that would only be feasible when the number of different terms is a lot smaller than the number of documents in the index.&lt;/p&gt;

&lt;p&gt;For location grid-blocks one needs to deal with more than one dimension. In such cases my first thought is to use indexed hierarchical prefixes in each dimension, because this allows skipTo() to be used on the documents for the intersection between the dimensions. (But there may be better ways, it&apos;s a long time ago that I had a look at the literature for this.)&lt;br/&gt;
Do you need to index separate lower bounds and upper bounds on the data? That would complicate things.&lt;br/&gt;
Without indexed bounds (i.e. point data only) for each dimension it could make sense to use this multi range filter.&lt;/p&gt;
</comment>
                    <comment id="12649494" author="tsturge" created="Thu, 20 Nov 2008 21:47:49 +0000"  >&lt;p&gt;For small subsets of a large set (in my case around 1000 out of 1million) I suspect a simple open hash may perform better than a binary search. &lt;/p&gt;

&lt;p&gt;For location blocks (point data) my plan is just to number the grid with N^2 numbers and create a set based on a circle around the desired place. Ideally this solution doesn&apos;t degrade with circle size so it&apos;s not necessary to do hierarchical prefixes, but I don&apos;t have benchmarks to support or refute that assumption. Agreed bounded locations make this much trickier.&lt;/p&gt;

</comment>
                    <comment id="12649575" author="tsturge" created="Fri, 21 Nov 2008 02:11:35 +0000"  >&lt;p&gt;I tried a short[] array and it is about 20% faster than the int[] array (I&apos;m assuming this is a memory bandwidth issue.)&lt;/p&gt;

&lt;p&gt;I also tried replacing catching the ArrayIndexOutOfBoundsException with a check in the loop and discovered that the exception handling is about 3% faster.&lt;/p&gt;

&lt;p&gt;Finally, I implemented TermMultiFilter as well which has about the same performance characteristics.&lt;/p&gt;</comment>
                    <comment id="12649576" author="tsturge" created="Fri, 21 Nov 2008 02:12:10 +0000"  >&lt;p&gt;Added TermMultiFilter.java&lt;/p&gt;</comment>
                    <comment id="12649637" author="paul.elschot@xs4all.nl" created="Fri, 21 Nov 2008 10:03:26 +0000"  >&lt;blockquote&gt;&lt;p&gt;I tried a short[] array and it is about 20% faster than the int[] array (I&apos;m assuming this is a memory bandwidth issue.) &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;20% is more than I expected. Have a look at &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1410&quot; title=&quot;PFOR implementation&quot;&gt;&lt;del&gt;LUCENE-1410&lt;/del&gt;&lt;/a&gt; for optimal bit packing in a frame of reference. There are also some performance numbers there for different numbers of frame bits. (A short[] is equivalent to 16 frame bits.)&lt;br/&gt;
This 20% means that it could well be wortwhile to always use such a frame for the docContents here.&lt;/p&gt;

&lt;p&gt;I would not expect that TermMultiFilter has an advantage over a TermFilter, since it does a linear search even for skipTo(). The only advantage it has it that it does the linear search from memory where TermFilter does its skipping using the skip info in the index.&lt;/p&gt;

&lt;p&gt;Would anyone else have an idea where this could be added, in core or contrib, and what (new) package name could be used?&lt;/p&gt;</comment>
                    <comment id="12649639" author="mikemccand" created="Fri, 21 Nov 2008 10:34:05 +0000"  >&lt;p&gt;It seems like the core class here (DisjointMultiFilter) is doing the same thing as FieldCache&apos;s StringIndex?  Ie, it builds a data structure that maps String &amp;lt;-&amp;gt; ord and docID -&amp;gt; ord.  So maybe we can merge DisjointMultiFilter into the FieldCache API.&lt;/p&gt;

&lt;p&gt;And then RangeMultiFilter is a great addition for quickly &quot;spawning&quot; numerous new RangeFilters, having pulled &amp;amp; stored the StringIndex from the FieldCache?  So I think it should live in core org.apache.lucene.search.*?  I&apos;d prefer a different name (RangeMultiFilter implies it can filter over multiple ranges) but can&apos;t think of one.  Or maybe we absorb it into RangeFilter, as a different &quot;rewrite&quot; method like &quot;useFieldCache=true|false&quot;?&lt;/p&gt;</comment>
                    <comment id="12649777" author="tsturge" created="Fri, 21 Nov 2008 19:55:12 +0000"  >&lt;p&gt;Paul,&lt;/p&gt;

&lt;p&gt;Wow, I didn&apos;t realize people spent so much time on integer packing. I think there&apos;s lots of opportunities here, particularly if this ends up in the index (so the potential I/O cost becomes a factor as well as mem bandwidth). &lt;/p&gt;

&lt;p&gt;I agree that TermMultiFilter is not that useful; I mostly have it because I&apos;m looking at TermsMultiFilter for location matching and wanted some benchmarks versus regular filters so I could compare set implementations.&lt;/p&gt;

&lt;p&gt;Mike,&lt;/p&gt;

&lt;p&gt;I hadn&apos;t looked at fieldcache before, but StringIndex does seem to be the same thing as DisjointMultiFilter (modulo using a String[] instead of a TreeMap).  I&apos;ll port RangeMultiFilter to run on top of FieldCache and check it is identical and performs similarly (which seems like a fairly sure bet once I figure out the FieldCache API.) &lt;/p&gt;

&lt;p&gt;FieldCacheRangeFilter?  (yeah, I know &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; )&lt;/p&gt;




</comment>
                    <comment id="12649794" author="paul.elschot@xs4all.nl" created="Fri, 21 Nov 2008 21:06:21 +0000"  >&lt;blockquote&gt;&lt;p&gt;I didn&apos;t realize people spent so much time on integer packing.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Well, it appears that the memory-CPU bus really is getting to be a bottleneck, and you&apos;re not the first one to discover that, see the papers on which &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1410&quot; title=&quot;PFOR implementation&quot;&gt;&lt;del&gt;LUCENE-1410&lt;/del&gt;&lt;/a&gt; is based.&lt;br/&gt;
Nevertheless I was surprised by a 20% performance increase when moving from int[] to short[].&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I&apos;ll port RangeMultiFilter to run on top of FieldCache.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;That means that bit packing could be confined to the FieldCache lateron, which is good.&lt;br/&gt;
At the moment I&apos;m factoring out the exceptions in the 1410 code. The FieldCache may need to wait for that because it will probably not be using exceptions.&lt;br/&gt;
Just think of the extreme case of a field that has only two indexed values, it would be effectively cached as a bit set.&lt;/p&gt;</comment>
                    <comment id="12650292" author="tsturge" created="Mon, 24 Nov 2008 19:38:38 +0000"  >&lt;p&gt;This is a version of RangeMultiFilter built on top of FieldCache. This is much cleaner; it automatically handles changing the IndexReader and no longer requires the user to manually build a separate DisjointMultiFilter.&lt;/p&gt;

&lt;p&gt;Performance is the same:&lt;/p&gt;

&lt;p&gt;Cached Range Filter:&lt;br/&gt;
startup: 2&lt;br/&gt;
Hits: 167390&lt;br/&gt;
first query: 2009&lt;br/&gt;
100 queries: 4733&lt;/p&gt;

&lt;p&gt;RangeMultiFilter + FieldCache&lt;br/&gt;
startup: 0&lt;br/&gt;
Hits: 167390&lt;br/&gt;
first query: 5405&lt;br/&gt;
100 queries: 8091&lt;/p&gt;

&lt;p&gt;ConstantScoreRangeQuery&lt;br/&gt;
startup: 3&lt;br/&gt;
Hits: 167390&lt;br/&gt;
first query: 2012&lt;br/&gt;
100 queries: 56620&lt;/p&gt;

&lt;p&gt;Boolean Query for Range&lt;br/&gt;
startup: 0&lt;br/&gt;
Hits: 121151&lt;br/&gt;
first query: 3518&lt;br/&gt;
100 queries: 118690&lt;/p&gt;


</comment>
                    <comment id="12650303" author="tsturge" created="Mon, 24 Nov 2008 20:04:44 +0000"  >&lt;p&gt;Paul, Mike,&lt;/p&gt;

&lt;p&gt;FieldCache.StringIndex doesn&apos;t behave in the way I expect. In particular, the first element of the lookup[] array is null (which causes the binarySearch to NPE when you select a range wider than the one that actually exists.)&lt;/p&gt;

&lt;p&gt;Is this a bug in FieldCache? I would expect it to only contain terms actually in the index and I&apos;m sincerely hoping that null is not a valid term.&lt;/p&gt;</comment>
                    <comment id="12650308" author="tsturge" created="Mon, 24 Nov 2008 20:15:28 +0000"  >&lt;p&gt;Looking at FieldCache and FieldDocSortedHitQueue I am very tempted to change the null sentinel (which already causes lots of grief in the comparator) to an empty string. &lt;/p&gt;

&lt;p&gt;I&apos;m not sure that lucene is prepared to distinguish a field that is completely missing with an empty field (or field that is analyzed away), and I think the null exception handling is a significant pain.&lt;/p&gt;
</comment>
                    <comment id="12650495" author="paul.elschot@xs4all.nl" created="Tue, 25 Nov 2008 08:52:26 +0000"  >&lt;p&gt;Here&apos;s a patch for the latest RangeMultiFilter. I&apos;ve changed the package to o.a.l.search, changed the layout (where&apos;s the tool to automatically do that?), and I&apos;ve added the Apache Licence, assuming that&apos;s ok from the earlier licence grant.&lt;/p&gt;</comment>
                    <comment id="12650496" author="paul.elschot@xs4all.nl" created="Tue, 25 Nov 2008 09:01:30 +0000"  >&lt;p&gt;Tim,&lt;/p&gt;

&lt;p&gt;If there is code that depends on some particular null/empty string behaviour of FieldCache&lt;br/&gt;
there should be a test for that, so just try and patch FieldCache as you need it, and then see whether all tests still pass.&lt;br/&gt;
This way is a bit pushing, but it gets things going, and it&apos;s still no more than a patch.&lt;/p&gt;

&lt;p&gt;Could you add some test code for RangeMultiFilter?&lt;/p&gt;</comment>
                    <comment id="12650527" author="mikemccand" created="Tue, 25 Nov 2008 11:04:38 +0000"  >&lt;p&gt;In fact, could you add a test that actually indexes an empty-string token (you&apos;ll have to make your own &quot;degenerate&quot; TokenStrem to do this I think), to ensure that switching to empty-string as sentinel doesn&apos;t break anything?&lt;/p&gt;</comment>
                    <comment id="12650530" author="mikemccand" created="Tue, 25 Nov 2008 11:12:06 +0000"  >&lt;p&gt;Should we absorb RangeMultiFilter into RangeFilter, and add a &quot;setMethod&quot; to RangeFilter?&lt;/p&gt;

&lt;p&gt;Someday, I think RangeFilter and RangeQuery should be implemented using hierarchical ranges (there was a reference to a page in the wiki, specifically about date range searching, recently), which would be another method.&lt;/p&gt;</comment>
                    <comment id="12650562" author="paul.elschot@xs4all.nl" created="Tue, 25 Nov 2008 13:38:17 +0000"  >&lt;blockquote&gt;&lt;p&gt;Someday, I think RangeFilter and RangeQuery should be implemented using hierarchical ranges (there was a reference to a page in the wiki, specifically about date range searching, recently), which would be another method.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think you&apos;re referring to the hierarchical prefixes here:&lt;br/&gt;
&lt;a href=&quot;http://wiki.apache.org/jakarta-lucene/DateRangeQueries&quot; class=&quot;external-link&quot;&gt;http://wiki.apache.org/jakarta-lucene/DateRangeQueries&lt;/a&gt;&lt;br/&gt;
These hierarchical ranges require an analyzer to output all tokens &quot;to the root&quot; and a disjunction filter on the terms corresponding to the levels in the range. At each level a RangeMultiFilter could be used, but that would require a lot of memory. TermFilters would be better in that case I think.&lt;/p&gt;</comment>
                    <comment id="12650566" author="thetaphi" created="Tue, 25 Nov 2008 13:46:16 +0000"  >&lt;p&gt;I understood this in the same way. This is why I reported to the java-dev-Mailing list my developments going in this directions, perhaps for contrib: &lt;a href=&quot;http://www.gossamer-threads.com/lists/lucene/java-dev/67807&quot; class=&quot;external-link&quot;&gt;http://www.gossamer-threads.com/lists/lucene/java-dev/67807&lt;/a&gt;&lt;/p&gt;</comment>
                    <comment id="12650579" author="paul.elschot@xs4all.nl" created="Tue, 25 Nov 2008 14:32:15 +0000"  >&lt;p&gt;Uwe,&lt;/p&gt;

&lt;p&gt;As it is already under APL 2.0, TrieRangeQuery and its utilities would make a nice addition to Lucene as a contrib package.&lt;/p&gt;</comment>
                    <comment id="12650685" author="tsturge" created="Tue, 25 Nov 2008 19:02:21 +0000"  >&lt;p&gt;Paul,&lt;/p&gt;

&lt;p&gt;Thanks for the updates. I&apos;ll see about  toString() and hashCode() methods. Are we settled on RangeMultiFilter as the least confusing name?&lt;/p&gt;

&lt;p&gt;Mike, Paul,&lt;/p&gt;

&lt;p&gt;I&apos;ll play with the lucene test infrastructure. Right now all the tests have been in my application but I can make a clean build to try them out.&lt;/p&gt;

&lt;p&gt;Mike,&lt;/p&gt;

&lt;p&gt;I have a slight bias against adding RangeMultiFilter to RangeFilter due to the slight difference in semantics. RangeMultiFilter only works on single term fields (which should probably be mentioned in the java docs) whereas RangeFilter works on multiple term fields as well.&lt;/p&gt;

&lt;p&gt;While I expect more than 95% of the RangeFilter use cases are met by RangeMultiFilter (I suspect they are primarily dates, and otherwise prices and other numeric ranges.) I bet there are some people who really do a text range search between &quot;aardvark&quot; and &quot;antelope&quot;. Those people will unexpectedly break if they set &quot;useFieldCache=true&quot; or setMethod(). I would rather we add a comment in the RangeFilter javadocs to the effect of:&lt;/p&gt;

&lt;p&gt;&quot;If you have a single term field (for example a date, or a price) that is repeatedly used in a RangeFilter with many different ranges, you should consider using RangeMultiFilter as a faster alternative to building a RangeFilter on this field for each query. You need to ensure that this field is untokenized, or that it always tokenizes to a single term.&quot;&lt;/p&gt;


</comment>
                    <comment id="12650694" author="mikemccand" created="Tue, 25 Nov 2008 19:16:21 +0000"  >&lt;p&gt;OK that makes sense &amp;#8211; let&apos;s leave it as a separate class, and can you add that difference to the javadocs?&lt;/p&gt;</comment>
                    <comment id="12650697" author="paul.elschot@xs4all.nl" created="Tue, 25 Nov 2008 19:32:54 +0000"  >&lt;blockquote&gt;&lt;p&gt;Are we settled on RangeMultiFilter as the least confusing name?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Names are important, although not as important as javadocs.&lt;br/&gt;
I&apos;m happy to leave the choice of name to someone with an English/... mother tongue. &lt;/p&gt;</comment>
                    <comment id="12650777" author="tsturge" created="Tue, 25 Nov 2008 22:43:29 +0000"  >&lt;p&gt;Progress report:&lt;/p&gt;

&lt;p&gt;Having written some javadocs, I think FieldCacheRangeFilter is a better name; without DisjointMultiFilter the &quot;multi&quot; in RangeMultiFilter is confusing (after all, it indexes a field containing a &lt;b&gt;single&lt;/b&gt; term). So at the risk of repainting the bikeshed I will go with FieldCacheRangeFilter.&lt;/p&gt;

&lt;p&gt;The null versus &quot;&quot; distinction is completely confusing to me. I see this in ConstantScoreRangeQuery:&lt;/p&gt;

&lt;p&gt;    // Map to RangeFilter semantics which are slightly different...&lt;br/&gt;
    RangeFilter rangeFilt = new RangeFilter&lt;br/&gt;
        (fieldName, lowerVal != null?lowerVal:&quot;&quot;, upperVal,&lt;br/&gt;
         lowerVal==&quot;&quot;?false:includeLower, upperVal==null?false:includeUpper,&lt;br/&gt;
         collator);&lt;/p&gt;

&lt;p&gt;which makes no sense to me at all.&lt;/p&gt;

&lt;p&gt;I&apos;m also not sure it makes sense to allow the indexing of an empty field and distinguishing that case from there being nothing there. Please let me know if there is a usecase. The lowest impedance solution may be to write a version of binarySearch() that allows there to be a null in the first element and use that instead of Arrays.binarySearch().&lt;/p&gt;
</comment>
                    <comment id="12650840" author="tsturge" created="Wed, 26 Nov 2008 01:58:14 +0000"  >&lt;p&gt;Here&apos;s the first cleanup&lt;/p&gt;

&lt;p&gt;Changes:&lt;/p&gt;

&lt;p&gt;RangeMultiFilter now FieldCacheRangeFilter&lt;/p&gt;

&lt;p&gt;FieldCache.StringIndex gains a binarySearchLookup() method that handles null&lt;/p&gt;

&lt;p&gt;toString(), hashCode() and equals() methods.&lt;/p&gt;

&lt;p&gt;This hasn&apos;t been tested very well; but I wanted to post something before I left for Thanksgiving.&lt;/p&gt;</comment>
                    <comment id="12650882" author="earwin" created="Wed, 26 Nov 2008 07:26:59 +0000"  >&lt;p&gt;Somewhat off topic, but nonetheless, my two techniques for superfast range queries/filters:&lt;br/&gt;
1. cache &lt;span class=&quot;error&quot;&gt;&amp;#91;from, null&amp;#93;&lt;/span&gt;+&lt;span class=&quot;error&quot;&gt;&amp;#91;null, to&amp;#93;&lt;/span&gt; filters instead of &lt;span class=&quot;error&quot;&gt;&amp;#91;from, to&amp;#93;&lt;/span&gt; and intersect them&lt;br/&gt;
-&amp;gt; can tremendously improve cache hits for certain setups&lt;/p&gt;

&lt;p&gt;2. when indexing a field that will be used for range filter, index lower-resolution versions of it additionally, than use a union of rangefilters over different resolution fields, ie:&lt;br/&gt;
a. we have severalM documents with a date field spanning few years with say minute precision (we&apos;d like to sort on it afterward)&lt;br/&gt;
b. we index additional fields with dates rounded down to something like years, months, days, hours (best combination depends on width of the queries you&apos;re most likely to perform, let&apos;s say it&apos;s day+hour for queries rarely spanning more than a month)&lt;br/&gt;
c. we have a query like &lt;span class=&quot;error&quot;&gt;&amp;#91;2008-05-05 18:00 .. 2008-06-01 10:53&amp;#93;&lt;/span&gt;, it is converted to -&amp;gt; hour:[05-05 18 .. 05-06 00) or day:[05-06 .. 06-01) or hour:[06-01 00 .. 06-01 10) or minute:&lt;span class=&quot;error&quot;&gt;&amp;#91;06-01 10:00 .. 06-01 10:53&amp;#93;&lt;/span&gt;&lt;br/&gt;
-&amp;gt; massive win for ranges over fields having lots of high-selectivity terms, with timestamps being a good example, also salaries, coordinates, whatever&lt;/p&gt;</comment>
                    <comment id="12650926" author="mikemccand" created="Wed, 26 Nov 2008 10:16:20 +0000"  >&lt;blockquote&gt;&lt;p&gt;my two techniques for superfast range queries/filters&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I like those approaches &amp;#8211; I think 2 is similar to &lt;a href=&quot;#action_12650562&quot;&gt;above&lt;/a&gt; and similar to Uwe&apos;s approach (described on java-dev).  One nice property of these &quot;factor the range into a set of OR/AND clauses&quot; is RangeQuery no longer relies on the sort order of the terms, which means tricks like padding numeric terms are no longer needed, I think?&lt;/p&gt;

&lt;p&gt;This sudden burst of innovation around RangeQuery is very exciting!&lt;/p&gt;</comment>
                    <comment id="12650936" author="thetaphi" created="Wed, 26 Nov 2008 10:37:31 +0000"  >&lt;p&gt;The RangeQuery still relies on the sort order of terms (this is how it works). For storing terms with lower precision you have two possiblities:&lt;/p&gt;

&lt;p&gt;a) use another field name for each precision&lt;br/&gt;
b) prefix the terms with a precision marker. The prefix is important for the sort order, so that all terms of one precision are in one &quot;bunch&quot; and not distributed between higher precsion terms.&lt;/p&gt;

&lt;p&gt;The first version of my TrieRangeQuery was invented before the RangeFilter occurred first in Lucene. This version did exactly what was proposed here: combining more range queries with OR.&lt;/p&gt;

&lt;p&gt;For my last implementation, based on filters I did not use a BooleanQuery with OR&apos;ed ranges because of resource usage: Each RangeFilter needs an OpenBitSet instance, and all of them must be OR&apos;ed during query execution. Using only one OpenBitSet for all range parts is more effective, I think. I am currently working on including my extension to the contrib-query package. I refactored the code a little bit, so the TrieRangeFilter is now separated from the query (and because of that could be used with e.g. filter caching). I think, I will start n issue this afternoon.&lt;/p&gt;</comment>
                    <comment id="12650939" author="mikemccand" created="Wed, 26 Nov 2008 10:39:39 +0000"  >&lt;p&gt;This patch looks good!  I think it&apos;s ready to commit?  I plan to commit in a day or two.&lt;/p&gt;

&lt;p&gt;I made some small changes &amp;#8211; added CHANGES.txt entry, fixed whitespace, removed one unnecessary import.&lt;/p&gt;

&lt;p&gt;Thanks Tim!&lt;/p&gt;</comment>
                    <comment id="12650947" author="mikemccand" created="Wed, 26 Nov 2008 10:48:12 +0000"  >&lt;blockquote&gt;&lt;p&gt;The RangeQuery still relies on the sort order of terms (this is how it works)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Ahh OK. Allowing each field to provide its own Comparator may still be helpful then (Lucene doesn&apos;t allow this today since fields are always sorted in java char order) to avoid padding and other binary conversion tricks.&lt;/p&gt;</comment>
                    <comment id="12650974" author="earwin" created="Wed, 26 Nov 2008 12:03:32 +0000"  >&lt;blockquote&gt;&lt;p&gt;RangeQuery no longer relies on the sort order of the terms, which means tricks like padding numeric terms are no longer needed, I think?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I do rely on sort order for speed and simplicity, though I never used padding for numeric/date terms &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; All dates/numbers/somethingelsespecial are converted to strings using base-2 &lt;sup&gt;15&lt;/sup&gt; (to keep high bit=0, as 0xFFFF is used somewhere within Lucene intestines as EOS marker, darn it!) encoding. Plus adjustment to preserve sort order for negative numbers in face of unsigned java char. This transformation is insanely fast, and produces well-compressed results (I have FAT read-&amp;gt;mem/write-&amp;gt;mem+disk indexes).&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;b) prefix the terms with a precision marker. The prefix is important for the sort order, so that all terms of one precision are in one &quot;bunch&quot; and not distributed between higher precsion terms.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;And you can no longer use this field for sorting, as it has more than one term for each document.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;For my last implementation, based on filters I did not use a BooleanQuery with OR&apos;ed ranges because of resource usage&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Using filters here too&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Allowing each field to provide its own Comparator may still be helpful then&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;But you still store strings in the index. So essentially you&apos;ll convert your value from T to String, store it, retrieve it, convert back to T in such a custom comparator, and finally compare. Why should I need that second conversion and custom comparators, if I can have order-preserving bijective T&amp;lt;-&amp;gt;String relation?&lt;/p&gt;
</comment>
                    <comment id="12650994" author="mikemccand" created="Wed, 26 Nov 2008 13:32:49 +0000"  >&lt;blockquote&gt;&lt;p&gt;But you still store strings in the index. So essentially you&apos;ll convert your value from T to String, store it, retrieve it, convert back to T in such a custom comparator, and finally compare. Why should I need that second conversion and custom comparators, if I can have order-preserving bijective T&amp;lt;-&amp;gt;String relation?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;True, since you&apos;ll need to xform anyway for non-textual fields.  Or maybe eventually we can simply allow T to be the key in the terms dict (so long as T.compareTo(T) exists), which KS/Lucy apparently does.&lt;/p&gt;</comment>
                    <comment id="12651095" author="mikemccand" created="Wed, 26 Nov 2008 18:42:52 +0000"  >&lt;p&gt;See also &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1470&quot; title=&quot;Add TrieRangeFilter to contrib&quot;&gt;&lt;del&gt;LUCENE-1470&lt;/del&gt;&lt;/a&gt;, which is another way to achieve faster RangeFilter/Query, by pre-aggregating ranges during indexing and then factoring queries at search time to use the aggregates when possible.&lt;/p&gt;</comment>
                    <comment id="12651708" author="mikemccand" created="Sat, 29 Nov 2008 11:51:01 +0000"  >&lt;p&gt;Committed revision 721663.&lt;/p&gt;

&lt;p&gt;Thanks Tim!&lt;/p&gt;</comment>
                    <comment id="12652100" author="tsturge" created="Mon, 1 Dec 2008 19:07:03 +0000"  >&lt;p&gt;Mike,&lt;/p&gt;

&lt;p&gt;Thanks for committing. I have a slightly more tested version which uncovered a couple of bugs:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;using null for the upper limit didn&apos;t work&lt;/li&gt;
	&lt;li&gt;bad combinations of ranges weren&apos;t rejected with IllegalArgumentException&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;This also includes the correct version of the test suite (I accidentally included the pre edit version before)&lt;/p&gt;
</comment>
                    <comment id="12652101" author="tsturge" created="Mon, 1 Dec 2008 19:08:00 +0000"  >&lt;p&gt;New patch. Only changes are:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;initialize() in FieldCacheRangeFilter&lt;/li&gt;
	&lt;li&gt;correct version of TestFieldCacheRangeFilter.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12652107" author="mikemccand" created="Mon, 1 Dec 2008 19:22:59 +0000"  >&lt;p&gt;No problem!  Could you redo the patch relative to what&apos;s now committed (on trunk)?  This way I can more easily see the new changes.&lt;/p&gt;

&lt;p&gt;&quot;svn diff&quot; (after checking out the trunk) is the simplest way to generate a patch.&lt;/p&gt;</comment>
                    <comment id="12652117" author="tsturge" created="Mon, 1 Dec 2008 19:36:57 +0000"  >&lt;p&gt;Patch from trunk fixing upper bound in FieldCacheRangeFilter&lt;/p&gt;</comment>
                    <comment id="12652118" author="tsturge" created="Mon, 1 Dec 2008 19:37:26 +0000"  >&lt;p&gt;Patch from incorrect to correct test suite&lt;/p&gt;</comment>
                    <comment id="12652126" author="mikemccand" created="Mon, 1 Dec 2008 19:53:15 +0000"  >&lt;p&gt;Committed revision 722203.&lt;/p&gt;

&lt;p&gt;Thanks Tim!&lt;/p&gt;</comment>
                    <comment id="12653361" author="otis" created="Thu, 4 Dec 2008 17:03:31 +0000"  >&lt;p&gt;Is this related to &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-855&quot; title=&quot;MemoryCachedRangeFilter to boost performance of Range queries&quot;&gt;&lt;del&gt;LUCENE-855&lt;/del&gt;&lt;/a&gt;?  The same?  Aha, I see Paul asked the reverse question in &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-855&quot; title=&quot;MemoryCachedRangeFilter to boost performance of Range queries&quot;&gt;&lt;del&gt;LUCENE-855&lt;/del&gt;&lt;/a&gt; already... Tim?&lt;/p&gt;</comment>
                    <comment id="12653408" author="tsturge" created="Thu, 4 Dec 2008 18:59:03 +0000"  >&lt;p&gt;That&apos;s amazing. &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-855&quot; title=&quot;MemoryCachedRangeFilter to boost performance of Range queries&quot;&gt;&lt;del&gt;LUCENE-855&lt;/del&gt;&lt;/a&gt; (the FieldCacheRangeFilter part) is pretty much identical in purpose and design, down to the name. The major implementation differences are that it overloaded BitSet which was necessary prior to the addition of DocIdSetIterator. Thus my implementation looks significantly cleaner even though it is basically functionally identical.&lt;/p&gt;

&lt;p&gt;I think this shows that any decent idea will be repeatedly reinvented until it is widely enough known. I personally would have saved some time both in conceptualization and implementation had I been aware of this. &lt;/p&gt;

&lt;p&gt;I would very much like to credit Matt in CHANGES.txt for this as well; it seems like an accident of fate that I&apos;m not using his implementation today.&lt;/p&gt;</comment>
                    <comment id="12723306" author="thetaphi" created="Tue, 23 Jun 2009 22:07:31 +0100"  >&lt;p&gt;I reopened the wrong issue &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;The class to handle is FieldCacheRangeFilter! Here, why reopen:&lt;/p&gt;

&lt;p&gt;This Filter is really cool on iterating on the FieldCache for StringIndex and can be even faster for ranges, that are int/float/double/... - so why not retrofit to our new naming-convention and extend:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;FieldCacheRangeFilter.newTermRange()&lt;/li&gt;
	&lt;li&gt;FieldCacheRangeFilter.newByteRange()&lt;/li&gt;
	&lt;li&gt;FieldCacheRangeFilter.newShortRange()&lt;/li&gt;
	&lt;li&gt;FieldCacheRangeFilter.newIntRange()&lt;/li&gt;
	&lt;li&gt;...&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;It could because of that also be used on &quot;old&quot; int/long fields of dates, if a good parser is given (parser that does SimpleDateFormat -&amp;gt; long -&amp;gt; FieldCache -&amp;gt; direct comparison on this raw numbers). I would try to extend this to all types and it can be faster than TrieRange, if the range is already in FieldCache!&lt;/p&gt;</comment>
                    <comment id="12723671" author="thetaphi" created="Wed, 24 Jun 2009 19:30:14 +0100"  >&lt;p&gt;Here is an first version of retrofitted FieldCacheRangeFilter. It supports StringIndex like before for normal string ranges and as an example Byte ranges on FieldCache.getBytes(). Optional a parser can be given, passed to getBytes(). The internal code structure was changed to make it easier to implement the iterator for each data type.&lt;/p&gt;

&lt;p&gt;The test currently only checks StringIndex (it is the original test), other datatypes beyond byte are not implemented until now (it&apos;s mostly copy&apos;n&apos;paste...)&lt;/p&gt;</comment>
                    <comment id="12723819" author="thetaphi" created="Thu, 25 Jun 2009 01:14:28 +0100"  >&lt;p&gt;Patch that implements all FieldCache data types. The Double/Float includesXxxx code is a littly bit a hack, I will think about it again.&lt;/p&gt;

&lt;p&gt;What is currently not consistent for all types of range queries (RangeQuery, NumericRangeQuery, FieldCacheRangeFilter) is, if it is allowed to have one bound null and include it. In my opinion, this should always be allowed and should deliver same results for inclusive or not.&lt;/p&gt;

&lt;p&gt;There is a first test together with TrieRangeQuery (for ints) in TestNumericRangeQuery32.java - which passes.&lt;/p&gt;

&lt;p&gt;An important restricion for this type with numeric field caches is: There must be exactly one value per document. If value is missing, 0 is assumed. For Strings, no value is allowed, not for numbers (because arrays like int[] cannot contain null values).&lt;/p&gt;</comment>
                    <comment id="12723983" author="thetaphi" created="Thu, 25 Jun 2009 10:50:29 +0100"  >&lt;p&gt;Updated patch. It now changes the includeUpper/Lower behaviour to be consistent with other range query types (RangeQuery, NumericRangeQuery). It also has updates to hashCode and equals (missing parser).&lt;/p&gt;

&lt;p&gt;After I wrote some additional tests (possibly inside TestNumericRangeQuery32/64), I think it is ready to commit.&lt;/p&gt;

&lt;p&gt;I found no better solution to remove the large dupplicate code parts, but this is not possible because of different array data types.&lt;/p&gt;</comment>
                    <comment id="12724096" author="mikemccand" created="Thu, 25 Jun 2009 15:07:58 +0100"  >&lt;p&gt;Patch looks good, Uwe!  The only issue I found was you&apos;re using includeUpper where you should be using includeLower.&lt;/p&gt;</comment>
                    <comment id="12724097" author="thetaphi" created="Thu, 25 Jun 2009 15:09:55 +0100"  >&lt;p&gt;where? these are typical copy&apos;n&apos;paste errors and missing tests...&lt;/p&gt;</comment>
                    <comment id="12724100" author="thetaphi" created="Thu, 25 Jun 2009 15:13:04 +0100"  >&lt;p&gt;oh ja, found it - was copy&apos;n&apos;paste&lt;/p&gt;</comment>
                    <comment id="12724322" author="thetaphi" created="Thu, 25 Jun 2009 23:17:27 +0100"  >&lt;p&gt;Mike: There is one thing, I wanted to know, as I am not so familar with the whole internal query handling:&lt;/p&gt;

&lt;p&gt;The DocIdSet for the native numeric types may return document ids, that are deleted (because for native types there is no possibility to find out if there was no term saved, null-fields or deleted docs would simply have 0 in the field cache array). A range covering 0 always returns all doc ids of deleted docs or docs without a numeric field (this can be noted in the javadocs: &quot;for numeric queries every document must have exact &lt;b&gt;one&lt;/b&gt; numeric term per field&quot;). Is this a problem, will the false-hits in the iterator be filted because doc is deleted?&lt;/p&gt;

&lt;p&gt;In the case of an real filter the query, that is filtered will not return deleted docs, but a ConstantScoreQuery on this filter would return deleted docs?&lt;/p&gt;</comment>
                    <comment id="12724443" author="mikemccand" created="Fri, 26 Jun 2009 10:20:48 +0100"  >&lt;blockquote&gt;&lt;p&gt;but a ConstantScoreQuery on this filter would return deleted docs?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;You are right!  I guess one workaround is to AND it with a MatchAllDocsQuery, if you are using ConstantScoreQuery w/o already ANDing it with a query that takes deletions into account.&lt;/p&gt;

&lt;p&gt;So there are two issues:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;This filter returns deleted docs&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;This filter &quot;pretends&quot; deleted docs had a value of zero&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;This is then only a problem if nothing else in the query applies deletions.  Other FieldCache driven filters have challenges here, too; eg we just fixed &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1571&quot; title=&quot;DistanceFilter problem with deleted documents&quot;&gt;&lt;del&gt;LUCENE-1571&lt;/del&gt;&lt;/a&gt; where local lucene tripped up on deleted docs (because it&apos;s using the Strings FieldCache, and hit nulls for deleted docs)&lt;/p&gt;

&lt;p&gt;I&apos;m not sure how we should fix this... (and I think we should open a new issue to do so).  I don&apos;t want to force this filter to always take deletions into account (since for many queries the filter is &quot;and&apos;d&quot; on, deletions are already factored in).  More generally, we need to think about what&apos;s the &quot;right&quot; top-down way to ask a scorer to take deletions and filters into account.  Eg, &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1536&quot; title=&quot;if a filter can support random access API, we should use it&quot;&gt;&lt;del&gt;LUCENE-1536&lt;/del&gt;&lt;/a&gt; is looking at sizable performance improvements for the &quot;relatively dense and supports random access&quot; type of filters.&lt;/p&gt;</comment>
                    <comment id="12724446" author="thetaphi" created="Fri, 26 Jun 2009 10:28:36 +0100"  >&lt;p&gt;Hey Mike, same time... &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;I did some recherche and also found out, that a filter&apos;s DocIdSet should not list deleted documents.&lt;/p&gt;

&lt;p&gt;Because of that, I changed the non-StringIndex (which will never contain strings of deleted docs because it has a order[]-&amp;gt;0 mapping) to use IndexReader.termDocs(null) to lists the docIds (which is no real problem, as it is just an iterator an a bitset, the additional cost is low, tested with 10 Mio index).&lt;/p&gt;

&lt;p&gt;I also created a superclass for all the iterators working on numbers, to get the termDocs handled easily. The type-specific iterators ony override a matchDoc() method. StringIndex iterator stays separate, because it is optimized and has no deleted docs problem as described before.&lt;/p&gt;

&lt;p&gt;This patch also contains tests for all (except byte) types.&lt;/p&gt;

&lt;p&gt;I will commit in a day or two.&lt;/p&gt;

&lt;p&gt;(an other solution for future would be to have an additional bitset for numeric values in addition to the native type array (in FieldCache), that holds the information, if the document had a term available. This would also cover the deleted docs)&lt;/p&gt;</comment>
                    <comment id="12724452" author="mikemccand" created="Fri, 26 Jun 2009 10:55:30 +0100"  >&lt;p&gt;OK, patch looks good Uwe!&lt;/p&gt;

&lt;p&gt;Having this filter just always take deletions into account is the safe solution; presumably the added performance cost is OK since this filter is so fast to begin with.&lt;/p&gt;

&lt;p&gt;Longer term I think we need a cleaner way to ask a Scorer to &quot;carry out&quot; deletions &amp;amp; filtering, and have it more optimally delegate that request to its sub-scorers as needed.&lt;/p&gt;

&lt;p&gt;One corner case issue: if I eg make a newShortRange w/ lowerVal == Short.MAX_VALUE and includeLower=false, which should match no docs, I think in this case you overflow short in computing inclusiveLowerPoint and thus match possibly many docs incorrectly?  (Same for byte/int/long).&lt;/p&gt;</comment>
                    <comment id="12724466" author="thetaphi" created="Fri, 26 Jun 2009 11:40:23 +0100"  >&lt;p&gt;I did some performance tests and compared this filter with TrieRange (precStep 8) on an 5 Mio index with homegenous distributed int values from Integer.MIN_VALUE to Integer.MAX_VALUE and 200 queries with random bounds in same range. Platform was Win32 with 1.5 GIG RAM on my Thinkpad T60 Core Duo (not 2 Duo!), Java 1.5:&lt;/p&gt;

&lt;p&gt;loading field cache&lt;br/&gt;
time: 11826.602264 ms&lt;br/&gt;
Warming searcher...&lt;br/&gt;
avg number of terms: 414.365&lt;br/&gt;
TRIE: best time=4.51482 ms; worst time=1560.544985 ms; avg=470.56886981499997 ms; sum=323328111&lt;br/&gt;
FIELDCACHE: best time=314.611773 ms; worst time=878.438461 ms; avg=511.93189495499996 ms; sum=323328111&lt;/p&gt;

&lt;p&gt;This test shows, that with a good warmed searcher and the whole index in OS cache is the same in speed. A constant score convential range query is far out (about 10 to 1000 times slower dependent on how far the random range bounds are away).&lt;/p&gt;

&lt;p&gt;The same with the old patch (using no TermDocs) and a completely separate loop (not matchDoc() method call), the FieldCache filter only hits the trie filter here:&lt;/p&gt;

&lt;p&gt;loading field cache&lt;br/&gt;
time: 12134.143027 ms&lt;br/&gt;
Warming searcher...&lt;br/&gt;
avg number of terms: 403.785&lt;br/&gt;
TRIE: best time=3.890159 ms; worst time=1266.979462 ms; avg=453.553236545ms; sum=308154314&lt;br/&gt;
FIELDCACHE: best time=84.019897 ms; worst time=434.558023 ms; avg=235.91554798500002 ms; sum=308154314&lt;/p&gt;

&lt;p&gt;Both test runs show, that the queries work correct (sum is identical, it shows that both returned exact the same hits).&lt;/p&gt;

&lt;p&gt;In all cases I would still prefer TrieRange (hihi), especially because of the long warming time for the field cache. And TrieRange gets even better with lower precSteps, but not really (in constant score mode the bits sets are the bigger problem)&lt;/p&gt;</comment>
                    <comment id="12724468" author="thetaphi" created="Fri, 26 Jun 2009 11:43:35 +0100"  >&lt;p&gt;Attached my performance test program for reference.&lt;/p&gt;</comment>
                    <comment id="12724485" author="thetaphi" created="Fri, 26 Jun 2009 12:46:17 +0100"  >&lt;blockquote&gt;&lt;p&gt;One corner case issue: if I eg make a newShortRange w/ lowerVal == Short.MAX_VALUE and includeLower=false, which should match no docs, I think in this case you overflow short in computing inclusiveLowerPoint and thus match possibly many docs incorrectly? (Same for byte/int/long).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This problem has also NumericRangeQuery (see the TermEnum impl there). I could change both queries to simply return the empty iterator (like when upper&amp;lt;lower)&lt;/p&gt;</comment>
                    <comment id="12724573" author="mikemccand" created="Fri, 26 Jun 2009 16:23:49 +0100"  >&lt;blockquote&gt;&lt;p&gt;This problem has also NumericRangeQuery (see the TermEnum impl there). I could change both queries to simply return the empty iterator (like when upper&amp;lt;lower)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Right, and I see you&apos;ve already fixed it!&lt;/p&gt;

&lt;p&gt;From your performance runs, looking at the average times, forcing this&lt;br/&gt;
filter to take deletions into account made it ~2X slower.  That&apos;s&lt;br/&gt;
quite costly.&lt;/p&gt;

&lt;p&gt;(Though, you really should seed the Random() so the two tests run&lt;br/&gt;
precisely the same set of queries against precisely the same index).&lt;/p&gt;

&lt;p&gt;I would imagine that for most usage of this filter, taking deletes&lt;br/&gt;
into account is not necessary, because it&apos;s being used as a filter&lt;br/&gt;
with a query whose scorer won&apos;t return deleted docs.  Then we&apos;ve taken&lt;br/&gt;
this perf hit for nothing...&lt;/p&gt;

&lt;p&gt;Somehow, we really need better control, when creating scorers, on just&lt;br/&gt;
when we need and don&apos;t need deletions / filters to be &quot;AND&apos;d&quot; in.&lt;/p&gt;

&lt;p&gt;Also, this filter isn&apos;t good when not many docs pass the filter, since&lt;br/&gt;
it&apos;s an O(N) scan through the index.  Trie should do much better in&lt;br/&gt;
those cases.&lt;/p&gt;

&lt;p&gt;I wonder, if we could make a hybrid approach that eg loads the trie&lt;br/&gt;
fields into a fast in-memory postings format (simple int arrays), just&lt;br/&gt;
how much faster it&apos;d be.  Ie, if you want to spend memory, spending it&lt;br/&gt;
on trie&apos;s postings would presumably net the best performance.  Once we&lt;br/&gt;
have flexible indexing we could presumably &quot;swap in&quot; an in-RAM&lt;br/&gt;
postings impl and then run trie against that.&lt;/p&gt;</comment>
                    <comment id="12724577" author="thetaphi" created="Fri, 26 Jun 2009 16:31:36 +0100"  >&lt;p&gt;Here an updated patch with the corner cases fixed (incl tests) for this filter (TrieRange is already fixed in trunk).&lt;/p&gt;</comment>
                    <comment id="12724580" author="thetaphi" created="Fri, 26 Jun 2009 16:38:04 +0100"  >&lt;blockquote&gt;
&lt;p&gt;From your performance runs, looking at the average times, forcing this&lt;br/&gt;
filter to take deletions into account made it ~2X slower. That&apos;s&lt;br/&gt;
quite costly.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This is not only because of the deleted docs. Its also because the while loops are no longer hard coded with bounds, so there is an additional method call to check if something is a hit. The linear scan makes this also very costly. But without it, the code is unmaintainable (with all problems like copy/paste errors) and so on. It is almost 6 times the same code &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I would imagine that for most usage of this filter, taking deletes&lt;br/&gt;
into account is not necessary, because it&apos;s being used as a filter&lt;br/&gt;
with a query whose scorer won&apos;t return deleted docs. Then we&apos;ve taken&lt;br/&gt;
this perf hit for nothing...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I could put in a switch, that uses another iterator, if 0 is not inside the range (because then all deleted docs would never be hits) or the IR has no deletions. But I think this optimization is something for later.&lt;/p&gt;

&lt;p&gt;In my opinion, in most cases TrieRange is better (and with Payloads, too). So I keeps this filter how it is for the beginning.&lt;/p&gt;</comment>
                    <comment id="12724605" author="mikemccand" created="Fri, 26 Jun 2009 17:26:23 +0100"  >&lt;blockquote&gt;&lt;p&gt;This is not only because of the deleted docs. Its also because the while loops are no longer hard coded with bounds, so there is an additional method call to check if something is a hit. The linear scan makes this also very costly. But without it, the code is unmaintainable (with all problems like copy/paste errors) and so on. It is almost 6 times the same code.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The tradeoff of code ugliness vs performance is always an &quot;interesting&quot; one, but here we lost 2X performance &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  Maybe we leave this to future source code specialization.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;In my opinion, in most cases TrieRange is better (and with Payloads, too).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Since, with the 2X slowdown, and with the linear-scan impl, this filter is not faster than trie... should we even bother?  It&apos;s going to confuse users having two ways to do numeric filtering, and, trie seems to be best across the board anyway?  Are there any times that this filter is better than trie?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;So I keeps this filter how it is for the beginning.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;OK, you mean leave this filter as only doing text (term) ranges?  OK, that sounds good.&lt;/p&gt;</comment>
                    <comment id="12724615" author="thetaphi" created="Fri, 26 Jun 2009 18:07:49 +0100"  >&lt;p&gt;I wanted to inform, that the latest patch (and the ones before) are still buggy. During changing the upper/lower bound settings I missed the case that StringIndex.binarySearch can return negative values, if the exact key was not found. See javadocs of Arrays.binarySearch. The problem is that the testcase did not found that.&lt;/p&gt;

&lt;p&gt;I will fix that and do some further tests later, but I am away now.&lt;/p&gt;</comment>
                    <comment id="12724743" author="thetaphi" created="Fri, 26 Jun 2009 23:22:49 +0100"  >&lt;p&gt;Attached is a new patch, that has 2 DocIdSetIterator implementations, one with TermDocs, one without. The TermDocs one is for numeric types only choosen, if the reader contains deletions &lt;b&gt;and&lt;/b&gt; 0 is inside the range. For all other cases (also StringIndex) the simple DocIdSetIterator using the counter is used.&lt;/p&gt;

&lt;p&gt;For more code-reuse, all range implementations now use the same abstract DocIdSet implementation and only override matchDoc(). My tests showed, that use of this method does not affect performance (method is inlined), the original stringindex impl is as fast as the new one with matchDoc().&lt;/p&gt;

&lt;p&gt;This patch also restores the original handling of the return value of binarySearch (which can be negative).&lt;/p&gt;

&lt;p&gt;Here again the comparison:&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Version with TermDocs:&lt;/b&gt;&lt;br/&gt;
loading field cache&lt;br/&gt;
time: 6767.23131 ms&lt;br/&gt;
Warming searcher...&lt;br/&gt;
avg number of terms: 378.75&lt;br/&gt;
TRIE: best time=5.232229 ms; worst time=553.791334 ms; avg=250.4418579 ms; sum=31996909&lt;br/&gt;
FIELDCACHE: best time=212.763912 ms; worst time=357.100414 ms; avg=279.75582110000005 ms; sum=31996909&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Version without (because index in testcase has no deletions):&lt;/b&gt;&lt;br/&gt;
loading field cache&lt;br/&gt;
time: 6463.311678 ms&lt;br/&gt;
Warming searcher...&lt;br/&gt;
avg number of terms: 378.75&lt;br/&gt;
TRIE: best time=4.539963 ms; worst time=581.657446 ms; avg=246.58688465 ms; sum=31996909&lt;br/&gt;
FIELDCACHE: best time=64.747614 ms; worst time=211.557335 ms; avg=139.16517340000001 ms; sum=31996909&lt;/p&gt;

&lt;p&gt;(my T60 was not on battery, because of this the measurement with TermDocs and FieldCache loading was faster that before). But both tests before and after optimization were done with same settings. The randseed was identical (0L)&lt;/p&gt;</comment>
                    <comment id="12725518" author="thetaphi" created="Tue, 30 Jun 2009 09:03:58 +0100"  >&lt;p&gt;It seems that the latest patch has no problems anymore. Without deletions or if 0 is not inside the range it seems to be faster than trie range, with the problem of long first-time searches (cache loading). But if you e.g. search on this field or use the cache for something other, it may not be a problem.&lt;/p&gt;

&lt;p&gt;The biggest advantage of this is, that you do not need to index the values in a special way, you can simply use your old Number.toString() formatted fields and do range queries on them. For term/string ranges it works better than RangeFilter, but the memory usage is much higher (if you have lots of distinct terms) with StringIndex.&lt;/p&gt;

&lt;p&gt;Maybe for the future, there would also be a possibility to implement a TrieRangeQuery for Strings (the precisionStep would there be the number of chars per precision, so e.g. precStep=2 would be to index for &quot;lucene&quot; the tokens &quot;lu&quot;, &quot;luce&quot;, &quot;lucene&quot;). The same here like with TrieRange: a TokenStream that does this would be good.&lt;/p&gt;

&lt;p&gt;In my opinion, this class is a good approach for range queries, if you have enough RAM and warm your searchers correctly, but do not want to change you index structure to use the new TrieRange. This class is not good for indexes where you will hit only few documents per range, as the cost of the linear scan for all data types then overweight.&lt;/p&gt;

&lt;p&gt;I think I will commit this later, if nobody objects. If you think, that only StringIndex and not numeric values should be handled by this class (throw away the new code), I tend to rename this class before release according to &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1713&quot; title=&quot;Rename RangeQuery -&amp;gt; TermRangeQuery&quot;&gt;&lt;del&gt;LUCENE-1713&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                    <comment id="12725520" author="thetaphi" created="Tue, 30 Jun 2009 09:08:22 +0100"  >&lt;p&gt;I forgot: Here the latest optimizations and corrections in the corner cases for StringIndex.&lt;/p&gt;</comment>
                    <comment id="12725546" author="mikemccand" created="Tue, 30 Jun 2009 10:40:47 +0100"  >&lt;p&gt;OK let&apos;s keep the new code, and keep the current name; it&apos;s great that it can now be faster than trie in some cases.  I&apos;d love to eventually see an in-memory trie structure; seems like this&apos;d be the fastest of all &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;I only briefly skimmed the patch (I&apos;m on &quot;vacation&quot; until Jul 6) and it looks good!&lt;/p&gt;</comment>
                    <comment id="12725547" author="thetaphi" created="Tue, 30 Jun 2009 10:48:27 +0100"  >&lt;blockquote&gt;&lt;p&gt;I only briefly skimmed the patch (I&apos;m on &quot;vacation&quot; until Jul 6) and it looks good!&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Happy holidays! (my holiday is later). I commit shortly.&lt;/p&gt;</comment>
                    <comment id="12725578" author="thetaphi" created="Tue, 30 Jun 2009 12:18:17 +0100"  >&lt;p&gt;Added CHANGES.txt &amp;amp; committed revision 789682.&lt;/p&gt;</comment>
                </comments>
                <issuelinks>
                        <issuelinktype id="10030">
                <name>Reference</name>
                                <outwardlinks description="relates to">
                            <issuelink>
            <issuekey id="12409265">LUCENE-1470</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12428610">LUCENE-1713</issuekey>
        </issuelink>
                    </outwardlinks>
                                            </issuelinktype>
                    </issuelinks>
                <attachments>
                    <attachment id="12394209" name="DisjointMultiFilter.java" size="3058" author="tsturge" created="Wed, 19 Nov 2008 01:17:30 +0000" />
                    <attachment id="12395034" name="FieldCacheRangeFilter.patch" size="1501" author="tsturge" created="Mon, 1 Dec 2008 19:36:57 +0000" />
                    <attachment id="12394638" name="LUCENE-1461a.patch" size="3997" author="paul.elschot@xs4all.nl" created="Tue, 25 Nov 2008 08:52:25 +0000" />
                    <attachment id="12394712" name="LUCENE-1461b.patch" size="25581" author="tsturge" created="Wed, 26 Nov 2008 01:58:14 +0000" />
                    <attachment id="12395031" name="LUCENE-1461c.patch" size="18374" author="tsturge" created="Mon, 1 Dec 2008 19:08:00 +0000" />
                    <attachment id="12412145" name="LUCENE-1461.patch" size="58828" author="thetaphi" created="Tue, 30 Jun 2009 09:08:21 +0100" />
                    <attachment id="12411964" name="LUCENE-1461.patch" size="58737" author="thetaphi" created="Fri, 26 Jun 2009 23:22:49 +0100" />
                    <attachment id="12411932" name="LUCENE-1461.patch" size="56882" author="thetaphi" created="Fri, 26 Jun 2009 16:31:36 +0100" />
                    <attachment id="12411896" name="LUCENE-1461.patch" size="52897" author="thetaphi" created="Fri, 26 Jun 2009 10:28:35 +0100" />
                    <attachment id="12411783" name="LUCENE-1461.patch" size="38572" author="thetaphi" created="Thu, 25 Jun 2009 10:50:29 +0100" />
                    <attachment id="12411732" name="LUCENE-1461.patch" size="37615" author="thetaphi" created="Thu, 25 Jun 2009 01:14:28 +0100" />
                    <attachment id="12411681" name="LUCENE-1461.patch" size="21306" author="thetaphi" created="Wed, 24 Jun 2009 19:30:14 +0100" />
                    <attachment id="12394729" name="LUCENE-1461.patch" size="26193" author="mikemccand" created="Wed, 26 Nov 2008 10:39:39 +0000" />
                    <attachment id="12411903" name="PerfTest.java" size="4288" author="thetaphi" created="Fri, 26 Jun 2009 11:43:35 +0100" />
                    <attachment id="12394587" name="RangeMultiFilter.java" size="2681" author="tsturge" created="Mon, 24 Nov 2008 19:38:38 +0000" />
                    <attachment id="12394210" name="RangeMultiFilter.java" size="2250" author="tsturge" created="Wed, 19 Nov 2008 01:19:14 +0000" />
                    <attachment id="12394390" name="TermMultiFilter.java" size="2064" author="tsturge" created="Fri, 21 Nov 2008 02:12:10 +0000" />
                    <attachment id="12395035" name="TestFieldCacheRangeFilter.patch" size="17479" author="tsturge" created="Mon, 1 Dec 2008 19:37:26 +0000" />
                </attachments>
            <subtasks>
        </subtasks>
                <customfields>
                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                <customfieldname>Attachment count</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>18.0</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                <customfieldname>Date of First Response</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>Wed, 19 Nov 2008 19:31:53 +0000</customfieldvalue>

                </customfieldvalues>
            </customfield>
                                                                                                        <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Global Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>12290</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                <customfieldname>Lucene Fields</customfieldname>
                <customfieldvalues>
                        <customfieldvalue key="10121"><![CDATA[New]]></customfieldvalue>
    <customfieldvalue key="10120"><![CDATA[Patch Available]]></customfieldvalue>
    
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>26266</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                <customfieldname>Time in Status</customfieldname>
                <customfieldvalues>
                    
                </customfieldvalues>
            </customfield>
                            </customfields>
    </item>
</channel>
</rss>