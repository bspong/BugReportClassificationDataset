<!-- 
RSS generated by JIRA (5.2.8#851-sha1:3262fdc28b4bc8b23784e13eadc26a22399f5d88) at Tue Jul 16 13:23:39 UTC 2013

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/LUCENE-1333/LUCENE-1333.xml?field=key&field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>5.2.8</version>
        <build-number>851</build-number>
        <build-date>26-02-2013</build-date>
    </build-info>

<item>
            <title>[LUCENE-1333] Token implementation needs improvements</title>
                <link>https://issues.apache.org/jira/browse/LUCENE-1333</link>
                <project id="12310110" key="LUCENE">Lucene - Core</project>
                        <description>&lt;p&gt;This was discussed in the thread (not sure which place is best to reference so here are two):&lt;br/&gt;
&lt;a href=&quot;http://mail-archives.apache.org/mod_mbox/lucene-java-dev/200805.mbox/%3C21F67CC2-EBB4-48A0-894E-FBA4AECC0D50@gmail.com%3E&quot; class=&quot;external-link&quot;&gt;http://mail-archives.apache.org/mod_mbox/lucene-java-dev/200805.mbox/%3C21F67CC2-EBB4-48A0-894E-FBA4AECC0D50@gmail.com%3E&lt;/a&gt;&lt;br/&gt;
or to see it all at once:&lt;br/&gt;
&lt;a href=&quot;http://www.gossamer-threads.com/lists/lucene/java-dev/62851&quot; class=&quot;external-link&quot;&gt;http://www.gossamer-threads.com/lists/lucene/java-dev/62851&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Issues:&lt;br/&gt;
1. JavaDoc is insufficient, leading one to read the code to figure out how to use the class.&lt;br/&gt;
2. Deprecations are incomplete. The constructors that take String as an argument and the methods that take and/or return String should &lt;b&gt;all&lt;/b&gt; be deprecated.&lt;br/&gt;
3. The allocation policy is too aggressive. With large tokens the resulting buffer can be over-allocated. A less aggressive algorithm would be better. In the thread, the Python example is good as it is computationally simple.&lt;br/&gt;
4. The parts of the code that currently use Token&apos;s deprecated methods can be upgraded now rather than waiting for 3.0. As it stands, filter chains that alternate between char[] and String are sub-optimal. Currently, it is used in core by Query classes. The rest are in contrib, mostly in analyzers.&lt;br/&gt;
5. Some internal optimizations can be done with regard to char[] allocation.&lt;br/&gt;
6. TokenStream has next() and next(Token), next() should be deprecated, so that reuse is maximized and descendant classes should be rewritten to over-ride next(Token)&lt;br/&gt;
7. Tokens are often stored as a String in a Term. It would be good to add constructors that took a Token. This would simplify the use of the two together.&lt;/p&gt;</description>
                <environment>&lt;p&gt;All&lt;/p&gt;</environment>
            <key id="12400127">LUCENE-1333</key>
            <summary>Token implementation needs improvements</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                    <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png">Closed</status>
                    <resolution id="1">Fixed</resolution>
                                <assignee username="mikemccand">Michael McCandless</assignee>
                                <reporter username="dmsmith">DM Smith</reporter>
                        <labels>
                    </labels>
                <created>Fri, 11 Jul 2008 18:19:06 +0100</created>
                <updated>Sat, 11 Oct 2008 13:49:37 +0100</updated>
                    <resolved>Wed, 20 Aug 2008 15:40:41 +0100</resolved>
                            <version>2.3.1</version>
                                <fixVersion>2.4</fixVersion>
                                <component>modules/analysis</component>
                        <due></due>
                    <votes>0</votes>
                        <watches>1</watches>
                                                    <comments>
                    <comment id="12613457" author="dmsmith" created="Mon, 14 Jul 2008 22:28:26 +0100"  >&lt;p&gt;The following has been addressed in this patch:&lt;br/&gt;
1. JavaDoc is improved (as always, there is still room for improvement. For example, it says the field type is interned, but it is not.)&lt;/p&gt;

&lt;p&gt;2. Deprecated the Token constructors taking a String.&lt;/p&gt;

&lt;p&gt;3. Changed the allocation policy to be less aggressive.&lt;/p&gt;

&lt;p&gt;5. Optimized the growing of the internal termBuffer immediately followed by storing a new term. In doing this added, setTermBuffer(String) and setTermBuffer(String, int, int). Setting from a string is roughly the same cost as setting from a char[].&lt;/p&gt;

&lt;p&gt;6. TokenStream has next() has been deprecated. The javadoc has been updated to recommend next(Token) over next().&lt;/p&gt;

&lt;p&gt;7. Rather than modifying Term to take a Token, public String term() has been added. With termText() still deprecated, this gives upgraders a clean choice to use term() or termBuffer(), with the knowledge of the performance differences.&lt;/p&gt;

&lt;p&gt;I also updated TestToken to test all the changes.&lt;/p&gt;

&lt;p&gt;Left to do: (I&apos;d like to get a nod of whether I need to make further changes to the supplied patch before doing #4)&lt;br/&gt;
4. Changing of the remainder of core and contrib to remove calls to deprecated Token and TokenStream methods, i.e. to use the reuse API.&lt;/p&gt;
</comment>
                    <comment id="12618387" author="mikemccand" created="Wed, 30 Jul 2008 16:30:04 +0100"  >
&lt;p&gt;This patch looks good; thanks DM!&lt;/p&gt;

&lt;p&gt;I made a few small changes &amp;amp; attached a new rev of the patch:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Fixed Token.setTermLength to throw IllegalArgumentException if you&lt;br/&gt;
    pass in a length &amp;gt; termBuffer.length&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Changed Token.growTermBuffer to use oal.util.ArrayUtil (it has&lt;br/&gt;
    that same growth logic)&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Changed if statements in Token.growTermBuffer to first handle the&lt;br/&gt;
    &lt;span class=&quot;error&quot;&gt;&amp;#91;I think most frequent&amp;#93;&lt;/span&gt; case where termBuffer is already&lt;br/&gt;
    allocated.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Javadoc/whitespace&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12619667" author="dmsmith" created="Mon, 4 Aug 2008 21:01:43 +0100"  >&lt;p&gt;Better comments based upon migrating all of core and contrib. This patch replaces the prior two.&lt;/p&gt;

&lt;p&gt;Marked fields as deprecated, with documentation that they should be made private and setters/getters should be used instead.&lt;/p&gt;</comment>
                    <comment id="12619669" author="dmsmith" created="Mon, 4 Aug 2008 21:07:22 +0100"  >&lt;p&gt;I&apos;ve broken up the changes to core and contrib into small patches. My reasoning for this is that it is a lot easier for me to keep up with other people&apos;s changes and re-issue a small patch.&lt;/p&gt;

&lt;p&gt;Apply &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1333&quot; title=&quot;Token implementation needs improvements&quot;&gt;&lt;del&gt;LUCENE-1333&lt;/del&gt;&lt;/a&gt;.patch before any of the following. I don&apos;t know if there is an order dependency for any of the following.&lt;/p&gt;

&lt;p&gt;This one is for core in o.a.l.analysis but not the files contained in &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1333&quot; title=&quot;Token implementation needs improvements&quot;&gt;&lt;del&gt;LUCENE-1333&lt;/del&gt;&lt;/a&gt;.patch&lt;/p&gt;</comment>
                    <comment id="12619670" author="dmsmith" created="Mon, 4 Aug 2008 21:07:58 +0100"  >&lt;p&gt;This patch covers the rest of core Lucene.&lt;/p&gt;</comment>
                    <comment id="12619671" author="dmsmith" created="Mon, 4 Aug 2008 21:08:42 +0100"  >&lt;p&gt;This is for contrib analyzers.&lt;/p&gt;</comment>
                    <comment id="12619672" author="dmsmith" created="Mon, 4 Aug 2008 21:09:19 +0100"  >&lt;p&gt;for contrib snowball&lt;/p&gt;</comment>
                    <comment id="12619674" author="dmsmith" created="Mon, 4 Aug 2008 21:09:51 +0100"  >&lt;p&gt;for contrib highlighter&lt;/p&gt;</comment>
                    <comment id="12619675" author="dmsmith" created="Mon, 4 Aug 2008 21:10:26 +0100"  >&lt;p&gt;For contrib instantiated&lt;/p&gt;</comment>
                    <comment id="12619676" author="dmsmith" created="Mon, 4 Aug 2008 21:10:54 +0100"  >&lt;p&gt;for contrib lucli&lt;/p&gt;</comment>
                    <comment id="12619678" author="dmsmith" created="Mon, 4 Aug 2008 21:11:14 +0100"  >&lt;p&gt;for contrib memory&lt;/p&gt;</comment>
                    <comment id="12619679" author="dmsmith" created="Mon, 4 Aug 2008 21:11:43 +0100"  >&lt;p&gt;for contrib misc&lt;/p&gt;</comment>
                    <comment id="12619680" author="dmsmith" created="Mon, 4 Aug 2008 21:12:03 +0100"  >&lt;p&gt;for contrib queries&lt;/p&gt;</comment>
                    <comment id="12619681" author="dmsmith" created="Mon, 4 Aug 2008 21:12:24 +0100"  >&lt;p&gt;for contrib wikipedia&lt;/p&gt;</comment>
                    <comment id="12619684" author="dmsmith" created="Mon, 4 Aug 2008 21:12:43 +0100"  >&lt;p&gt;for contrib wordnet&lt;/p&gt;</comment>
                    <comment id="12619685" author="dmsmith" created="Mon, 4 Aug 2008 21:13:10 +0100"  >&lt;p&gt;for contrib xml-query-parser&lt;/p&gt;</comment>
                    <comment id="12619695" author="dmsmith" created="Mon, 4 Aug 2008 21:45:38 +0100"  >&lt;p&gt;All the code has been migrated to use the reuse interface. I have run all the tests and they pass. (There is a weird dependency. One test depends upon demo. I hacked that to work.) I did not test to see if the code were any slower or faster. I&apos;m not sure how one would do that. I think it should be faster since it doesn&apos;t bounce back and forth with termText and termBuffer.&lt;/p&gt;

&lt;p&gt;I did not improve the code to use char[] instead of String. The places that can be improved call Token.setTermBuffer(String). I don&apos;t think these are necessary to this issue being resolved.&lt;/p&gt;

&lt;p&gt;A couple of other minor opportunities for char[] manipulation via o.a.l.util.ArrayUtil.&lt;/p&gt;

&lt;p&gt;Here and there, there is a need to remove leading and trailing whitespace from input before (sub-)tokenizing it. Currently this is done with String.trim(), even when working with char[]. It is sub-optimal as marshalling it into a String involves allocation and copying. Likewise, so does getting it out. It would be better to have int trim(char[]) which shifts leading spaces off the front and returns the length of the string without trailing spaces.&lt;/p&gt;

&lt;p&gt;There is a &quot;randomize&quot; routine that shuffles an array. While this is only used in one place, it appears to be general purpose array manipulation.&lt;/p&gt;</comment>
                    <comment id="12620438" author="dmsmith" created="Wed, 6 Aug 2008 22:48:27 +0100"  >&lt;p&gt;This issue supersedes &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1350&quot; title=&quot;Filters which are &amp;quot;consumers&amp;quot; should not reset the payload or flags and should better reuse the token&quot;&gt;&lt;del&gt;LUCENE-1350&lt;/del&gt;&lt;/a&gt;, incorporating all the changes in it. This either needs to go in after it or instead of it.&lt;/p&gt;</comment>
                    <comment id="12621064" author="dmsmith" created="Fri, 8 Aug 2008 22:03:21 +0100"  >&lt;p&gt;This patch includes all the previous ones.&lt;/p&gt;

&lt;p&gt;Note: It includes the functionality solving  &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1350&quot; title=&quot;Filters which are &amp;quot;consumers&amp;quot; should not reset the payload or flags and should better reuse the token&quot;&gt;&lt;del&gt;LUCENE-1350&lt;/del&gt;&lt;/a&gt;. If this patch is applied before &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1350&quot; title=&quot;Filters which are &amp;quot;consumers&amp;quot; should not reset the payload or flags and should better reuse the token&quot;&gt;&lt;del&gt;LUCENE-1350&lt;/del&gt;&lt;/a&gt;, then that issue is resolved. If it is done after then the patch will need to be rebuilt.&lt;/p&gt;

&lt;p&gt;I did not do the &quot;reuse&quot; API mentioned in &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1350&quot; title=&quot;Filters which are &amp;quot;consumers&amp;quot; should not reset the payload or flags and should better reuse the token&quot;&gt;&lt;del&gt;LUCENE-1350&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                    <comment id="12621101" author="mikemccand" created="Sat, 9 Aug 2008 00:59:58 +0100"  >&lt;p&gt;OK since you pulled it all together under this issue, I think we should commit this one instead of &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1350&quot; title=&quot;Filters which are &amp;quot;consumers&amp;quot; should not reset the payload or flags and should better reuse the token&quot;&gt;&lt;del&gt;LUCENE-1350&lt;/del&gt;&lt;/a&gt;.  I&apos;ll review the &lt;span class=&quot;error&quot;&gt;&amp;#91;massive&amp;#93;&lt;/span&gt; patch &amp;#8211; thanks DM!&lt;/p&gt;</comment>
                    <comment id="12621130" author="mikemccand" created="Sat, 9 Aug 2008 11:12:02 +0100"  >&lt;p&gt;DM, one pattern that makes me nervous is this, from QueryTermVector.java:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;          &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (Token next = stream.next(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Token()); next != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;; next = stream.next(next)) {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I don&apos;t think you should be &quot;recycling&quot; that next and passing it back in the next time you call stream.next, because a TokenStream is not &lt;b&gt;required&lt;/b&gt; to use the Token you had passed in and so suddenly you are potentially asking it to re-use a token it had previously returned, which it may not expect.  Likely it won&apos;t matter but I think this is still safer:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;          &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; Token result = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Token();
          &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (Token next = stream.next(result); next != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;; next = stream.next(result)) {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                    <comment id="12621132" author="dmsmith" created="Sat, 9 Aug 2008 13:16:29 +0100"  >&lt;p&gt;I&apos;ll give my analysis here. Feel free to make the change or kick it back to me to make it, if you think your pattern is best. (If I do it, it will be after this weekend.)&lt;/p&gt;

&lt;p&gt;I&apos;ve tried to be consistent here. The prior pattern was inconsistent and often was:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt; Token token = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;
  &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; ((token = input.next()) != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;There were other variants including &quot;forever loops&quot;. As you noticed, I replace&lt;br/&gt;
There are two basic implementations of Token next(Token):&lt;br/&gt;
1) Producer: These create tokens from input. Their pattern is to take their argument and call clear on it and then set startOffset, endOffset and type appropriately. Their assumption is that they have to start with a pristine token and that other than space, there is nothing about the token that is passed in that can be reused.&lt;/p&gt;

&lt;p&gt;2) Consumer: These &quot;filter&quot; their argument. Their only assumption is that in the call chain that there was a producer that created the token that they need to reuse. In this case, they typically will preserve startOffset and endOffset because those are to represent the position of the token in the input. They may refine type, flags and payload, but otherwise have to preserve them. Most typically, they will set the termBuffer. There are a few types of consumers. Here are some:&lt;br/&gt;
a) Transformational Filters: They take their argument and transform it&apos;s termBuffer.&lt;br/&gt;
b) Splitting Filters: They take their argument and split the token into several. Sometimes they will return the original; other times just the parts. When creating these tokens, calling clone() on the prototype will preserve flags, payloads, start and end offsets and type. These clones are sometimes stored in a buffer, but sometimes are incrementally computed with each call to next(Token). With the latter, they will typically cache a clone of the passed in token. I think that, when possible, incremental computation is preferable, but at the cost of a less obvious implementation.&lt;br/&gt;
c) Caching Filter: If their buffer is empty, they repeatedly call result = input.next(token), clone and buffer cache their result in some collection. Once full, they will return their buffer&apos;s content. If, the caching filter is resettable, they must return clones of their content. Otherwise, down stream consumers may change their arguments, disastrously.&lt;/p&gt;

&lt;p&gt;Callers of Token next(Token) have the responsibility of never calling with a null token. (I think producer tokens probably should check and create a token if it is so. But I don&apos;t think that is what they do now.)&lt;/p&gt;

&lt;p&gt;The upshot of all of this, Producers don&apos;t care which token they reuse. If it was from the original loop, or from the result of the last call to token = stream.next(token), both are equally good. The token pre-existed and needs to be fully reset. Consumers presume that the token was produced (or at least appropriately re-initialized and filled in) by a producer.&lt;/p&gt;

&lt;p&gt;Your form of the loop is very advisable in a few places. Most typically with a loop within a loop, with the inner looping over all the tokens in a stream. In this case, the final Token would be created outside the outer loop. Using your pattern, there would encourage maximal reuse. Using mine, the programmer would have to figure out when it was appropriate to do one or the other.&lt;/p&gt;

&lt;p&gt;The other value to your pattern is that next(Token) is always called with a non-null Token.&lt;/p&gt;

&lt;p&gt;I think that calling the token &quot;result&quot; is not the best. It is a bit confusing as it is not the result of calling next(Token). Perhaps, to make reuse acutely obvious:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; Token reusableToken = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Token();
 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (Token token = stream.next(reusableToken); token != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;; token = stream.next(reusableToken)) {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
</comment>
                    <comment id="12621181" author="doronc" created="Sat, 9 Aug 2008 21:22:56 +0100"  >&lt;p&gt;This &apos;final&apos; pattern is indeed more clear about reuse.&lt;/p&gt;

&lt;p&gt;But still would like to clarify on what can the TokenStream assume. I think &lt;br/&gt;
TokenStream cannot assume anything about the token it gets as input, and, &lt;br/&gt;
once it returned a token, it cannot assume anything about how that token &lt;br/&gt;
is used.  So why should it not expect being passed the token it just returned?&lt;/p&gt;</comment>
                    <comment id="12621220" author="doronc" created="Sun, 10 Aug 2008 09:56:54 +0100"  >&lt;p&gt;The new patch applies cleanly.&lt;br/&gt;
A few tests are failing though - TestChineseTokenizer for one.&lt;br/&gt;
I&apos;m looking into it, might be that a problem is in the test.&lt;/p&gt;</comment>
                    <comment id="12621224" author="doronc" created="Sun, 10 Aug 2008 11:14:59 +0100"  >&lt;p&gt;Seems start/end offset were lost in ChineseTokenizer.&lt;br/&gt;
Adding this in flush(Token) will fix it.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;token.setStartOffset(start);
token.setEndOffset(start+length);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Possibly true for other places where new Token() that takes start/end offsets was replaced by clear() and setTermBuffer().&lt;/p&gt;</comment>
                    <comment id="12621231" author="mikemccand" created="Sun, 10 Aug 2008 11:30:40 +0100"  >&lt;blockquote&gt;
&lt;p&gt;But still would like to clarify on what can the TokenStream assume. I think&lt;br/&gt;
TokenStream cannot assume anything about the token it gets as input, and,&lt;br/&gt;
once it returned a token, it cannot assume anything about how that token&lt;br/&gt;
is used. So why should it not expect being passed the token it just returned?&lt;/p&gt;&lt;/blockquote&gt;

&lt;blockquote&gt;
&lt;p&gt;The upshot of all of this, Producers don&apos;t care which token they reuse.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I agree &amp;#8211; technically speaking, whenever a Token is returned from a source/filter&apos;s next(Token) method, &lt;b&gt;anything&lt;/b&gt; is allowed to happen do it (including any &amp;amp; all changes, and subsequent reuse in future calls to next(Token)) and so the current pattern will run correctly if all sources &amp;amp; filters are implemented correctly. This is the contract in the reuse API.&lt;/p&gt;

&lt;p&gt;It&apos;s just that it looks spooky, when you are consuming tokens, not to create &amp;amp; re-use your own reusable token.  I think it&apos;s also possible (but not sure) that the JRE can compile/run the &quot;single reusable token&quot; pattern more efficienctly, since you are making many method calls with a constant (for the life time of the for loop) single argument, but this is pure speculation on my part...&lt;/p&gt;

&lt;p&gt;I think from a code-smell standpoint I&apos;d still like to use the &quot;single re-use&quot; pattern when applicable.  DM I&apos;ll make this change &amp;amp; post a new patch.&lt;/p&gt;</comment>
                    <comment id="12621233" author="mikemccand" created="Sun, 10 Aug 2008 11:31:21 +0100"  >&lt;p&gt;I&apos;m also seeing the test failures.&lt;/p&gt;</comment>
                    <comment id="12621241" author="mikemccand" created="Sun, 10 Aug 2008 12:54:39 +0100"  >&lt;blockquote&gt;&lt;p&gt;Seems start/end offset were lost in ChineseTokenizer.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;OK, I&apos;ll fold this into my changes to the patch.  Thanks Doron!&lt;/p&gt;</comment>
                    <comment id="12621242" author="mikemccand" created="Sun, 10 Aug 2008 13:02:53 +0100"  >&lt;blockquote&gt;&lt;p&gt;(I think producer tokens probably should check and create a token if it is so. But I don&apos;t think that is what they do now.)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Actually I think one should never pass null to next(Token) API &amp;#8211; ie a source token stream need not check for null.&lt;/p&gt;</comment>
                    <comment id="12621244" author="doronc" created="Sun, 10 Aug 2008 13:06:25 +0100"  >&lt;p&gt;Thanks Mike!&lt;/p&gt;

&lt;p&gt;One more...&lt;/p&gt;

&lt;p&gt;While looking into the failure of TestSingleTokenTokenFilter I saw that if these lines are executed:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;Token t1 = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Token();
Token t2 = t1.clone();
&lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; isEqual = t1.equals(t2)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Surprisingly,   &lt;b&gt;isEqual = false&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;Do you see this too?&lt;/p&gt;
</comment>
                    <comment id="12621245" author="mikemccand" created="Sun, 10 Aug 2008 13:13:53 +0100"  >&lt;blockquote&gt;&lt;p&gt;Do you see this too?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Hmm, indeed I do see this too &amp;#8211; but this is because Token has never overridden &quot;equals&quot; right? &lt;/p&gt;</comment>
                    <comment id="12621246" author="doronc" created="Sun, 10 Aug 2008 13:16:26 +0100"  >&lt;blockquote&gt;
&lt;p&gt;Actually I think one should never pass null to next(Token) API - ie a source token stream need not check for null.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Funny I was about to comment on the same thing... &lt;/p&gt;

&lt;p&gt;In fact when the reuse API was introduced I believe null was suppose to mean - &quot;nothing to be reused, please just create your own&quot;. &lt;/p&gt;

&lt;p&gt;In case of a producer that cannot reuse - say it creates its own implementation of Token - then there is no point in creating tokens by the consumer that will never be reused. &lt;/p&gt;

&lt;p&gt;But this also meant that in all the common cases, all tokenizers would need an additional if() to verify that the reusable token is not null. Not so nice. &lt;/p&gt;

&lt;p&gt;So yes, I agree with you, just need to clarify this in TokenStream.nextToken(Token)&apos;s javadocs.&lt;/p&gt;</comment>
                    <comment id="12621248" author="mikemccand" created="Sun, 10 Aug 2008 13:22:26 +0100"  >&lt;blockquote&gt;&lt;p&gt;just need to clarify this in TokenStream.nextToken(Token)&apos;s javadocs.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I agree; I&apos;ll do this in next patch iteration...&lt;/p&gt;</comment>
                    <comment id="12621250" author="doronc" created="Sun, 10 Aug 2008 13:25:53 +0100"  >&lt;blockquote&gt;
&lt;p&gt;Hmm, indeed I do see this too - but this is because Token has never overridden &quot;equals&quot; right?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes you&apos;re right. I was under the impression for a moment Object&apos;s equals() works like clone() and goes in one layer only... that&apos;s stupid of course, it just compares the object references (or nulls).  I wonder how this test ever passed before... Oh I see it now, - trunk&apos;s of SingleTokenTokenStream never called Token.clone() while patched version calls it twice. So definitely, Token should implement equals().&lt;/p&gt;</comment>
                    <comment id="12621251" author="mikemccand" created="Sun, 10 Aug 2008 13:43:46 +0100"  >&lt;blockquote&gt;&lt;p&gt;So definitely, Token should implement equals().&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I agree.  This is technically a break in backwards compatibility, but I think it&apos;s OK?&lt;/p&gt;</comment>
                    <comment id="12621252" author="doronc" created="Sun, 10 Aug 2008 14:00:07 +0100"  >&lt;blockquote&gt;
&lt;p&gt;This is technically a break in backwards compatibility, but I think it&apos;s OK?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I think so. &lt;br/&gt;
I feel good about this whole change, it will make reuse chain more clear, especially once all deprecations can be removed.&lt;/p&gt;</comment>
                    <comment id="12621255" author="doronc" created="Sun, 10 Aug 2008 14:07:57 +0100"  >&lt;p&gt;I couldn&apos;t leave this without seeing that test passing... so here is the code for Token.equals() in case you didn&apos;t write that part yet -&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;  @Override
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; equals(&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; obj) {
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; == obj)
      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;;
   
    Token other = (Token) obj;
    
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt;
      termLength == other.termLength &amp;amp;&amp;amp;
      startOffset == other.startOffset &amp;amp;&amp;amp;  
      endOffset == other.endOffset &amp;amp;&amp;amp;
      flags == other.flags &amp;amp;&amp;amp;
      positionIncrement == other.positionIncrement &amp;amp;&amp;amp; 
      subEqual(termBuffer, other.termBuffer) &amp;amp;&amp;amp;
      subEqual(type, other.type) &amp;amp;&amp;amp;
      subEqual(payload, other.payload);
  }

  &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; subEqual(&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; o1, &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; o2) {
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (o1==&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;)
      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; o2==&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;; 
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; o1.equals(o2);
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                    <comment id="12621262" author="mikemccand" created="Sun, 10 Aug 2008 15:29:48 +0100"  >&lt;p&gt;I&apos;m unable to get javacc to run cleanly on PrecedenceQueryParser.jj.  It produces this:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;bash-3.2$ javacc ./src/java/org/apache/lucene/queryParser/precedence/PrecedenceQueryParser.jj
Java &lt;span class=&quot;code-object&quot;&gt;Compiler&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Compiler&lt;/span&gt; Version 4.0 (Parser Generator)
(type &lt;span class=&quot;code-quote&quot;&gt;&quot;javacc&quot;&lt;/span&gt; with no arguments &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; help)
Reading from file ./src/java/org/apache/lucene/queryParser/precedence/PrecedenceQueryParser.jj . . .
org.javacc.parser.ParseException: Encountered &lt;span class=&quot;code-quote&quot;&gt;&quot;&amp;lt;&amp;lt;&quot;&lt;/span&gt; at line 658, column 3.
Was expecting one of:
    &amp;lt;STRING_LITERAL&amp;gt; ...
    &lt;span class=&quot;code-quote&quot;&gt;&quot;&amp;lt;&quot;&lt;/span&gt; ...
    
Detected 1 errors and 0 warnings.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Does anyone else hit this?&lt;/p&gt;</comment>
                    <comment id="12621263" author="mikemccand" created="Sun, 10 Aug 2008 15:36:23 +0100"  >&lt;blockquote&gt;&lt;p&gt;here is the code for Token.equals() in case you didn&apos;t write that part yet&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Thanks Doron; I&apos;ll merge into my version &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  Both your version and my version had bugs, so it&apos;s great you posted yours!  And I hope the merged result has no bugs &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="12621264" author="doronc" created="Sun, 10 Aug 2008 15:47:41 +0100"  >&lt;p&gt;ok now I&apos;m curious cause I still can&apos;t see that bug... &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;For PrecedenceQueryParser, Is there a way to use ant to run javacc on contrib/misc? &lt;/p&gt;</comment>
                    <comment id="12621265" author="mikemccand" created="Sun, 10 Aug 2008 15:50:01 +0100"  >
&lt;p&gt;OK new patch attached:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Created Token.equals and Payloads.equals &amp;#8211; this fixed&lt;br/&gt;
    TestSingleTokenTokenFilter.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Switched to the &quot;final reusableToken&quot; pattern.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Added to TokenStream.next javadoc stating that parameter should&lt;br/&gt;
    never be null&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Fixed test failures (all tests should pass now)&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12621267" author="mikemccand" created="Sun, 10 Aug 2008 15:51:14 +0100"  >&lt;blockquote&gt;&lt;p&gt;For PrecedenceQueryParser, Is there a way to use ant to run javacc on contrib/misc? &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I couldn&apos;t find a way... there is a TODO comment in it&apos;s build.xml saying something about it though!&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;ok now I&apos;m curious cause I still can&apos;t see that bug...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;OK I&apos;ll let you diff &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  And please look closely to see if there are any other bugs!  These equals() methods are tricky!&lt;/p&gt;</comment>
                    <comment id="12621268" author="doronc" created="Sun, 10 Aug 2008 16:13:12 +0100"  >&lt;blockquote&gt;
&lt;p&gt;For PrecedenceQueryParser... there is a TODO comment in it&apos;s build.xml saying something about it though!&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes I saw that, but since I don&apos;t have a javacc executable.&lt;br/&gt;
Maybe I&apos;ll look at that build.xml later.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;OK I&apos;ll let you diff&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;OK I can see them now... you were right as usual &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;Patch applies cleanly and I&apos;m running the test now, so far all looks good but my PC is not that fast and it will take some more time to complete. I hope to review later tonight or tomorrow morning.&lt;/p&gt;

</comment>
                    <comment id="12621319" author="dmsmith" created="Mon, 11 Aug 2008 00:16:22 +0100"  >&lt;p&gt;Back from a trip. Would have jumped in to help, but it looks like you&apos;ve found and fixed a couple of my mistakes/oversights. Thanks.&lt;/p&gt;

&lt;p&gt;Regarding the equals implementation. Perhaps it would also be good to finish the canonical implementation and provide hashcode? That would allow for storage in sets and maps. (Not terribly sure how that would be useful. But I can imagine sorting on startOffsets to organize the contents.)&lt;/p&gt;

&lt;p&gt;Regarding the changes to the jj files. I also made the corresponding changes in their generate java files. While it would be good to fix the generation problem, you can compare the jj and java pairs to see that they match.&lt;/p&gt;

&lt;p&gt;I agree that Token next(Token) should assume a non-null. Perhaps an assert in a producer is a good idea. I find it easier to debug a failed assert than a null pointer exception.&lt;/p&gt;</comment>
                    <comment id="12621384" author="doronc" created="Mon, 11 Aug 2008 10:07:28 +0100"  >&lt;p&gt;All tests pass here. &lt;br/&gt;
131 files were modified - I reviewed core and part of contrib, with minor comments only:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;CompoundWordTokenFilterBase - createToken() calls clone() which deep&lt;br/&gt;
   copies the char array, and then calls also setTermBuffer() which iterates the chars again.&lt;br/&gt;
   This can come to play in some analyzers. Usually I would ignore things like this, but this &lt;br/&gt;
   issue is so much about reusing and avoiding unneeded reallocation that I decided to &lt;br/&gt;
   bring this up. Actually there is no reallocation, just re-copying, so maybe it is not too bad?
	&lt;ul&gt;
		&lt;li&gt;Similarly in NgramTokenFilter - seems termBuffer would be copied twice for each &quot;secondary&quot; token.&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Cloning: behavior regarding cloning is modified in few places.
	&lt;ul&gt;
		&lt;li&gt;In SingleTokenTokenStream - adding cloning - I think it is correct.&lt;/li&gt;
		&lt;li&gt;In TokenTypeSinkTokenizer.add(Token) cloning was removed because it is&lt;br/&gt;
      taken care of in super.add(). I first thought it a bug but no, patch is correct.&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;I find the comment in TokenFilter about implementing next() vs. next(Token) confusing.&lt;br/&gt;
  Perhaps use here the same comment as in Tokenizer.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12621393" author="doronc" created="Mon, 11 Aug 2008 10:39:49 +0100"  >&lt;p&gt;I think that &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1350&quot; title=&quot;Filters which are &amp;quot;consumers&amp;quot; should not reset the payload or flags and should better reuse the token&quot;&gt;&lt;del&gt;LUCENE-1350&lt;/del&gt;&lt;/a&gt;&apos;s failing test can be included here?&lt;/p&gt;

&lt;p&gt;TestSnowball.testFilterTokens() then changes to:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void testFilterTokens() &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; Exception {
    &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; Token tok = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Token(2, 7, &lt;span class=&quot;code-quote&quot;&gt;&quot;wrd&quot;&lt;/span&gt;);
    tok.setTermBuffer(&lt;span class=&quot;code-quote&quot;&gt;&quot;accents&quot;&lt;/span&gt;);
    tok.setPositionIncrement(3);
    Payload tokPayload = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Payload(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[]{0,1,2,3});
    tok.setPayload(tokPayload);
    &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; tokFlags = 77;
    tok.setFlags(tokFlags);

    SnowballFilter filter = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; SnowballFilter(
        &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; TokenStream() {
          &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; Token next(Token token) {
            &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; tok;
          }
        },
        &lt;span class=&quot;code-quote&quot;&gt;&quot;English&quot;&lt;/span&gt;
    );

    Token newtok = filter.next(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Token());

    assertEquals(&lt;span class=&quot;code-quote&quot;&gt;&quot;accent&quot;&lt;/span&gt;, newtok.term());
    assertEquals(2, newtok.startOffset());
    assertEquals(7, newtok.endOffset());
    assertEquals(&lt;span class=&quot;code-quote&quot;&gt;&quot;wrd&quot;&lt;/span&gt;, newtok.type());
    assertEquals(3, newtok.getPositionIncrement());
    assertEquals(tokFlags, newtok.getFlags());
    assertEquals(tokPayload, newtok.getPayload());
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                    <comment id="12621410" author="mikemccand" created="Mon, 11 Aug 2008 12:05:29 +0100"  >
&lt;p&gt;I forgot to say (in last patch): I also added Token.reinit() methods.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I think that &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1350&quot; title=&quot;Filters which are &amp;quot;consumers&amp;quot; should not reset the payload or flags and should better reuse the token&quot;&gt;&lt;del&gt;LUCENE-1350&lt;/del&gt;&lt;/a&gt;&apos;s failing test can be included here? &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;OK I&apos;ll update this test case.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I find the comment in TokenFilter about implementing next() vs. next(Token) confusing.&lt;br/&gt;
Perhaps use here the same comment as in Tokenizer.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;OK I&apos;ll update comment in TokenFilter.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I also made the corresponding changes in their generate java files. While it would be good to fix the generation problem, you can compare the jj and java pairs to see that they match.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I ended up doing the same.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Perhaps it would also be good to finish the canonical implementation and provide hashcode?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;OK I&apos;ll add.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Perhaps an assert in a producer is a good idea. I find it easier to debug a failed assert than a null pointer exception.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Agreed, I&apos;ll add.&lt;/p&gt;</comment>
                    <comment id="12621411" author="mikemccand" created="Mon, 11 Aug 2008 12:08:51 +0100"  >&lt;blockquote&gt;
&lt;p&gt;CompoundWordTokenFilterBase - createToken() calls clone() which deep&lt;br/&gt;
copies the char array, and then calls also setTermBuffer() which iterates the chars again.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Maybe we need a variant of clone that takes a new term buffer &amp;amp; start/end offsets, and creates a new token but with the new term buffer &amp;amp; start/end offsets you&apos;ve passed in?  Analagous to reinit, but first making a cloned token.&lt;/p&gt;</comment>
                    <comment id="12621416" author="mikemccand" created="Mon, 11 Aug 2008 12:44:13 +0100"  >&lt;p&gt;Attached new patch w/ above changes.&lt;/p&gt;</comment>
                    <comment id="12621417" author="dmsmith" created="Mon, 11 Aug 2008 13:02:17 +0100"  >&lt;p&gt;Caching flies in the face of reuse. I think that a comment needs to be some where to that effect.&lt;br/&gt;
Putting Tokens into a collection requires that the reusable token be copied. I.e. via new or clone. One cannot directly store the reusable Token, i.e. the argument from Token next(Token), nor the value to be returned from it.&lt;/p&gt;

&lt;p&gt;If a caching TokenStream is also resettable, then that means that the tokens coming from it need to be protected from being changed. This means that they need to return a copy. (Perhaps comment reset() to that effect?)&lt;/p&gt;

&lt;p&gt;The only value I see in caching is if the computation of the token stream is so expensive that re-using it has a significant savings.&lt;/p&gt;

&lt;p&gt;(The current code does not take such care and is a bug. This patch fixes it. It would have become obvious if the cache were used in the context of reuse.)&lt;/p&gt;

&lt;p&gt;Some TokenStreams cache Tokens internally (as a detail of their implementation) and then return them incrementally. Many of these can be rewritten to compute the next Token when next(Token) is called. This would improve both time and space usage.&lt;/p&gt;

&lt;p&gt;(I felt that such changes were outside the scope of this patch.)&lt;/p&gt;

&lt;p&gt;All this leads to my response to the NGram filter.&lt;/p&gt;

&lt;p&gt;The NGram filters could be improved in this fashion. This would eliminate the clone() problem noted above.&lt;/p&gt;

&lt;p&gt;But failing that, a variant of clone to solve the intermediate problem would work. So would using new Token(...). The problem with using new Token() is that it requires manual propagation of flags, payloads, offsets and types and is not resilient to future fields.&lt;/p&gt;</comment>
                    <comment id="12621715" author="doronc" created="Tue, 12 Aug 2008 08:09:27 +0100"  >&lt;blockquote&gt;
&lt;p&gt;I also made the corresponding changes in their generate java files. While it would be good to fix the generation problem, you can compare the jj and java pairs to see that they match.&lt;/p&gt;&lt;/blockquote&gt;

&lt;blockquote&gt;
&lt;p&gt;I ended up doing the same.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;There&apos;s a patch for this in &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1353&quot; title=&quot;javacc ant task for contrib/misc precedence query parser&quot;&gt;&lt;del&gt;LUCENE-1353&lt;/del&gt;&lt;/a&gt; ...&lt;/p&gt;</comment>
                    <comment id="12621762" author="mikemccand" created="Tue, 12 Aug 2008 11:25:02 +0100"  >&lt;blockquote&gt;&lt;p&gt;I&apos;m unable to get javacc to run cleanly on PrecedenceQueryParser.jj.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I figured this out: you have to use javacc 3.2 (not 4.0 or beyond) for contrib/misc, then &quot;ant javacc&quot; runs fine (with the patch from &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1353&quot; title=&quot;javacc ant task for contrib/misc precedence query parser&quot;&gt;&lt;del&gt;LUCENE-1353&lt;/del&gt;&lt;/a&gt;).&lt;/p&gt;</comment>
                    <comment id="12621775" author="mikemccand" created="Tue, 12 Aug 2008 12:15:03 +0100"  >&lt;p&gt;Attached new patch:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Fixed comments about caching &amp;amp; cloning&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Added partial clone method, that clones all except replaces termBuffer &amp;amp; start/end offset; fixed NGramTokenFilter and CompoundWordTokenFilterBase to use this method&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Fixed bug in PrecedenceQueryParser.jj that became obvious once I ran javacc&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I think we are close!&lt;/p&gt;</comment>
                    <comment id="12621800" author="doronc" created="Tue, 12 Aug 2008 13:54:28 +0100"  >&lt;p&gt;I diffed current patch and previous one and all seems correct to me. &lt;/p&gt;

&lt;p&gt;One tiny thing in Token - in two locations there&apos;s this code:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;setTermBuffer(newTermBuffer, newTermOffset, newTermLength);
setTermLength(newTermLength);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Second call is redundant since first call already sets termLength.&lt;/p&gt;
</comment>
                    <comment id="12621815" author="mikemccand" created="Tue, 12 Aug 2008 14:44:18 +0100"  >&lt;p&gt;Woops, you&apos;re right &amp;#8211; new patch attached.&lt;/p&gt;</comment>
                    <comment id="12621818" author="doronc" created="Tue, 12 Aug 2008 14:48:52 +0100"  >&lt;p&gt;Still with previous patch - all core tests passed, but then contrib compilation failed. &lt;br/&gt;
I tried ant clean contrib-test (to not repeat core test) and still compilation errors:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;    [javac] Compiling 27 source files to build\contrib\analyzers\classes\test
    [javac] contrib\analyzers\src\test\org\apache\lucene\analysis\miscellaneous\TestSingleTokenTokenFilter.java:23: cannot find symbol
    [javac] symbol  : class LuceneTestCase
    [javac] location: package org.apache.lucene.util
    [javac] import org.apache.lucene.util.LuceneTestCase;
    [javac]                              ^
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;In yesterday&apos;s version all tests passed.&lt;br/&gt;
Let me check recent patch.&lt;/p&gt;</comment>
                    <comment id="12621823" author="doronc" created="Tue, 12 Aug 2008 15:03:04 +0100"  >&lt;p&gt;Wait... &lt;br/&gt;
&quot;ant  clean  test-comtrib&quot; was a bad idea, because there&apos;s a missing dependency of contrib-test in test-compile.&lt;br/&gt;
So &quot;ant clean compile-test  test-contrib&quot;  doesn&apos;t have the compile errors above.&lt;br/&gt;
The errors that got me started on this were in contrib/analyzers but with the new patch and after clean, all contrib tests passed!&lt;/p&gt;
</comment>
                    <comment id="12621940" author="gsingers" created="Tue, 12 Aug 2008 20:32:31 +0100"  >&lt;p&gt;The SinkTokenizer changes don&apos;t seem right to me.   The token is already cloned in the add() method, no need to clone again in the next() call.&lt;/p&gt;

&lt;p&gt;At least, that&apos;s my understanding based on trying to piece together the changes being proposed here.&lt;/p&gt;</comment>
                    <comment id="12621969" author="dmsmith" created="Tue, 12 Aug 2008 21:50:13 +0100"  >&lt;blockquote&gt;
&lt;p&gt;The SinkTokenizer changes don&apos;t seem right to me. The token is already cloned in the add() method, no need to clone again in the next() call.&lt;/p&gt;

&lt;p&gt;At least, that&apos;s my understanding based on trying to piece together the changes being proposed here.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It is because SinkTokenizer implements reset(). SinkTokenizer needs to ensure that the subsequent times it returns the same token that the token is actually the same.&lt;/p&gt;

&lt;p&gt;A token is not immutable, so SinkTokenizer needs to ensure that the tokens in its list are immutable.&lt;/p&gt;

&lt;p&gt;The token that is added to the list can be a reusable Token. If it is added without cloning, some other user of the token might change it and thus the list changes.&lt;/p&gt;

&lt;p&gt;When the token is removed from the list and returned from next, it is presumed to be a reusable token. (This is true whether next() or next(Token) is called.) If it does not return a clone then some other user of the token might change it and thus the internal list changes. This is only a problem when reset is implemented. This is because a single token can be returned more than once from the TokenStream.&lt;/p&gt;

&lt;p&gt;If SinkTokenizer did not implement reset, then next() would not need to create a clone.&lt;/p&gt;</comment>
                    <comment id="12622168" author="gsingers" created="Wed, 13 Aug 2008 12:13:04 +0100"  >&lt;p&gt;My point is it is already cloned when it is added to the list, so now it is being cloned twice, and I think the second clone is extraneous.  In other words, it already is returning a clone from next.  The only way that Token could be changed is by doing it via the getTokens() method, which would have to be done outside of the Analysis process, which I would argue does not violate the reusability process.&lt;/p&gt;

&lt;p&gt;Cloning Tokens is not cheap, as I recall.  In fact, I seem to recall testing that it was cheaper to do a new.  Now, maybe that is fixed in this issue, but I am not sure.  &lt;/p&gt;</comment>
                    <comment id="12622171" author="doronc" created="Wed, 13 Aug 2008 12:22:50 +0100"  >&lt;p&gt;But how do you cope with reset()?&lt;/p&gt;

&lt;p&gt;Consider this:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;step 1: tokens added to the sink. They are cloned, so sink &quot;owns&quot; them.&lt;/li&gt;
	&lt;li&gt;step 2: sink is used, until exhausted (until its next(Token) returns null).&lt;/li&gt;
	&lt;li&gt;step 3: sink.reset() is invoked.&lt;/li&gt;
	&lt;li&gt;step 4: sink is used again, until exhaustion.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Point is that if step 2 did not return clones, the consumer that invoked step 2 might have overridden the tokens it got from step 2. Now in step 4 sink &quot;thinks&quot; it returns clones of original tokens, unaware that the consumer of step 2 modified them.&lt;/p&gt;</comment>
                    <comment id="12622195" author="gsingers" created="Wed, 13 Aug 2008 13:27:50 +0100"  >&lt;p&gt;Sorry, you guys are right.  My bad.  Does look like we improved some of the cloning costs, though.&lt;/p&gt;</comment>
                    <comment id="12622201" author="dmsmith" created="Wed, 13 Aug 2008 13:54:17 +0100"  >&lt;blockquote&gt;
&lt;p&gt;Cloning Tokens is not cheap, as I recall. In fact, I seem to recall testing that it was cheaper to do a new. Now, maybe that is fixed in this issue, but I am not sure.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I was going on hearsay when I uniformly used clone() rather than new when dealing with creating a deep copy of an existing token. I was under the impression that clone was faster than new to do equivalent work.&lt;/p&gt;

&lt;p&gt;The test is rather simple and worthy of doing before accepting this issue. I don&apos;t think I have time to do it today.&lt;/p&gt;

&lt;p&gt;The equivalent of clone is (done from memory, so this is close):&lt;br/&gt;
Token token = new Token(oldToken.startOffset(), oldToken.endOffset(), oldToken.getFlags(), oldToken.type());&lt;br/&gt;
token.setPositionIncrement(oldToken.positionIncrement());&lt;br/&gt;
if (oldToken.getPayload() != null) {&lt;br/&gt;
 Payload p = new Payload(....); // Create a new Payload with a deep copy of the payload&lt;br/&gt;
}&lt;/p&gt;

&lt;p&gt;While this might be faster, there are two flaws with this that clone avoids, clone has direct access to the parts and avoids method calls and also is future proof. If a new field is added to Token, it will automatically be carried forward.&lt;/p&gt;

&lt;p&gt;There are a couple of places in the code where:&lt;br/&gt;
public Token(Token prototype) // only if new is faster&lt;br/&gt;
and&lt;br/&gt;
public void copyFrom(Token prototype)&lt;br/&gt;
would beneficially solve these maintenance issues.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;But how do you cope with reset()?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This problem is a bug in the existing code. Today, one can create a chain of TokenFilters, each of which calls input.next() or input.next(token), and any one of which modifies the return value. It does not matter which is invoked. If the token returned is held in a cache then the cache is corrupted. Every cache of Tokens needs to ensure that it&apos;s cache is immutable on creation. It also needs to ensure that it is immutable on usage if the tokens can be served more than once.&lt;/p&gt;

&lt;p&gt;Two personal opinions:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Caches that don&apos;t implement reset should return cache.remove(0) &lt;span class=&quot;error&quot;&gt;&amp;#91;or equivalent&amp;#93;&lt;/span&gt; so it is clear that the cache can only be used once.&lt;/li&gt;
	&lt;li&gt;Caches should not be used except when it gives a clear performance advantage.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12622202" author="doronc" created="Wed, 13 Aug 2008 13:59:47 +0100"  >&lt;p&gt;I&apos;m not using sink tokenizer (yet) so not sure if the following worths it, but...&lt;/p&gt;

&lt;p&gt;One simple possibility to avoid those extra clones is to add a way to allow notifying the sink that reset() will not be called anymore. &lt;/p&gt;

&lt;p&gt;I.e. that for each token to be consumed from now on, this is the last time it s consumed. &lt;/p&gt;

&lt;p&gt;This can be added in the constructor, or a special setter can be added for that, such as: disableRest(). &lt;br/&gt;
There would not be an enableReset().&lt;br/&gt;
When disabled, next() would not clone, and reset() will throw an exception.&lt;/p&gt;</comment>
                    <comment id="12622204" author="gsingers" created="Wed, 13 Aug 2008 14:06:41 +0100"  >&lt;p&gt;I think the main performance issue with clone in the old Token was that it had to do the initTermBuffer before, even though clone already knows what size the buffer should be, etc.  It looks like this is fixed now, so it may be a non-issue.&lt;/p&gt;</comment>
                    <comment id="12622238" author="dmsmith" created="Wed, 13 Aug 2008 16:00:37 +0100"  >&lt;p&gt;Regarding the implementation of hashCode:&lt;br/&gt;
You are using the following:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;  &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; hashCode(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; i) {
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;(i).hashCode();
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This is rather expensive. Integer.hashCode() merely returns its value. Constructing a new Integer is unnecessary.&lt;/p&gt;

&lt;p&gt;While adding Token&apos;s integer values in Token&apos;s hashCode is perfectly fine, it is not quite optimal. And may cause unnecessary collisions.&lt;/p&gt;

&lt;p&gt;It might be better to pretend that Token&apos;s integer values are also in an array (using the ArrayUtil algorithm, this could be):&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; hashCode() {
    initTermBuffer();
    &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; code = termLength;
   code = code * 31 + startOffset;
   code = code * 31 + endOffset;
   code = code * 31 + flags;
   code = code * 31 + positionIncrement;
   code = code * 31 + type.hashCode();
   code = (payload == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; ? code : code * 31 + payload.hashCode());
   code = code * 31 + ArrayUtil.hashCode(termBuffer, 0, termLength);
   &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; code;
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Also, are the reinit methods used? If not, I&apos;d like to work up a patch that uses them. (And I&apos;ll include the above in it.)&lt;br/&gt;
(never mind. I see that they are! super! But I&apos;m working up a patch for this and a couple of minor optimizations that affect Token)&lt;/p&gt;

&lt;p&gt;I&apos;ll probably add copyFrom(Token) as a means to initialize one token to have the same content as another. There are a couple of places that this is appropriate.&lt;/p&gt;</comment>
                    <comment id="12622371" author="mikemccand" created="Wed, 13 Aug 2008 23:14:41 +0100"  >
&lt;blockquote&gt;&lt;p&gt;This is rather expensive. Integer.hashCode() merely returns its value. Constructing a new Integer is unnecessary.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Duh, I didn&apos;t realize that&apos;s the hashCode function for Integer.  I like you&apos;re new hashCode.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I&apos;ll probably add copyFrom(Token) as a means to initialize one token to have the same content as another. There are a couple of places that this is appropriate.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I like this, but maybe name it reinit(Token)?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Also, are the reinit methods used?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think we could use it in further places (I didn&apos;t search exhaustively).&lt;/p&gt;

&lt;p&gt;DM if you can pull together a patch w/ these fixes that&apos;d be great!&lt;/p&gt;</comment>
                    <comment id="12623366" author="dmsmith" created="Mon, 18 Aug 2008 16:04:37 +0100"  >&lt;ul&gt;
	&lt;li&gt;Added reinit(Token ...) methods to initialize one token from another.&lt;/li&gt;
	&lt;li&gt;Improved hashCode.&lt;/li&gt;
	&lt;li&gt;Made Token next(Token) have a final argument everywhere it is implemented to clarify the &quot;best practice&quot; for reuse and did the same for helper methods in various classes. As part of this, I renamed the token retrieved by next(Token) to be nextToken.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The typical pattern I used is for TokenFilters:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; Token next(&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; Token reusableToken) {
  &lt;span class=&quot;code-keyword&quot;&gt;assert&lt;/span&gt; reusableToken != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;
  Token nextToken = input.next(reusableToken);
   &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (nextToken != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;)
       &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;
   .... Do something with nextToken ....
   &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; nextToken;
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;and for other TokenStreams:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; Token next(&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; Token reusableToken) {
  &lt;span class=&quot;code-keyword&quot;&gt;assert&lt;/span&gt; reusableToken != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;
   .... Do something with reusableToken ....
   &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; reusableToken;
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;and for looping over a TokenStream:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; Token reusableToken = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Token();
&lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (Token nextToken = stream.next(reusableToken); nextToken != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;; nextToken = stream.next(reusableToken)) {
    .... Do something with nextToken ....
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;ul&gt;
	&lt;li&gt;Improved Payload.clone() to avoid new if possible.&lt;/li&gt;
	&lt;li&gt;Removed last remaining calls to termText() in a *.jj file.&lt;/li&gt;
&lt;/ul&gt;

</comment>
                    <comment id="12623394" author="mikemccand" created="Mon, 18 Aug 2008 17:12:42 +0100"  >&lt;p&gt;Patch &amp;amp; changes look good, thanks DM.&lt;/p&gt;

&lt;p&gt;I attached new patch with tiny changes:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Fixed javadoc warnings&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Removed extra unnecessary comparison in ArrayUtil.getShrinkSize&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I plan to commit in a day or two!&lt;/p&gt;</comment>
                    <comment id="12624005" author="mikemccand" created="Wed, 20 Aug 2008 15:40:41 +0100"  >&lt;p&gt;I just committed this.  Thanks DM!  This was one humongous patch &amp;#8211; almost 10K lines.  I sure hope we didn&apos;t break anything &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                </comments>
                <issuelinks>
                        <issuelinktype id="12310010">
                <name>Incorporates</name>
                                <outwardlinks description="incorporates">
                            <issuelink>
            <issuekey id="12401676">LUCENE-1350</issuekey>
        </issuelink>
                    </outwardlinks>
                                            </issuelinktype>
                    </issuelinks>
                <attachments>
                    <attachment id="12387511" name="LUCENE-1333-analysis.patch" size="32371" author="dmsmith" created="Mon, 4 Aug 2008 21:07:22 +0100" />
                    <attachment id="12387513" name="LUCENE-1333-analyzers.patch" size="113624" author="dmsmith" created="Mon, 4 Aug 2008 21:08:42 +0100" />
                    <attachment id="12386015" name="LUCENE-1333a.txt" size="19316" author="dmsmith" created="Mon, 14 Jul 2008 22:28:26 +0100" />
                    <attachment id="12387512" name="LUCENE-1333-core.patch" size="23698" author="dmsmith" created="Mon, 4 Aug 2008 21:07:58 +0100" />
                    <attachment id="12387515" name="LUCENE-1333-highlighter.patch" size="10505" author="dmsmith" created="Mon, 4 Aug 2008 21:09:51 +0100" />
                    <attachment id="12387516" name="LUCENE-1333-instantiated.patch" size="5702" author="dmsmith" created="Mon, 4 Aug 2008 21:10:26 +0100" />
                    <attachment id="12387517" name="LUCENE-1333-lucli.patch" size="1305" author="dmsmith" created="Mon, 4 Aug 2008 21:10:54 +0100" />
                    <attachment id="12387518" name="LUCENE-1333-memory.patch" size="10878" author="dmsmith" created="Mon, 4 Aug 2008 21:11:14 +0100" />
                    <attachment id="12387519" name="LUCENE-1333-miscellaneous.patch" size="10857" author="dmsmith" created="Mon, 4 Aug 2008 21:11:43 +0100" />
                    <attachment id="12388460" name="LUCENE-1333.patch" size="425106" author="mikemccand" created="Mon, 18 Aug 2008 17:12:42 +0100" />
                    <attachment id="12388439" name="LUCENE-1333.patch" size="424635" author="dmsmith" created="Mon, 18 Aug 2008 16:04:37 +0100" />
                    <attachment id="12388048" name="LUCENE-1333.patch" size="351591" author="mikemccand" created="Tue, 12 Aug 2008 14:44:18 +0100" />
                    <attachment id="12388039" name="LUCENE-1333.patch" size="351197" author="mikemccand" created="Tue, 12 Aug 2008 12:15:03 +0100" />
                    <attachment id="12387946" name="LUCENE-1333.patch" size="348713" author="mikemccand" created="Mon, 11 Aug 2008 12:44:13 +0100" />
                    <attachment id="12387900" name="LUCENE-1333.patch" size="335029" author="mikemccand" created="Sun, 10 Aug 2008 15:50:01 +0100" />
                    <attachment id="12387854" name="LUCENE-1333.patch" size="298829" author="dmsmith" created="Fri, 8 Aug 2008 22:03:21 +0100" />
                    <attachment id="12387509" name="LUCENE-1333.patch" size="25379" author="dmsmith" created="Mon, 4 Aug 2008 21:01:43 +0100" />
                    <attachment id="12387201" name="LUCENE-1333.patch" size="19125" author="mikemccand" created="Wed, 30 Jul 2008 16:30:04 +0100" />
                    <attachment id="12387520" name="LUCENE-1333-queries.patch" size="4803" author="dmsmith" created="Mon, 4 Aug 2008 21:12:03 +0100" />
                    <attachment id="12387514" name="LUCENE-1333-snowball.patch" size="3648" author="dmsmith" created="Mon, 4 Aug 2008 21:09:19 +0100" />
                    <attachment id="12387521" name="LUCENE-1333-wikipedia.patch" size="38939" author="dmsmith" created="Mon, 4 Aug 2008 21:12:24 +0100" />
                    <attachment id="12387522" name="LUCENE-1333-wordnet.patch" size="3988" author="dmsmith" created="Mon, 4 Aug 2008 21:12:43 +0100" />
                    <attachment id="12387523" name="LUCENE-1333-xml-query-parser.patch" size="4584" author="dmsmith" created="Mon, 4 Aug 2008 21:13:10 +0100" />
                </attachments>
            <subtasks>
        </subtasks>
                <customfields>
                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                <customfieldname>Attachment count</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>23.0</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                <customfieldname>Date of First Response</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>Wed, 30 Jul 2008 15:30:04 +0000</customfieldvalue>

                </customfieldvalues>
            </customfield>
                                                                                                        <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Global Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>12415</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                <customfieldname>Lucene Fields</customfieldname>
                <customfieldvalues>
                        <customfieldvalue key="10121"><![CDATA[New]]></customfieldvalue>
    
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>26395</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                <customfieldname>Time in Status</customfieldname>
                <customfieldvalues>
                    
                </customfieldvalues>
            </customfield>
                            </customfields>
    </item>
</channel>
</rss>