<!-- 
RSS generated by JIRA (5.2.8#851-sha1:3262fdc28b4bc8b23784e13eadc26a22399f5d88) at Tue Jul 16 13:30:16 UTC 2013

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/LUCENE-2507/LUCENE-2507.xml?field=key&field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>5.2.8</version>
        <build-number>851</build-number>
        <build-date>26-02-2013</build-date>
    </build-info>

<item>
            <title>[LUCENE-2507] automaton spellchecker</title>
                <link>https://issues.apache.org/jira/browse/LUCENE-2507</link>
                <project id="12310110" key="LUCENE">Lucene - Core</project>
                        <description>&lt;p&gt;The current spellchecker makes an n-gram index of your terms, and queries this for spellchecking.&lt;br/&gt;
The terms that come back from the n-gram query are then re-ranked by an algorithm such as Levenshtein.&lt;/p&gt;

&lt;p&gt;Alternatively, we could just do a levenshtein query directly against the index, then we wouldn&apos;t need&lt;br/&gt;
a separate index to rebuild.&lt;/p&gt;</description>
                <environment></environment>
            <key id="12467529">LUCENE-2507</key>
            <summary>automaton spellchecker</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/newfeature.png">New Feature</type>
                                <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                    <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png">Closed</status>
                    <resolution id="1">Fixed</resolution>
                                <assignee username="rcmuir">Robert Muir</assignee>
                                <reporter username="rcmuir">Robert Muir</reporter>
                        <labels>
                    </labels>
                <created>Tue, 22 Jun 2010 03:57:28 +0100</created>
                <updated>Fri, 10 May 2013 11:44:13 +0100</updated>
                    <resolved>Fri, 1 Oct 2010 21:41:23 +0100</resolved>
                                            <fixVersion>4.0-ALPHA</fixVersion>
                                <component>modules/spellchecker</component>
                        <due></due>
                    <votes>0</votes>
                        <watches>1</watches>
                                                    <comments>
                    <comment id="12881032" author="rcmuir" created="Tue, 22 Jun 2010 04:01:06 +0100"  >&lt;p&gt;prototype patch that adds &apos;DirectSpellChecker&apos;, with some tests showing use with IndexWriter.getReader()&lt;/p&gt;

&lt;p&gt;For now I only implemented Levenshtein, since its for free &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; But it would be good to support re-ranking against the existing StringDistance metrics, etc.&lt;/p&gt;

&lt;p&gt;The larger problem is that the existing APIs are really built around this idea of a separate index, so I&apos;m open to suggestions as to how this can be better integrated.&lt;/p&gt;
</comment>
                    <comment id="12881086" author="rcmuir" created="Tue, 22 Jun 2010 07:10:23 +0100"  >&lt;p&gt;there was a bug in conversion between fuzzy term enum&apos;s scaling.&lt;/p&gt;

&lt;p&gt;i ran some simple perf tests, this is essentially just as fast as the existing code&lt;br/&gt;
with setMaxEdits(1). but with setMaxEdits(2) is much slower.&lt;/p&gt;

&lt;p&gt;i&apos;ll try to think of ways to speed it up... one idea would be to add lev automata with transposition&lt;br/&gt;
support instead of using higher distances, etc.&lt;/p&gt;</comment>
                    <comment id="12915853" author="rcmuir" created="Tue, 28 Sep 2010 18:44:18 +0100"  >&lt;p&gt;we have sped up this seeking a lot recently, and i improved this patch some:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;avoid calling docfreq on the suggestions, by using the TermsEnum&apos;s docfreq&lt;/li&gt;
	&lt;li&gt;Mike had the idea that we should actually try lower edit distances first. The&lt;br/&gt;
  general use case here is a small number of suggestions (e.g. 1), so &lt;br/&gt;
  we actually try edit distance=1 first... only if this doesn&apos;t give enough suggestions &lt;br/&gt;
  do we then try higher distances. &lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I think this is a good approach here, because we are getting levenshtein directly, &lt;br/&gt;
so we don&apos;t have the problem the n-gram based spellchecker has... (for reference below)&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;   * &amp;lt;p&amp;gt;As the Lucene similarity that is used to fetch the most relevant n-grammed terms
   * is not the same as the edit distance strategy used to calculate the best
   * matching spell-checked word from the hits that Lucene found, one usually has
   * to retrieve a couple of numSug&apos;s in order to get the true best match.
   *
   * &amp;lt;p&amp;gt;I.e. if numSug == 1, don&apos;t count on that suggestion being the best one.
   * Thus, you should set this value to &amp;lt;b&amp;gt;at least&amp;lt;/b&amp;gt; 5 for a good suggestion.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Since we are actually doing levenshtein, you can safely use lower values for numSug,&lt;br/&gt;
such as numSug=1&lt;/p&gt;</comment>
                    <comment id="12916651" author="rcmuir" created="Thu, 30 Sep 2010 21:52:35 +0100"  >&lt;p&gt;I improved the quality and performance of this spellchecker, integrated it with the other spellchecker APIs,&lt;br/&gt;
and did the Solr side. I think minus some more tests and docs (especially on the various options) its good to go.&lt;/p&gt;</comment>
                    <comment id="12916753" author="cmale" created="Fri, 1 Oct 2010 02:24:02 +0100"  >&lt;p&gt;Hey Robert,&lt;/p&gt;

&lt;p&gt;Do you have any benchmarks for this spellchecker? I notice you mention a few times that you improved the performance.  Do you know how it compares against the separate index approach? &lt;/p&gt;

&lt;p&gt;Equally, is this spellchecker a conceptual drop in replacement? By that I mean, are the suggestions it generates radically different to the separate index spellcheckers or are they along the same lines?&lt;/p&gt;</comment>
                    <comment id="12916757" author="rcmuir" created="Fri, 1 Oct 2010 03:01:26 +0100"  >&lt;blockquote&gt;&lt;p&gt;Do you have any benchmarks for this spellchecker? I notice you mention a few times that you improved the performance. Do you know how it compares against the separate index approach?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;In general I think the performance is fine. I did a lot of testing against the geonames database (&amp;gt; 2 million unique terms).&lt;br/&gt;
But, it completely depends upon the parameters you set. Here are some that can affect performance and quality:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;avoid doing work if the query term is already spelled correctly:
	&lt;ul&gt;
		&lt;li&gt;minQueryLength (example: 4), query words of 3 characters or less are not checked.&lt;br/&gt;
In general, with any metric, the candidates here will mostly be nonsense anyway.&lt;/li&gt;
		&lt;li&gt;maxQueryFrequency (example: 1% or 1):  if the query word is high frequency (e.g. appears in more&lt;br/&gt;
than 1% of the documents its assumed to be correct, and no suggestions are given.&lt;br/&gt;
You can also set this to something like 1, if say you have a small product database &lt;br/&gt;
and you feel all your products are spelled completely correct in your index, and you &lt;br/&gt;
don&apos;t want to &lt;b&gt;ever&lt;/b&gt; suggest anything if the query term is in your products database.&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;avoid doing work examining potentially bad suggestions:
	&lt;ul&gt;
		&lt;li&gt;maxEdits (example: 1), the majority of misspellings are only 1 distance away.&lt;br/&gt;
So if you lower this from the default &quot;2&quot; to 1, its faster and more &quot;lightweight&quot; in the sense you get less a chance of getting a bad suggestion.&lt;/li&gt;
		&lt;li&gt;minPrefix (example: 1), most misspellings don&apos;t occur in the first character.&lt;br/&gt;
For the solr example, i set this to zero (the wiki has an example correcting &quot;hell&quot; with &quot;dell&quot;), but in practice I think 1 is a good value. &lt;br/&gt;
Additionally this has a practical use for solr users: you need a rather &quot;raw&quot; (e.g. not stemmed) analyzed field for spellchecking,&lt;br/&gt;
if you set this to 1 you can re-use your reverse-wildcard field for spellchecking too, and it will never suggest reversed terms.&lt;/li&gt;
		&lt;li&gt;thresholdFrequency (example: 1% or 1): this plays the role of Solr&apos;s &quot;HighFrequencyDictionary&quot;.&lt;br/&gt;
In other words, you could set this to 1 to never suggest words that only appear in a single document... in many cases these are misspellings.&lt;/li&gt;
		&lt;li&gt;maxInspections (example: 5), the existing spellchecker uses a hardcoded 10 here.&lt;br/&gt;
A lower value can work well here, since the algorithm used to draw candidates is actually levenshtein. &lt;br/&gt;
However, I set the default to 5 (instead of 1), because its good to gather a few candidates for docFreq-sorting.... &lt;br/&gt;
but if you increase thresholdFrequency you can probably lower this.&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;blockquote&gt;&lt;p&gt;Equally, is this spellchecker a conceptual drop in replacement? By that I mean, are the suggestions it generates radically different to the separate index spellcheckers or are they along the same lines?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think they are better, e.g. if you are ranking by an edit-distance like function such as Levenshtein or Jaro-Winkler, it makes more sense to get your &lt;b&gt;candidates&lt;/b&gt; via the same or similar algorithm! The existing spellchecker gets candidates with n-grams... I think this causes a mismatch... (Of course the inverse is true, if you use NGramDistance, use the existing spellchecker!)&lt;/p&gt;

&lt;p&gt;Again I did a lot of testing with various corpora, and I&apos;m not a spellchecking expert but i didn&apos;t get particularly good results from the existing spellchecker.&lt;br/&gt;
And for some corpora such as geonames, it didnt seem to have the configurability I needed to tune the spellchecker to that domain.&lt;/p&gt;

&lt;p&gt;For example, i queried on &quot;zeeland&quot; and the existing spellchecker returned freeland, leland, ireland, deland, and cleland as suggestions.&lt;br/&gt;
Whats worse, is that it created a 240MB auxiliary index when my original index was only 300MB, and it took it 141 seconds to do this.&lt;/p&gt;

&lt;p&gt;The idea here isn&apos;t to solve the world&apos;s spellchecking problems, its mainly to get rid of the extra index. I think its trivial to&lt;br/&gt;
set this one up to beat SpellChecker&apos;s suggestions, because I don&apos;t think SpellChecker&apos;s suggestions are very good.&lt;/p&gt;</comment>
                    <comment id="12916761" author="cmale" created="Fri, 1 Oct 2010 04:03:35 +0100"  >&lt;p&gt;Hi,&lt;/p&gt;

&lt;p&gt;Thanks for that.  Covers my questions nicely.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The idea here isn&apos;t to solve the world&apos;s spellchecking problems, its mainly to get rid of the extra index.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes definitely.   I was just checking that we weren&apos;t doing that at a cost of reasonable suggestions.  But your argument makes clear sense.  &lt;/p&gt;

&lt;p&gt;This really is a great feature.&lt;/p&gt;</comment>
                    <comment id="12916763" author="rcmuir" created="Fri, 1 Oct 2010 04:09:55 +0100"  >&lt;blockquote&gt;&lt;p&gt;Yes definitely. I was just checking that we weren&apos;t doing that at a cost of reasonable suggestions. But your argument makes clear sense.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Well, aspell has some test data here: &lt;a href=&quot;http://aspell.net/test/cur/batch0.tab&quot; class=&quot;external-link&quot;&gt;http://aspell.net/test/cur/batch0.tab&lt;/a&gt;&lt;br/&gt;
I could index some wikipedia, and run both spellcheckers?&lt;/p&gt;

&lt;p&gt;Additionally I suppose it would be fair to run the correct answers from this set, and see the results across both spellcheckers as far as spell-correcting already correct words (and what they suggest if they do!)&lt;/p&gt;</comment>
                    <comment id="12916764" author="cmale" created="Fri, 1 Oct 2010 04:13:38 +0100"  >&lt;p&gt;That is a very good idea yes, but I don&apos;t think its necessary to do that before this is committed.   We can do that afterwards, get an idea of where the spellcheckers are, and improve them through other issues if needs be.&lt;/p&gt;</comment>
                    <comment id="12916779" author="rcmuir" created="Fri, 1 Oct 2010 05:48:05 +0100"  >&lt;blockquote&gt;&lt;p&gt;That is a very good idea yes, but I don&apos;t think its necessary to do that before this is committed.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Here&apos;s some &lt;b&gt;very rough&lt;/b&gt; numbers from that batch0.tab, against the FIRE english corpus (sorry i&apos;m still downloading wikipedia, its quite large!)&lt;br/&gt;
Note, this is only relative, e.g. i dont even know if these terms all exist in that corpus.&lt;br/&gt;
additionally, some contain punctuation etc, i only lowercased them for consistency.&lt;/p&gt;

&lt;p&gt;for reference, there are 547 incorrect/correct term pairs in this aspell spelling correction test.&lt;br/&gt;
My corpus has ~150,000 docs, with 304,000 unique terms in the body field.&lt;br/&gt;
for both spellcheckers I used all defaults, e.g. spellchecker.suggestSimilar(words&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt;.toLowerCase(), 1, reader, &quot;body&quot;, true);&lt;/p&gt;

&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;impl&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Number correct&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt; (out of 547)&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Number correct, inverted&lt;span class=&quot;error&quot;&gt;&amp;#91;2&amp;#93;&lt;/span&gt; (out of 547)&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Avg time in ms&lt;span class=&quot;error&quot;&gt;&amp;#91;3&amp;#93;&lt;/span&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;SpellChecker&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;214&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;218&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1.47ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;DirectSpellChecker&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;242&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;303&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4.53ms&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;


&lt;p&gt;1. using the misspelling as a query term, does the spellchecker return the correct spelling?&lt;br/&gt;
2. using the correct spelling as a query term, does the spellchecker return nothing at all?&lt;br/&gt;
3. this is the average time to perform an actual correction, both spellcheckers have some way to do no work at all for the common (correctly spelled) case.&lt;/p&gt;

&lt;p&gt;So although the benchmark itself isnt for search engine benchmarking (e.g. contains stopwords/punctuation), this basically shows what I&apos;ve been seeing, that I think this spellchecker outperforms the existing one, and the perf cost is reasonable.&lt;/p&gt;</comment>
                    <comment id="12916787" author="rcmuir" created="Fri, 1 Oct 2010 06:24:17 +0100"  >&lt;p&gt;By the way, out of curiousity i tested an alternative configuration, DirectSpellChecker with .setMaxEdits(1)&lt;/p&gt;

&lt;p&gt;With this &quot;lighter&quot; configuration:&lt;/p&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;impl&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Number correct (out of 547)&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Number correct, inverted (out of 547)&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Avg time in ms&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;DirectSpellChecker(n=1)&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;165&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;432&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1.83ms&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;


&lt;p&gt;So here, you have the flexibility to have essentially the same performance as the existing spellchecker,&lt;br/&gt;
and the false positive rate is hugely reduced (in this contrived test). You trade off only being able to&lt;br/&gt;
catch 77% of the suggestions relative to the old spellchecker... but this might be good for setups&lt;br/&gt;
that feel the n=2 default is too aggressive.&lt;/p&gt;

&lt;p&gt;And again, like the original configuration, you have no index to rebuild at all.&lt;/p&gt;</comment>
                    <comment id="12916800" author="cmale" created="Fri, 1 Oct 2010 07:33:32 +0100"  >&lt;p&gt;They&apos;re both very fast and you get the flexibility of not having an additional index.  +1 to committing.  &lt;/p&gt;</comment>
                    <comment id="12916841" author="mikemccand" created="Fri, 1 Oct 2010 10:41:52 +0100"  >&lt;p&gt;This is an awesome step forward!&lt;/p&gt;

&lt;p&gt;It requires no parallel index, and, it gets better accuracy (if your metric is edit distance like) at a negligible perf hit.&lt;/p&gt;

&lt;p&gt;It&apos;s great that it leverages the absurd speedups we&apos;ve made to FuzzyQuery in 4.0.&lt;/p&gt;</comment>
                    <comment id="12916883" author="rcmuir" created="Fri, 1 Oct 2010 14:21:09 +0100"  >&lt;p&gt;I&apos;ll work on cleaning up tests and doc, i think we can then commit this with the functionality it has.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;It&apos;s great that it leverages the absurd speedups we&apos;ve made to FuzzyQuery in 4.0.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes, if you read that scary fuzzy paper it seems thats its original use-case all along (we just did FuzzyQuery first, and re-used it here):&lt;br/&gt;
&lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.16.652&quot; class=&quot;external-link&quot;&gt;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.16.652&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Along the same lines, I think we can then later improve both spellcheckers in easy ways. For example,&lt;br/&gt;
it would be good to add a concept of &quot;SpellCheckFilter&quot; that can return true/false if a word is correctly spelled.&lt;/p&gt;

&lt;p&gt;Docfreq-based stuff helps, but if you know the language, something like hunspell could go a long way here&lt;br/&gt;
to both preventing either spellchecker from trying to correct an already-correctly-spelled word or preventing&lt;br/&gt;
it from suggesting misspellings.&lt;/p&gt;</comment>
                    <comment id="12916931" author="rcmuir" created="Fri, 1 Oct 2010 17:07:41 +0100"  >&lt;p&gt;here&apos;s the improved docs and tests.&lt;/p&gt;

&lt;p&gt;I&apos;d like to commit this one and we can iterate as discussed, hopefully improve both spellcheckers.&lt;/p&gt;</comment>
                    <comment id="12917031" author="rcmuir" created="Fri, 1 Oct 2010 21:41:23 +0100"  >&lt;p&gt;Committed revision 1003642.&lt;/p&gt;</comment>
                </comments>
                    <attachments>
                    <attachment id="12456129" name="LUCENE-2507.patch" size="38908" author="rcmuir" created="Fri, 1 Oct 2010 17:07:41 +0100" />
                    <attachment id="12456052" name="LUCENE-2507.patch" size="32276" author="rcmuir" created="Thu, 30 Sep 2010 21:52:35 +0100" />
                    <attachment id="12455856" name="LUCENE-2507.patch" size="10108" author="rcmuir" created="Tue, 28 Sep 2010 18:44:18 +0100" />
                    <attachment id="12447670" name="LUCENE-2507.patch" size="9453" author="rcmuir" created="Tue, 22 Jun 2010 07:10:23 +0100" />
                    <attachment id="12447657" name="LUCENE-2507.patch" size="9377" author="rcmuir" created="Tue, 22 Jun 2010 04:01:05 +0100" />
                </attachments>
            <subtasks>
        </subtasks>
                <customfields>
                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                <customfieldname>Attachment count</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>5.0</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                <customfieldname>Date of First Response</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>Fri, 1 Oct 2010 01:24:02 +0000</customfieldvalue>

                </customfieldvalues>
            </customfield>
                                                                                                        <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Global Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>11317</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                <customfieldname>Lucene Fields</customfieldname>
                <customfieldvalues>
                        <customfieldvalue key="10121"><![CDATA[New]]></customfieldvalue>
    <customfieldvalue key="10120"><![CDATA[Patch Available]]></customfieldvalue>
    
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>25185</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                <customfieldname>Time in Status</customfieldname>
                <customfieldvalues>
                    
                </customfieldvalues>
            </customfield>
                            </customfields>
    </item>
</channel>
</rss>