<!-- 
RSS generated by JIRA (5.2.8#851-sha1:3262fdc28b4bc8b23784e13eadc26a22399f5d88) at Tue Jul 16 13:22:13 UTC 2013

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/LUCENE-994/LUCENE-994.xml?field=key&field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>5.2.8</version>
        <build-number>851</build-number>
        <build-date>26-02-2013</build-date>
    </build-info>

<item>
            <title>[LUCENE-994] Change defaults in IndexWriter to maximize &quot;out of the box&quot; performance</title>
                <link>https://issues.apache.org/jira/browse/LUCENE-994</link>
                <project id="12310110" key="LUCENE">Lucene - Core</project>
                        <description>&lt;p&gt;This is follow-through from &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-845&quot; title=&quot;If you &amp;quot;flush by RAM usage&amp;quot; then IndexWriter may over-merge&quot;&gt;&lt;del&gt;LUCENE-845&lt;/del&gt;&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-847&quot; title=&quot;Factor merge policy out of IndexWriter&quot;&gt;&lt;del&gt;LUCENE-847&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-870&quot; title=&quot;add concurrent merge policy&quot;&gt;&lt;del&gt;LUCENE-870&lt;/del&gt;&lt;/a&gt;;&lt;br/&gt;
I&apos;ll commit this once those three are committed.&lt;/p&gt;

&lt;p&gt;Out of the box performance of IndexWriter is maximized when flushing&lt;br/&gt;
by RAM instead of a fixed document count (the default today) because&lt;br/&gt;
documents can vary greatly in size.&lt;/p&gt;

&lt;p&gt;Likewise, merging performance should be faster when merging by net&lt;br/&gt;
segment size since, to minimize the net IO cost of merging segments&lt;br/&gt;
over time, you want to merge segments of equal byte size.&lt;/p&gt;

&lt;p&gt;Finally, ConcurrentMergeScheduler improves indexing speed&lt;br/&gt;
substantially (25% in a simple initial test in &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-870&quot; title=&quot;add concurrent merge policy&quot;&gt;&lt;del&gt;LUCENE-870&lt;/del&gt;&lt;/a&gt;) because it&lt;br/&gt;
runs the merges in the backround and doesn&apos;t block&lt;br/&gt;
add/update/deleteDocument calls.  Most machines have concurrency&lt;br/&gt;
between CPU and IO and so it makes sense to default to this&lt;br/&gt;
MergeScheduler.&lt;/p&gt;

&lt;p&gt;Note that these changes will break users of ParallelReader because the&lt;br/&gt;
parallel indices will no longer have matching docIDs.  Such users need&lt;br/&gt;
to switch IndexWriter back to flushing by doc count, and switch the&lt;br/&gt;
MergePolicy back to LogDocMergePolicy.  It&apos;s likely also necessary to&lt;br/&gt;
switch the MergeScheduler back to SerialMergeScheduler to ensure&lt;br/&gt;
deterministic docID assignment.&lt;/p&gt;

&lt;p&gt;I think the combination of these three default changes, plus other&lt;br/&gt;
performance improvements for indexing (&lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-966&quot; title=&quot;A faster JFlex-based replacement for StandardAnalyzer&quot;&gt;&lt;del&gt;LUCENE-966&lt;/del&gt;&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-843&quot; title=&quot;improve how IndexWriter uses RAM to buffer added documents&quot;&gt;&lt;del&gt;LUCENE-843&lt;/del&gt;&lt;/a&gt;,&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-963&quot; title=&quot;Add setters to Field to allow re-use of Field instances during indexing&quot;&gt;&lt;del&gt;LUCENE-963&lt;/del&gt;&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-969&quot; title=&quot;Optimize the core tokenizers/analyzers &amp;amp; deprecate Token.termText&quot;&gt;&lt;del&gt;LUCENE-969&lt;/del&gt;&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-871&quot; title=&quot;ISOLatin1AccentFilter a bit slow&quot;&gt;&lt;del&gt;LUCENE-871&lt;/del&gt;&lt;/a&gt;, etc.) should make for some sizable&lt;br/&gt;
performance gains Lucene 2.3!&lt;/p&gt;</description>
                <environment></environment>
            <key id="12377963">LUCENE-994</key>
            <summary>Change defaults in IndexWriter to maximize &quot;out of the box&quot; performance</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                    <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png">Closed</status>
                    <resolution id="1">Fixed</resolution>
                                <assignee username="mikemccand">Michael McCandless</assignee>
                                <reporter username="mikemccand">Michael McCandless</reporter>
                        <labels>
                    </labels>
                <created>Tue, 11 Sep 2007 11:34:36 +0100</created>
                <updated>Fri, 25 Jan 2008 03:24:04 +0000</updated>
                    <resolved>Sat, 29 Sep 2007 20:58:26 +0100</resolved>
                            <version>2.3</version>
                                <fixVersion>2.3</fixVersion>
                                <component>core/index</component>
                        <due></due>
                    <votes>0</votes>
                        <watches>0</watches>
                                                    <comments>
                    <comment id="12528916" author="mikemccand" created="Wed, 19 Sep 2007 22:42:35 +0100"  >
&lt;p&gt;Attached patch.&lt;/p&gt;

&lt;p&gt;I changed these defaults:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Use ConcurrentMergeScheduler so merges are run in the background.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Flush by RAM usage by default.  I set buffer size to 16 MB.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Merge segments according to byte size, not doc count.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Most unit tests just passed, but a handful had to be switched back to&lt;br/&gt;
LogDocMergePolicy because they were checking specific doc-count based&lt;br/&gt;
details on how merges are selected.  All tests pass now.&lt;/p&gt;

&lt;p&gt;I added an entry in CHANGES.txt under &quot;Changes in runtime behavior&quot;&lt;br/&gt;
including a NOTE for ParallelReader users.  I think when we release&lt;br/&gt;
2.3 we should also put a caveat into the release announcement calling&lt;br/&gt;
attention to this specifically for users of ParallelReader.&lt;/p&gt;

&lt;p&gt;I also fixed up contrib/benchmark to accept double-typed params and to&lt;br/&gt;
pull the defaults for its Open/CreateIndexTask from IndexWriter&apos;s&lt;br/&gt;
defaults.&lt;/p&gt;

&lt;p&gt;Finally I had to make a few small changes to gdata-server.&lt;/p&gt;</comment>
                    <comment id="12530257" author="mikemccand" created="Tue, 25 Sep 2007 21:04:26 +0100"  >&lt;p&gt;I just committed this!&lt;/p&gt;

&lt;p&gt;This is a non-backwards-compatible change (and affects at least users&lt;br/&gt;
of ParallelReader).  I put a comment in the top section of CHANGES.txt&lt;br/&gt;
explaining this.&lt;/p&gt;</comment>
                    <comment id="12530313" author="markrmiller@gmail.com" created="Tue, 25 Sep 2007 23:52:33 +0100"  >&lt;p&gt;Perhaps this is expected, but my experience:&lt;/p&gt;

&lt;p&gt;I load all my docs and then optimize the index. I load with a mergefactor of 3 because I have found it takes just as much time to merge as you go as it does to optimize everything at the end (I have not tested this with recent improvements).&lt;/p&gt;

&lt;p&gt;After changing to the new default merge policy my app (which does a lot more loading a doc than just index it with Lucene) lost 46% of its performance (processing the data, fully loading lucene and my database, and then optimizing an index).&lt;br/&gt;
Switching back to LogDocMergePolicy() returns my performance.&lt;/p&gt;

&lt;p&gt;I am using flushbyram(42) and the concurrent merger.&lt;/p&gt;

&lt;p&gt;Triple checked this time &amp;lt;G&amp;gt;&lt;/p&gt;

&lt;p&gt;Is this expected?&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Mark&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12530401" author="mikemccand" created="Wed, 26 Sep 2007 10:44:46 +0100"  >
&lt;p&gt;This is certainly not expected!&lt;/p&gt;

&lt;p&gt;So you are flushing by RAM usage, and then find that merging according&lt;br/&gt;
to doc count gives substantially better performance than merging&lt;br/&gt;
according to byte size of the segments?&lt;/p&gt;

&lt;p&gt;I&apos;ll run a test with contrib/benchmark on wikipedia content.  I&apos;ll set&lt;br/&gt;
mergeFactor to 3 and ramBufferMB = 42 and I&apos;ll optimize in the end.&lt;br/&gt;
Is there anything else interesting in how you&apos;re using Lucene?&lt;/p&gt;

&lt;p&gt;Do you have any sense of where this sizable slowdown shows up?  EG, is&lt;br/&gt;
the optimize in the end substantially slower, or something?&lt;/p&gt;

&lt;p&gt;Is there any way to tease out the time actually spent in Lucene vs the&lt;br/&gt;
rest of your application?&lt;/p&gt;</comment>
                    <comment id="12530414" author="markrmiller@gmail.com" created="Wed, 26 Sep 2007 11:47:30 +0100"  >&lt;p&gt;Okay, I ran some tests loading about 4000 docs:&lt;/p&gt;

&lt;p&gt;autocommit=false, non compound format, mergefactor=3, flushbyram=42, build: latest from trunk (yesterday)&lt;/p&gt;

&lt;p&gt;new merge policy i load about 30 docs per second:&lt;/p&gt;

&lt;p&gt;time for load: 142828ms&lt;br/&gt;
time for optimize: 2422ms&lt;/p&gt;

&lt;p&gt;LogDocMergePolicy() I load about 50 docs per second:&lt;/p&gt;

&lt;p&gt;time for load: 86781ms&lt;br/&gt;
optimize: 4891ms&lt;/p&gt;

&lt;p&gt;So it looks like optimize is quicker, but I pay for it during the load?&lt;/p&gt;

&lt;p&gt;I am not doing anything else special with Lucene that I can think of, and I got duplicate results for a much larger load.&lt;/p&gt;

&lt;p&gt;Not too easy to pull out the non Lucene parts without just writing a test from scratch for Lucene.&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Mark&lt;/li&gt;
&lt;/ul&gt;

</comment>
                    <comment id="12530458" author="mikemccand" created="Wed, 26 Sep 2007 15:49:28 +0100"  >&lt;p&gt;Hmmm ... it seems like your index is fairly small because optimize&lt;br/&gt;
runs pretty quickly in both cases.  But that would mean (I think)&lt;br/&gt;
you&apos;re not actually flushing very many segments since you have a high&lt;br/&gt;
RAM buffer size (42 MB).  So then I&apos;m baffled why merge policy would&lt;br/&gt;
be changing your numbers so much because your 4000 doc test should not&lt;br/&gt;
(I think?) actually be doing that much merging.&lt;/p&gt;

&lt;p&gt;Are you creating the index from scratch in each test?  How large is&lt;br/&gt;
the resulting index?  Are you using FSDirectory?&lt;/p&gt;

&lt;p&gt;I ran my own test on Wikipedia content.  I ran this alg:&lt;/p&gt;

&lt;p&gt;  analyzer=org.apache.lucene.analysis.SimpleAnalyzer&lt;br/&gt;
  doc.maker=org.apache.lucene.benchmark.byTask.feeds.LineDocMaker&lt;br/&gt;
  directory=FSDirectory&lt;br/&gt;
  docs.file=/lucene/wikifull.txt&lt;/p&gt;

&lt;p&gt;  ram.flush.mb=42&lt;br/&gt;
  max.field.length=2147483647&lt;br/&gt;
  merge.factor=3&lt;br/&gt;
  compound=false&lt;br/&gt;
  autocommit=false&lt;/p&gt;

&lt;p&gt;  doc.maker.forever=false&lt;br/&gt;
  doc.add.log.step=5000&lt;/p&gt;

&lt;p&gt;  ResetSystemErase&lt;br/&gt;
  CreateIndex&lt;br/&gt;
  {AddDoc &amp;gt;: *&lt;br/&gt;
  Optimize&lt;br/&gt;
  CloseIndex&lt;/p&gt;

&lt;p&gt;  RepSumByName&lt;/p&gt;

&lt;p&gt;to index all of wikipedia with the same params you&apos;re using (flush @&lt;br/&gt;
42 MB, compound false, merge factor 3).&lt;/p&gt;

&lt;p&gt;LogByteSizeMergePolicy (the current default) gives this output (times&lt;br/&gt;
are best of 2 runs):&lt;/p&gt;

&lt;p&gt;  indexing 1198 sec&lt;br/&gt;
  optimize  282 sec&lt;/p&gt;

&lt;p&gt;LogDocMergePolicy took this long&lt;/p&gt;

&lt;p&gt;  indexing 1216 sec&lt;br/&gt;
  optimize  270 sec&lt;/p&gt;

&lt;p&gt;I think those numbers are &quot;within the noise&quot; of each other, ie pretty&lt;br/&gt;
much the same.  This is what I would expect.  So we need to figure out&lt;br/&gt;
why I&apos;m seeing different results than you.&lt;/p&gt;

&lt;p&gt;Can you call writer.setInfoStream(System.out) and attach the resulting&lt;br/&gt;
output from each of your 4000 doc runs?  Thanks!&lt;/p&gt;</comment>
                    <comment id="12530498" author="markrmiller@gmail.com" created="Wed, 26 Sep 2007 18:39:35 +0100"  >&lt;p&gt;Sorry about the small test...just started using 4000 because I was having same results with 20000.&lt;/p&gt;

&lt;p&gt;A sample run with 20000:&lt;/p&gt;

&lt;p&gt;old merge:&lt;br/&gt;
load: 1320453 ms&lt;br/&gt;
optimize: 8891 ms&lt;/p&gt;

&lt;p&gt;new merge:&lt;br/&gt;
load: 393625&lt;br/&gt;
optimize: 17937 ms&lt;/p&gt;

&lt;p&gt;Its a fresh index each time of docs about 5-10k. I am using StandardAnalyzer.&lt;/p&gt;

&lt;p&gt;And I forgot to mention a big quirk: I am writing to two indexes, but only analyzing to a tokenstream once (cachingtoken filter) to have a stemmed and unstemmed index. So obviously a slowdown in writing an index would be a bit exaggerated.&lt;/p&gt;

&lt;p&gt;Still, its a major difference for my app.&lt;/p&gt;

&lt;p&gt;I will get you some debug output from the writers.&lt;/p&gt;</comment>
                    <comment id="12530521" author="yseeley@gmail.com" created="Wed, 26 Sep 2007 19:59:03 +0100"  >&lt;p&gt;So based on your 20000 run, the &quot;new merge&quot; completed 3 times as fast?&lt;/p&gt;

&lt;p&gt;Some of the differences are going to be luck as to when big segment merges are done.&lt;/p&gt;

&lt;p&gt;If scheme &quot;A&quot; just did a big merge right before the optimize,  much of that is wasted effort (the entire index will be rewritten anyway).  If scheme &quot;B&quot; was just about to do a big merge, but then optimize was called, it wins.&lt;/p&gt;

&lt;p&gt;For a particular test run, tweaking the parameters can result in huge differences, but they may be &quot;false&quot;.&lt;/p&gt;

&lt;p&gt;The only way I can think of minimizing this effect is to do very large runs and cap the maximum size of segments to get rid of the possibility of random huge segment merges.&lt;/p&gt;</comment>
                    <comment id="12530526" author="markrmiller@gmail.com" created="Wed, 26 Sep 2007 20:11:33 +0100"  >&lt;p&gt;It was 3 times as fast, but to be fair, its more often closer to 2 times as fast. I just gave the result of the latest run. After running the test many many times, the new merge is much closer to 1/2 as fast as the old, and it has never been faster than that...rarely its slower....1/3 is worst I say actually.&lt;/p&gt;
</comment>
                    <comment id="12531075" author="mikemccand" created="Fri, 28 Sep 2007 17:13:38 +0100"  >&lt;p&gt;Mark, are you working on the debug output?  I&apos;m hoping that gives a clue as to why you see such performance loss when merging by net byte size of each segment rather than by doc count... thanks.&lt;/p&gt;</comment>
                    <comment id="12531076" author="mikemccand" created="Fri, 28 Sep 2007 17:13:55 +0100"  >&lt;p&gt;Reopening until we get to the bottom of the performance loss...&lt;/p&gt;</comment>
                    <comment id="12531259" author="markrmiller@gmail.com" created="Sat, 29 Sep 2007 18:08:29 +0100"  >&lt;p&gt;Sorry for the delay. Here is the debug output. As I said, I am actually writing to two indexes per doc, but I am also doing other processing and storing, so the slow down must be significant anyway (well over 25%?). The first Writer has an analyzer that stems and caches the unstemmed form , the second writer reads from the cached unstemmed tokens.&lt;/p&gt;

&lt;p&gt;If the debug does not lead anywhere I can try to isolate the slowdown out of my app code (if it exists without writing with two writers, though the writing is sequential). Also, I will try with some other merge factors etc.&lt;/p&gt;

&lt;p&gt;I think that the performance gap grows with the number of documents.&lt;/p&gt;

&lt;p&gt;Attached: 4 files, one for each writer with the old policy and the new. Run details: 4000 some docs, 30 doc/s new, 50 doc/s old&lt;/p&gt;</comment>
                    <comment id="12531269" author="mikemccand" created="Sat, 29 Sep 2007 20:27:11 +0100"  >&lt;p&gt;Thanks Mark!  OK, I noticed a few things from the logs:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;It looks like you are actually flushing every 10 docs, not 42 MB.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;You seem to have a mergeFactor of 10 through all the indexing&lt;br/&gt;
    except at some point near the end, before optimize is called, you&lt;br/&gt;
    switch to mergeFactor 3?&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;That said, the LogByteSizeMergePolicy is definitely not acting right.&lt;br/&gt;
OH, I see the problem!&lt;/p&gt;

&lt;p&gt;OK, the bug happens when autoCommit is false and your docs have stored&lt;br/&gt;
fields / term vectors and you&apos;re using LogByteSizeMergePolicy.  In&lt;br/&gt;
this case I am incorrectly calculating the byte size of the segment:&lt;br/&gt;
I&apos;m counting the shared doc stores against all segments.  This then&lt;br/&gt;
causes merge policy to think all segments are about the same size&lt;br/&gt;
(since the doc stores grow very large).&lt;/p&gt;

&lt;p&gt;I&apos;ll open a new issue &amp;amp; fix it.  Thanks for testing Mark &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="12531270" author="markrmiller@gmail.com" created="Sat, 29 Sep 2007 20:51:59 +0100"  >&lt;p&gt;Anytime Michael. Thanks for pointing out the mergefactor issue to me. I recently retrofitted my indexer with google guice, and it seems that something is not working as expected. Glad this little debug session worked out for all &amp;lt;g&amp;gt; &lt;/p&gt;

&lt;p&gt;Can&apos;t thank you enough for all of your Lucene patches. Keep em coming!&lt;/p&gt;</comment>
                    <comment id="12531271" author="mikemccand" created="Sat, 29 Sep 2007 20:58:26 +0100"  >&lt;p&gt;Marking this as fixed again; I opened &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1009&quot; title=&quot;LogByteSizeMergePolicy over-merges with autoCommit=false and documents with term vectors and/or stored fields&quot;&gt;&lt;del&gt;LUCENE-1009&lt;/del&gt;&lt;/a&gt; for the slowdown in merging.&lt;/p&gt;</comment>
                    <comment id="12531273" author="mikemccand" created="Sat, 29 Sep 2007 21:07:27 +0100"  >&lt;p&gt;&amp;gt; Anytime Michael. Thanks for pointing out the mergefactor issue to&lt;br/&gt;
&amp;gt; me. I recently retrofitted my indexer with google guice, and it&lt;br/&gt;
&amp;gt; seems that something is not working as expected. Glad this little&lt;br/&gt;
&amp;gt; debug session worked out for all &amp;lt;g&amp;gt;&lt;/p&gt;

&lt;p&gt;Sure!  Make sure you also fix your flushing to actually flush at 42 MB&lt;br/&gt;
RAM buffer (things should go MUCH faster with that &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;.&lt;/p&gt;

&lt;p&gt;&amp;gt; Can&apos;t thank you enough for all of your Lucene patches. Keep em&lt;br/&gt;
&amp;gt; coming!&lt;/p&gt;

&lt;p&gt;You&apos;re welcome!  I enjoy it &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="12531388" author="yseeley@gmail.com" created="Sun, 30 Sep 2007 23:02:12 +0100"  >&lt;p&gt;While trying Solr with the latest Lucene, I ran into this back-incompatibility:&lt;br/&gt;
Caused by: java.lang.IllegalArgumentException: this method can only be called when the merge policy is LogDocMergePolicy&lt;br/&gt;
	at org.apache.lucene.index.IndexWriter.getLogDocMergePolicy(IndexWriter.java:316)&lt;br/&gt;
	at org.apache.lucene.index.IndexWriter.setMaxMergeDocs(IndexWriter.java:768)&lt;/p&gt;


&lt;p&gt;It&apos;s not an issue at all for Solr - we&apos;ll fix things up when we officially upgrade Lucene versions, but it does seem like it might affect a number of apps that try and just drop in a new lucene jar.  Thoughts?&lt;/p&gt;</comment>
                    <comment id="12531390" author="markrmiller@gmail.com" created="Sun, 30 Sep 2007 23:35:52 +0100"  >&lt;p&gt;It was my impression that this Lucene release would be unusual in that you shouldn&apos;t just drop the jar without first making sure you are in compliance with the new changes? Since some apps are going to break no matter what (few they may be) perhaps you just make a big fuss about possible incompatible changes?&lt;/p&gt;</comment>
                    <comment id="12531433" author="mikemccand" created="Mon, 1 Oct 2007 08:57:20 +0100"  >
&lt;p&gt;&amp;gt; While trying Solr with the latest Lucene, I ran into this back-incompatibility:&lt;br/&gt;
&amp;gt; Caused by: java.lang.IllegalArgumentException: this method can only be called when the merge policy is LogDocMergePolicy&lt;br/&gt;
&amp;gt; at org.apache.lucene.index.IndexWriter.getLogDocMergePolicy(IndexWriter.java:316)&lt;br/&gt;
&amp;gt; at org.apache.lucene.index.IndexWriter.setMaxMergeDocs(IndexWriter.java:768)&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; It&apos;s not an issue at all for Solr - we&apos;ll fix things up when we&lt;br/&gt;
&amp;gt; officially upgrade Lucene versions, but it does seem like it might&lt;br/&gt;
&amp;gt; affect a number of apps that try and just drop in a new lucene&lt;br/&gt;
&amp;gt; jar. Thoughts?&lt;/p&gt;

&lt;p&gt;Hmm, good catch.&lt;/p&gt;

&lt;p&gt;This should only happen when &quot;setMaxMergeDocs&quot; is called (this is the&lt;br/&gt;
only method that requires a LogDocMergePolicy).  I think we have&lt;br/&gt;
various options:&lt;/p&gt;

&lt;p&gt;  1. Leave things as is and put up-front comment in the release saying&lt;br/&gt;
     you could either switch to LogDocMergePolicy, or, use&lt;br/&gt;
     &quot;setMaxMergeMB&quot; on the default LogByteSizeMergePolicy, instead.&lt;br/&gt;
     Also put details in the javadocs for this method explaining these&lt;br/&gt;
     options.&lt;/p&gt;

&lt;p&gt;  2. Switch back to LogDocMergePolicy by default &quot;out of the box&quot;.&lt;/p&gt;

&lt;p&gt;  3. If setMaxMergeDocs() is called, switch back to LogDocMergePolicy&lt;br/&gt;
     &quot;on-demand&quot;.&lt;/p&gt;

&lt;p&gt;  4. Modify LogByteSizeMergePolicy to in fact accept both&lt;br/&gt;
     &quot;maxMergeDocs&quot; or &quot;maxMergeMB&quot;, allowing either one or both just&lt;br/&gt;
     like &quot;flush by RAM&quot; and/or &quot;flush by doc count&quot; is being done in&lt;br/&gt;
     &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1007&quot; title=&quot;Flexibility to turn on/off any flush triggers&quot;&gt;&lt;del&gt;LUCENE-1007&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I think I like option 4 the best.  3 seems to magical (violates&lt;br/&gt;
&quot;principle of least surprise&quot;).  2 I think is bad because it&apos;s best to&lt;br/&gt;
match the merge policy with how we are flushing (by RAM by default).&lt;br/&gt;
1 is clearly disruptive to people who want to drop Lucene JAR in and&lt;br/&gt;
test.&lt;/p&gt;

&lt;p&gt;I&apos;ll open a new issue.  Thanks Yonik!&lt;/p&gt;</comment>
                    <comment id="12531434" author="mikemccand" created="Mon, 1 Oct 2007 09:01:10 +0100"  >
&lt;p&gt;&amp;gt; It was my impression that this Lucene release would be unusual in&lt;br/&gt;
&amp;gt; that you shouldn&apos;t just drop the jar without first making sure you&lt;br/&gt;
&amp;gt; are in compliance with the new changes? Since some apps are going to&lt;br/&gt;
&amp;gt; break no matter what (few they may be) perhaps you just make a big&lt;br/&gt;
&amp;gt; fuss about possible incompatible changes?&lt;/p&gt;

&lt;p&gt;I &lt;b&gt;think&lt;/b&gt; this release should in fact &quot;drop in&quot; for most apps.  The&lt;br/&gt;
only known case where there is non-backwards compatibility (besides&lt;br/&gt;
this setMaxMergeDocs issue) is users of ParallelReader, I think?  I&lt;br/&gt;
think Lucene 3.0 is when we are &quot;allowed&quot; to remove deprecated APIs,&lt;br/&gt;
switch to Java 1.5, etc.&lt;/p&gt;</comment>
                    <comment id="12531623" author="hossman" created="Mon, 1 Oct 2007 21:31:23 +0100"  >&lt;p&gt;lucene&apos;s &quot;commitment&quot; to backward compatibility requires that 2.X be API compatible with all previous 2.Y releases...&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://wiki.apache.org/jakarta-lucene/BackwardsCompatibility&quot; class=&quot;external-link&quot;&gt;http://wiki.apache.org/jakarta-lucene/BackwardsCompatibility&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;...the performance characteristics and file formats (and merge behavior) doesn&apos;t need to be exactly the same (so switching the Merge Policy should be fine) as long as a note is made about this in the &quot;run time behavior&quot; section of CHANGES.txt (we already have one) ... but any code that could compile and run against 2.2 should still run against 2.3 ... it might be really slow without some minor tweaks, and it might violate &quot;principle of least surprise&quot; but it&apos;s important that it still run so that people don&apos;t have to fear a minor version upgrade.&lt;/p&gt;

&lt;p&gt;if we can&apos;t provide that &amp;#8211; then the release should be called 3.0, but i haven&apos;t seen anything that least  me to think it&apos;s not possible.  (it just might not be pretty)&lt;/p&gt;</comment>
                    <comment id="12537668" author="markrmiller@gmail.com" created="Thu, 25 Oct 2007 18:48:49 +0100"  >&lt;p&gt;Quick question due to a new issue I am seeing in my application...could the concurrent merge possibly break apps that add a doc and then expect to be able to find it &lt;b&gt;immediately&lt;/b&gt; after? I suspect this is not the case, just wondering based on some odd new behavior I am seeing. For example, if you call adddoc and it triggers a background merge, the doc is still immediately  visible to the next call from the same thread right? No possibility for a race?&lt;/p&gt;</comment>
                    <comment id="12537670" author="yseeley@gmail.com" created="Thu, 25 Oct 2007 18:56:14 +0100"  >&lt;blockquote&gt;
&lt;p&gt;For example, if you call adddoc and it triggers a background merge, the doc is still immediately visible&lt;br/&gt;
to the next call from the same thread right?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&quot;visible&quot; by opening a new reader you mean?&lt;br/&gt;
I don&apos;t think so... this was never a guarantee (although it might have been normally true in the past), and concurrent merge breaks this.&lt;br/&gt;
So does autocommit=false.&lt;/p&gt;</comment>
                    <comment id="12537673" author="markrmiller@gmail.com" created="Thu, 25 Oct 2007 19:06:50 +0100"  >&lt;p&gt;Well that would explain a lot then. I use both the concurrent merge and autocommit=false, where in the past I did not. Before that I certainly did seem to be able to count on it, as long as it was sequential in the same thread. I never &lt;b&gt;wanted&lt;/b&gt; to count on it, but when other developers start using your libraries in ways you never intended or okay&apos;d...so much for ever warming searchers.&lt;/p&gt;

&lt;p&gt;Isn&apos;t this a problem for certain unit tests? After adding a bunch of docs and then searching to see if they are there must you pause for a bit to make sure enough ms have passed?&lt;/p&gt;</comment>
                    <comment id="12537678" author="yseeley@gmail.com" created="Thu, 25 Oct 2007 19:16:12 +0100"  >&lt;p&gt;Yes, I guess one could consider it a minor breakage.&lt;br/&gt;
maxBufferedDocs previously ensured that changes were flushed every &quot;n&quot; docs.  They were flushed in a visible way, and I don&apos;t recall anything saying that one shouldn&apos;t open a reader before the writer was closed.&lt;/p&gt;</comment>
                    <comment id="12537688" author="markrmiller@gmail.com" created="Thu, 25 Oct 2007 19:25:57 +0100"  >&lt;p&gt;Sorry Yonik...I was not being explicit enough &amp;#8211; I &lt;b&gt;am&lt;/b&gt; closing the Writer before opening the Reader. Which is why I assumed I could count on this behavior. Semi randomly it is failing in my app now though. I am not positive it is due to Lucene, I just thought that maybe the concurrent merge was somehow not adding the document before triggering the merge in a background thread? Perhaps you dont see the doc till the background threads are done merging? Just looking for someone to tell me, no, even with concurrent merge, as long as you close the writer and then open a new reader, you are guaranteed to find the doc just added (if all from the same thread). I really do assume this is the case, I just have not changed anything else other than updating Lucene, so I am grasping at some straws...&lt;/p&gt;</comment>
                    <comment id="12537691" author="mikemccand" created="Thu, 25 Oct 2007 19:32:06 +0100"  >&lt;p&gt;When you close the writer &amp;amp; open a reader, the reader should see all&lt;br/&gt;
docs added, regardless of whether the writer was using concurrent&lt;br/&gt;
merge scheduler or serial merge scheduler, autoCommit true or false,&lt;br/&gt;
flushing by ram or by doc count, etc.&lt;/p&gt;

&lt;p&gt;IndexWriter.close() first flushes any buffered docs to a new segment,&lt;br/&gt;
and then allows merges to run if they are necessary.  It will also&lt;br/&gt;
wait for all merges to finish (in the case of concurrent merge&lt;br/&gt;
scheduler) unless you call close(false) which will abort all running&lt;br/&gt;
merges.&lt;/p&gt;

&lt;p&gt;If you&apos;re not seeing this behavior then something is seriously wrong!&lt;br/&gt;
Can you post some more details about how you see this intermittant&lt;br/&gt;
failure?&lt;/p&gt;</comment>
                    <comment id="12537692" author="cutting" created="Thu, 25 Oct 2007 19:32:32 +0100"  >&lt;p&gt;&amp;gt; After adding a bunch of docs and then searching to see if they are there must you pause for a bit to make sure enough ms have passed?&lt;/p&gt;

&lt;p&gt;No.  You could previously never rely on a newly added being visible to search until you called IndexWriter#close().  Added documents have always been buffered and all buffers were only flushed by IndexWriter#close().  It used to be the case that the buffer was memory-only and a fixed number of documents.  So the last up to MaxBufferedDocs added would not yet be visible.&lt;/p&gt;

&lt;p&gt;Now there is an IndexWriter#flush() method that flushes buffers without closing the IndexWriter.  And with the &quot;autocommit=false&quot; feature, nothing is visible to searchers until either #close() or #flush() is called.  The primary change of concurrent merging is that calls to addDocument() generally return faster, with merging work done in the background, but concurrent merging and &quot;autocommit=false&quot; don&apos;t fundamentally change the need to call #close() or #flush() in order to guarantee that all changes are visible to searchers.&lt;/p&gt;

&lt;p&gt;At least that&apos;s my understanding...&lt;/p&gt;</comment>
                    <comment id="12537696" author="markrmiller@gmail.com" created="Thu, 25 Oct 2007 19:42:23 +0100"  >&lt;p&gt;Based on the responses I am going to assume the problem is not with Lucene or concurrent merge. I have to figure it out though, so if I can determine otherwise, you&apos;ll be the first to know. Gotto assume its me first though.&lt;/p&gt;</comment>
                    <comment id="12537702" author="mikemccand" created="Thu, 25 Oct 2007 20:06:57 +0100"  >
&lt;blockquote&gt;
&lt;p&gt;Based on the responses I am going to assume the problem is not with Lucene or concurrent merge. I have to figure it out though, so if I can determine otherwise, you&apos;ll be the first to know. Gotto assume its me first though.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I sure hope you&apos;re right!  Keep us posted...&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;No.  You could previously never rely on a newly added being visible to search until you called IndexWriter#close().  Added documents have always been buffered and all buffers were only flushed by IndexWriter#close().  It used to be the case that the buffer was memory-only and a fixed number of documents.  So the last up to MaxBufferedDocs added would not yet be visible.&lt;/p&gt;

&lt;p&gt;Now there is an IndexWriter#flush() method that flushes buffers without closing the IndexWriter.  And with the &quot;autocommit=false&quot; feature, nothing is visible to searchers until either #close() or #flush() is called.  The primary change of concurrent merging is that calls to addDocument() generally return faster, with merging work done in the background, but concurrent merging and &quot;autocommit=false&quot; don&apos;t fundamentally change the need to call #close() or #flush() in order to guarantee that all changes are visible to searchers.&lt;/p&gt;

&lt;p&gt;At least that&apos;s my understanding...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This is my understanding too, except calling flush() with&lt;br/&gt;
autoCommit=false does not actually make the changes visible to readers&lt;br/&gt;
(though it does flush buffered added/deleted docs to the Directory).&lt;br/&gt;
Only close() will make all changes visible to readers when&lt;br/&gt;
autoCommit=false.&lt;/p&gt;</comment>
                </comments>
                    <attachments>
                    <attachment id="12366234" name="LUCENE-994.patch" size="21879" author="mikemccand" created="Wed, 19 Sep 2007 22:42:35 +0100" />
                    <attachment id="12366802" name="writerinfo.zip" size="832665" author="markrmiller@gmail.com" created="Sat, 29 Sep 2007 18:12:49 +0100" />
                </attachments>
            <subtasks>
        </subtasks>
                <customfields>
                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                <customfieldname>Attachment count</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>2.0</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                <customfieldname>Date of First Response</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>Tue, 25 Sep 2007 22:52:33 +0000</customfieldvalue>

                </customfieldvalues>
            </customfield>
                                                                                                        <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Global Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>12750</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                <customfieldname>Lucene Fields</customfieldname>
                <customfieldvalues>
                        <customfieldvalue key="10121"><![CDATA[New]]></customfieldvalue>
    
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>26735</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                <customfieldname>Time in Status</customfieldname>
                <customfieldvalues>
                    
                </customfieldvalues>
            </customfield>
                            </customfields>
    </item>
</channel>
</rss>