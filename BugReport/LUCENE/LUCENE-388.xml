<!-- 
RSS generated by JIRA (5.2.8#851-sha1:3262fdc28b4bc8b23784e13eadc26a22399f5d88) at Tue Jul 16 13:29:57 UTC 2013

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/LUCENE-388/LUCENE-388.xml?field=key&field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>5.2.8</version>
        <build-number>851</build-number>
        <build-date>26-02-2013</build-date>
    </build-info>

<item>
            <title>[LUCENE-388] [PATCH] IndexWriter.maybeMergeSegments() takes lots of CPU resources</title>
                <link>https://issues.apache.org/jira/browse/LUCENE-388</link>
                <project id="12310110" key="LUCENE">Lucene - Core</project>
                        <description>&lt;p&gt;Note: I believe this to be the same situation with 1.4.3 as with SVN HEAD.&lt;/p&gt;

&lt;p&gt;Analysis using hprof utility shows that during index creation with many&lt;br/&gt;
documents highlights that the CPU spends a large portion of it&apos;s time in&lt;br/&gt;
IndexWriter.maybeMergeSegments(), which seems to be a &apos;waste&apos; compared with&lt;br/&gt;
other valuable CPU intensive operations such as tokenization etc.&lt;/p&gt;

&lt;p&gt;Using the following test snippet to retrieve some rows from the db and create an&lt;br/&gt;
index:&lt;/p&gt;

&lt;p&gt;        Analyzer a = new StandardAnalyzer();&lt;br/&gt;
        writer = new IndexWriter(indexDir, a, true);&lt;br/&gt;
        writer.setMergeFactor(1000);&lt;br/&gt;
        writer.setMaxBufferedDocs(10000);&lt;br/&gt;
        writer.setUseCompoundFile(false);&lt;br/&gt;
        connection = DriverManager.getConnection(&lt;br/&gt;
                &quot;jdbc:inetdae7:tower.aconex.com?database=&amp;lt;somedb&amp;gt;&quot;, &quot;secret&quot;,&lt;br/&gt;
                &quot;squirrel&quot;);&lt;br/&gt;
        String sql = &quot;select userid, userfirstname, userlastname, email from userx&quot;;&lt;br/&gt;
        LOG.info(&quot;sql=&quot; + sql);&lt;br/&gt;
        Statement statement = connection.createStatement();&lt;br/&gt;
        statement.setFetchSize(5000);&lt;br/&gt;
        LOG.info(&quot;Executing sql&quot;);&lt;br/&gt;
        ResultSet rs = statement.executeQuery(sql);&lt;br/&gt;
        LOG.info(&quot;ResultSet retrieved&quot;);&lt;br/&gt;
        int row = 0;&lt;/p&gt;

&lt;p&gt;        LOG.info(&quot;Indexing users&quot;);&lt;br/&gt;
        long begin = System.currentTimeMillis();&lt;br/&gt;
        while (rs.next()) {&lt;br/&gt;
            int userid = rs.getInt(1);&lt;br/&gt;
            String firstname = rs.getString(2);&lt;br/&gt;
            String lastname = rs.getString(3);&lt;br/&gt;
            String email = rs.getString(4);&lt;br/&gt;
            String fullName = firstname + &quot; &quot; + lastname;&lt;br/&gt;
            Document doc = new Document();&lt;br/&gt;
            doc.add(Field.Keyword(&quot;userid&quot;, userid+&quot;&quot;));&lt;br/&gt;
            doc.add(Field.Keyword(&quot;firstname&quot;, firstname.toLowerCase()));&lt;br/&gt;
            doc.add(Field.Keyword(&quot;lastname&quot;, lastname.toLowerCase()));&lt;br/&gt;
            doc.add(Field.Text(&quot;name&quot;, fullName.toLowerCase()));&lt;br/&gt;
            doc.add(Field.Keyword(&quot;email&quot;, email.toLowerCase()));&lt;br/&gt;
            writer.addDocument(doc);&lt;br/&gt;
            row++;&lt;br/&gt;
            if((row % 100)==0)&lt;/p&gt;
{
                LOG.info(row + &quot; indexed&quot;);
            }
&lt;p&gt;        }&lt;br/&gt;
        double end = System.currentTimeMillis();&lt;br/&gt;
        double diff = (end-begin)/1000;&lt;br/&gt;
        double rate = row/diff;&lt;br/&gt;
        LOG.info(&quot;rate:&quot; +rate);&lt;/p&gt;

&lt;p&gt;On my 1.5GHz PowerBook with 1.5Gb RAM and a 5400 RPM drive, my CPU is maxed out,&lt;br/&gt;
and I end up getting a rate of indexing between 490-515 documents/second run&lt;br/&gt;
over 10 times in succession.  &lt;/p&gt;

&lt;p&gt;By applying a simple patch to IndexWriter (see attached shortly), which defers&lt;br/&gt;
the calling of maybeMergeSegments() so that it is only called every 2000&lt;br/&gt;
times(an arbitrary figure), I appear to get a new rate of between 945-970&lt;br/&gt;
documents/second.  Using Luke to look inside each index created between these 2&lt;br/&gt;
there does not appear to be any difference.  Same number of Documents, same&lt;br/&gt;
number of Terms.&lt;/p&gt;

&lt;p&gt;I&apos;m not suggesting one should apply this patch, I&apos;m just highlighting the&lt;br/&gt;
difference in performance that this sort of change gives you.  &lt;/p&gt;

&lt;p&gt;We are about to use Lucene to index 4 million construction document records, and&lt;br/&gt;
so speeding up the indexing process is in our best interest! &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  If one&lt;br/&gt;
considers the amount of CPU time spent in maybeMergeSegments over the initial&lt;br/&gt;
index creation of 4 million documents, I think one could see how it would be&lt;br/&gt;
ideal to try to speed this area up (at least move the bottleneck to IO). &lt;/p&gt;

&lt;p&gt;I woul appreciate anyone taking a moment to comment on this.&lt;/p&gt;</description>
                <environment>&lt;p&gt;Operating System: Mac OS X 10.3&lt;br/&gt;
Platform: Macintosh&lt;/p&gt;</environment>
            <key id="12314538">LUCENE-388</key>
            <summary>[PATCH] IndexWriter.maybeMergeSegments() takes lots of CPU resources</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                    <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png">Closed</status>
                    <resolution id="1">Fixed</resolution>
                                <assignee username="yseeley@gmail.com">Yonik Seeley</assignee>
                                <reporter username="psmith@apache.org">Paul Smith</reporter>
                        <labels>
                    </labels>
                <created>Mon, 16 May 2005 17:18:21 +0100</created>
                <updated>Fri, 10 May 2013 11:44:20 +0100</updated>
                    <resolved>Thu, 17 Aug 2006 03:54:42 +0100</resolved>
                                            <fixVersion>2.1</fixVersion>
                                <component>core/index</component>
                        <due></due>
                    <votes>2</votes>
                        <watches>3</watches>
                                                    <comments>
                    <comment id="12322373" author="psmith@apache.org" created="Mon, 16 May 2005 17:19:32 +0100"  >&lt;p&gt;Created an attachment (id=15042)&lt;br/&gt;
HPROF log of test run pre-patch&lt;/p&gt;

&lt;p&gt;Added HPROF log showing high CPU usage inside IndexWriter.maybeMergeSegments()&lt;br/&gt;
method&lt;/p&gt;</comment>
                    <comment id="12322374" author="psmith@apache.org" created="Mon, 16 May 2005 17:20:26 +0100"  >&lt;p&gt;Created an attachment (id=15043)&lt;br/&gt;
Demonstration Patch to defer the call to IndexWriter.maybeMergeSegments() for&lt;br/&gt;
every 2000 times.&lt;/p&gt;</comment>
                    <comment id="12322375" author="daniel.naber@t-online.de" created="Mon, 16 May 2005 20:22:41 +0100"  >&lt;p&gt;Isn&apos;t the effect the same as setting mergeFactor to 2000, i.e. indexing gets  &lt;br/&gt;
faster but more RAM is needed?  &lt;/p&gt;
</comment>
                    <comment id="12322376" author="yseeley@gmail.com" created="Tue, 17 May 2005 02:11:27 +0100"  >&lt;p&gt;(In reply to comment #3)&lt;br/&gt;
&amp;gt; Isn&apos;t the effect the same as setting mergeFactor to 2000, i.e. indexing gets  &lt;br/&gt;
&amp;gt; faster but more RAM is needed?  &lt;/p&gt;

&lt;p&gt;On every add, it looks like the entire segment list is walked looking to see of&lt;br/&gt;
enough docs (minMergeDocs) can be collected together to do a merge.  With a&lt;br/&gt;
large minMergeDocs, this can get expensive.  Perhaps a count should be kept of&lt;br/&gt;
the number of docs in memory, and when it exceeds minMergeDocs, then call the&lt;br/&gt;
merge logic.&lt;/p&gt;

&lt;p&gt;Of course keeping track of the count would require modifications to many&lt;br/&gt;
IndexWriter methods. It looks like the performance gains may well be worth it&lt;br/&gt;
though.&lt;/p&gt;

&lt;p&gt;BTW, I don&apos;t think a mergefactor of 1000 is typical (way too many&lt;br/&gt;
filedescriptors in use, and a big hit to searchers).  A high minMergeDocs (now&lt;br/&gt;
maxBufferedDocs) &lt;b&gt;is&lt;/b&gt; typical and useful though.&lt;/p&gt;
</comment>
                    <comment id="12322377" author="cutting@apache.org" created="Tue, 17 May 2005 03:17:00 +0100"  >&lt;p&gt;Your benchmark might run faster if you set maxBufferedDocs smaller.  Also, it&lt;br/&gt;
doesn&apos;t look like you&apos;re including the cost of closing the IndexWriter in your&lt;br/&gt;
benchmark statistics.  You should, as, with such a large buffer, you&apos;ve delayed&lt;br/&gt;
much of the work to that point.&lt;/p&gt;

&lt;p&gt;The bottleneck you&apos;re hitting is that maybeMergeDocs sums the size of the&lt;br/&gt;
buffered indexes each time to decide whether to merge.  When you have thousands&lt;br/&gt;
buffered, this dominates.&lt;/p&gt;

&lt;p&gt;To optimize this case (small docs, large maxBufferedDocs) we could keep count of&lt;br/&gt;
the number of documents buffered by adding a bufferedDocCount field. &lt;br/&gt;
addDocument could increment this, mergeSegments could decrement it, and&lt;br/&gt;
maybeMergeSegments could check it with something like:&lt;/p&gt;

&lt;p&gt;if (targetMergeDocs == minMergeDocs)  {&lt;br/&gt;
  mergeDocs = bufferedDocCount;&lt;br/&gt;
} else {&lt;br/&gt;
  while (--minSegment &amp;gt;= 0) &lt;/p&gt;
{
  ...
  }
&lt;p&gt;}&lt;/p&gt;

&lt;p&gt;Does that make sense?&lt;/p&gt;</comment>
                    <comment id="12322378" author="psmith@apache.org" created="Tue, 17 May 2005 08:53:10 +0100"  >&lt;p&gt;&amp;gt;&amp;gt; Your benchmark might run faster if you set maxBufferedDocs smaller.  Also, it&lt;br/&gt;
&amp;gt;&amp;gt; doesn&apos;t look like you&apos;re including the cost of closing the IndexWriter in your&lt;br/&gt;
&amp;gt;&amp;gt; benchmark statistics.  You should, as, with such a large buffer, you&apos;ve delayed&lt;br/&gt;
&amp;gt;&amp;gt; much of the work to that point.&lt;br/&gt;
&amp;gt;&amp;gt; &lt;/p&gt;

&lt;p&gt;Yes, by not factoring in the optmize()/close() call into the rate calculation,&lt;br/&gt;
there is still &apos;work to be done&apos; at the end, but that would only be the tail end&lt;br/&gt;
of the remaining docs stored in memory, right?  When indexing millions of&lt;br/&gt;
records, this is probably not going to be a large percentage of the overall&lt;br/&gt;
time, as it would only, at most, the last maxBufferedDocs to be tidied up.  Or&lt;br/&gt;
have I confused myself?  I&apos;m still quite new to Lucene and it&apos;s inner workings.  &lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt; The bottleneck you&apos;re hitting is that maybeMergeDocs sums the size of the&lt;br/&gt;
&amp;gt;&amp;gt; buffered indexes each time to decide whether to merge.  When you have thousands&lt;br/&gt;
&amp;gt;&amp;gt; buffered, this dominates.&lt;/p&gt;

&lt;p&gt;Yes, when maxBufferedDocs is relatively high (which is useful, I thought, if you&lt;br/&gt;
have the memory to throw at the application and one is trying to stay off IO as&lt;br/&gt;
much as possible, that&apos;s what I&apos;ve understood anyway) the loop ends up something&lt;br/&gt;
like this, where N is maxBufferedDocs&lt;/p&gt;

&lt;p&gt;n + (n-1)+(n-2) + ....(n-n)&lt;/p&gt;

&lt;p&gt;(I&apos;m no math wiz, sorry)&lt;br/&gt;
You can notice this when indexing and outputing logging information, you see the&lt;br/&gt;
&apos;rate&apos; slow down slightly as the number of docs is added to the in memory&lt;br/&gt;
buffer, then once the automatic merge is performed, the rate speeds up, then&lt;br/&gt;
progressively slows down again.&lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt; &lt;br/&gt;
&amp;gt;&amp;gt; To optimize this case (small docs, large maxBufferedDocs) we could keep count of&lt;br/&gt;
&amp;gt;&amp;gt; the number of documents buffered by adding a bufferedDocCount field. &lt;br/&gt;
&amp;gt;&amp;gt; addDocument could increment this, mergeSegments could decrement it, and&lt;br/&gt;
&amp;gt;&amp;gt; maybeMergeSegments could check it with something like:&lt;br/&gt;
&amp;gt;&amp;gt; &lt;br/&gt;
&amp;gt;&amp;gt; if (targetMergeDocs == minMergeDocs)  &lt;/p&gt;
{
&amp;gt;&amp;gt;   mergeDocs = bufferedDocCount;
&amp;gt;&amp;gt; }
&lt;p&gt; else {&lt;br/&gt;
&amp;gt;&amp;gt;   while (--minSegment &amp;gt;= 0) &lt;/p&gt;
{
&amp;gt;&amp;gt;   ...
&amp;gt;&amp;gt;   }
&lt;p&gt;&amp;gt;&amp;gt; }&lt;br/&gt;
&amp;gt;&amp;gt; &lt;br/&gt;
&amp;gt;&amp;gt; Does that make sense?&lt;/p&gt;

&lt;p&gt;Err, to be honest I&apos;m not quite sure what you mean by &quot;small docs&quot; in the above&lt;br/&gt;
first statement.  I&apos;m also a little confused on the:&lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt; if (targetMergeDocs == minMergeDocs)  {&lt;/p&gt;

&lt;p&gt;and how it relates to the bufferedDocCount you mention.  &lt;/p&gt;

&lt;p&gt;In my hack/patch I&apos;m effectively keeping track of the number of documents added&lt;br/&gt;
as you suggest, so I believe we&apos;re pretty close to the same thing, but I blame&lt;br/&gt;
only having one coffee on trying to understand it.  &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  I think I like where you&lt;br/&gt;
going though, it smells right.&lt;/p&gt;

&lt;p&gt;Something I thought about last night is that the current code works fine for all&lt;br/&gt;
cases, however the &apos;clean index being rebuilt&apos; seems to get the raw end of the&lt;br/&gt;
stick.  When an index is being incrementally or batch updated, IndexWriter&lt;br/&gt;
probably does need to scan the Segments to see if they need merging to obey the&lt;br/&gt;
configuration settings.  However a fresh index is a special case, and seems like&lt;br/&gt;
it could be optimized (this may be what you meant by &apos;small docs&apos; ?).  &lt;/p&gt;

&lt;p&gt;In really large scale indexes/indices&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/help_16.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; the number of documents being&lt;br/&gt;
incrementally/batch updated is going to be totally minor compared to the cost of&lt;br/&gt;
building the full index for the first time.  For a true High Availability&lt;br/&gt;
solution, one will always need to factor in the cost to rebuild the index from&lt;br/&gt;
scratch should it come to that.  Making the initial index as fast as possible&lt;br/&gt;
gives much smaller down time.  &lt;/p&gt;

&lt;p&gt;For crawling applications that use Lucene, this optimization will probably not&lt;br/&gt;
even get noticed, because of the latency in retrieving the source material to&lt;br/&gt;
make up the document.  Only when the source material can be accessed fast will&lt;br/&gt;
this optimization be important.&lt;/p&gt;

&lt;p&gt;Removing this CPU bottleneck has even more benefits when you consider those&lt;br/&gt;
solutions using Lucene to parallel index documents.  This optimization means&lt;br/&gt;
that you get a multiplication of benefit the more CPU&apos;s being utilized,&lt;br/&gt;
particularly if the architecture is a producer/consumer operation with a Buffer&lt;br/&gt;
in between. (obviously IO starts to get in the way more).  With an optimization&lt;br/&gt;
the CPU can be better utilized performing tokenization etc.&lt;/p&gt;

&lt;p&gt;cheers,&lt;/p&gt;

&lt;p&gt;Paul&lt;/p&gt;</comment>
                    <comment id="12322379" author="psmith@apache.org" created="Tue, 17 May 2005 12:19:56 +0100"  >&lt;p&gt;Doug, after more testing, you are correct that tweaking the maxBuffered from&lt;br/&gt;
10,000 to 5000 gives slightly better performance.&lt;/p&gt;

&lt;p&gt;However I believe this is because with maxBufferedDocs==5000, this loop counter&lt;br/&gt;
is reset more frequently, and so suffers less of the CPU drain.  &lt;/p&gt;

&lt;p&gt;I ran more tests using the hacked version using both 5000 and 10000, and the&lt;br/&gt;
hacked version still runs better.  I&apos;ll attach an Excel sheet with the results,&lt;br/&gt;
but I only had time to run it over 5 samples each run, which is not exactly&lt;br/&gt;
statistically significant, but hopefully still correct.&lt;/p&gt;

&lt;p&gt;As you can see, deferring this loop enables larger maxBuffered to gain ahead of&lt;br/&gt;
smaller maxBufferedDocs.&lt;/p&gt;

&lt;p&gt;As always with these tests there are transient factors that affect things&lt;br/&gt;
(getting DB results for one thing).&lt;/p&gt;</comment>
                    <comment id="12322380" author="psmith@apache.org" created="Tue, 17 May 2005 12:21:30 +0100"  >&lt;p&gt;Created an attachment (id=15053)&lt;br/&gt;
Excel file containg results over small samples between Hacked and Non-hacked&lt;br/&gt;
code using different maxBufferedDocs settings&lt;/p&gt;

&lt;p&gt;Attached Excel file with some results&lt;/p&gt;</comment>
                    <comment id="12322381" author="psmith@apache.org" created="Tue, 24 May 2005 13:59:58 +0100"  >&lt;p&gt;Created an attachment (id=15137)&lt;br/&gt;
Patch that hopefully is what Doug means&lt;/p&gt;

&lt;p&gt;Doug,&lt;/p&gt;

&lt;p&gt;I could not resolve in my mind exactly what you meant in your example code&lt;br/&gt;
snippet, but here&apos;s a patch that I believe accomplishes the same thing.  It&apos;s&lt;br/&gt;
merely a renaming of the variable, and using the &apos;mergeSegement decrements&apos;&lt;br/&gt;
concept that you mention which I think is a good idea.&lt;/p&gt;

&lt;p&gt;This patch still doesn&apos;t speed up the actual detecting of what segments on the&lt;br/&gt;
stack to merge when it does go into that loop.	I need to re-baseline the&lt;br/&gt;
performance measurements with this patch to see where the CPU is now spending&lt;br/&gt;
most of it&apos;s time, as it it may now be somewhere else entirely.&lt;/p&gt;

&lt;p&gt;NOTE: all current unit tests still pass with this patch.&lt;/p&gt;</comment>
                    <comment id="12322382" author="psmith@apache.org" created="Tue, 24 May 2005 15:43:05 +0100"  >&lt;p&gt;Created an attachment (id=15139)&lt;br/&gt;
HPROF output of the same test with the patch applied&lt;/p&gt;

&lt;p&gt;This HPROF shows the CPU savings of the patch.&lt;/p&gt;

&lt;p&gt;In summary, the original was this:&lt;/p&gt;

&lt;p&gt;   1 24.14% 24.14%     859 300342&lt;br/&gt;
org.apache.lucene.index.IndexWriter.maybeMergeSegments&lt;br/&gt;
   2  4.83% 28.97%     172 300306 java.lang.Throwable.fillInStackTrace&lt;br/&gt;
   3  4.07% 33.04%     145 300336 org.apache.lucene.index.SegmentInfos.info&lt;br/&gt;
   4  2.50% 35.54%	89 300505&lt;br/&gt;
org.apache.lucene.store.RAMInputStream.readInternal&lt;br/&gt;
   5  2.33% 37.88%	83 300299 java.util.Vector.addElement&lt;br/&gt;
   6  2.16% 40.04%	77 300334 org.apache.lucene.document.Field.readerValue&lt;br/&gt;
   7  2.14% 42.17%	76 300272 java.net.SocketInputStream.socketRead0&lt;br/&gt;
   8  1.40% 43.58%	50 300598 org.apache.lucene.util.PriorityQueue.downHeap&lt;/p&gt;

&lt;p&gt;   9  1.15% 44.73%	41 300617 org.apache.lucene.util.PriorityQueue.downHeap&lt;/p&gt;

&lt;p&gt;  10  1.01% 45.74%	36 300581 java.io.RandomAccessFile.writeBytes&lt;br/&gt;
.....&lt;/p&gt;

&lt;p&gt;And after the patch is applied it becomes:&lt;/p&gt;

&lt;p&gt;   1  5.45%  5.45%     130 300287 java.lang.Throwable.fillInStackTrace&lt;br/&gt;
   2  5.20% 10.65%     124 300277 java.net.SocketInputStream.socketRead0&lt;br/&gt;
   3  3.86% 14.51%	92 300515&lt;br/&gt;
org.apache.lucene.store.RAMInputStream.readInternal&lt;br/&gt;
   4  3.27% 17.79%	78 300332 java.util.Vector.addElement&lt;br/&gt;
   5  2.35% 20.13%	56 300548 java.io.RandomAccessFile.writeBytes&lt;br/&gt;
   6  2.22% 22.36%	53 300305 org.apache.lucene.document.Field.readerValue&lt;br/&gt;
   7  1.85% 24.20%	44 300595 org.apache.lucene.util.PriorityQueue.downHeap&lt;/p&gt;

&lt;p&gt;   8  1.72% 25.92%	41 300580 org.apache.lucene.util.PriorityQueue.downHeap&lt;/p&gt;

&lt;p&gt;   9  1.51% 27.43%	36 300645 java.net.SocketInputStream.socketRead0&lt;br/&gt;
  10  1.43% 28.86%	34 300284&lt;br/&gt;
org.apache.lucene.store.BufferedIndexOutput.&amp;lt;init&amp;gt;&lt;br/&gt;
  11  1.43% 30.29%	34 300562 java.lang.Object.clone&lt;br/&gt;
  12  1.17% 31.46%	28 300346 java.io.StringReader.read&lt;br/&gt;
  13  1.01% 32.47%	24 300363&lt;br/&gt;
org.apache.lucene.index.DocumentWriter.writeNorms&lt;/p&gt;

&lt;p&gt;(Note: The Socket reading element is the JDBC driver retrieving the results).&lt;/p&gt;

&lt;p&gt;cheers,&lt;/p&gt;

&lt;p&gt;Paul&lt;/p&gt;</comment>
                    <comment id="12322383" author="mario@ops.co.at" created="Tue, 24 May 2005 15:54:53 +0100"  >&lt;p&gt;Where do the java.lang.Throwable.fillInStackTrace come from?&lt;/p&gt;</comment>
                    <comment id="12322384" author="whoschek@lbl.gov" created="Tue, 24 May 2005 16:14:23 +0100"  >&lt;p&gt;Most likely the IOExceptions stem from FastCharStream of StandardAnalyzer, at least that&apos;s my experience. &lt;br/&gt;
See the header of your hprof file to check if that&apos;s the case.&lt;/p&gt;

&lt;p&gt;Javacc has a gotcha in that it &quot;likes&quot; IOExceptions as part of the normal control flow on stream termination.&lt;br/&gt;
I have performance patches for this that make FastCharStream 2-10 times faster for small inputs (it &lt;br/&gt;
doesn&apos;t matter on large inputs), but I never bothered submitted them since they were not crucial for me, &lt;br/&gt;
and seeing that most submissions to lucene-dev go into a black hole anyway without any response, &lt;br/&gt;
neither negative or positive, simply ignored... Hint &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="12322385" author="psmith@apache.org" created="Tue, 24 May 2005 17:02:50 +0100"  >&lt;p&gt;I expanded the depth of the HPFOF test (will attach shortly) but in summary,&lt;br/&gt;
this is where it comes from:&lt;/p&gt;

&lt;p&gt;TRACE 300351:&lt;br/&gt;
        java.lang.Throwable.fillInStackTrace(Throwable.java:Unknown line)&lt;br/&gt;
        java.lang.Throwable.&amp;lt;init&amp;gt;(Throwable.java:196)&lt;br/&gt;
        java.lang.Exception.&amp;lt;init&amp;gt;(Exception.java:41)&lt;br/&gt;
        java.lang.RuntimeException.&amp;lt;init&amp;gt;(RuntimeException.java:43)&lt;br/&gt;
        java.lang.ClassCastException.&amp;lt;init&amp;gt;(ClassCastException.java:39)&lt;br/&gt;
        org.apache.lucene.document.Field.readerValue(Field.java:262)&lt;/p&gt;

&lt;p&gt;org.apache.lucene.index.DocumentWriter.invertDocument(DocumentWriter.java:152)&lt;br/&gt;
        org.apache.lucene.index.DocumentWriter.addDocument(DocumentWriter.java:93)&lt;/p&gt;

&lt;p&gt;Very strang I must say, I will have to look into that in more detail.  Anyone&lt;br/&gt;
care to comment?  &lt;/p&gt;</comment>
                    <comment id="12322386" author="psmith@apache.org" created="Tue, 24 May 2005 17:07:09 +0100"  >&lt;p&gt;Created an attachment (id=15141)&lt;br/&gt;
Same HPFOF trace, patch applied, but with deeper stack trace&lt;/p&gt;</comment>
                    <comment id="12322387" author="psmith@apache.org" created="Tue, 24 May 2005 17:34:07 +0100"  >&lt;p&gt;See Bug 35037 for related info&lt;/p&gt;</comment>
                    <comment id="12322388" author="psmith@apache.org" created="Wed, 25 May 2005 11:22:55 +0100"  >&lt;p&gt;(In reply to comment #12)&lt;br/&gt;
&amp;gt; Most likely the IOExceptions stem from FastCharStream of StandardAnalyzer, at&lt;br/&gt;
least that&apos;s my experience. &lt;br/&gt;
&amp;gt; See the header of your hprof file to check if that&apos;s the case.&lt;br/&gt;
&amp;gt; &lt;br/&gt;
&amp;gt; Javacc has a gotcha in that it &quot;likes&quot; IOExceptions as part of the normal&lt;br/&gt;
control flow on stream termination.&lt;br/&gt;
&amp;gt; I have performance patches for this that make FastCharStream 2-10 times faster&lt;br/&gt;
for small inputs (it &lt;br/&gt;
&amp;gt; doesn&apos;t matter on large inputs), but I never bothered submitted them since&lt;br/&gt;
they were not crucial for me, &lt;br/&gt;
&amp;gt; and seeing that most submissions to lucene-dev go into a black hole anyway&lt;br/&gt;
without any response, &lt;br/&gt;
&amp;gt; neither negative or positive, simply ignored... Hint &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;Hey, could you send me the patch for this?  I&apos;d like to test it out. I&apos;ve&lt;br/&gt;
verified the FastCharStream class does throw IOException when EOF, which of&lt;br/&gt;
course occurs very frequently when indexing small Fields.  I can&apos;t see a quick&lt;br/&gt;
and easy solution to indicate EOF without the exception, so I&apos;m keen to see your&lt;br/&gt;
work and test it out with my scenarios.&lt;/p&gt;

&lt;p&gt;cheers,&lt;/p&gt;

&lt;p&gt;Paul Smith&lt;/p&gt;
</comment>
                    <comment id="12322389" author="whoschek@lbl.gov" created="Wed, 25 May 2005 14:40:54 +0100"  >&lt;p&gt;Yep, throwing and catching exception in the critical path is always a performance gotcha, common case &lt;br/&gt;
or not. See any VM implementation performance papers such as in the IBM Systems journal some years &lt;br/&gt;
ago, and others. &lt;/p&gt;

&lt;p&gt;No idea why the javacc folks didn&apos;t come up with an API that does not involve exceptions for &lt;b&gt;normal&lt;/b&gt; &lt;br/&gt;
control flow. Well, javacc has probably been unmaintained dead code for some time now. [Even Xerces &lt;br/&gt;
has such gotchas deep inside it&apos;s low level native API - I chatted with this some time ago with a Sun &lt;br/&gt;
engineer].&lt;/p&gt;

&lt;p&gt;Anyway, you can preallocate the IOException in FastCharStream in  a private static final var, and then &lt;br/&gt;
throw the same exception object again and again on EOS. That gives some factor 2x the cheap way &lt;br/&gt;
because the stack trace does not have to be generated and filled repeatadly (Same for the QueryParser &lt;br/&gt;
copy of FastCharStream).&lt;/p&gt;

&lt;p&gt;The other additional 5x comes from getting rid of the exception completely - catching exceptions is &lt;br/&gt;
expensive. This is done via dirty patching the javacc generated code to not require EOS exceptions at &lt;br/&gt;
all. Instead you can return 0xFFFF as an EOS marker, or some other unused Unicode value. Look at the &lt;br/&gt;
javacc generated code and see where it catches the EOS exception. That&apos;s where you&apos;d need to fiddle &lt;br/&gt;
around, making sure true abnormal exceptions are still handled properly. It&apos;s really an akward &lt;br/&gt;
maintainance nightmare because it interferes with generated code, so I don&apos;t really recommend this. &lt;/p&gt;

&lt;p&gt;Still, StandardAnalyzer eats CPU (and buffer memory) like there&apos;s no tomorrow. Instead, I&apos;d recommend &lt;br/&gt;
giving PatternAnalyzer (from the &quot;memory&quot; SVN contrib area) a try. The functionality is almost the same &lt;br/&gt;
as StandardAnalyzer, but it can be many times faster, especially when using it with a String rather than &lt;br/&gt;
a Reader, and you don&apos;t have to wait indefinitely for lucene to get fixed.&lt;/p&gt;</comment>
                    <comment id="12427743" author="otis" created="Sun, 13 Aug 2006 09:17:54 +0100"  >&lt;p&gt;This last patch looks good to me, and I remember looking at this issue when Paul brought it up.  If I recall correctly, I saw the same wasted time in maybeMergeSegments().&lt;/p&gt;

&lt;p&gt;All tests pass, so I&apos;m committing this, only 15 months after it was reported &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;.  Thanks Paul!&lt;/p&gt;</comment>
                    <comment id="12427787" author="lucenebugs@danielnaber.de" created="Mon, 14 Aug 2006 00:49:01 +0100"  >&lt;p&gt;Something is wrong with this patch (as it has been applied) as it increases memory usage. Indexing files with the IndexFiles demo worked before using writer.setMaxBufferedDocs(50) and a tight JVM memory setting (-Xmx2M), now it fails with an OutOfMemoryError.&lt;/p&gt;</comment>
                    <comment id="12427794" author="yseeley@gmail.com" created="Mon, 14 Aug 2006 04:46:35 +0100"  >&lt;p&gt;One problem I see:&lt;br/&gt;
If you continuously add batches of documents of size less than maxBufferedDocs, maybeMergeSegments will never trigger a merge.  On a close(), it looks like there is some merging logic in flushRamSegments, but it doesn&apos;t do full multi-level merging like maybeMergeSegments does.&lt;/p&gt;

&lt;p&gt;I think I know how to fix it, but perhaps this should be reverted in the meantime?&lt;/p&gt;</comment>
                    <comment id="12427796" author="yseeley@gmail.com" created="Mon, 14 Aug 2006 05:14:32 +0100"  >&lt;p&gt;Another problem I see even for single-sessions is that bufferedDocCount is not maintained correctly... all merges are subtracted, not just those of the buffered docs.  This will lead to fewer and fewer merges than expected over time.&lt;/p&gt;

&lt;p&gt;I definitely vote to revert this.  There isn&apos;t an easy fix to this patch - a different approach is required.&lt;/p&gt;</comment>
                    <comment id="12427818" author="psmith@apache.org" created="Mon, 14 Aug 2006 07:29:55 +0100"  >&lt;p&gt;geez, yep definitely don&apos;t put this in, my patch was only a &apos;suggestion&apos; to highlight how it fixes the root cause of the problem. iIt is interesting that originally, all the test cases still pass, yet the problems Yonik highlights is real.  Might warrant some extra test cases to cover exactly those situation, even if this problem is not addressed.&lt;/p&gt;

&lt;p&gt;Be great if this could be fixed completely though, but I haven&apos;t got any headspace left to continue research on this one.. sorry &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="12427821" author="otis" created="Mon, 14 Aug 2006 07:58:33 +0100"  >&lt;p&gt;Ah, too bad. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  Reverted.  I do recall seeing maybeMergeSegments being called a lot, although I don&apos;t recall how much actual time was spent in there.&lt;/p&gt;</comment>
                    <comment id="12427932" author="yseeley@gmail.com" created="Mon, 14 Aug 2006 17:28:45 +0100"  >&lt;p&gt;How does this patch look?&lt;/p&gt;

&lt;p&gt;It&apos;s designed to exactly match the previous merging behavior, and it&apos;s conservative (an exact count is not maintained at all times).&lt;/p&gt;</comment>
                    <comment id="12427967" author="lucenebugs@danielnaber.de" created="Mon, 14 Aug 2006 22:15:43 +0100"  >&lt;p&gt;Hi Yonik, I just tested the patch: sorry, but the problem is the same as before: I get an OutOfMemoryError using settings that without the patch. That doesn&apos;t mean that the patch is wrong of course, but as we&apos;re after performance improvements it wouldn&apos;t make sense to compare it to the old version which uses less memory.&lt;/p&gt;</comment>
                    <comment id="12427969" author="yseeley@gmail.com" created="Mon, 14 Aug 2006 22:25:42 +0100"  >&lt;p&gt;&amp;gt; the problem is the same as before: I get an OutOfMemoryError using settings that without the patch&lt;/p&gt;

&lt;p&gt;That&apos;s worrisome though... the increase in code and data is minimal, and my patch should not trigger any different merging behavior.  Unless the previous version was passing the low-mem test by a few bytes, something is still wrong.&lt;/p&gt;</comment>
                    <comment id="12427975" author="psmith@apache.org" created="Mon, 14 Aug 2006 23:08:07 +0100"  >&lt;p&gt;This is where some tracing logging code would be useful.  Maybe a YourKit memory snapshot to see what&apos;s going on.. ?  I can&apos;t see Yonik&apos;s patch should influence the memory profile. It&apos;s just delaying the check for merging until an appropriate time, and should not be removing opportunities to merge segments.  I can&apos;t see why checking less often uses more memory.&lt;/p&gt;

&lt;p&gt;Obviously something strange is happening.  &lt;/p&gt;</comment>
                    <comment id="12427976" author="yseeley@gmail.com" created="Mon, 14 Aug 2006 23:19:55 +0100"  >&lt;p&gt;Well, the patch changes what the hotspot is, so the hotspot compiler could be trying to compile different code...&lt;/p&gt;

&lt;p&gt;Daniel, what is the exact test you are running?  what JVM and other settings?&lt;br/&gt;
Perhaps trying both versions with -Xbatch or -Xint would remove the differences?&lt;/p&gt;

&lt;p&gt;Perhaps we need a method to determine if index &quot;invariants&quot; have been met...&lt;/p&gt;</comment>
                    <comment id="12427981" author="lucenebugs@danielnaber.de" created="Tue, 15 Aug 2006 00:05:37 +0100"  >&lt;p&gt;I just see that this OOM is not exactly reproducible. I would have expected that it always happens when it has happened once when indexing the same data with the same settings (though not necessarily at the same time). But that doesn&apos;t seem to be the case. I use Java 1.4.2, -Xmx2M, writer.setMaxBufferedDocs(50) and I am indexing 2200 files with the IndexFiles class from the Lucene demo package. Also, I let the code run in Eclipse, maybe this has negative side effects.&lt;/p&gt;

&lt;p&gt;So your code is probably okay, although I suggest you set up a similar test case just to be sure.&lt;/p&gt;</comment>
                    <comment id="12427984" author="dmsmith555" created="Tue, 15 Aug 2006 00:14:52 +0100"  >&lt;p&gt;In Eclipse you can set the run to use its own JVM. Otherwise it runs in Eclipse&apos;s JVM and it has negative memory side effects.&lt;/p&gt;</comment>
                    <comment id="12428033" author="yseeley@gmail.com" created="Tue, 15 Aug 2006 05:02:16 +0100"  >&lt;p&gt;Something is wrong with my patch... the behavior still differs from the original.&lt;br/&gt;
I wrote a testInvariants() method, and merges are not always done when they need to be.&lt;/p&gt;</comment>
                    <comment id="12428038" author="yseeley@gmail.com" created="Tue, 15 Aug 2006 06:11:24 +0100"  >&lt;p&gt;Got it!&lt;/p&gt;

&lt;p&gt;Attatching new version with a minor change... I forgot to take into account deleted documents.  After a merge, instead of setting the count to minMergeDocs, we set it to 0, forcing a recount on the next add.  The reason is that deleted docs could have been squeezed out during the merge ,leaving a smaller segment that might be used in another merge shortly.&lt;/p&gt;

&lt;p&gt;Example of original behavior (minMergeDocs=10):&lt;br/&gt;
   // segment sizes = 55,8,1&lt;br/&gt;
  add  doc&lt;br/&gt;
   // segment sizes = 55,8,1,1&lt;br/&gt;
  maybe merge&lt;br/&gt;
  // segment sizes = 55,9     (not 10 because of a previously deleted doc)&lt;br/&gt;
  add doc&lt;br/&gt;
   // segment sizes = 55,9,1&lt;br/&gt;
  maybe merge&lt;br/&gt;
   // segment sizes = 55,10&lt;/p&gt;

&lt;p&gt;Now, the original behavior isn&apos;t necessarily desirable,  but we are taking baby steps... first &quot;do no harm&quot;.  A separate patch can address merging behavior in the presence of deleted documents.&lt;/p&gt;</comment>
                    <comment id="12428522" author="doronc" created="Wed, 16 Aug 2006 23:07:04 +0100"  >&lt;p&gt;It seems that the excessive cpu usage is mainly for (re)scanning those single-doc segments at the top of the &quot;stack&quot;. &lt;/p&gt;

&lt;p&gt;The following simple patch (small modification to previous one) only keeps track of the number of single doc segments, and when iterating for merge candidate segments, takes all those single doc segments in one step. &lt;/p&gt;

&lt;p&gt;All tests pass with this patch, running a bit faster (3 seconds - can be just noise). A &quot;tight mem setting&quot; (2048 cacm files with -Xmx3m and setMaxBufferedDocs(50) ) that fails with previous patch passes with this one. I checked the trace for which segments were merged - same merge decisions as before this change for these 2048 filess.&lt;/p&gt;</comment>
                    <comment id="12428527" author="yseeley@gmail.com" created="Wed, 16 Aug 2006 23:33:04 +0100"  >&lt;p&gt;I was literally a minute away from committing my version when Doron sumbitted his  &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
Actually, I think I like Doron&apos;s &quot;singleDocSegmentsCount&quot; better.... it&apos;s easier to understand at a glance.&lt;/p&gt;

&lt;p&gt;I was testing the performance for mine... not as much of a speeup as I would have liked...&lt;br/&gt;
5 to 6% better with maxBufferedDocs=1000, and a trivial single field document.&lt;br/&gt;
You need to go to maxBufferedDocs=10000 to see a good speedup, and that&apos;s probably not advisable for most real indicies (and the maxBufferedDocs=1000 used much less memory and was slightly faster anyway).&lt;/p&gt;

&lt;p&gt;Here is the code I added to IndexWriter to test my version (add testInvariants() after add() call and after flushRamSegments() in close(), then do &quot;ant test&quot;)&lt;/p&gt;

&lt;p&gt;  private synchronized void testInvariants() {&lt;br/&gt;
    // index segments should decrease in size&lt;br/&gt;
    int maxSegLevel = 0;&lt;br/&gt;
    for (int i=segmentInfos.size()&lt;del&gt;1; i&amp;gt;=0; i&lt;/del&gt;-) {&lt;br/&gt;
      SegmentInfo si = segmentInfos.info&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/information.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;;&lt;br/&gt;
      int segLevel = (si.docCount)/minMergeDocs;&lt;br/&gt;
      if (segLevel &amp;lt; maxSegLevel) &lt;/p&gt;
{

        throw new RuntimeException(&quot;Segment #&quot; + i + &quot; is too small. &quot; + segInfo());
      }
&lt;p&gt;      maxSegLevel = Math.max(maxSegLevel,segLevel);&lt;br/&gt;
    }&lt;/p&gt;

&lt;p&gt;    // check if merges needed&lt;br/&gt;
    long targetMergeDocs = minMergeDocs;&lt;br/&gt;
    int minSegment = segmentInfos.size();&lt;/p&gt;

&lt;p&gt;    while (targetMergeDocs &amp;lt;= maxMergeDocs &amp;amp;&amp;amp; minSegment&amp;gt;=0) {&lt;br/&gt;
      int mergeDocs = 0;&lt;br/&gt;
      while (--minSegment &amp;gt;= 0) &lt;/p&gt;
{
        SegmentInfo si = segmentInfos.info(minSegment);
        if (si.docCount &amp;gt;= targetMergeDocs) break;
        mergeDocs += si.docCount;
      }

&lt;p&gt;      if (mergeDocs &amp;gt;= targetMergeDocs) &lt;/p&gt;
{
        throw new RuntimeException(&quot;Merge needed at level &quot;+targetMergeDocs + &quot; :&quot;+segInfo());
      }

&lt;p&gt;      targetMergeDocs *= mergeFactor;		  // increase target size&lt;br/&gt;
    }&lt;br/&gt;
  }&lt;/p&gt;

&lt;p&gt;  private String segInfo() {&lt;br/&gt;
    StringBuffer sb = new StringBuffer(&quot;minMergeDocs=&quot;&lt;ins&gt;minMergeDocs&lt;/ins&gt;&quot;docsLeftBeforeMerge=&quot;&lt;ins&gt;docsLeftBeforeMerge&lt;/ins&gt;&quot; segsizes:&quot;);&lt;br/&gt;
    for (int i=0; i&amp;lt;segmentInfos.size(); i++) &lt;/p&gt;
{
      sb.append(segmentInfos.info(i).docCount);
      sb.append(&quot;,&quot;);
    }
&lt;p&gt;    return sb.toString();&lt;br/&gt;
  }&lt;/p&gt;</comment>
                    <comment id="12428560" author="yseeley@gmail.com" created="Thu, 17 Aug 2006 03:54:42 +0100"  >&lt;p&gt;I&apos;ve committed Doron&apos;s version after review and further testing with my testInvariants() (also committed, but commented out).  Thanks Doron &amp;amp; Paul!&lt;/p&gt;</comment>
                    <comment id="12428953" author="doronc" created="Fri, 18 Aug 2006 10:21:28 +0100"  >&lt;p&gt;well....  there is a problem in the current patch after all... the counter is not decremented when a merge is triggerred by a call to optimize. It is only decremented when a merge is called from maybeMergeSegments(). Therefore the counter decrement should move to mergeSegments(int,int). I am testing this fix now and will add a new patch for this soon.&lt;br/&gt;
Doron&lt;/p&gt;</comment>
                    <comment id="12428964" author="doronc" created="Fri, 18 Aug 2006 11:03:14 +0100"  >&lt;p&gt;The attached doron_2_IndexWriter.patch is fixing the updating of singleDocSegmentsCount to take place in mergeSegments(minSegment, end) so that it would apply also when optimize() is called. The update of the counter now considers the range of the merge (so the counter is not necessarily updated to 0).&lt;/p&gt;

&lt;p&gt;The bug in previous implementation was occasionally using TestIndexModifier.testIndexWithThreads() to fail with ArrayIndexOutOfBoundsException on the segments array.&lt;/p&gt;

&lt;p&gt;I ran this test several times with this fix and now it consistently passes. &quot;ant test&quot; passes as well.&lt;/p&gt;

&lt;p&gt;I hope we&apos;re done with this bug...&lt;/p&gt;

&lt;p&gt;Doron&lt;/p&gt;</comment>
                    <comment id="12429012" author="yseeley@gmail.com" created="Fri, 18 Aug 2006 14:34:35 +0100"  >&lt;p&gt;Thanks Doron, I caught that too and I was just going to set the count to 0 in mergeSegments (mergeSegments is always called with end == size() currently I think).  Your fix is better though - gives more flexibility.&lt;/p&gt;</comment>
                    <comment id="12429027" author="yseeley@gmail.com" created="Fri, 18 Aug 2006 15:27:33 +0100"  >&lt;p&gt;We could also make the following change to flushRamSegments, right?&lt;/p&gt;

&lt;p&gt;  private final void flushRamSegments() throws IOException {&lt;br/&gt;
    int minSegment = segmentInfos.size() - singleDocSegmentsCount;&lt;br/&gt;
    int docCount = singleDocSegmentsCount;&lt;/p&gt;</comment>
                    <comment id="12429069" author="doronc" created="Fri, 18 Aug 2006 18:42:18 +0100"  >&lt;p&gt;Right... actually it should be like this:&lt;/p&gt;

&lt;p&gt;   int minSegment = segmentInfos.size() - singleDocSegmentsCount - 1; &lt;/p&gt;

&lt;p&gt;But since flushRamSegments() is only called by close() and optimize(), no real performance gain is expected here. &lt;/p&gt;

&lt;p&gt;So I&apos;m not sure what my preference is between - &lt;br/&gt;
(a) do not to change here, because &quot;why change a working code to be perhaps a bit more complex for no performance gain&quot;. &lt;br/&gt;
(b) change here too, also to be consistent with how this counter is used in maybeMergeSegments().&lt;/p&gt;

&lt;p&gt;Anyway I tested this change and it works - so I am attaching also this version - doron_2b_IndexWriter.patch - in case there is a favor for (b).&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Doron&lt;/li&gt;
&lt;/ul&gt;

</comment>
                    <comment id="12429248" author="doronc" created="Sun, 20 Aug 2006 08:02:41 +0100"  >&lt;p&gt;Paul, would you like to re-open this issue for (re)solving it with one of the two recent patches (2 or 2b)  - I think that once an issue is resolved it can be re-opened (or closed) by the developer who opened it. (I assume commiters can also re-open, but I&apos;m not sure - well, at least I can&apos;t.)&lt;br/&gt;
Thanks, Doron&lt;/p&gt;</comment>
                    <comment id="12429262" author="yseeley@gmail.com" created="Sun, 20 Aug 2006 14:47:32 +0100"  >&lt;p&gt;No need to re-open Doron, I committed doron_2_IndexWriter.patch at the same time as my first reply (shortly after you posted it).&lt;/p&gt;</comment>
                    <comment id="12429522" author="doronc" created="Mon, 21 Aug 2006 21:40:29 +0100"  >&lt;p&gt;Oh - sorry for the &apos;noise&apos;  - got used to systems where a commit must be attached to an issue/defect - should have checked the commits list or the code itself - I&apos;m learning all the time...&lt;/p&gt;</comment>
                    <comment id="12429525" author="yseeley@gmail.com" created="Mon, 21 Aug 2006 21:46:33 +0100"  >&lt;p&gt;No problem... I probably should have put &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-388&quot; title=&quot;[PATCH] IndexWriter.maybeMergeSegments() takes lots of CPU resources&quot;&gt;&lt;del&gt;LUCENE-388&lt;/del&gt;&lt;/a&gt;&quot; in the commit log (it allows JIRA to link up the related commits automatically)&lt;/p&gt;</comment>
                </comments>
                    <attachments>
                    <attachment id="12312619" name="ASF.LICENSE.NOT.GRANTED--IndexWriter.patch" size="818" author="psmith@apache.org" created="Mon, 16 May 2005 17:20:26 +0100" />
                    <attachment id="12312618" name="ASF.LICENSE.NOT.GRANTED--log-compound.txt" size="139362" author="psmith@apache.org" created="Mon, 16 May 2005 17:19:32 +0100" />
                    <attachment id="12312623" name="ASF.LICENSE.NOT.GRANTED--log.optimized.deep.txt" size="465336" author="psmith@apache.org" created="Tue, 24 May 2005 17:07:09 +0100" />
                    <attachment id="12312622" name="ASF.LICENSE.NOT.GRANTED--log.optimized.txt" size="187734" author="psmith@apache.org" created="Tue, 24 May 2005 15:43:05 +0100" />
                    <attachment id="12312621" name="ASF.LICENSE.NOT.GRANTED--lucene.34930.patch" size="1868" author="psmith@apache.org" created="Tue, 24 May 2005 13:59:58 +0100" />
                    <attachment id="12312620" name="ASF.LICENSE.NOT.GRANTED--Lucene Performance Test - with &amp; without hack.xls" size="36352" author="psmith@apache.org" created="Tue, 17 May 2005 12:21:30 +0100" />
                    <attachment id="12339116" name="doron_2b_IndexWriter.patch" size="1441" author="doronc" created="Fri, 18 Aug 2006 18:42:18 +0100" />
                    <attachment id="12339078" name="doron_2_IndexWriter.patch" size="975" author="doronc" created="Fri, 18 Aug 2006 11:03:14 +0100" />
                    <attachment id="12338992" name="doron_IndexWriter.patch" size="1712" author="doronc" created="Wed, 16 Aug 2006 23:07:04 +0100" />
                    <attachment id="12338857" name="yonik_indexwriter.diff" size="2581" author="yseeley@gmail.com" created="Tue, 15 Aug 2006 06:11:24 +0100" />
                    <attachment id="12338820" name="yonik_indexwriter.diff" size="2592" author="yseeley@gmail.com" created="Mon, 14 Aug 2006 17:28:45 +0100" />
                </attachments>
            <subtasks>
        </subtasks>
                <customfields>
                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                <customfieldname>Attachment count</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>11.0</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_10010" key="com.atlassian.jira.plugin.system.customfieldtypes:importid">
                <customfieldname>Bugzilla Id</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>34930</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                <customfieldname>Date of First Response</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>Mon, 16 May 2005 19:22:41 +0000</customfieldvalue>

                </customfieldvalues>
            </customfield>
                                                                                                        <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Global Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>13361</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>27343</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                <customfieldname>Time in Status</customfieldname>
                <customfieldvalues>
                    
                </customfieldvalues>
            </customfield>
                            </customfields>
    </item>
</channel>
</rss>