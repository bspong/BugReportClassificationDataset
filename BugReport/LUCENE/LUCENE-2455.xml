<!-- 
RSS generated by JIRA (5.2.8#851-sha1:3262fdc28b4bc8b23784e13eadc26a22399f5d88) at Tue Jul 16 13:16:17 UTC 2013

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/LUCENE-2455/LUCENE-2455.xml?field=key&field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>5.2.8</version>
        <build-number>851</build-number>
        <build-date>26-02-2013</build-date>
    </build-info>

<item>
            <title>[LUCENE-2455] Some house cleaning in addIndexes*</title>
                <link>https://issues.apache.org/jira/browse/LUCENE-2455</link>
                <project id="12310110" key="LUCENE">Lucene - Core</project>
                        <description>&lt;p&gt;Today, the use of addIndexes and addIndexesNoOptimize is confusing - &lt;br/&gt;
especially on when to invoke each. Also, addIndexes calls optimize() in &lt;br/&gt;
the beginning, but only on the target index. It also includes the &lt;br/&gt;
following jdoc statement, which from how I understand the code, is &lt;br/&gt;
wrong: &lt;em&gt;After this completes, the index is optimized.&lt;/em&gt; &amp;#8211; optimize() is &lt;br/&gt;
called in the beginning and not in the end. &lt;/p&gt;

&lt;p&gt;On the other hand, addIndexesNoOptimize does not call optimize(), and &lt;br/&gt;
relies on the MergeScheduler and MergePolicy to handle the merges. &lt;/p&gt;

&lt;p&gt;After a short discussion about that on the list (Thanks Mike for the &lt;br/&gt;
clarifications!) I understand that there are really two core differences &lt;br/&gt;
between the two: &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;addIndexes supports IndexReader extensions&lt;/li&gt;
	&lt;li&gt;addIndexesNoOptimize performs better&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;This issue proposes the following:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;Clear up the documentation of each, spelling out the pros/cons of&lt;br/&gt;
  calling them clearly in the javadocs.&lt;/li&gt;
	&lt;li&gt;Rename addIndexesNoOptimize to addIndexes&lt;/li&gt;
	&lt;li&gt;Remove optimize() call from addIndexes(IndexReader...)&lt;/li&gt;
	&lt;li&gt;Document that clearly in both, w/ a recommendation to call optimize()&lt;br/&gt;
  before on any of the Directories/Indexes if it&apos;s a concern. &lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;That way, we maintain all the flexibility in the API - &lt;br/&gt;
addIndexes(IndexReader...) allows for using IR extensions, &lt;br/&gt;
addIndexes(Directory...) is considered more efficient, by allowing the &lt;br/&gt;
merges to happen concurrently (depending on MS) and also factors in the &lt;br/&gt;
MP. So unless you have an IR extension, addDirectories is really the one &lt;br/&gt;
you should be using. And you have the freedom to call optimize() before &lt;br/&gt;
each if you care about it, or don&apos;t if you don&apos;t care. Either way, &lt;br/&gt;
incurring the cost of optimize() is entirely in the user&apos;s hands. &lt;/p&gt;

&lt;p&gt;BTW, addIndexes(IndexReader...) does not use neither the MergeScheduler &lt;br/&gt;
nor MergePolicy, but rather call SegmentMerger directly. This might be &lt;br/&gt;
another place for improvement. I&apos;ll look into it, and if it&apos;s not too &lt;br/&gt;
complicated, I may cover it by this issue as well. If you have any hints &lt;br/&gt;
that can give me a good head start on that, please don&apos;t be shy &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;. &lt;/p&gt;</description>
                <environment></environment>
            <key id="12464201">LUCENE-2455</key>
            <summary>Some house cleaning in addIndexes*</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                <priority id="5" iconUrl="https://issues.apache.org/jira/images/icons/priorities/trivial.png">Trivial</priority>
                    <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png">Closed</status>
                    <resolution id="1">Fixed</resolution>
                                <assignee username="shaie">Shai Erera</assignee>
                                <reporter username="shaie">Shai Erera</reporter>
                        <labels>
                    </labels>
                <created>Tue, 11 May 2010 04:59:17 +0100</created>
                <updated>Wed, 30 Mar 2011 16:50:31 +0100</updated>
                    <resolved>Thu, 27 May 2010 16:37:06 +0100</resolved>
                                            <fixVersion>3.1</fixVersion>
                <fixVersion>4.0-ALPHA</fixVersion>
                                <component>core/index</component>
                        <due></due>
                    <votes>0</votes>
                        <watches>0</watches>
                                                    <comments>
                    <comment id="12866118" author="mikemccand" created="Tue, 11 May 2010 11:04:54 +0100"  >&lt;blockquote&gt;&lt;p&gt;Remove optimize() call from addIndexes(IndexReader...)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This still makes me nervous.  Yeah it&apos;s bad that this method does optimize() now.  But if we remove it, it&apos;s bad that this method can attempt to do a ridiculously immense merge, since it &lt;span class=&quot;error&quot;&gt;&amp;#91;naively&amp;#93;&lt;/span&gt; just stuffs everything and and does one merge.  Ie, both at are bad.&lt;/p&gt;

&lt;p&gt;Maybe... we could do this: only merge the the incoming IndexReaders, appending a new segment to the end of the index?  Ie do no merging whatsoever of the current segments in the index.&lt;/p&gt;

&lt;p&gt;Yes, this can result in &quot;unbalanced&quot; segments (ie, a huge segment appears after the long tail of level 0 segments), but, the merge policy can handle this &amp;#8211; it&apos;ll work out whatever merges are then necessary to get this segment onto the level that roughly matches its size. &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;So unless you have an IR extension, addDirectories is really the one  you should be using.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;You mean addIndexes(Directory..)?&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;BTW, addIndexes(IndexReader...) does not use neither the MergeScheduler &lt;br/&gt;
nor MergePolicy, but rather call SegmentMerger directly. This might be &lt;br/&gt;
another place for improvement. I&apos;ll look into it, and if it&apos;s not too &lt;br/&gt;
complicated, I may cover it by this issue as well. If you have any hints &lt;br/&gt;
that can give me a good head start on that, please don&apos;t be shy .&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This would be best of all &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  But it&apos;s tricky, because our MP/MS assume they are working w/ a SegmentInfo.  But, maybe it could somehow be made to work &amp;#8211; eg IR does give us maxDoc, numDocs (so we can know del doc count).  But eg LogByteSizeMergePolicy goes and computes total byte size of the segment (via SegmentInfo) which we cannot do from an IR.&lt;/p&gt;
</comment>
                    <comment id="12866245" author="shaie" created="Tue, 11 May 2010 19:18:05 +0100"  >&lt;blockquote&gt;&lt;p&gt;You mean addIndexes(Directory..)?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes, copy-paste error.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Maybe... we could do this: only merge the the incoming IndexReaders, appending a new segment to the end of the index?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I like it. IMO, that&apos;s what the method should do anyway, for better performance and service to the users. If I&apos;m adding indexes, that doesn&apos;t mean I want a whole merge process to kick off. If I want that, I can call maybeMerge or optimize afterwards.&lt;/p&gt;

&lt;p&gt;Basically, what I would like to add (and I&apos;m not sure it belongs to this issue) is a &quot;super fast&quot; addIndexes method, something like registerIndexes, which doesn&apos;t even traverses the posting lists, removes deleted docs etc. - simply registering the new segments in the Directory. If needed - do a bulk copy of the files and update segments*. Simple as that. Maybe it does fit in that issue, as part of the general &quot;house cleaning&quot;?&lt;/p&gt;

&lt;p&gt;I will look more closely into supporting MP + MS w/ addIndexes(readers). Can&apos;t promise anything as I learn the code as I go &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;.&lt;/p&gt;</comment>
                    <comment id="12866302" author="mikemccand" created="Tue, 11 May 2010 21:01:58 +0100"  >&lt;p&gt;I agree, addIndexes should be minimal in the work it does...&lt;/p&gt;

&lt;p&gt;But bulk copy of the files isn&apos;t really possible for addIndexes(IR...) in general, since the readers can be arbitrary (eg FilterIndexReader).&lt;/p&gt;</comment>
                    <comment id="12866444" author="shaie" created="Wed, 12 May 2010 04:35:11 +0100"  >&lt;p&gt;Ok. But since addIndexes(IR) is for IR extensions only, I think the number of people tha will be limited by it is very low.&lt;/p&gt;

&lt;p&gt;But, why wouldn&apos;t they be able to use the Directory... version of the method? Since it&apos;s a bulk copy, we don&apos;t need IR methods. Maybe just call dir.copyTo or something of that sort? The method will only be asked to copy files (in case they exist elsewhere). I was thinking of introducing just a Directoy version of such method.&lt;/p&gt;

&lt;p&gt;Basically, if you use NoMP and call addIndexesNoOptimize today, you get half of what I want, as only resolveExternals will be called. What I want is for the resolveExternals to be even faster, plain and shallow &quot;resolution&quot;.&lt;/p&gt;</comment>
                    <comment id="12866524" author="mikemccand" created="Wed, 12 May 2010 10:31:12 +0100"  >&lt;blockquote&gt;&lt;p&gt;But, why wouldn&apos;t they be able to use the Directory... version of the method?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Adding indexes using FilterIndexReader is useful &amp;#8211; eg look @ how the multi-pass index splitter tool works.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;What I want is for the resolveExternals to be even faster, plain and shallow &quot;resolution&quot;.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;For addIndexes(Directory), assuming the codecs are identical (the &quot;write&quot; codec equals the codec used to write the external segment), and assuming the doc stores of the external segment are private to it, I think we should be able to do a straight file-level copy, but renaming the segment in the process?&lt;/p&gt;</comment>
                    <comment id="12866539" author="shaie" created="Wed, 12 May 2010 11:57:19 +0100"  >&lt;blockquote&gt;&lt;p&gt;Adding indexes using FilterIndexReader is useful &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;m not against that Mike. addIndexes should allow for both IndexReader and Directory. It&apos;s the registerIndexes (or whatever name we come up with) which should work with Directory only, and then, even if the app calls addIndexes with its own custom IR, it can still call registerIndexes w/ the Directory only, to do that fast copy/registration. Since no IR method will be involved in the process.&lt;/p&gt;

&lt;p&gt;So let&apos;s not confuse the two - addIndexes will exist and work as they are today. registerIndexes will be a new one.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;assuming the codecs are identical (the &quot;write&quot; codec equals the codec used to write the external segment), and assuming the doc stores of the external segment are private to it&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Right. Thanks for pointing that out, as it will become an important NOTE in the documentation. This method (registerIndexes) is definitely for advanced users, that have to know &lt;b&gt;exactly&lt;/b&gt; what&apos;s in the foreign indexes. For example, I need this because I&apos;m building several indexes on several nodes and then I want to add them to a central/master one. I know they don&apos;t have deletions, and each is already optimized. Therefore traversing the posting lists (as fast as it would be) is completely unnecessary.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;but renaming the segment in the process?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Sure! I think we should really &apos;register&apos; them in the Directory, as if they are the newly flushed segments. I&apos;m sure you have a general idea on how this can be done? Assuming through SegmentInfos or something?&lt;/p&gt;</comment>
                    <comment id="12867498" author="shaie" created="Fri, 14 May 2010 14:22:04 +0100"  >&lt;p&gt;While changing addIndexes(reader), I&apos;ve noticed it first obtains read lock and then calls startTransaction(true). In between it calls flush + optimize, which I&apos;ve removed (as we no longer want to do that). When I ran the tests, TestIndexWriter.testAddIndexesWithThreads failed on the assert in startTransaction about numDocsInRam != 0. That&apos;s expected as I no longer call flush. The failure does not occur always.&lt;/p&gt;

&lt;p&gt;In addIndexes(Dir) flush is called before startTransaction. But it makes sense to do it there, as the local segments are also merged. In the new addIndexes(reader) they won&apos;t and so I wonder if:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;I shouldn&apos;t call startTransaction at all, or&lt;/li&gt;
	&lt;li&gt;I should, but also call flush before?&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12867500" author="shaie" created="Fri, 14 May 2010 14:43:22 +0100"  >&lt;p&gt;Patch handles the changes for 3x:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;addIndexesNoOptimize deprecated - new addIndexes(Directory...) instead&lt;/li&gt;
	&lt;li&gt;CHANGES updates&lt;/li&gt;
	&lt;li&gt;addIndexes does not do optimize before&lt;/li&gt;
	&lt;li&gt;TestAddIndexesNoOptimize renamed to TestAddIndexes&lt;/li&gt;
	&lt;li&gt;Changed calls to addIndexesNoOpt to use addIndexes(Dir...) (except for backwards tests)&lt;/li&gt;
	&lt;li&gt;Changed textual references to addIndexesNoOpt.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;You should &quot;svn mv lucene/src/test/org/apache/lucene/index/TestAddIndexesNoOptimize.java lucene/src/test/org/apache/lucene/index/TestAddIndexes.java&quot; before you apply the patch.&lt;/p&gt;

&lt;p&gt;The patch is much smaller than it looks - it&apos;s the rename of TestAddIndexesNoOpt that takes a lot of space.&lt;/p&gt;

&lt;p&gt;As I&apos;ve mentioned before, I&apos;m not sure about addIndexes calling startTransaction w/o flushing. Even though the tests pass, this seems wrong. So I&apos;d appreciate a review.&lt;/p&gt;</comment>
                    <comment id="12867519" author="mikemccand" created="Fri, 14 May 2010 16:10:38 +0100"  >&lt;p&gt;I think you should still call flush, and still start/commitTransaction &amp;#8211; addIndexes is &quot;all or nothing&quot;, which is why we have those transaction methods.  Ie, on exception, the rollbackTransaction puts the original segments back.&lt;/p&gt;</comment>
                    <comment id="12867523" author="mikemccand" created="Fri, 14 May 2010 16:13:47 +0100"  >&lt;p&gt;Patch looks good Shai!  Only a small typo in CHANGES (unles -&amp;gt; unless).&lt;/p&gt;</comment>
                    <comment id="12867554" author="shaie" created="Fri, 14 May 2010 17:39:22 +0100"  >&lt;p&gt;I see. I understand why it&apos;s called in addIndexes(Dir), because the local segments are also touched. But now in the Reader version, they aren&apos;t. So it looked odd to me that we flush whatever is in RAM. I think you said once that addIndexes should have done the merge outside, adding the new segment when it&apos;s done?&lt;/p&gt;

&lt;p&gt;But if you think that flushing the RAM, even though its content is touched, is ok then I&apos;ll change it.&lt;/p&gt;</comment>
                    <comment id="12867567" author="mikemccand" created="Fri, 14 May 2010 18:07:08 +0100"  >&lt;blockquote&gt;&lt;p&gt;I understand why it&apos;s called in addIndexes(Dir), because the local segments are also touched. But now in the Reader version, they aren&apos;t. So it looked odd to me that we flush whatever is in RAM. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yeah maybe we should no longer flush (but still call start/commitTransaction).  I think there may&apos;ve been a reason to flush first (besides that we were also merging local segments)... but I can&apos;t remember it.  If you comment out that assert (and the corresponding assert for deletions) do any tests fail?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I think you said once that addIndexes should have done the merge outside, adding the new segment when it&apos;s done?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes, I would love to fix this &amp;#8211; it&apos;d mean we would not need the start/commit/rollbackTransaction code.&lt;/p&gt;

&lt;p&gt;Ie, we play a dangerous game now, where addIndexes is allowed to muck with the in-memory SegmentInfos before it&apos;s complete.  It&apos;d be better if all merging happened outside of its SegmentInfos, and only when addIndexes finished, it&apos;d atomically commit to SegmentInfos.&lt;/p&gt;

&lt;p&gt;This would then allow commit() to run immediately, not having to wait for any running addIndexes to finish first.  And we would not need to block add/updateDocument nor deleteDocuments while addIndexes is running.&lt;/p&gt;

&lt;p&gt;So, actually, I think in addIndexes(IR...) you should not use the transaction logic at all?  Just do the merge externally &amp;amp; commit in the end?  (And try not flushing as well.).&lt;/p&gt;</comment>
                    <comment id="12867572" author="shaie" created="Fri, 14 May 2010 18:25:15 +0100"  >&lt;p&gt;Ha &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;, I knew this will get more complicated and interesting ... So basically, it feels to me that if we&apos;d have registerIndexes, we could in addIndexes merge outside IW and then call register?&lt;/p&gt;

&lt;p&gt;So far, tests pass w/ startTransaction. But that test is multi-threaded so it may be a concurrency issue. I&apos;ll try to do the addIndexes outside IW and then commit the new segment. If that will be straightforward, then I think I&apos;ll understand better how to develop registerIndexes.&lt;/p&gt;</comment>
                    <comment id="12867579" author="mikemccand" created="Fri, 14 May 2010 18:33:58 +0100"  >&lt;blockquote&gt;&lt;p&gt;Ha , I knew this will get more complicated and interesting ..&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It always does!&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;So basically, it feels to me that if we&apos;d have registerIndexes, we could in addIndexes merge outside IW and then call register?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Hmm but register will be an external API for copying over segments in a foreign directory, right?  (And segment must be renamed).&lt;/p&gt;

&lt;p&gt;Vs these segments which will be in our directory already, with the right segment name, and just need to be committed to the segmentInfos?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;So far, tests pass w/ startTransaction.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;You mean w/o the flush?&lt;/p&gt;</comment>
                    <comment id="12867791" author="shaie" created="Sat, 15 May 2010 04:52:10 +0100"  >&lt;blockquote&gt;&lt;p&gt;You mean w/o the flush?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes. The start/commit transaction looks like that:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
startTransaction(&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;);

&lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
  mergedName = newSegmentName();
  merger = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; SegmentMerger(&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;, mergedName, &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;);

  &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (IndexReader reader : readers)      &lt;span class=&quot;code-comment&quot;&gt;// add &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; indexes
&lt;/span&gt;    merger.add(reader);
        
  &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; docCount = merger.merge();                &lt;span class=&quot;code-comment&quot;&gt;// merge &apos;em
&lt;/span&gt;        
  &lt;span class=&quot;code-keyword&quot;&gt;synchronized&lt;/span&gt;(&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;) {
    info = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; SegmentInfo(mergedName, docCount, directory, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;,
                  -1, &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, merger.hasProx());
    setDiagnostics(info, &lt;span class=&quot;code-quote&quot;&gt;&quot;addIndexes(IndexReader...)&quot;&lt;/span&gt;);
    segmentInfos.add(info);
  }
        
  &lt;span class=&quot;code-comment&quot;&gt;// Notify DocumentsWriter that the flushed count just increased
&lt;/span&gt;  docWriter.updateFlushedDocCount(docCount);
        
  success = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;;
} &lt;span class=&quot;code-keyword&quot;&gt;finally&lt;/span&gt; {
  &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (!success) {
    rollbackTransaction();
  } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
    commitTransaction();
  }
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
	&lt;li&gt;A new segment name is generated&lt;/li&gt;
	&lt;li&gt;All readers but the current one are merged&lt;/li&gt;
	&lt;li&gt;The new SI is added to the writer&apos;s SIs&lt;/li&gt;
	&lt;li&gt;DocWriter&apos;s updateFlushedDocCount is updated&lt;/li&gt;
	&lt;li&gt;The transaction is committed or rolled back if there was an error.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;So this looks like it already does the merge &quot;on the side&quot; and when it&apos;s done the new segment is registered?&lt;/p&gt;</comment>
                    <comment id="12867793" author="shaie" created="Sat, 15 May 2010 05:12:51 +0100"  >&lt;p&gt;In fact, I&apos;ve create newAddIndexes (just for the review) which works like that:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void newAddIndexes(IndexReader... readers) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; CorruptIndexException, IOException {

    ensureOpen();

    &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
      &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; mergedName = newSegmentName();
      SegmentMerger merger = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; SegmentMerger(&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;, mergedName, &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;);
      
      &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (IndexReader reader : readers)      &lt;span class=&quot;code-comment&quot;&gt;// add &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; indexes
&lt;/span&gt;        merger.add(reader);
      
      &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; docCount = merger.merge();                &lt;span class=&quot;code-comment&quot;&gt;// merge &apos;em
&lt;/span&gt;      
      SegmentInfo info = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;
      &lt;span class=&quot;code-keyword&quot;&gt;synchronized&lt;/span&gt;(&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;) {
        info = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; SegmentInfo(mergedName, docCount, directory, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;,
            -1, &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, merger.hasProx());
        setDiagnostics(info, &lt;span class=&quot;code-quote&quot;&gt;&quot;addIndexes(IndexReader...)&quot;&lt;/span&gt;);
        segmentInfos.add(info);
      }
      
      &lt;span class=&quot;code-comment&quot;&gt;// Notify DocumentsWriter that the flushed count just increased
&lt;/span&gt;      docWriter.updateFlushedDocCount(docCount);
      
      &lt;span class=&quot;code-comment&quot;&gt;// Now create the compound file &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; needed
&lt;/span&gt;      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (mergePolicy &lt;span class=&quot;code-keyword&quot;&gt;instanceof&lt;/span&gt; LogMergePolicy &amp;amp;&amp;amp; getUseCompoundFile()) {

        List&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&amp;gt; files = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;

        &lt;span class=&quot;code-keyword&quot;&gt;synchronized&lt;/span&gt;(&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;) {
          &lt;span class=&quot;code-comment&quot;&gt;// Must incRef our files so that &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; another thread
&lt;/span&gt;          &lt;span class=&quot;code-comment&quot;&gt;// is running merge/optimize, it doesn&apos;t delete our
&lt;/span&gt;          &lt;span class=&quot;code-comment&quot;&gt;// segment&apos;s files before we have a chance to
&lt;/span&gt;          &lt;span class=&quot;code-comment&quot;&gt;// finish making the compound file.
&lt;/span&gt;          &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (segmentInfos.contains(info)) {
            files = info.files();
            deleter.incRef(files);
          }
        }

        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (files != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
          &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
            merger.createCompoundFile(mergedName + &lt;span class=&quot;code-quote&quot;&gt;&quot;.cfs&quot;&lt;/span&gt;);
            &lt;span class=&quot;code-keyword&quot;&gt;synchronized&lt;/span&gt;(&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;) {
              info.setUseCompoundFile(&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;);
            }
          } &lt;span class=&quot;code-keyword&quot;&gt;finally&lt;/span&gt; {
            deleter.decRef(files);
          }
        }
      }
    } &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (OutOfMemoryError oom) {
      handleOOM(oom, &lt;span class=&quot;code-quote&quot;&gt;&quot;addIndexes(IndexReader...)&quot;&lt;/span&gt;);
    } &lt;span class=&quot;code-keyword&quot;&gt;finally&lt;/span&gt; {
      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (docWriter != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
        docWriter.resumeAllThreads();
      }
    }
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Question: if we&apos;ve just added the new SI to segmentInfos, why do we sync on &lt;em&gt;this&lt;/em&gt; and check if it exists (when we create the compound file)? Is it because there could be a running merge which will merge it into a new segment before we reach that point?&lt;/p&gt;

&lt;p&gt;What do you think? Is that what you had in mind about merging on the side and committing in the end?&lt;/p&gt;</comment>
                    <comment id="12867870" author="mikemccand" created="Sat, 15 May 2010 13:51:30 +0100"  >&lt;blockquote&gt;&lt;p&gt;Question: if we&apos;ve just added the new SI to segmentInfos, why do we sync on this and check if it exists (when we create the compound file)? Is it because there could be a running merge which will merge it into a new segment before we reach that point?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes, exactly.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;What do you think? Is that what you had in mind about merging on the side and committing in the end?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yup!  This looks great.... though I think you should move the docWriter.updateFlushedDocCount into the sync above it?  We didn&apos;t have to do this before because we blocked all add/updateDocument calls.&lt;/p&gt;

&lt;p&gt;Also, you shouldn&apos;t call docWriter.resumeAllThreads (you didn&apos;t pause them).&lt;/p&gt;

&lt;p&gt;So this change is a great step forward in concurrency of addIndexes(IndexReader...)!&lt;/p&gt;</comment>
                    <comment id="12867871" author="shaie" created="Sat, 15 May 2010 14:07:54 +0100"  >&lt;blockquote&gt;&lt;p&gt;Also, you shouldn&apos;t call docWriter.resumeAllThreads (you didn&apos;t pause them).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Oops, missed that &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;. Thanks !&lt;/p&gt;

&lt;p&gt;I&apos;ll replace addIndexes w/ this code and run tests to check how it flies.&lt;/p&gt;</comment>
                    <comment id="12867951" author="shaie" created="Sun, 16 May 2010 05:23:45 +0100"  >&lt;p&gt;I&apos;ve looked into implementing registerIndexes, and that&apos;s the approach I&apos;d like to take:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;For each incoming Directory, read its SegmentInfos&lt;/li&gt;
	&lt;li&gt;For each SegmentInfo:
	&lt;ul&gt;
		&lt;li&gt;Generate a new segment name&lt;/li&gt;
		&lt;li&gt;List its files&lt;/li&gt;
		&lt;li&gt;Copy them from incoming Dir to local Dir, w/ the new segment name&lt;/li&gt;
		&lt;li&gt;Add such SI to the local IW segmentInfos&lt;/li&gt;
		&lt;li&gt;Update DW docCount, like it&apos;s done in the addIndexes* methods.&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Few things:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;Does that sound reasonable? Am I missing something?&lt;/li&gt;
	&lt;li&gt;Directory exposes a copyTo(Dir, Collection) which I thought to use. But the files are copied to the target Dir w/ their current name - while I need to copy them over w/ their new name.
	&lt;ul&gt;
		&lt;li&gt;Adding rename to Dir feels wrong and dangerous to me&lt;/li&gt;
		&lt;li&gt;Adding copyFile(Dir, String old, String new) seems ok&lt;/li&gt;
		&lt;li&gt;Adding a variant of copyTo which accepts a Collection of the new names - the src and new should align. This also seems ok to me.&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;I&apos;d like to use Directory for the copy, since impls of Dir may do the copy very efficiently (i.e. FSDir vs. RAMDir) and I don&apos;t want to use IndexInput/Output for that.&lt;/p&gt;

&lt;p&gt;Do you know of another way I can achieve that? I only want to copy the actual segment files, w/o .gen and segments_N, so calling SI.files() seems ok?&lt;/p&gt;

&lt;p&gt;Another question that popped into my head was about consistency of the incoming Dirs vs. the local one, w.r.t. to CFS files - should I worry about that? I think not because today one can create an index w/ CFS and then turn it off and some segments will be compound and others not?&lt;/p&gt;</comment>
                    <comment id="12868018" author="mikemccand" created="Sun, 16 May 2010 19:03:52 +0100"  >&lt;blockquote&gt;&lt;p&gt;I&apos;ve looked into implementing registerIndexes, and that&apos;s the approach I&apos;d like to take:&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This looks good.&lt;/p&gt;

&lt;p&gt;Though if the src segments share docStores, you can&apos;t do a simple&lt;br/&gt;
copy (I think you have to fallback to the resolveExternalSegments&lt;br/&gt;
approach for such segments).&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Does that sound reasonable? Am I missing something?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think this should work!&lt;/p&gt;

&lt;p&gt;If the src segments are an older index rev, I think you are still OK.&lt;br/&gt;
They will just remain &quot;old&quot; on copy, and merge will eventually migrate&lt;br/&gt;
them forward.&lt;/p&gt;

&lt;p&gt;For trunk... you should note in the jdocs that no codec conversion&lt;br/&gt;
takes place.  So the CodecProvider used in IW (and later used to read&lt;br/&gt;
this index) must know how to provide the codec used by the src&lt;br/&gt;
segments.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Directory exposes a copyTo(Dir, Collection) which I thought to use. But the files are copied to the target Dir w/ their current name - while I need to copy them over w/ their new name.&lt;br/&gt;
Adding rename to Dir feels wrong and dangerous to me&lt;br/&gt;
Adding copyFile(Dir, String old, String new) seems ok&lt;br/&gt;
Adding a variant of copyTo which accepts a Collection of the new names - the src and new should align. This also seems ok to me.&lt;br/&gt;
I&apos;d like to use Directory for the copy, since impls of Dir may do the copy very efficiently (i.e. FSDir vs. RAMDir) and I don&apos;t want to use IndexInput/Output for that.&lt;/p&gt;

&lt;p&gt;Do you know of another way I can achieve that? I only want to copy the actual segment files, w/o .gen and segments_N, so calling SI.files() seems ok?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;SI.files() should be fine.&lt;/p&gt;

&lt;p&gt;I think falling back to copyFile is best?  Then copyTo could use it.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Another question that popped into my head was about consistency of the&lt;br/&gt;
incoming Dirs vs. the local one, w.r.t. to CFS files - should I worry&lt;br/&gt;
about that? I think not because today one can create an index w/ CFS&lt;br/&gt;
and then turn it off and some segments will be compound and others&lt;br/&gt;
not?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I think that&apos;s fine, but we should advertise in the jdocs.&lt;/p&gt;</comment>
                    <comment id="12868032" author="shaie" created="Sun, 16 May 2010 20:55:28 +0100"  >&lt;p&gt;So it sounds like addIndexes should really be that registerIndexes. Specifically it should do a quick and dirty copy of all segments that don&apos;t share doc stores, and then resolveExternals those that do? Maybe we can get rid of those transactions and not block add/update/delete/commit/addIndexes attempts anymore?&lt;/p&gt;

&lt;p&gt;Usually, I expect this to be a win-win. In cases where you add Directories w/ plenty of segments that share doc stores it will be slower, because we won&apos;t utilize MP and MS. But this can be improved in the future as well by e.g. just taking care of the shared doc stores, and don&apos;t remove deleted document entries etc.&lt;/p&gt;

&lt;p&gt;But .. it will prevent (in some cases) the use of PayloadProcessorProvider ... hmm. So it seems we do need a separate registerIndexes for the really quick &amp;amp; dirty addIndexes operation.&lt;/p&gt;

&lt;p&gt;BTW, Directory.copyTo* should be replaced w/ Directory.copy(Dir, File, File), for a couple of reasons:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;There&apos;s no reason to believe the dest file should be named the same as the source file&lt;/li&gt;
	&lt;li&gt;The method is not entirely safe - only jdocs protect the user from doing really stupid thing such as overwriting the segments* files.&lt;/li&gt;
	&lt;li&gt;I don&apos;t see a proper usecase for that method, other than copying a Directory into an empty one. At least, other use cases are very dangerous.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Instead, the user should do this logic outside - call dir.listAll(), w/ and w/o FilenameFilter and copy the files of interest, and be allowed to rename them in the process.&lt;/p&gt;</comment>
                    <comment id="12868103" author="shaie" created="Mon, 17 May 2010 07:51:28 +0100"  >&lt;p&gt;So ... after I slept over it, I don&apos;t think I can easily let go of the so-near victory &amp;#8211; having addIndexes not blocking anything, done on the side, be as efficient as possible and give up a chance to do some serious code cleanup &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;. So I&apos;d like to propose the following, we can discuss them one by one, but they all aim at the same thing:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;addIndexes(Directory ...) will be a quick &amp;amp; dirty copy of segments. No deleted docs removal in the process, no merges.
	&lt;ul&gt;
		&lt;li&gt;It&apos;s clear how this can be done for segments that don&apos;t share doc stores.&lt;/li&gt;
		&lt;li&gt;What isn&apos;t clear to me is why can&apos;t this work for segments that do share doc stores - can&apos;t we copy all of them at once, and add to segmentInfos when the segments + their doc store were copied? So, if I have 5 segments, w/ the following doc stores: 1-2, 3 and 4-5 (3 stores for 5 segments), can&apos;t I copy 1+2+store, 3, 4+5+store? Wouldn&apos;t that work? I&apos;ll give it a shot.&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;PayloadProcessorProvider won&apos;t be used in the process. If you want, you can set it on the source writer, and call optimize(). Performance-wise it will be nearly identical - instead of processing the postings + payloads during addIndexes, you&apos;ll do that during optimize() (all segments will be processed anyway) and addIndexes will do a bulk IO copy, which on most modern machines is really cheap.
	&lt;ul&gt;
		&lt;li&gt;Further more, you will end up w/ just one segment, which means it can be copied at once for sure.&lt;/li&gt;
		&lt;li&gt;It will also simplify PPP &amp;#8211; no need for DirPP anymore. PPP would get a Term and return a PP for that term, as it will always work on just one Directory.&lt;/li&gt;
		&lt;li&gt;People can still use it with the target IW if they want, but not through addIndexes.&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;Apps can call maybeMerge or optimize() following addIndexes, if they want to.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;What remains is addIndexes(IndexReader...) and I&apos;m not sure why this cannot be removed. In the back of my head I remember a discussion about it once, so I guess there is a good reason. But at least from what I see now, and armed w/ my use cases only, it seems like even if you use an extension of IndexReader you should still be able to do a bulk copy? Hmm ... unless if your extension assumes different postings structure or something like that, which the regular SegmentReader won&apos;t know about &amp;#8211; then during addIndexes those postings are converted.&lt;/p&gt;

&lt;p&gt;But, how common is this? And wouldn&apos;t it be better if such indexes are migrated beforehand? I mean, anyway after addIndexes those postings won&apos;t retain the custom IndexReader-assuming format? Or is there another reason?&lt;/p&gt;

&lt;p&gt;If we go with that, then SegmentMerger can be simplified as well, assuming only SegmentReader?&lt;/p&gt;

&lt;p&gt;What do you think?&lt;/p&gt;</comment>
                    <comment id="12868158" author="mikemccand" created="Mon, 17 May 2010 11:05:53 +0100"  >&lt;blockquote&gt;&lt;p&gt;What isn&apos;t clear to me is why can&apos;t this work for segments that do share doc stores &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;You are right!&lt;/p&gt;

&lt;p&gt;If we copy over the doc stores, also renaming them, and fixup the incoming SegmentInto to reference the newly named one, this should work fine!&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;PayloadProcessorProvider won&apos;t be used in the process.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This (and not needing DirPP anymore) is a great simplification.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;What remains is addIndexes(IndexReader...) and I&apos;m not sure why this cannot be removed.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think we still need it... look at how multi-pass index splitter (contrib/misc) works.&lt;/p&gt;</comment>
                    <comment id="12868166" author="shaie" created="Mon, 17 May 2010 12:06:14 +0100"  >&lt;blockquote&gt;&lt;p&gt;look at how multi-pass index splitter (contrib/misc) works.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I see ...&lt;/p&gt;

&lt;p&gt;I think this can be achieved by also deleting docs that fall outside the split range and calling optimize() / expungeDeletes()? So, you copy the index once (using one of the copying addIndexes methods), delete the docs that you don&apos;t care about and optimize/expunge. Then copy the index again and repeat the process, w/ a different range of ids. In fact, that&apos;s more or less what the method does - only it calls addIndexes, to copy into an existing/empty Directory.&lt;/p&gt;

&lt;p&gt;So I think it can be changed to not call addIndexes? Only problem is that now the method adds the docs into the target Directory directly, while in the other solution it will need to create a Directory on the side w/ the range of requested IDs and then copy that one into the target Dir?&lt;/p&gt;

&lt;p&gt;But I&apos;m not sure that&apos;s worth it to have addIndexes(IndexReader...) and the relevant code in SM which handles the non-SegmentReader readers? Of course, this is just one scenario, but if that&apos;s our justifying case, then I&apos;m not sure about how justifying it is.&lt;/p&gt;</comment>
                    <comment id="12868177" author="ab" created="Mon, 17 May 2010 12:33:53 +0100"  >&lt;p&gt;FYI, I&apos;m working on a different version of IndexSplitter that uses the logic in SegmentMerger directly, without going through IW.addIndexes(FilterIndexReader).&lt;/p&gt;

&lt;p&gt;However, there are other applications for which this API is crucial, e.g. &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1812&quot; title=&quot;Static index pruning by in-document term frequency (Carmel pruning)&quot;&gt;&lt;del&gt;LUCENE-1812&lt;/del&gt;&lt;/a&gt; or IndexSorter (in Nutch) - in short, any client apps that want to merge-in index data that does not correspond 1:1 to a Directory. For this reason I think the pair of IndexWriter.addIndexes(IndexReader...) and FilterIndexReader abstraction is extremely useful and that IndexWriter.addIndexes(Directory...) is not a sufficient replacement.&lt;/p&gt;

&lt;p&gt;(edit: unless there is a better user-level API based on the flex producers/consumers...)&lt;/p&gt;</comment>
                    <comment id="12868191" author="shaie" created="Mon, 17 May 2010 13:11:05 +0100"  >&lt;blockquote&gt;&lt;p&gt;any client apps that want to merge-in index data that does not correspond 1:1 to a Directory&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I understand that. But when you call addIndexes w/ such IndexReaders, all they do is read the postings. Those are written down using the logic of the target IndexWriter. So I wonder how important is it for addIndexes to be in place, rather than say rewriting those indexes before they are added? I mean, all that addIndexes will do is call SegmentMerger and iterate on the readers and segments, merging the posting lists ...&lt;/p&gt;

&lt;p&gt;I don&apos;t object to that API. But, SM is used extensively, and is more of a main-path code, while addIndexes(IndexReader) is something only few out there use. Yet it affects everyone else who reads SM code, as well as those of us who are confused about which method to call (Reader or Directory) ... It almost feels like such operation - the relevant code from SM which handles non-SegmentReaders, should be extracted to a utility or something. But if I&apos;m the only one that&apos;s bothered by it, then so be it. I can take care of the rest now, and resolve that one later.&lt;/p&gt;</comment>
                    <comment id="12868198" author="ab" created="Mon, 17 May 2010 13:26:07 +0100"  >&lt;p&gt;I understand - see the edited section in my comment: I think that extracting this non-SR code would be great. I would be in fact glad if there was an easier to control API that allows us to directly stream-process postings / stored / tvf-s / etc. in a way that results in a functioning index. Take for example &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1812&quot; title=&quot;Static index pruning by in-document term frequency (Carmel pruning)&quot;&gt;&lt;del&gt;LUCENE-1812&lt;/del&gt;&lt;/a&gt; - the only reason it uses addIndexes(IndexReader) is that there was no easy way to modify postings in a way that would still result in a valid index, and there was no other API to add artificially created postings (i.e. not coming from a Directory) to a target index.&lt;/p&gt;</comment>
                    <comment id="12868215" author="shaie" created="Mon, 17 May 2010 14:23:13 +0100"  >&lt;p&gt;So can&apos;t the PrunningReader run on the side, converting the postings to whatever they&apos;re supposed to look like in the index they are about to be added to, and then call addIndexes w/ the Directory to do the bulk copy? I mean, instead of looking for a standalone tool, perhaps this can be solved on a case by case basis? Of course, if this can be made generic enough, then we can add it as a core utility, or IW method.&lt;/p&gt;</comment>
                    <comment id="12868221" author="ab" created="Mon, 17 May 2010 14:45:09 +0100"  >&lt;blockquote&gt;&lt;p&gt;So can&apos;t the PrunningReader run on the side, converting the postings to whatever they&apos;re supposed to look like &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Erhm ... Currently the only way in the user API to write out existing postings (no matter how created) is to use IndexWriter.addIndexes(IndexReader). We can read postings just fine, using various *Enum classes that we can obtain from IndexReader, but there are no comparable high-level output methods  - Codecs and other flex classes are IMHO too low-level.&lt;/p&gt;

&lt;p&gt;Also, with large indexes the amount of IO/CPU for writing out a Directory and reopening it is non-trivial - it&apos;s much more efficient to do this via streaming from the original, already open index.&lt;/p&gt;

&lt;p&gt;Also, if we remove this method, then FilterIndexReader may as well go too, because it loses its utility.&lt;/p&gt;</comment>
                    <comment id="12868277" author="shaie" created="Mon, 17 May 2010 18:01:55 +0100"  >&lt;p&gt;Ok let&apos;s keep addIndexes(IndexReader) around. This means though that we cannot simplify the PPP API. We&apos;ll still need DirPP.&lt;/p&gt;</comment>
                    <comment id="12869563" author="shaie" created="Thu, 20 May 2010 12:07:59 +0100"  >&lt;p&gt;I&apos;ve started to implement addIndexes(Directory...) as agreed - copy files from the incoming ones into the local directory, while renaming them on the fly. This works really well with non-CFS segments: a new segment name is generated, the incoming files are renamed and this all flies smoothly (didn&apos;t test w/ deletions yet) - even shared doc stores work great.&lt;/p&gt;

&lt;p&gt;But with CFS it doesn&apos;t work well because CFS writes the file names in the CFS file itself, and so even if the segment is renamed to _5 (for example), the names that are written in the file are _2.* (for example), and openInput fails to locate them. To overcome this, I propose we do the following:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Introduce on IndexFileNames a stripName method (3x and trunk) - will return the file name w/o the _x part.&lt;/li&gt;
	&lt;li&gt;CFR ctor - strip names of read file names by calling IFN.stripName --&amp;gt; 3x only&lt;/li&gt;
	&lt;li&gt;CFR.openInput - strip name by calling IFN.stripName --&amp;gt; 3x and trunk&lt;/li&gt;
	&lt;li&gt;Document that files should be created through IFN only --&amp;gt; 3x (for clarity) and trunk (otherwise may not be supported).&lt;/li&gt;
	&lt;li&gt;Not save the name in CFS --&amp;gt; trunk only. Will remove the need to strip it off when it&apos;s read.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;That will ensure that files are named following a certain convention which we can rely on in CFR. I don&apos;t think it&apos;s too hard to ask for. CFS itself already knows the name - it&apos;s named like it. So there&apos;s no value in storing the names of the files it holds.&lt;/p&gt;

&lt;p&gt;For 3x it should work well b/c we don&apos;t allow for custom index files. For trunk we&apos;ll ask to go through IFN to name files - so one can create mycustom.file through IFN which will be called _x_mycustom.file.&lt;/p&gt;

&lt;p&gt;What do you think?&lt;/p&gt;</comment>
                    <comment id="12869581" author="mikemccand" created="Thu, 20 May 2010 13:15:04 +0100"  >&lt;p&gt;Ahh sneaky that CFS still embeds the old segment&apos;s name (you&apos;re right).  The only other option would be to rewrite the CFS header, but then that&apos;s not easy to do a bulk copy on.  So I like you&apos;re approach!&lt;/p&gt;

&lt;p&gt;We should  document in Codec.java that this (you must gen your filename via IFN&apos;s APIs) is a requirement of any custom files your codec wants to store in the index.&lt;/p&gt;</comment>
                    <comment id="12870276" author="shaie" created="Sat, 22 May 2010 07:14:23 +0100"  >&lt;p&gt;Patch includes the following:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;addIndexesNoOpt renamed to addIndexes2 for now, until we resolve the failing test (see below). I&apos;ll remove it and fix jdocs accordingly afterwards.&lt;/li&gt;
	&lt;li&gt;addIndexes(Dir...) implements the simple file copy strategy.&lt;/li&gt;
	&lt;li&gt;Tests updated accordingly.&lt;/li&gt;
	&lt;li&gt;Some minor changes to CompoundFileReader and IndexFileNames, as discussed before.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;All tests pass except for TestIndexWriter.testAddIndexesWithThreads. I&apos;ve debugged it, but cannot find the reason. addIndexes copies all segments, before it adds them to the writer&apos;s segmentInfos. Maybe I need to use start/commit transaction on that part only, to lock all ops? I don&apos;t see why, but maybe?&lt;/p&gt;

&lt;p&gt;Also, TestAddIndexes.testWithPendingDeletes2() (and some others) fail before I added a call to flush to addIndexes. It seems that w/o it, existing buffered deleted docs are ignored after addIndexes returns (even when no multi-threading is involved). Can someone please confirm that?&lt;/p&gt;

&lt;p&gt;Also, I cannot simplify PPP (to remove DirPP) because we kept addIndexes(Reader...). It&apos;s an annoyance if you don&apos;t call this method (need to return a DirPP for the target Dir always - if you want to use it), but maybe not so bad ...&lt;/p&gt;</comment>
                    <comment id="12870391" author="shaie" created="Sun, 23 May 2010 12:16:57 +0100"  >&lt;p&gt;Attached patch includes:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Fixes a bug that caused some tests to fail.&lt;/li&gt;
	&lt;li&gt;CFS is now versioned:
	&lt;ul&gt;
		&lt;li&gt;CFW writes a version header, and CFR reads it&lt;/li&gt;
		&lt;li&gt;CFW strips the segment name from the filename before writing it&lt;/li&gt;
		&lt;li&gt;CFR back-supports pre-3.1 indexes depending on the existence/absence of the version header.&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;TestBackwardsCompatibility now covers 3.0 indexes as well, and addIndexes* ops.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The beauty of all this is that IndexWriter no longer needs those transactions, and is now 500 lines of code + jdoc down !&lt;/p&gt;

&lt;p&gt;After we&apos;ve iterated through this patch, I&apos;ll do the same changes on trunk. Backwards support should be much easier there, because we will provide an index migration tool anyway, and so CFW/CFR can always assume they&apos;re reading the latest version (at least in 4.0). CFW should probably use CodecUtils in trunk - it cannot be used in 3x because of how CFW works today - writing a VInt first, while CodecUtils assumes an Int. And I don&apos;t think it&apos;s healthy to do so much changes on 3x.&lt;/p&gt;</comment>
                    <comment id="12870548" author="mikemccand" created="Mon, 24 May 2010 10:56:42 +0100"  >&lt;p&gt;Patch looks great!  So awesome seeing all the -&apos;s in IW.java!!  Keep it up &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;And it&apos;s great that you added 3.0 back compat case to&lt;br/&gt;
TestBackwardsCompatibility...&lt;/p&gt;

&lt;p&gt;Some feedback:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Can you change the code to read to a &quot;int firstInt&quot; instead of&lt;br/&gt;
    version?  And make an explicit version (say &quot;PRE_VERSION&quot;), and&lt;br/&gt;
    then check if version is PRE_VERSION in the code.  Ie, any tests&lt;br/&gt;
    against version (eg version &amp;gt; 0) should be against constants&lt;br/&gt;
    (version == PRE_VEFRSION) not against 0.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;CFW&apos;s comment should be &quot;make it 1 lower&quot; than the current one&lt;br/&gt;
    right?  Ie, -2 is the next version?&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12870549" author="mikemccand" created="Mon, 24 May 2010 10:59:46 +0100"  >&lt;blockquote&gt;&lt;p&gt;Backwards support should be much easier there, because we will provide an index migration tool anyway, and so CFW/CFR can always assume they&apos;re reading the latest version (at least in 4.0).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Hmm I think we should do live migration for this (ie don&apos;t require a&lt;br/&gt;
migration tool to fix your index)?  This is trivial to do on the fly&lt;br/&gt;
right (ie as you&apos;ve done in 3.x).&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;CFW should probably use CodecUtils in trunk - it cannot be used in 3x because of how CFW works today - writing a VInt first, while CodecUtils assumes an Int. And I don&apos;t think it&apos;s healthy to do so much changes on 3x.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Hmm yeah because of the live migration I think CodecUtils is not&lt;br/&gt;
actually a fit here (trunk or 3x).&lt;/p&gt;</comment>
                    <comment id="12870688" author="shaie" created="Mon, 24 May 2010 17:31:47 +0100"  >&lt;p&gt;I&apos;m not sure about the live migration, Mike. First because all the problems I&apos;ve mentioned about CodecUtils in 3x will apply to live migration of 3.x indexes in 4.0 code. Second, if everyone who upgrades to 4.0 will need to run the migration tool, then why do any work in supporting online migration? What&apos;s the benefit? Do u think of a case where someone upgrades to 4.0 w/o migrating his indexes (unless he reindexes of course, in which case there is no problem)?&lt;/p&gt;

&lt;p&gt;I just think it&apos;s weird that we support online migration together w/ a migration tool. If we migrate the indexes w/ the tool to include the new format of CFS, then the online migration code won&apos;t ever run, right? And not doing this in the tool seems just a waste? I mean the user already migrates his indexes, so why incur the cost of an additional online migration?&lt;/p&gt;</comment>
                    <comment id="12870724" author="mikemccand" created="Mon, 24 May 2010 18:27:54 +0100"  >&lt;p&gt;Sorry &amp;#8211; for each major release, I think it&apos;ll be either live&lt;br/&gt;
migration or offline migration, but not both.&lt;/p&gt;

&lt;p&gt;So far for 4.0 we haven&apos;t had a major enough structural change to the&lt;br/&gt;
index format, that&apos;d make live migration too hard/risky, so, so far I&lt;br/&gt;
think we can offer live migration for 4.0.&lt;/p&gt;

&lt;p&gt;The biggest change was flex, but it has the preflex codec to read (not&lt;br/&gt;
write) the pre-4.0 format... so, so far I think we can still offer&lt;br/&gt;
live migration for 4.0?&lt;/p&gt;</comment>
                    <comment id="12870735" author="shaie" created="Mon, 24 May 2010 18:44:15 +0100"  >&lt;p&gt;Ahh, I knew we must be talking past each other &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;. I assumed that the flex changes will go under the migration tool. If we have live migration for it, then I agree we should do live migration here.&lt;/p&gt;

&lt;p&gt;With that behind us, did someone start an API migration guide? Since I remove addIndexesnoOptimize in favor of the new addIndexes, I wanted to document it somewhere. It&apos;s a tiny change, so perhaps it can go other the API Changes in CHANGES?&lt;/p&gt;</comment>
                    <comment id="12870743" author="mikemccand" created="Mon, 24 May 2010 18:54:18 +0100"  >&lt;blockquote&gt;&lt;p&gt;With that behind us, did someone start an API migration guide?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Not yet, I think?  Go for it!&lt;/p&gt;</comment>
                    <comment id="12870761" author="shaie" created="Mon, 24 May 2010 19:24:36 +0100"  >&lt;p&gt;I will document it in CHANGES under API section. I think the migration guide format will need its own discussion, and I don&apos;t want to block that issue. When we&apos;ve agreed on the format (people have made few suggestions), I don&apos;t mind helping w/ porting everything relevant from changes to that guide.&lt;/p&gt;</comment>
                    <comment id="12871023" author="shaie" created="Tue, 25 May 2010 07:41:01 +0100"  >&lt;blockquote&gt;&lt;p&gt;CFW&apos;s comment should be &quot;make it 1 lower&quot;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Right ! I copied it from FieldsWriter where the versions are kept as positive ints. Will post a patch shortly.&lt;/p&gt;</comment>
                    <comment id="12871024" author="shaie" created="Tue, 25 May 2010 07:43:07 +0100"  >&lt;p&gt;Patch applies Mike&apos;s comments. I think this is ready to go in. I&apos;d like to commit to 3x before trunk, because there are lots of changes here.&lt;/p&gt;</comment>
                    <comment id="12871075" author="mikemccand" created="Tue, 25 May 2010 10:52:36 +0100"  >&lt;p&gt;Could you fix &quot;firstInt&apos; to have a very short life?&lt;/p&gt;

&lt;p&gt;Meaning, you read firstInt, and very quickly use that to assign to version &amp;amp; count, and no longer use it again.  Ie, all subsequent checks when loading should be against version, not firstInt...&lt;/p&gt;

&lt;p&gt;Also, can you maybe rename CFW.PRE_VERSION -&amp;gt; CFW.FORMAT_PRE_VERSION?  (to match the other FORMAT_X).&lt;/p&gt;

&lt;p&gt;Otherwise looks great!&lt;/p&gt;</comment>
                    <comment id="12871109" author="shaie" created="Tue, 25 May 2010 13:17:03 +0100"  >&lt;p&gt;The only place I see firstInt is used perhaps unnecessarily is in the for-loop. So I&apos;ve changed the code to look like this:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; count, version;
&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (firstInt &amp;lt; CompoundFileWriter.FORMAT_PRE_VERSION) {
  count = stream.readVInt();
  version = firstInt;
} &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
  count = firstInt;
  version = CompoundFileWriter.FORMAT_PRE_VERSION;
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And then I query for version == CompoundFileWriter.FORMAT_PRE_VERSION inside the for-loop. Is that what you meant?&lt;/p&gt;

&lt;p&gt;There is a check before all that ensuring that read firstInt does not indicate an index corruption &amp;#8211; that should remain as-is, right?&lt;/p&gt;</comment>
                    <comment id="12871225" author="shaie" created="Tue, 25 May 2010 17:14:07 +0100"  >&lt;p&gt;Update w/ comments. I plan to commit this either later today or tomorrow (and then port it to trunk). So if you haven&apos;t done so and want a last chance review - that&apos;s your chance.&lt;/p&gt;</comment>
                    <comment id="12871233" author="mikemccand" created="Tue, 25 May 2010 17:30:28 +0100"  >&lt;p&gt;Patch looks good Shai!  Thanks.&lt;/p&gt;</comment>
                    <comment id="12871622" author="shaie" created="Wed, 26 May 2010 12:11:15 +0100"  >&lt;p&gt;Committed revision 948394 (3x).&lt;/p&gt;

&lt;p&gt;Will now port everything to trunk&lt;/p&gt;</comment>
                    <comment id="12871630" author="thetaphi" created="Wed, 26 May 2010 12:30:53 +0100"  >&lt;p&gt;Hi Shai,&lt;/p&gt;

&lt;p&gt;I have seen this only lately. You added a 3.0 Index ZIP to the tests. This conflicts a little bit with trunk, where a 3.0 Index ZIP is already available. I would prefer to keep the &quot;older version&quot; ZIPs equal against each release, so it would be fine, if the trunk-added numerics backwards test could also be in 3.x branch. Would this be possible? You have to just merge the code.&lt;/p&gt;

&lt;p&gt;Also it looks strange that the 3.0 backwards tests now contain also 3.0 index ZIPs, but there is no code for that??? Why have you added this to backwards? The 3.0 backwards tests should only modify this one addindexes test, but not add the zips. Maybe simple delete, they are not used.&lt;/p&gt;

&lt;p&gt;By the way the 3.0 index zip file generation code is in the 3.0 branch, have you edited it there? You should commit the code there so one is able to regenerate the 3.0 ZIPs from the stable 3.0.x branch.&lt;/p&gt;</comment>
                    <comment id="12871631" author="thetaphi" created="Wed, 26 May 2010 12:35:56 +0100"  >&lt;p&gt;I looked at the code, it simply tests trhat old indexes can be added. Maybe you just copy the trunk ZIPs for 3.0 to the 3x branch to keep them consistent. The files dont seem to be equal.&lt;/p&gt;</comment>
                    <comment id="12871639" author="shaie" created="Wed, 26 May 2010 13:10:12 +0100"  >&lt;p&gt;Ok I added the indexes from trunk (didn&apos;t know they were there). I&apos;ve changed CFS to write a version header in the file, so that&apos;s why I&apos;ve added a 3.0 index - to make sure it can be read properly by 3.1. What I&apos;ve added to TestBackwardsCompatibility are tests to ensure that addIndexes work on old indexes (which was good, because after the changes they weren&apos;t !).&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Maybe simple delete, they are not used.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The testAddIndexes were just added, and the 30 indexes are used. So I cannot delete them (see my comment above)&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;By the way the 3.0 index zip file generation code is in the 3.0 branch, have you edited it there?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Nope, it exists in TestBackwardsCompatibility as commented out, w/ instructions to uncomment. I&apos;ve used that code.&lt;/p&gt;</comment>
                    <comment id="12871641" author="shaie" created="Wed, 26 May 2010 13:11:37 +0100"  >&lt;p&gt;While porting the code to trunk, I&apos;ve noticed that acquireRead/Write, releaseRead/Write, upgradeReadToWrite are either not called anymore, or called in relation to addIndexes. So I think these can be safely removed as well (from 3x and trunk)?&lt;/p&gt;</comment>
                    <comment id="12871718" author="mikemccand" created="Wed, 26 May 2010 13:34:04 +0100"  >&lt;blockquote&gt;&lt;p&gt;So I think these can be safely removed as well (from 3x and trunk)?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think so!&lt;/p&gt;</comment>
                    <comment id="12871728" author="shaie" created="Wed, 26 May 2010 13:54:14 +0100"  >&lt;p&gt;Committed revision 948415 (copied the 3.0 indexes from trunk) and removed more unnecessary code from IndexWriter.&lt;/p&gt;</comment>
                    <comment id="12872127" author="shaie" created="Thu, 27 May 2010 08:45:39 +0100"  >&lt;p&gt;Like the 3x patch, only this one changes IndexFileNames.segmentFileName to take another parameter for custom names, as well as update some jdocs to match flex (Codecs). I think this is ready to go in.&lt;/p&gt;</comment>
                    <comment id="12872140" author="thetaphi" created="Thu, 27 May 2010 09:32:02 +0100"  >&lt;p&gt;Should we not add a 3.1 index (created with HEAD 3.x branch) to the TestBackwardsCompatibility? So we can verify that preflex indexes with new CFS header also work?&lt;/p&gt;</comment>
                    <comment id="12872149" author="shaie" created="Thu, 27 May 2010 09:55:55 +0100"  >&lt;p&gt;Yes! I&apos;ll add them and update the tests. Will post a patch after I get more comments&lt;/p&gt;</comment>
                    <comment id="12872153" author="shaie" created="Thu, 27 May 2010 10:13:28 +0100"  >&lt;p&gt;Hmm ... I&apos;ve created the indexes using the 3x branch, copied them to trunk and updated TestBackwardsCompatibility to refer to them. All tests pass except for testNumericFields. It fails on both CFS and non-CFS indexes, and so I&apos;m not sure it&apos;s related to this issue at all. The failure is this:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
junit.framework.AssertionFailedError: wrong number of hits expected:&amp;lt;1&amp;gt; but was:&amp;lt;0&amp;gt;
	at org.apache.lucene.index.TestBackwardsCompatibility.testNumericFields(TestBackwardsCompatibility.java:773)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Can you try to run it on your checkout?&lt;/p&gt;</comment>
                    <comment id="12872156" author="thetaphi" created="Thu, 27 May 2010 10:43:58 +0100"  >&lt;p&gt;For me it passes.&lt;/p&gt;

&lt;p&gt;Are you sure that you used the &lt;b&gt;latest&lt;/b&gt; checkout of 3x. I added the index generation code yesterday after your last 3x commit. This code was not merged to 3x from trunk, as it was postflex added. This is done sice yesterday:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Author: uschindler
Date: Wed May 26 13:13:10 2010
New Revision: 948420

URL: http://svn.apache.org/viewvc?rev=948420&amp;amp;view=rev
Log:
Merge the 3.0 index backwards tests from trunk (numeric field support). This makes it consistent across all branches.

Modified:
    lucene/dev/branches/branch_3x/lucene/src/test/org/apache/lucene/index/   (props changed)
    lucene/dev/branches/branch_3x/lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java   (contents, props changed)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I attached the generated ZIP files from my 3x checkout.&lt;/p&gt;</comment>
                    <comment id="12872182" author="shaie" created="Thu, 27 May 2010 12:23:07 +0100"  >&lt;p&gt;Yes - after I updated my checkout and re-create the indexes, the test passes. So I will include them with this patch as well.&lt;/p&gt;</comment>
                    <comment id="12872258" author="shaie" created="Thu, 27 May 2010 16:37:06 +0100"  >&lt;p&gt;Committed revision 948861 (trunk).&lt;/p&gt;</comment>
                    <comment id="13013510" author="gsingers" created="Wed, 30 Mar 2011 16:50:31 +0100"  >&lt;p&gt;Bulk close for 3.1&lt;/p&gt;</comment>
                </comments>
                    <attachments>
                    <attachment id="12445632" name="index.31.cfs.zip" size="4792" author="thetaphi" created="Thu, 27 May 2010 10:43:58 +0100" />
                    <attachment id="12445633" name="index.31.nocfs.zip" size="8951" author="thetaphi" created="Thu, 27 May 2010 10:43:58 +0100" />
                    <attachment id="12445469" name="LUCENE-2455_3x.patch" size="107333" author="shaie" created="Tue, 25 May 2010 17:14:07 +0100" />
                    <attachment id="12445427" name="LUCENE-2455_3x.patch" size="107236" author="shaie" created="Tue, 25 May 2010 07:43:06 +0100" />
                    <attachment id="12445252" name="LUCENE-2455_3x.patch" size="107108" author="shaie" created="Sun, 23 May 2010 12:16:57 +0100" />
                    <attachment id="12445232" name="LUCENE-2455_3x.patch" size="78832" author="shaie" created="Sat, 22 May 2010 07:14:23 +0100" />
                    <attachment id="12444493" name="LUCENE-2455_3x.patch" size="57000" author="shaie" created="Fri, 14 May 2010 14:43:22 +0100" />
                    <attachment id="12445628" name="LUCENE-2455_trunk.patch" size="144237" author="shaie" created="Thu, 27 May 2010 08:45:39 +0100" />
                </attachments>
            <subtasks>
        </subtasks>
                <customfields>
                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                <customfieldname>Attachment count</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>8.0</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                <customfieldname>Date of First Response</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>Tue, 11 May 2010 10:04:54 +0000</customfieldvalue>

                </customfieldvalues>
            </customfield>
                                                                                                        <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Global Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>11364</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                <customfieldname>Lucene Fields</customfieldname>
                <customfieldvalues>
                        <customfieldvalue key="10121"><![CDATA[New]]></customfieldvalue>
    <customfieldvalue key="10120"><![CDATA[Patch Available]]></customfieldvalue>
    
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>25237</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                <customfieldname>Time in Status</customfieldname>
                <customfieldvalues>
                    
                </customfieldvalues>
            </customfield>
                            </customfields>
    </item>
</channel>
</rss>