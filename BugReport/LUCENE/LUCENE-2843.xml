<!-- 
RSS generated by JIRA (5.2.8#851-sha1:3262fdc28b4bc8b23784e13eadc26a22399f5d88) at Tue Jul 16 13:22:46 UTC 2013

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/LUCENE-2843/LUCENE-2843.xml?field=key&field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>5.2.8</version>
        <build-number>851</build-number>
        <build-date>26-02-2013</build-date>
    </build-info>

<item>
            <title>[LUCENE-2843] Add variable-gap terms index impl.</title>
                <link>https://issues.apache.org/jira/browse/LUCENE-2843</link>
                <project id="12310110" key="LUCENE">Lucene - Core</project>
                        <description>&lt;p&gt;PrefixCodedTermsReader/Writer (used by all &quot;real&quot; core codecs) already&lt;br/&gt;
supports pluggable terms index impls.&lt;/p&gt;

&lt;p&gt;The only impl we have now is FixedGapTermsIndexReader/Writer, which&lt;br/&gt;
picks every Nth (default 32) term and holds it in efficient packed&lt;br/&gt;
int/byte arrays in RAM.  This is already an enormous improvement (RAM&lt;br/&gt;
reduction, init time) over 3.x.&lt;/p&gt;

&lt;p&gt;This patch adds another impl, VariableGapTermsIndexReader/Writer,&lt;br/&gt;
which lets you specify an arbitrary IndexTermSelector to pick which&lt;br/&gt;
terms are indexed, and then uses an FST to hold the indexed terms.&lt;br/&gt;
This is typically even more memory efficient than packed int/byte&lt;br/&gt;
arrays, though, it does not support ord() so it&apos;s not quite a fair&lt;br/&gt;
comparison.&lt;/p&gt;

&lt;p&gt;I had to relax the terms index plugin api for&lt;br/&gt;
PrefixCodedTermsReader/Writer to not assume that the terms index impl&lt;br/&gt;
supports ord.&lt;/p&gt;

&lt;p&gt;I also did some cleanup of the FST/FSTEnum APIs and impls, and broke&lt;br/&gt;
out separate seekCeil and seekFloor in FSTEnum.  Eg we need seekFloor&lt;br/&gt;
when the FST is used as a terms index but seekCeil when it&apos;s holding&lt;br/&gt;
all terms in the index (ie which SimpleText uses FSTs for).&lt;/p&gt;</description>
                <environment></environment>
            <key id="12494480">LUCENE-2843</key>
            <summary>Add variable-gap terms index impl.</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                    <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png">Closed</status>
                    <resolution id="1">Fixed</resolution>
                                <assignee username="mikemccand">Michael McCandless</assignee>
                                <reporter username="mikemccand">Michael McCandless</reporter>
                        <labels>
                    </labels>
                <created>Mon, 3 Jan 2011 11:04:32 +0000</created>
                <updated>Fri, 10 May 2013 11:44:50 +0100</updated>
                    <resolved>Wed, 5 Jan 2011 10:52:18 +0000</resolved>
                                            <fixVersion>4.0-ALPHA</fixVersion>
                                <component>core/index</component>
                        <due></due>
                    <votes>0</votes>
                        <watches>0</watches>
                                                    <comments>
                    <comment id="12976699" author="mikemccand" created="Mon, 3 Jan 2011 11:09:52 +0000"  >&lt;p&gt;Attached patch.&lt;/p&gt;

&lt;p&gt;Still some nocommits but I think it&apos;s close... though I still need to&lt;br/&gt;
get indexDivisor working for var gap.  Note that this patch changes&lt;br/&gt;
the index format, even for Standard codec (using fixed gap terms&lt;br/&gt;
index).&lt;/p&gt;

&lt;p&gt;A few tests fail because they assume Standard codec supports ord...&lt;/p&gt;

&lt;p&gt;To properly test the alternatives we now have for the terms index&lt;br/&gt;
(including fixed vs variable, and then different index term selectors&lt;br/&gt;
fro the variable case), I created a new fun testing codec,&lt;br/&gt;
MockRandomCodec.  It randomly pairs up a postings impl with a terms&lt;br/&gt;
index impl.  EG it sometimes uses an IndexTermPolicy that randomly&lt;br/&gt;
picks index terms.  We may now be able to remove the other Mock*&lt;br/&gt;
codecs...&lt;/p&gt;</comment>
                    <comment id="12976709" author="mikemccand" created="Mon, 3 Jan 2011 11:57:05 +0000"  >&lt;p&gt;As a first test, I just made a policy that&apos;s identical to the fixed&lt;br/&gt;
gap terms index, ie, it just picks every 32nd term as the index term.&lt;br/&gt;
So this is really a test of the packed int/bytes vs FST.&lt;/p&gt;

&lt;p&gt;On the 10M Wikipedia test index, the resulting terms index files (=&lt;br/&gt;
RAM used by SegmentReader) is ~38% smaller (~52% once optimized &amp;#8211; FST&lt;br/&gt;
&quot;scales up&quot; well).&lt;/p&gt;

&lt;p&gt;Here&apos;s the query perf vs trunk:&lt;/p&gt;

&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Query&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;QPS base&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;QPS vargap&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Pct diff&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;spanFirst(unit, 5)&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;17.13&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;16.75&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-2.2%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;unit state&quot;~3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5.31&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5.20&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-2.1%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;spanNear(&lt;span class=&quot;error&quot;&gt;&amp;#91;unit, state&amp;#93;&lt;/span&gt;, 10, true)&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4.59&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4.52&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-1.4%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;unit state&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;7.86&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;7.77&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-1.1%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+nebraska +state&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;204.74&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;202.85&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-0.9%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+unit +state&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;11.37&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;11.30&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-0.6%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;doctimesecnum:&lt;span class=&quot;error&quot;&gt;&amp;#91;10000 TO 60000&amp;#93;&lt;/span&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;9.74&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;9.76&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;0.2%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;unit~1.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;21.70&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;21.82&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;0.6%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;unit*&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;26.18&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;26.55&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;1.4%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;state&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;29.29&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;29.75&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;1.6%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;uni*&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;15.06&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;15.32&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;1.7%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;unit state&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10.73&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10.93&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;1.9%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;unit~2.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;21.05&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;21.45&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;1.9%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;un*d&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;77.10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;79.65&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;3.3%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;u*d&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;26.41&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;28.81&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;9.1%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;united~1.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;102.27&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;116.88&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;14.3%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;united~2.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;25.47&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;31.18&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;22.4%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;


&lt;p&gt;It&apos;s great that for the seek intensive fuzzy queries, the FST-based&lt;br/&gt;
seeking is substantially faster.  For other queries the term seek time&lt;br/&gt;
is in the noise.&lt;/p&gt;

&lt;p&gt;I think we should make this (VariableGapTermsIndex) terms index impl&lt;br/&gt;
the default (for Standard codec).&lt;/p&gt;</comment>
                    <comment id="12976724" author="rcmuir" created="Mon, 3 Jan 2011 13:06:52 +0000"  >&lt;p&gt;I like this idea, it would be interesting to see what other type of policies we can come up with.&lt;/p&gt;

&lt;p&gt;Just curious, how would the &apos;let FST decide&apos; work? Do we have some quick way to know that &lt;br/&gt;
selecting term X versus term Y would reduce the number of states/transitions? Isn&apos;t the resulting&lt;br/&gt;
FST size also dependent upon the output value (terms dict file pointer)? And if we optimize&lt;br/&gt;
this locally (X versus Y) does it tend to hold globally?&lt;/p&gt;</comment>
                    <comment id="12976893" author="mikemccand" created="Mon, 3 Jan 2011 19:20:17 +0000"  >&lt;blockquote&gt;&lt;p&gt;Just curious, how would the &apos;let FST decide&apos; work?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The FST builder is able to prune-as-it-builds.  EG it prunes a node if the number of unique terms going through it is less than N.  Alternatively, it prunes if the node just before had &amp;lt; N nodes coming through.  To do this we&apos;d pass all terms to the builder, and specify the prune threshold.  So the FST would be &quot;bushy&quot;/deep when terms are a high density, and shallowish elsewhere.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Isn&apos;t the resulting&lt;br/&gt;
FST size also dependent upon the output value (terms dict file pointer)? And if we optimize&lt;br/&gt;
this locally (X versus Y) does it tend to hold globally?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes, very much so &amp;#8211; the more stuff you store in the output the bigger the FST.  But we only store the long file pointer into the main terms dict for this usage, and the FST is efficient (delta-codes the long values).  But, I&apos;m not trying in anyway to minimize that net size (in bytes)...&lt;/p&gt;</comment>
                    <comment id="12977246" author="mikemccand" created="Tue, 4 Jan 2011 11:35:41 +0000"  >&lt;p&gt;New patch, resolving all nocommits.  I think it&apos;s ready to commit.&lt;/p&gt;

&lt;p&gt;I cutover StandardCodec to the VariableGapTermsIndex, with &apos;every 32&apos; as the index term selection policy.  We could lower 32 to eg 20, since FST uses so much less RAM than packed ints/bytes, but for now I&apos;m just leaving it at 32 to be safe.&lt;/p&gt;

&lt;p&gt;The &quot;let FST builder pick the indexed terms&quot; turns out not to be very easy to do w/ this API.  I put a big comment explaining this in the var gap writer.  It&apos;s also not clear we&apos;d want to use this approach, since the resulting term index density can then vary substantially.&lt;/p&gt;</comment>
                    <comment id="12979277" author="earwin" created="Sun, 9 Jan 2011 08:57:08 +0000"  >&lt;p&gt;And we&apos;re nearing a day when we keep the whole term dictionary in memory (as Sphinx does for instance).&lt;br/&gt;
At that point a gazillion of term lookup-related hacks (like lookup cache) become obsolete &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
Term dictionary itself can also be memory-mapped after this, instead of being &quot;read&quot; and &quot;built&quot; from disk, which makes new segment opening near-instantaneous.&lt;/p&gt;</comment>
                    <comment id="12979292" author="mikemccand" created="Sun, 9 Jan 2011 11:07:15 +0000"  >&lt;p&gt;In-memory terms dict would be great.  I agree it&apos;d fundamentally change how we execute eg the automaton queries (suddenly we can just intersect against the terms dict instead of doing the seek/next thing); FuzzyQuery might be a direct search through the terms dict instead of first building the LevN DFA; respelling similarly...&lt;/p&gt;

&lt;p&gt;But, I suspect we&apos;ll always have to support the &quot;on-disk only&quot; option because some apps seem to have an insane number of terms.&lt;/p&gt;</comment>
                    <comment id="12979305" author="earwin" created="Sun, 9 Jan 2011 11:50:43 +0000"  >&lt;p&gt;As I said, there&apos;s already a search server with strictly in-memory (in mmap sense. it can theoretically be paged out) terms dict AND widespread adoption. Their users somehow manage.&lt;/p&gt;

&lt;p&gt;My guess is that&apos;s because people with &quot;insane number of terms&quot; store various crap like unique timestamps as terms. With CSF (&quot;attributes&quot; in Sphinx lingo), and some nice filters that can work over CSF, there&apos;s no longer any need to stuff your timestamps in the same place you stuff your texts. That can be reflected in documentation, and then, suddenly, we can drop &quot;on-disk only&quot; support.&lt;/p&gt;</comment>
                    <comment id="12979313" author="rcmuir" created="Sun, 9 Jan 2011 12:23:58 +0000"  >&lt;blockquote&gt;&lt;p&gt;As I said, there&apos;s already a search server with strictly in-memory (in mmap sense. it can theoretically be paged out) terms dict AND widespread adoption. Their users somehow manage&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don&apos;t like the reasoning that, just because sphinx does it and their &apos;users manage&apos;, that makes it ok.&lt;br/&gt;
sphinx also requires mysql, which only when started supporting &lt;b&gt;real&lt;/b&gt; utf-8?! (not that 3-byte crap they tried to pass off instead)&lt;/p&gt;

&lt;p&gt;I don&apos;t think we should really be looking there for inspiration.&lt;/p&gt;</comment>
                    <comment id="12979334" author="mikemccand" created="Sun, 9 Jan 2011 14:32:12 +0000"  >&lt;p&gt;Yes doc values should cut back on these large term dicts.&lt;/p&gt;

&lt;p&gt;But, I&apos;m not a fan of pure disk-based terms dict.  Expecting the OS to make good decisions on what gets swapped out is risky &amp;#8211; Lucene is better informed than the OS on which data structures are worth spending RAM on (norms, terms index, field cache, del docs).&lt;/p&gt;

&lt;p&gt;If indeed the terms dict (thanks to FSTs) becomes small enough to &quot;fit&quot; in RAM, then we should load it into RAM (and do away w/ the terms index).&lt;/p&gt;</comment>
                    <comment id="12979345" author="yseeley@gmail.com" created="Sun, 9 Jan 2011 15:11:11 +0000"  >&lt;blockquote&gt;&lt;p&gt;Their users somehow manage. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That neglects to count those who are not users because they could not manage with the limitations &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;Anyway, being able to optionally keep the term dict in memory, per-field, if it&apos;s below a certain limits (terms/memory or whatever) would be very cool!&lt;/p&gt;</comment>
                    <comment id="12979346" author="earwin" created="Sun, 9 Jan 2011 15:26:13 +0000"  >&lt;blockquote&gt;&lt;p&gt;I don&apos;t like the reasoning that, just because sphinx does it and their &apos;users manage&apos;, that makes it ok.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I&apos;m in no way advocating it as an all-round better solution. It has it&apos;s wrinkles just as anything else.&lt;br/&gt;
My reasoning is merely that alternative exists, and it is viable. As proven by pretty high-profile users.&lt;br/&gt;
They have memory-resident term dictionary, and it works, I heard no complaints regarding this ever.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;sphinx also requires mysql&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Have you read anything at all? It has an integration ready, for the layman user who just wants to stick a fulltext search into their little app, but it is in no way reliant on it.&lt;br/&gt;
Sphinx is a direct alternative to Solr.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;But, I&apos;m not a fan of pure disk-based terms dict. Expecting the OS to make good decisions on what gets swapped out is risky - Lucene is better informed than the OS on which data structures are worth spending RAM on (norms, terms index, field cache, del docs).&lt;br/&gt;
If indeed the terms dict (thanks to FSTs) becomes small enough to &quot;fit&quot; in RAM, then we should load it into RAM (and do away w/ the terms index).&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;That&apos;s a bit delusional. If a system is forced to swap out, it&apos;ll swap your explicitly managed RAM just as likely as memory-mapped files. I&apos;ve seen this countless times.&lt;br/&gt;
But then, you have a number of benefits - like sharing filesystem cache when opening same file multiple times, offloading things from Java heap (which is almost always a good thing), fastest load-into-memory times possible.&lt;/p&gt;


&lt;p&gt;Sorry, if I sound offending at times, but, damn, there&apos;s a whole world of simple and efficient code lying ahead in that direction &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="12979347" author="rcmuir" created="Sun, 9 Jan 2011 15:57:32 +0000"  >&lt;blockquote&gt;&lt;p&gt;Have you read anything at all?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Nope, havent looked at their code... i think i stopped at the documentation when i saw how they analyzed text!&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Sorry, if I sound offending at times, but, damn, there&apos;s a whole world of simple and efficient code lying ahead in that direction&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;So where is the problem?&lt;/p&gt;

&lt;p&gt;You can make your own all-on-disk impl, or all-in-ram impl and contribute it? And you dont have to implement terms dict cache,&lt;br/&gt;
thats contained in the implementation?&lt;/p&gt;

&lt;p&gt;My problem is that we shouldnt assume all users can fit all their terms in RAM.&lt;/p&gt;

&lt;p&gt;I think its great to offer alternative impls that work all in ram, and maybe if termsdict &amp;lt; X where X is some configurable value,&lt;br/&gt;
even consider using these automatically in standardcodec... but i don&apos;t see any benefit of &apos;forcing&apos; this when we have this&lt;br/&gt;
whole flexible indexing thing!&lt;/p&gt;</comment>
                    <comment id="12979348" author="yseeley@gmail.com" created="Sun, 9 Jan 2011 15:58:58 +0000"  >&lt;blockquote&gt;&lt;p&gt;My reasoning is merely that alternative exists, and it is viable. As proven by pretty high-profile users.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Actually, I sort of agree.  I read the &quot;in memory&quot; too fast and didn&apos;t realize you were talking about memory mapped.&lt;br/&gt;
There are other parts of sphinx that are kept directly in memory (not memory mapped) and do limit it&apos;s single-node scalability too much IMO.&lt;br/&gt;
Unfortunately, Java has additional overhead wrt mmap,  and you also can&apos;t do some stuff that you could do in C.  All this means is that trade-offs that made sense for C/C++ solutions may or may not make sense for Java solutions.&lt;/p&gt;</comment>
                    <comment id="12979353" author="rcmuir" created="Sun, 9 Jan 2011 16:20:27 +0000"  >&lt;blockquote&gt;&lt;p&gt;Unfortunately, Java has additional overhead wrt mmap&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Its not just that, you cant assume mmap even &quot;works&quot; (32-bit platform, even some troubles on 64-bit windows).&lt;br/&gt;
Because this is a search engine library, not just a server on 64-bit linux only, then we need to support&lt;br/&gt;
other situations like 32-bit users doing desktop search.&lt;/p&gt;

&lt;p&gt;In other words, Test2BTerms in src/test should pass on my 32-bit windows machine with whatever we default to.&lt;/p&gt;</comment>
                    <comment id="12979366" author="earwin" created="Sun, 9 Jan 2011 16:56:16 +0000"  >&lt;blockquote&gt;&lt;p&gt;Nope, havent looked at their code... i think i stopped at the documentation when i saw how they analyzed text!&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;All my points are contained within their documentation. No need to look at the code (it&apos;s as shady as Lucene&apos;s).&lt;br/&gt;
In the same manner, Lucene had crappy analyzis for years, until you&apos;ve taken hold of (unicode) police baton.&lt;br/&gt;
So let&apos;s not allow color differences between our analyzers affect our judgement on other parts of ours : )&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;In other words, Test2BTerms in src/test should pass on my 32-bit windows machine with whatever we default to.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I&apos;m questioning is there any legal, adequate reason to have that much terms.&lt;br/&gt;
I&apos;m agreeing on mmap+32bit/mmap+windows point for reasonable amount of terms though :/&lt;/p&gt;

&lt;p&gt;A hybrid solution, with term-dict being loaded completely into memory (either via mmap, or into arrays) on per-field basis, is probably best in the end, however sad it may be.&lt;/p&gt;</comment>
                    <comment id="12979372" author="rcmuir" created="Sun, 9 Jan 2011 17:13:40 +0000"  >&lt;blockquote&gt;&lt;p&gt;A hybrid solution, with term-dict being loaded completely into memory (either via mmap, or into arrays) on per-field basis, is probably best in the end, however sad it may be.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Whats the sad part again? why does it bother you if there is another alternative codec setup or terms dict implementation if you aren&apos;t using it?&lt;br/&gt;
Should we also only have RAMDirectory and MMapDirectory and its sad that we have NIOFSDirectory?&lt;/p&gt;</comment>
                    <comment id="12979553" author="mikemccand" created="Mon, 10 Jan 2011 12:03:31 +0000"  >&lt;blockquote&gt;&lt;p&gt;If a system is forced to swap out, it&apos;ll swap your explicitly managed RAM just as likely as memory-mapped files.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;In fact, even if it&apos;s not under any real memory pressure the OS will swap out your not-recently-accessed RAM.  Net/net this is a good policy, if your metric is total throughput accomplished by all programs.&lt;/p&gt;

&lt;p&gt;But if your metric is latency to search queries, this is an awful policy.&lt;/p&gt;

&lt;p&gt;Fortunately OSs (at least Windows &amp;amp; Linux) give you some tunability here.  Unfortunately, the tunable is global and it defaults &quot;badly&quot; for those programs that do make a careful distinction b/w what data structures are best held in RAM and what data is best left on disk.&lt;/p&gt;

&lt;p&gt;If I could I would offer an option to pin these pages, so the OS cannot swap them out, but I don&apos;t think we can do (easily) that from javaland (and I think you&apos;d have to be root).  Lacking pinning the best (approximation) we can do is pull these ourselves into RAM.&lt;/p&gt;</comment>
                    <comment id="12989662" author="toke" created="Wed, 2 Feb 2011 15:05:44 +0000"  >&lt;p&gt;I see that the VariableGapTermsIndexReader/Writer is now the default (or at least an experimental default) in trunk. This means that ord() and consequently seek() are not available. Are you, Michael, planning on adding these later on or are they gone for good?&lt;/p&gt;

&lt;p&gt;If they are gone for good, it does represent a bit of a problem for me as I use ord() and seek() for a memory-efficient hierarchical faceting system. Not having those in the default reader/writer means that most indexes &quot;out there&quot; will not support accessing terms by ordinals and that my code won&apos;t work on them unless they are re-build. Boo hoo for me, but not implementing the interface fully in the default implementation seems wrong. Or maybe the interface should be changed?&lt;/p&gt;</comment>
                    <comment id="12989666" author="rcmuir" created="Wed, 2 Feb 2011 15:15:29 +0000"  >&lt;blockquote&gt;&lt;p&gt;Or maybe the interface should be changed?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;+1, ord is not an interface, its an implementation detail specific&lt;br/&gt;
to only certain basic implementations that shouldn&apos;t be in TermsEnum.&lt;/p&gt;

&lt;p&gt;i would much prefer if this were some attribute, or somehow exposed&lt;br/&gt;
via those implementations&apos; TermStates... as in my opinion its really &lt;br/&gt;
actually an implementation detail of TermState, not even terms.&lt;/p&gt;</comment>
                    <comment id="12989670" author="mikemccand" created="Wed, 2 Feb 2011 15:26:39 +0000"  >&lt;p&gt;Toke, the FixedGapTermsIndexWriter/Reader supports ord, but requires more RAM for the terms index and may cause some queries to run slower.&lt;/p&gt;

&lt;p&gt;Can you describe how your faceting system is using ord?&lt;/p&gt;</comment>
                    <comment id="12989672" author="rcmuir" created="Wed, 2 Feb 2011 15:37:36 +0000"  >&lt;p&gt;Also, if faceting wants to exploit a codec-specific implementation detail,&lt;br/&gt;
its far more interesting to evaluate things like changing VariableGapIndex&apos;s &lt;br/&gt;
FST output to be a pair including max(docFreq) for the block it indexes.&lt;/p&gt;

&lt;p&gt;Then, faceting that wants to get the top-10 terms by docfreq, would &lt;br/&gt;
instead work an FSTEnum, and only go to disk for the top-10 blocks... this&lt;br/&gt;
would actually be a change in complexity order no?&lt;/p&gt;</comment>
                    <comment id="12989679" author="toke" created="Wed, 2 Feb 2011 15:47:50 +0000"  >&lt;p&gt;Thank you. I will use the FixedGap-version myself, but that only works when I&apos;m the one controlling the index build, right?&lt;/p&gt;

&lt;p&gt;As for the faceting system then the principle really simple: Instead of holding terms (BytesRefs) in memory, I just hold their ordinals. As the terms themselves only need to be resolved when the final faceting result is to be returned, seeking for a few hundred or thousand terms by their ordinal has worked very well so far (no guarantees for old hardware such as spinning disks though).&lt;/p&gt;

&lt;p&gt;The memory savings over holding BytesRefs in memory of course varies with term lengths. There are some numbers at &lt;a href=&quot;https://sbdevel.wordpress.com/2010/10/11/hierarchical-faceting/&quot; class=&quot;external-link&quot;&gt;https://sbdevel.wordpress.com/2010/10/11/hierarchical-faceting/&lt;/a&gt; if someone finds it interesting and &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-2369&quot; title=&quot;Locale-based sort by field with low memory overhead&quot;&gt;LUCENE-2369&lt;/a&gt; has some measurements of the same principle applied to sorting.&lt;/p&gt;</comment>
                    <comment id="12989691" author="toke" created="Wed, 2 Feb 2011 16:11:23 +0000"  >&lt;p&gt;Robert, there is already OrdTermState to hold the ord, but the ordinal itself is only interesting if the corresponding term can be seeked from it. Upon further inspection I see that the method &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;TermsIndexReaderBase.supportsOrd()&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt; is coupled logically to &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;seek(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; ord)&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt; and &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;ord()&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt; so support for ordinals does not seem like something one can expect.&lt;/p&gt;

&lt;p&gt;As for the FSTEnum-idea then I don&apos;t understand how it can work with faceting where the terms to return are defined by the documents from a search? ...But maybe we should discuss that elsewhere.&lt;/p&gt;</comment>
                    <comment id="12989695" author="rcmuir" created="Wed, 2 Feb 2011 16:18:58 +0000"  >&lt;blockquote&gt;&lt;p&gt;Robert, there is already OrdTermState to hold the ord, but the ordinal itself is only interesting if the corresponding term can be seeked from it. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;You can seek to any arbitrary TermState (even if its not holding ord), but it might hold other things you don&apos;t care about.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;As for the FSTEnum-idea then I don&apos;t understand how it can work with faceting where the terms to return are defined by the documents from a search? ...But maybe we should discuss that elsewhere.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;In the general case, if you are using something like a priority queue to get the top-N terms (even if you are filtering by the documents from a search), this number would mean that once your priority queue is full, you can tell that an entire block of low freq terms is not-competitive to enter the PQ, without going to disk?&lt;/p&gt;</comment>
                    <comment id="12990123" author="mikemccand" created="Thu, 3 Feb 2011 15:24:11 +0000"  >&lt;blockquote&gt;&lt;p&gt;Thank you. I will use the FixedGap-version myself, but that only works when I&apos;m the one controlling the index build, right?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Right, but, this is fair?  I mean, it&apos;s easy (in Lucene 4.0) to pick the appropriate codec per field.  So, if people want to use your faceting package, and you explain that it requires using a certain Codec, that seems OK?&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;As for the faceting system then the principle really simple: Instead of holding terms (BytesRefs) in memory, I just hold their ordinals. As the terms themselves only need to be resolved when the final faceting result is to be returned, seeking for a few hundred or thousand terms by their ordinal has worked very well so far (no guarantees for old hardware such as spinning disks though).&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;OK that makes sense... impressive that seeking up to a few thousand terms is giving you good perf.  You could also load DocTermsIndex in FieldCache, but of course then all terms data &amp;amp; ords are RAM resident (and the point of &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-2369&quot; title=&quot;Locale-based sort by field with low memory overhead&quot;&gt;LUCENE-2369&lt;/a&gt; is to have low memory overhead).&lt;/p&gt;</comment>
                    <comment id="12990477" author="toke" created="Fri, 4 Feb 2011 07:26:30 +0000"  >&lt;p&gt;Michael, I think I&apos;ll use a TermsEnum-wrapper which keeps every N BytesRef or TermState and uses that for ordinal-based random access. That&apos;s a simple configurable RAM/speed tradeoff that is Codec-agnostic. Question is what the lower bound of the amount of methods implemented by a given Codec is? Is anything besides ord/seek optional?&lt;/p&gt;</comment>
                </comments>
                    <attachments>
                    <attachment id="12467410" name="LUCENE-2843.patch" size="209744" author="mikemccand" created="Tue, 4 Jan 2011 11:35:41 +0000" />
                    <attachment id="12467311" name="LUCENE-2843.patch" size="197130" author="mikemccand" created="Mon, 3 Jan 2011 11:09:51 +0000" />
                </attachments>
            <subtasks>
        </subtasks>
                <customfields>
                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                <customfieldname>Attachment count</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>2.0</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                <customfieldname>Date of First Response</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>Mon, 3 Jan 2011 13:06:52 +0000</customfieldvalue>

                </customfieldvalues>
            </customfield>
                                                                                                        <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Global Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>11018</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                <customfieldname>Lucene Fields</customfieldname>
                <customfieldvalues>
                        <customfieldvalue key="10121"><![CDATA[New]]></customfieldvalue>
    
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>24849</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                <customfieldname>Time in Status</customfieldname>
                <customfieldvalues>
                    
                </customfieldvalues>
            </customfield>
                            </customfields>
    </item>
</channel>
</rss>