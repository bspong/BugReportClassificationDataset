<!-- 
RSS generated by JIRA (5.2.8#851-sha1:3262fdc28b4bc8b23784e13eadc26a22399f5d88) at Tue Jul 16 13:08:27 UTC 2013

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/LUCENE-1540/LUCENE-1540.xml?field=key&field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>5.2.8</version>
        <build-number>851</build-number>
        <build-date>26-02-2013</build-date>
    </build-info>

<item>
            <title>[LUCENE-1540] Improvements to contrib.benchmark for TREC collections</title>
                <link>https://issues.apache.org/jira/browse/LUCENE-1540</link>
                <project id="12310110" key="LUCENE">Lucene - Core</project>
                        <description>&lt;p&gt;The benchmarking utilities for  TREC test collections (&lt;a href=&quot;http://trec.nist.gov&quot; class=&quot;external-link&quot;&gt;http://trec.nist.gov&lt;/a&gt;) are quite limited and do not support some of the variations in format of older TREC collections.  &lt;/p&gt;

&lt;p&gt;I have been doing some benchmarking work with Lucene and have had to modify the package to support:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Older TREC document formats, which the current parser fails on due to missing document headers.&lt;/li&gt;
	&lt;li&gt;Variations in query format - newlines after &amp;lt;title&amp;gt; tag causing the query parser to get confused.&lt;/li&gt;
	&lt;li&gt;Ability to detect and read in uncompressed text collections&lt;/li&gt;
	&lt;li&gt;Storage of document numbers by default without storing full text.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I can submit a patch if there is interest, although I will probably want to write unit tests for the new functionality first.&lt;/p&gt;
</description>
                <environment></environment>
            <key id="12414521">LUCENE-1540</key>
            <summary>Improvements to contrib.benchmark for TREC collections</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                    <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png">Closed</status>
                    <resolution id="1">Fixed</resolution>
                                <assignee username="doronc">Doron Cohen</assignee>
                                <reporter username="tgar">Tim Armstrong</reporter>
                        <labels>
                    </labels>
                <created>Tue, 10 Feb 2009 23:56:57 +0000</created>
                <updated>Wed, 30 Mar 2011 16:50:04 +0100</updated>
                    <resolved>Mon, 7 Feb 2011 07:15:15 +0000</resolved>
                                            <fixVersion>3.1</fixVersion>
                <fixVersion>4.0-ALPHA</fixVersion>
                                <component>modules/benchmark</component>
                        <due></due>
                    <votes>0</votes>
                        <watches>1</watches>
                                                    <comments>
                    <comment id="12914301" author="rcmuir" created="Fri, 24 Sep 2010 01:50:58 +0100"  >&lt;p&gt;Tim, if you have modified benchmark to work with various formats of older TREC collections, that would be really nice.&lt;/p&gt;</comment>
                    <comment id="12980022" author="doronc" created="Tue, 11 Jan 2011 09:52:19 +0000"  >&lt;p&gt;Indeed TrecContentSource is inadequate for the Trec-Disks-4+5-minus-CR collection (FBIS, FR94, FT, LATimes) so I am writing something to process this collection, in which, interestingly, each sub-collection&apos;s format slightly differs. (Will use this with the robust 2004 queries.) If there are ready to use building blocks for this that would be helpful. &lt;/p&gt;

&lt;p&gt;I think of writing separate content source implementations for each format - current one being gov2 format, and at the method openNextFile() identify the correct trec format according to the file path - i.e. if it is under LATimes will use that appropriate content source. The default will remain as today, for backcompat, and will be used if the path does not match any of the defined patterns.Also should be possible to specify - perhaps in a property - the default trec format.&lt;/p&gt;</comment>
                    <comment id="12980080" author="shaie" created="Tue, 11 Jan 2011 12:17:19 +0000"  >&lt;p&gt;Perhaps instead of separate ContentSource implementations, we can have TrecContentSource use a TrecDocParser (new class) or something, for parsing different formats. We can then have Gov2Parser, LATimesParser etc. for parsing the different formats, and TrecContentSource would use the appropriate parser per the path detected, as you suggest.&lt;/p&gt;

&lt;p&gt;In addition, we can have it use a specific format through a configuration parameter, in which case it will not attempt to auto-detect the right format, but always use the specified parser. Through Benchmark (as well as all other contrib / modules) does not need to maintain back-compat, I think that if we go with this approach, it can default to using the Gov2Parser, and thus you achieve backwards support.&lt;/p&gt;</comment>
                    <comment id="12981538" author="doronc" created="Thu, 13 Jan 2011 23:03:56 +0000"  >&lt;p&gt;Initial patch - against 3.x - not ready to commit - refactors parsing of trec text from TrecContentSource into interface TrecDocParser, currently with single impl - TrecGov2Parser. &lt;/p&gt;

&lt;p&gt;The interaction between TCS and TDP is less clean than I hoped, for two reasons:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;trying to keep the synchronization pattern added while ago to that class, in which the reading of data from the file is synced but the parsing can go in parallel. For this reason there are two methods in that interface.&lt;/li&gt;
	&lt;li&gt;allowing the TDP impls to use whatever is in TCS caused required to expose some of its methods, and also to pass TCS as param to TDP.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;With this patch:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;TDP was cleaned to use ContentSource&apos;s method getInputStream() - this also supporting .gz, .bz2, and plain text (before the patch it supports only .gz).&lt;/li&gt;
	&lt;li&gt;should be easy to add parsers for other formats.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;I removed the retry logic for opening the stream - I don&apos;t remember why it was added in the first place and it seems strange - if opening failed in first trial why would the next trial succeed?&lt;/p&gt;

&lt;p&gt;Remaining to do:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;add parsers for the other formats&lt;/li&gt;
	&lt;li&gt;add tests for the other formats and also for bz2, plain text.&lt;/li&gt;
	&lt;li&gt;allow a single run to ingest file of different formats (needed for the disks 4+5 track).&lt;/li&gt;
	&lt;li&gt;fix some documemtation.&lt;/li&gt;
	&lt;li&gt;allow to specify the TDP to use in a property.&lt;/li&gt;
	&lt;li&gt;changes.txt.&lt;/li&gt;
	&lt;li&gt;port to trunk, so as to first commit in trunk and then backport to 3.x.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12982028" author="shaie" created="Sat, 15 Jan 2011 05:27:06 +0000"  >&lt;p&gt;Patch looks good !&lt;/p&gt;

&lt;p&gt;Can you make TrecContentSource.read() public and not package-private? That way people can use it outside benchmark&apos;s package as well, supporting other/newer/older TREC formats.&lt;/p&gt;</comment>
                    <comment id="12985420" author="doronc" created="Sun, 23 Jan 2011 21:20:53 +0000"  >&lt;p&gt;Hi Shai, thanks for reviewing!&lt;br/&gt;
I agree about making read() public, and same for parseDate().&lt;br/&gt;
As we discussed offline the interface with TrecParser is not ideal - I looked at the option we discussed to have the TrecContentSource just read everything between &amp;lt;Doc&amp;gt; and &amp;lt;/Doc&amp;gt; and then let the TrecDocParser do everything - in one call to it - but as this would mean going through the data 3 times (comparing to 2 times today) this is not appealing either and I rather stay with the two methods interface for now.&lt;/p&gt;</comment>
                    <comment id="12985506" author="shaie" created="Mon, 24 Jan 2011 04:20:26 +0000"  >&lt;p&gt;Ok though I really think the 3 vs 2 times is negligible. The extra time we add is very simple - it&apos;s the only one that does IO, and even then, it reads lines and compares them to &amp;lt;DOC&amp;gt; or &amp;lt;/DOC&amp;gt; (which is a very simple comparison). From then on, it parses the actual TREC document in-memory.&lt;/p&gt;

&lt;p&gt;This is something I think could have even improved the current multi-threading support in TrecContentSource - today the threads sync on each one reading the TREC document, which means parsing its structure, and the only thing that&apos;s done in parallel is parsing the Html content. It&apos;d be interesting to benchmark the 3-passes method, where each thread would sync on reading the section from &amp;lt;DOC&amp;gt; to &amp;lt;/DOC&amp;gt; and then proceed to actually parse the structure.&lt;/p&gt;

&lt;p&gt;It sounds like TrecContentSource could have acted like a SAX parser, reading TrecDoc objects and emitting them to a BlockingQueue, while threads would read from it and proceed on their own.&lt;/p&gt;

&lt;p&gt;What I do agree on is that 3-passes is unnecessarily more expensive for single-threaded benchmarks.&lt;/p&gt;</comment>
                    <comment id="12988917" author="doronc" created="Mon, 31 Jan 2011 22:02:25 +0000"  >&lt;p&gt;Updated patch:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;first the entire doc is read into docBuf, then it is parsed by trecParser&lt;/li&gt;
	&lt;li&gt;added trec parser impls for LATimes, FT, FBIS, FR94 - so covering all of Trec-Disks-4+5-minus-CR collection.&lt;/li&gt;
	&lt;li&gt;added a parser by path - it selects which parser to use according to the path of the input file.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Still not ready to commit but almost there.&lt;/p&gt;

&lt;p&gt;With this patch the following alg would index all the 4 dirs, each with its own trec-parser:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
# ----- properties
content.source=org.apache.lucene.benchmark.byTask.feeds.TrecContentSource
content.source.verbose=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
content.source.excludeIteration=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
doc.maker.forever=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
docs.dir=&amp;lt;my-in-dir&amp;gt;
trec.doc.parser=org.apache.lucene.benchmark.byTask.feeds.TrecParserByPath
content.source.log.step=2500
doc.term.vector=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
content.source.forever=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
directory=FSDirectory
work.dir=&amp;lt;my-result-index-dir&amp;gt;
doc.stored=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
doc.body.stored=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
doc.tokenized=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
# ----- alg
ResetSystemErase
CreateIndex
{ AddDoc &amp;gt; : *
CloseIndex
RepAll
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I am thinking of making TrecDocParser an abstract class, and move to it some of the functionality currently in TrecContentSource / TrecParserByPath.&lt;/p&gt;

&lt;p&gt;Also thinking of serving each input file to a separate thread - I think this would allow better performance when someone indexes in multiple threads - as with current synchronization (we sync on reading from the file) I got fastest indexing when running sequential, compared again 2,3,4 threads - likely in a separate issue.&lt;/p&gt;</comment>
                    <comment id="12989029" author="shaie" created="Tue, 1 Feb 2011 04:32:52 +0000"  >&lt;p&gt;Patch looks good !&lt;/p&gt;

&lt;p&gt;Few comments:&lt;/p&gt;

&lt;p&gt;In TrecFTParser.parse(), I think you can extract the logic which finds the date and title into a common method which receives the strings to look for as parameters (e.g. find(String str, String start, int startlen, String end))? Then the code can be simplified to:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Date date = trecSrc.parseDate(find(dobBuf, DATE, DATE_LENGTH, DATE_END));
&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; title = find(docBuf, HEADLINE, HEADLINE_LENGTH, HEADLINE_END);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I believe this method will be useful for other parsers as well, so might be good to pull it up to the abstract TrecDocParser (and +1 for making it abstract and moving logic from TCS to it).&lt;/p&gt;

&lt;p&gt;In TrecContentSource you changed rawDocSize from int to int[], however it&apos;s an array that&apos;s always allocated at size 1 and never resized. I think it can be an int?&lt;/p&gt;

&lt;p&gt;Also, TCS.cleanTags has two versions, one taking a String and one a StringBuilder (took me a minute to notice the difference) &amp;#8211; do you think the performance gain (of not allocating a String in the SB variant) is worth the code dup? I didn&apos;t understand what does cleanTags do - does it strip tags off of the HTML content?&lt;/p&gt;

&lt;p&gt;I would also make all those static methods public (and move them to TrecDocParser) in case someone wants to impl his own parser.&lt;/p&gt;

&lt;p&gt;Thanks for adding support for GZIP in ContentSource - I had this on my TODO list for a long time &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;. Two things:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;I think the try-catch can be extracted to wrap the &apos;switch&apos; because it is now needed by both BZIP and GZIP.&lt;/li&gt;
	&lt;li&gt;Is it possible to add support for ZIP as well? If it&apos;s not trivial, then let&apos;s resolve it in a different issue.&lt;/li&gt;
&lt;/ol&gt;
</comment>
                    <comment id="12989081" author="doronc" created="Tue, 1 Feb 2011 07:46:44 +0000"  >&lt;p&gt;Thanks for the review Shai!&lt;br/&gt;
All comments accepted.&lt;br/&gt;
Good catch with the int[] - added that sometimes and forgot to cleanup.&lt;br/&gt;
I think ZIP can wait for another day - let&apos;s get this one in.&lt;br/&gt;
Note that we are using &lt;a href=&quot;http://commons.apache.org/compress/apidocs/org/apache/commons/compress/compressors/CompressorStreamFactory.html#createCompressorInputStream(java.lang.String,%20java.io.InputStream)&quot; class=&quot;external-link&quot;&gt;CompressorInputStream.createCompressorInputStream()&lt;/a&gt; which at version 1.1 only supports BZIP2 and GZIP. But the docs for Compress specify ZIP as well - so I guess this is possible, just needs a deeper dig into, in another issue, which, I guess, should also upgrade benchmark/compress from 1.0 to 1.1 (solr already uses 1.1).&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;do you think the performance gain (of not allocating a String in the SB variant) is worth the code dup?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I think so, it is a rather short method, will add a javadoc clarification.&lt;/p&gt;</comment>
                    <comment id="12989455" author="doronc" created="Tue, 1 Feb 2011 23:42:05 +0000"  >&lt;p&gt;updated patch for 3x.&lt;/p&gt;

&lt;p&gt;To apply this also copy attached trecdocs.zip under lucene/contrib/benchmark/src/test/org/apache/lucene/benchmark/byTask/feeds&lt;/p&gt;

&lt;p&gt;A test case was added which reads all 5 trec formats with mix of txt/bz2/gz file formats.&lt;/p&gt;

&lt;p&gt;I moved unzip() from backcompat test to LuceneTestCase and fixed it to also open directory hierarchy. &lt;/p&gt;

&lt;p&gt;TrecDocParser is now abstract class as discussed and also the other suggestions by Shai were followed.&lt;/p&gt;

&lt;p&gt;Planning to commit tomorrow if there are no reservations.&lt;/p&gt;</comment>
                    <comment id="12989508" author="shaie" created="Wed, 2 Feb 2011 04:18:19 +0000"  >&lt;p&gt;We&apos;re very close indeed !&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Maybe instead of moving the unzip method to LuceneTestCase, you can put it as a static method in _TestUtil? LTC is crowded enough to be added more functionality &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;. Also, _TestUtil already has a rmDir method, I think we should use it? I would also do the same for fullTempDir.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;The method pathType(File f) in TrecDocParser &amp;#8211; maybe instead of walking up the path elements you can obtain its full absolute path (which is a String) and then do indexOf() checks for the 4 types? It will simplify matters IMO.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;stripTags:
	&lt;ul&gt;
		&lt;li&gt;Typo in TDP: unmodofied --&amp;gt; unmodified.&lt;/li&gt;
		&lt;li&gt;Maybe we can use String.replaceAll() which takes a regex? This is not critical ...&lt;/li&gt;
		&lt;li&gt;Does stripTags strips off tags of the HTML content? Or is it used for the TREC types other than GOV2?&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;In TrecContentSource, can you replace TrecParserByPath.pathType to TrecDocParser.pathType?&lt;/li&gt;
	&lt;li&gt;Also, do we still need TrecParserByPath? I don&apos;t see that it&apos;s used.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12989565" author="doronc" created="Wed, 2 Feb 2011 09:00:14 +0000"  >&lt;p&gt;Thanks for reviewing Shai!&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Maybe instead of moving the unzip method to LuceneTestCase, you can put it as a static method in _TestUtil? Also, _TestUtil already has a rmDir method, I think we should use it? I would also do the same for fullTempDir.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Good point, will do.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The method pathType(File f) in TrecDocParser &#8211; maybe instead of walking up the path elements you can obtain its full absolute path (which is a String) and then do indexOf() checks for the 4 types? It will simplify matters IMO.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Not sure yet if I like better this file separator sensitive approach, I&apos;ll take a look.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Typo in TDP: unmodofied --&amp;gt; unmodified.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Will fix.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Maybe we can use String.replaceAll() which takes a regex? This is not critical ...&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Right, much simpler this way, will do!&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Does stripTags strips off tags of the HTML content? Or is it used for the TREC types other than GOV2?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;It strips any tags, but it is used by parsers which are not using the HTML parser, that is, the Gov2 one does not use it.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;In TrecContentSource, can you replace TrecParserByPath.pathType to TrecDocParser.pathType?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Good catch, this is part of older code, will do.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Also, do we still need TrecParserByPath? I don&apos;t see that it&apos;s used.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes we do, this is an important addition of this patch - allowing you to index trec docs of several formats. It is used, but dynamically, through the algorithm in TrecContentSourceTest.testTrecFeedDirAllTypes(). So removing it will not break compilation but will fail the tests.&lt;/p&gt;</comment>
                    <comment id="12989726" author="doronc" created="Wed, 2 Feb 2011 17:58:57 +0000"  >&lt;p&gt;Updated patch, plan to commit later today or tomorrow.&lt;/p&gt;</comment>
                    <comment id="12989766" author="shaie" created="Wed, 2 Feb 2011 19:47:27 +0000"  >&lt;p&gt;I see that we both missed the CHANGES entry? &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;Other than that, patch looks good. +1 to commit !&lt;/p&gt;</comment>
                    <comment id="12990854" author="doronc" created="Sat, 5 Feb 2011 00:54:02 +0000"  >&lt;p&gt;Committed:&lt;br/&gt;
r1066771 - 3x&lt;br/&gt;
r1067359 - trunk,&lt;/p&gt;

&lt;p&gt;A comment about the merging and the fixing of mergeinfo&apos;s. &lt;br/&gt;
The great &lt;a href=&quot;http://wiki.apache.org/lucene-java/SvnMerge&quot; class=&quot;external-link&quot;&gt;wiki page about svn-merge&lt;/a&gt; was very helpful, just that I merged from 3x to trunk, while there it is recommended the other way around. I think the two are equivalent, but had to go carefully with it. &lt;/p&gt;

&lt;p&gt;Eventually these are the commands I ran:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;cd trunk/lucene/src
svn merge -c 1066771 https://svn.apache.org/repos/asf/lucene/dev/branches/branch_3x/lucene/src
cd trunk/modules/benchmark
svn merge -c 1066771 https://svn.apache.org/repos/asf/lucene/dev/branches/branch_3x/lucene/contrib/benchmark
cd trunk
svn merge --record-only -c 1066771 https://svn.apache.org/repos/asf/lucene/dev/branches/branch_3x
svn revert  --depth empty modules/benchmark
svn revert solr
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The record-only merge discarded, by itself, the (new) mergeinfo prop from trunk/lucene/src, and updated the ones in trunk and trunk/src.&lt;br/&gt;
Note the use of &lt;b&gt;revert --depth empty&lt;/b&gt; for reverting (all) property changes.&lt;/p&gt;

&lt;p&gt;I&apos;ll keep this issue open for a day in case any problem is revealed with this merge process which I am doing for the first time.&lt;/p&gt;</comment>
                    <comment id="12991145" author="mikemccand" created="Sun, 6 Feb 2011 12:18:54 +0000"  >&lt;p&gt;I think this commit has caused a failure on at least 3.x?&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;[junit] Testcase: testTrecFeedDirAllTypes(org.apache.lucene.benchmark.byTask.feeds.TrecContentSourceTest):	Caused an ERROR
    [junit] expected:&amp;lt;TEST-00[0]&amp;gt; but was:&amp;lt;TEST-00[1]&amp;gt;
    [junit] 	at org.apache.lucene.benchmark.byTask.feeds.TrecContentSourceTest.assertDocData(TrecContentSourceTest.java:70)
    [junit] 	at org.apache.lucene.benchmark.byTask.feeds.TrecContentSourceTest.testTrecFeedDirAllTypes(TrecContentSourceTest.java:369)
    [junit] 	at org.apache.lucene.util.LuceneTestCase$LuceneTestCaseRunner.runChild(LuceneTestCase.java:1045)
    [junit] 	at org.apache.lucene.util.LuceneTestCase$LuceneTestCaseRunner.runChild(LuceneTestCase.java:977)
    [junit] 
    [junit] 
    [junit] Tests run: 6, Failures: 0, Errors: 1, Time elapsed: 0.488 sec
    [junit] 
    [junit] ------------- Standard Error -----------------
    [junit] WARNING: test method: &apos;testBadDate&apos; left thread running: Thread[Thread-6,5,main]
    [junit] RESOURCE LEAK: test method: &apos;testBadDate&apos; left 1 thread(s) running
    [junit] NOTE: reproduce with: ant test -Dtestcase=TrecContentSourceTest -Dtestmethod=testBadDate -Dtests.seed=-1485993969467368126:6510043524258948665 -Dtests.multiplier=5
    [junit] NOTE: reproduce with: ant test -Dtestcase=TrecContentSourceTest -Dtestmethod=testTrecFeedDirAllTypes -Dtests.seed=-1485993969467368126:-9055415333820766139 -Dtests.multiplier=5
    [junit] NOTE: test params are: locale=tr_TR, timezone=Europe/Zagreb
    [junit] NOTE: all tests run in this JVM:
    [junit] [TrecContentSourceTest]
    [junit] NOTE: FreeBSD 8.2-RC2 amd64/Sun Microsystems Inc. 1.6.0 (64-bit)/cpus=16,threads=1,free=66439840,total=86376448
    [junit] ------------- ---------------- ---------------
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                    <comment id="12991176" author="doronc" created="Sun, 6 Feb 2011 17:09:50 +0000"  >&lt;p&gt;I am able to reproduce this on Linux.&lt;br/&gt;
The test fails with &lt;b&gt;locale tr_TR&lt;/b&gt; because TrecDocParser was upper-casing the file names for deciding which parser to apply.&lt;br/&gt;
Problem with this is that toUpperCase is locale sensitive, and so the file name no longer matched the enum name.&lt;br/&gt;
Fixed by adding a lower case dirName member to the enums.&lt;br/&gt;
Also recreated the test files zip with &apos;-UN u&apos; for UTF8 handling of file names in the zip.&lt;/p&gt;

&lt;p&gt;committed at r1067699 for 3x.&lt;/p&gt;

&lt;p&gt;In trunk the test passes with same args also in Linux, but fails if you pass the locale that was randomly selected in 3x, i.e. like this: &lt;br/&gt;
ant test -Dtestcase=TrecContentSourceTest -Dtestmethod=testTrecFeedDirAllTypes -Dtests.locale=tr_TR&lt;/p&gt;

&lt;p&gt;Will merge the fix to trunk shortly.&lt;/p&gt;</comment>
                    <comment id="12991179" author="rcmuir" created="Sun, 6 Feb 2011 17:19:11 +0000"  >&lt;p&gt;Hi Doron, about the test random seeds:&lt;/p&gt;

&lt;p&gt;It is complicated (though maybe we could fix this!) for the same random seed in trunk to work just like 3.x&lt;/p&gt;

&lt;p&gt;But for the locales: the way it picks a random locale is from the available system locales. This changes from jre to jre,&lt;br/&gt;
so unfortunately we cannot guarantee that the same seed chooses the same locale randomly... Its the same with &lt;br/&gt;
timezones too... and these even change in minor jdk updates! &lt;/p&gt;

&lt;p&gt;I wish we knew of a good solution, because I hate it when things aren&apos;t completely reproducible everywhere.&lt;/p&gt;</comment>
                    <comment id="12991181" author="doronc" created="Sun, 6 Feb 2011 17:22:31 +0000"  >&lt;p&gt;Fix for the locale issue merged to trunk at r1076605.&lt;br/&gt;
Keeping open for a day or so to make sure there are no more failures.&lt;/p&gt;</comment>
                    <comment id="12991210" author="doronc" created="Sun, 6 Feb 2011 20:14:25 +0000"  >&lt;blockquote&gt;&lt;p&gt;I wish we knew of a good solution, because I hate it when things aren&apos;t completely reproducible everywhere.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Thanks Robert, I am actually very pleased with this array of testing with various parameters like locale and others randomly selected - it is very powreful, and since the failure printed all the parameters used and even the ant line to reproduce(&amp;#33;)  - it was possible to reproduce in 3x, and, once understanding what the problem was also possible to reproduce in trunk - to me this is testing&apos;s heaven...&lt;/p&gt;</comment>
                    <comment id="12991224" author="doronc" created="Sun, 6 Feb 2011 21:30:07 +0000"  >&lt;p&gt;Following suggestions by Robert, brought back case insensitivity of path names by upper casing with Locale.ENGLISH as suggested in &lt;a href=&quot;http://download.oracle.com/javase/6/docs/api/java/lang/String.html#toUpperCase%28%29&quot; class=&quot;external-link&quot;&gt;toUpperCase()&lt;/a&gt;. &lt;br/&gt;
Committed:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;r1067764 - 3x&lt;/li&gt;
	&lt;li&gt;r1067772 - trunk&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12991289" author="doronc" created="Mon, 7 Feb 2011 07:15:15 +0000"  >&lt;p&gt;ok no new failures, closing as fixed, Thanks Shai and Robert for your help here!&lt;/p&gt;</comment>
                    <comment id="12995865" author="rcmuir" created="Thu, 17 Feb 2011 16:01:26 +0000"  >&lt;p&gt;Hi guys, this is just a feature request (we can open a new issue if anyone is up for it).&lt;/p&gt;

&lt;p&gt;I was wondering if we could do a simple write-up and put it in the website notes for 3.1, 3.2,&lt;br/&gt;
whenever we can get to it, with some basic instructions on how to use this functionality.&lt;/p&gt;

&lt;p&gt;I noticed with more research-oriented search engines, there are simple instructions for&lt;br/&gt;
how to index trec collections, run relevance experiments, and get trec_eval results... I feel&lt;br/&gt;
like if we had these it would be really beneficial towards getting new folks involved with Lucene.&lt;/p&gt;

&lt;p&gt;Some examples (some are simpler than others, but at least they all describe how to build the index):&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Terrier: &lt;a href=&quot;http://terrier.org/docs/current/trec_examples.html&quot; class=&quot;external-link&quot;&gt;http://terrier.org/docs/current/trec_examples.html&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;Zettair: &lt;a href=&quot;http://www.seg.rmit.edu.au/zettair/quick_start_trec.html&quot; class=&quot;external-link&quot;&gt;http://www.seg.rmit.edu.au/zettair/quick_start_trec.html&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;MG4J: &lt;a href=&quot;http://mg4j.dsi.unimi.it/man/manual/ch01s04.html#id2769812&quot; class=&quot;external-link&quot;&gt;http://mg4j.dsi.unimi.it/man/manual/ch01s04.html#id2769812&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;Indri: &lt;a href=&quot;http://ciir.cs.umass.edu/~strohman/indri/&quot; class=&quot;external-link&quot;&gt;http://ciir.cs.umass.edu/~strohman/indri/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</comment>
                    <comment id="12996015" author="doronc" created="Thu, 17 Feb 2011 20:00:26 +0000"  >&lt;p&gt;I agree, this would be helpful. &lt;br/&gt;
Let&apos;s have a new issue on this, I&apos;ll take it.&lt;br/&gt;
Doron&lt;/p&gt;</comment>
                    <comment id="13013358" author="gsingers" created="Wed, 30 Mar 2011 16:50:04 +0100"  >&lt;p&gt;Bulk close for 3.1&lt;/p&gt;</comment>
                </comments>
                    <attachments>
                    <attachment id="12470058" name="LUCENE-1540.patch" size="59973" author="doronc" created="Wed, 2 Feb 2011 17:58:56 +0000" />
                    <attachment id="12469997" name="LUCENE-1540.patch" size="56563" author="doronc" created="Tue, 1 Feb 2011 23:42:05 +0000" />
                    <attachment id="12469864" name="LUCENE-1540.patch" size="42299" author="doronc" created="Mon, 31 Jan 2011 22:02:25 +0000" />
                    <attachment id="12468309" name="LUCENE-1540.patch" size="15272" author="doronc" created="Thu, 13 Jan 2011 23:03:56 +0000" />
                    <attachment id="12469998" name="trecdocs.zip" size="2676" author="doronc" created="Tue, 1 Feb 2011 23:42:05 +0000" />
                </attachments>
            <subtasks>
        </subtasks>
                <customfields>
                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                <customfieldname>Attachment count</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>5.0</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                <customfieldname>Date of First Response</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>Fri, 24 Sep 2010 00:50:58 +0000</customfieldvalue>

                </customfieldvalues>
            </customfield>
                                                                                                        <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Global Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>12214</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                <customfieldname>Lucene Fields</customfieldname>
                <customfieldvalues>
                        <customfieldvalue key="10121"><![CDATA[New]]></customfieldvalue>
    <customfieldvalue key="10120"><![CDATA[Patch Available]]></customfieldvalue>
    
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>26189</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                <customfieldname>Time in Status</customfieldname>
                <customfieldvalues>
                    
                </customfieldvalues>
            </customfield>
                            </customfields>
    </item>
</channel>
</rss>