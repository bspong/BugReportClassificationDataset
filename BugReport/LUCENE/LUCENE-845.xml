<!-- 
RSS generated by JIRA (5.2.8#851-sha1:3262fdc28b4bc8b23784e13eadc26a22399f5d88) at Tue Jul 16 13:01:32 UTC 2013

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/LUCENE-845/LUCENE-845.xml?field=key&field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>5.2.8</version>
        <build-number>851</build-number>
        <build-date>26-02-2013</build-date>
    </build-info>

<item>
            <title>[LUCENE-845] If you &quot;flush by RAM usage&quot; then IndexWriter may over-merge</title>
                <link>https://issues.apache.org/jira/browse/LUCENE-845</link>
                <project id="12310110" key="LUCENE">Lucene - Core</project>
                        <description>&lt;p&gt;I think a good way to maximize performance of Lucene&apos;s indexing for a&lt;br/&gt;
given amount of RAM is to flush (writer.flush()) the added documents&lt;br/&gt;
whenever the RAM usage (writer.ramSizeInBytes()) has crossed the max&lt;br/&gt;
RAM you can afford.&lt;/p&gt;

&lt;p&gt;But, this can confuse the merge policy and cause over-merging, unless&lt;br/&gt;
you set maxBufferedDocs properly.&lt;/p&gt;

&lt;p&gt;This is because the merge policy looks at the current maxBufferedDocs&lt;br/&gt;
to figure out which segments are level 0 (first flushed) or level 1&lt;br/&gt;
(merged from &amp;lt;mergeFactor&amp;gt; level 0 segments).&lt;/p&gt;

&lt;p&gt;I&apos;m not sure how to fix this.  Maybe we can look at net size (bytes)&lt;br/&gt;
of a segment and &quot;infer&quot; level from this?  Still we would have to be&lt;br/&gt;
resilient to the application suddenly increasing the RAM allowed.&lt;/p&gt;

&lt;p&gt;The good news is to workaround this bug I think you just need to&lt;br/&gt;
ensure that your maxBufferedDocs is less than mergeFactor *&lt;br/&gt;
typical-number-of-docs-flushed.&lt;/p&gt;</description>
                <environment></environment>
            <key id="12365610">LUCENE-845</key>
            <summary>If you &quot;flush by RAM usage&quot; then IndexWriter may over-merge</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                    <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png">Closed</status>
                    <resolution id="1">Fixed</resolution>
                                <assignee username="mikemccand">Michael McCandless</assignee>
                                <reporter username="mikemccand">Michael McCandless</reporter>
                        <labels>
                    </labels>
                <created>Thu, 22 Mar 2007 20:15:31 +0000</created>
                <updated>Fri, 25 Jan 2008 03:23:53 +0000</updated>
                    <resolved>Tue, 18 Sep 2007 10:40:05 +0100</resolved>
                            <version>2.1</version>
                                <fixVersion>2.3</fixVersion>
                                <component>core/index</component>
                        <due></due>
                    <votes>0</votes>
                        <watches>2</watches>
                                                    <comments>
                    <comment id="12483631" author="mikemccand" created="Fri, 23 Mar 2007 15:27:08 +0000"  >&lt;p&gt;This bug is actually rather serious.&lt;/p&gt;

&lt;p&gt;If you set maxBufferedDocs to a very large number (on the expectation&lt;br/&gt;
that it&apos;s not used since you will manually flush by RAM usage) then&lt;br/&gt;
the merge policy will always merge the index down to 1 segment as soon&lt;br/&gt;
as it hits mergeFactor segments.&lt;/p&gt;

&lt;p&gt;This will be an O(N^2) slowdown.  EG if based on RAM you are&lt;br/&gt;
flushing every 100 docs, then at 1000 docs you will merge to 1&lt;br/&gt;
segment.  Then at 1900 docs, you merge to 1 segment again.  At 2800,&lt;br/&gt;
3700, 4600, ... (every 900 docs) you keep merging to 1 segment.  Your&lt;br/&gt;
indexing process will get very slow because every 900 documents the&lt;br/&gt;
entire index is effectively being optimized.&lt;/p&gt;

&lt;p&gt;With &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-843&quot; title=&quot;improve how IndexWriter uses RAM to buffer added documents&quot;&gt;&lt;del&gt;LUCENE-843&lt;/del&gt;&lt;/a&gt; I&apos;m thinking we should deprecate maxBufferedDocs&lt;br/&gt;
entirely and switch to flushing by RAM usage instead (you can always&lt;br/&gt;
manually flush every N documents in your app if for some reason you&lt;br/&gt;
need that).  But obviously we need to resolve this bug first.&lt;/p&gt;</comment>
                    <comment id="12484150" author="yseeley@gmail.com" created="Mon, 26 Mar 2007 17:22:44 +0100"  >&lt;p&gt;&amp;gt; With &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-843&quot; title=&quot;improve how IndexWriter uses RAM to buffer added documents&quot;&gt;&lt;del&gt;LUCENE-843&lt;/del&gt;&lt;/a&gt; I&apos;m thinking we should deprecate maxBufferedDocs entirely&lt;/p&gt;

&lt;p&gt;That might present a problem for users of ParallelReader.  Right now, it&apos;s possible to construct two indicies with corresponding docids.... switching to flush-by-ram would makesegment merging unpredictable and destroy the docid matching.&lt;/p&gt;</comment>
                    <comment id="12484175" author="mikemccand" created="Mon, 26 Mar 2007 19:13:37 +0100"  >&lt;p&gt;&amp;gt;&amp;gt; With &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-843&quot; title=&quot;improve how IndexWriter uses RAM to buffer added documents&quot;&gt;&lt;del&gt;LUCENE-843&lt;/del&gt;&lt;/a&gt; I&apos;m thinking we should deprecate maxBufferedDocs entirely&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; That might present a problem for users of ParallelReader. Right now,&lt;br/&gt;
&amp;gt; it&apos;s possible to construct two indicies with corresponding&lt;br/&gt;
&amp;gt; docids.... switching to flush-by-ram would makesegment merging&lt;br/&gt;
&amp;gt; unpredictable and destroy the docid matching.&lt;/p&gt;

&lt;p&gt;Ahhh, this is a very good point.  OK I won&apos;t deprecate &quot;flushing by&lt;br/&gt;
doc count&quot; and instead will allow either &quot;flush by RAM usage&quot; (default&lt;br/&gt;
to this?) or &quot;flush by doc count&quot;.&lt;/p&gt;</comment>
                    <comment id="12485722" author="mikemccand" created="Sat, 31 Mar 2007 13:21:49 +0100"  >&lt;p&gt;Just recapping some following discussion from java-dev ...&lt;/p&gt;

&lt;p&gt;The current merge policy can be thought of logically as two different&lt;br/&gt;
steps:&lt;/p&gt;

&lt;p&gt;  1. How to determine the &quot;level&quot; of each segment in the index.&lt;/p&gt;

&lt;p&gt;  2. How &amp;amp; when to pick which level N segments into a level N+1&lt;br/&gt;
     segment.&lt;/p&gt;

&lt;p&gt;The current policy determines a segment&apos;s level by looking at the doc&lt;br/&gt;
count in the segment as well as the current maxBufferedDocs, which is&lt;br/&gt;
very problematic when you &quot;flush by RAM usage&quot; instead.  This Jira&lt;br/&gt;
issue, then, is proposing to instead look at overall byte size of a&lt;br/&gt;
segment for determining its level, while keeping step 2. above.&lt;/p&gt;

&lt;p&gt;However, I would propose we also fix &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-854&quot; title=&quot;Create merge policy that doesn&amp;#39;t periodically inadvertently optimize&quot;&gt;&lt;del&gt;LUCENE-854&lt;/del&gt;&lt;/a&gt; (which addresses step&lt;br/&gt;
2 above and not step 1) at the same time, as a single merge policy,&lt;br/&gt;
and maybe at some point in the future make this new merge policy the&lt;br/&gt;
default merge policy.&lt;/p&gt;</comment>
                    <comment id="12492814" author="steven_parkes" created="Tue, 1 May 2007 00:24:38 +0100"  >&lt;p&gt;Following up on this, it&apos;s basically the idea that segments ought to be created/merged both either by-segment-size or by-doc-count but not by a mixture? That wouldn&apos;t be suprising ...&lt;/p&gt;

&lt;p&gt;It does impact the APIs, though. It&apos;s easy enough to imagine, with factored merge policies, both by-doc-count and by-segment-size policies. But the initial segment creation is going to be handled by IndexWriter, so you have to manually make sure you don&apos;t set that algorithm and the merge policy in conflict. Not great, but I don&apos;t have any great ideas. Could put in an API handshake, but I&apos;m not sure if it&apos;s worth the mess?&lt;/p&gt;

&lt;p&gt;Also, it sounds like, so far, there&apos;s no good way of managing parallel-reader setups w/by-segment-size algorithms, since the algorithm for creating/merging segments has to be globally consistent, not just per index, right?&lt;/p&gt;

&lt;p&gt;If that is right, what does that say about making by-segment-size the default? It&apos;s gonna break (as in bad results) people relying on that behavior that don&apos;t change their code. Is there a community consensus on this? It&apos;s not really an API change that would cause a compile/class-load failure, but in some ways, it&apos;s worse ...&lt;/p&gt;</comment>
                    <comment id="12493065" author="mikemccand" created="Wed, 2 May 2007 10:58:39 +0100"  >&lt;p&gt;&amp;gt; Following up on this, it&apos;s basically the idea that segments ought to be created/merged both either by-segment-size or by-doc-count but not by a mixture? That wouldn&apos;t be suprising ...&lt;/p&gt;

&lt;p&gt;Right, but we need the refactored merge policy framework in place&lt;br/&gt;
first.  I&apos;ll mark this issue dependent on &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-847&quot; title=&quot;Factor merge policy out of IndexWriter&quot;&gt;&lt;del&gt;LUCENE-847&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&amp;gt; It does impact the APIs, though. It&apos;s easy enough to imagine, with factored merge policies, both by-doc-count and by-segment-size policies. But the initial segment creation is going to be handled by IndexWriter, so you have to manually make sure you don&apos;t set that algorithm and the merge policy in conflict. Not great, but I don&apos;t have any great ideas. Could put in an API handshake, but I&apos;m not sure if it&apos;s worth the mess?&lt;/p&gt;

&lt;p&gt;Good question.  I think it&apos;s OK (at least for our first go at this &amp;#8211;&lt;br/&gt;
progress not perfection!) to expect the developer to choose a merge&lt;br/&gt;
policy and then to use IndexWriter in a way that&apos;s &quot;consistent&quot; with&lt;br/&gt;
that merge policy?  I think it&apos;s going to get too complex if we try to&lt;br/&gt;
formally couple &quot;when to flush/commit&quot; with the merge policy?&lt;/p&gt;

&lt;p&gt;But, I think the default merge policy needs to be resilient to people&lt;br/&gt;
doing things like changing maxBuffereDocs/mergeFactor partway through&lt;br/&gt;
an index, calling flush() whenever they want, etc.  The merge policy&lt;br/&gt;
today is not resilient to these &quot;normal&quot; usages of IndexWriter.  So I&lt;br/&gt;
think we need to do something here even without the pressure from&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-843&quot; title=&quot;improve how IndexWriter uses RAM to buffer added documents&quot;&gt;&lt;del&gt;LUCENE-843&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&amp;gt; Also, it sounds like, so far, there&apos;s no good way of managing parallel-reader setups w/by-segment-size algorithms, since the algorithm for creating/merging segments has to be globally consistent, not just per index, right?&lt;/p&gt;

&lt;p&gt;Right.  We clearly need to keep the current &quot;by doc&quot; merge policy&lt;br/&gt;
easily available for this use case.&lt;/p&gt;

&lt;p&gt;&amp;gt; If that is right, what does that say about making by-segment-size the default? It&apos;s gonna break (as in bad results) people relying on that behavior that don&apos;t change their code. Is there a community consensus on this? It&apos;s not really an API change that would cause a compile/class-load failure, but in some ways, it&apos;s worse ...&lt;/p&gt;

&lt;p&gt;I think there are actually two questions here:&lt;/p&gt;

&lt;p&gt;  1) What exactly makes for a good default merge policy?&lt;/p&gt;

&lt;p&gt;     I think the merge policy we have today has some limitations:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;It&apos;s not resilient to &quot;normal&quot; usage of the public APIs in&lt;br/&gt;
         IndexWriter.  If you call flush() yourself, if you change&lt;br/&gt;
         maxBufferedDocs (and maybe mergeFactor?) partway through an&lt;br/&gt;
         index, etc, you can cause disastrous amounts of over-merging&lt;br/&gt;
         (that&apos;s this issue).&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 	 I think the default policy should be entirely resilient to&lt;br/&gt;
	 any usage of the public IndexWriter APIs.&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Default merge policy should strive to minimize net cost&lt;br/&gt;
         (amortized over time) of merging, but the current one&lt;br/&gt;
         doesn&apos;t:&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;When docs differ in size (frequently the case) it will be&lt;br/&gt;
           too costly in CPU/IO consumption because small segments are&lt;br/&gt;
           merged with large ones.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;It does too much work in advance (too much &quot;pay it&lt;br/&gt;
           forward&quot;).  I don&apos;t think a merge policy should&lt;br/&gt;
           &quot;inadvertently optimize&quot; (I opened &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-854&quot; title=&quot;Create merge policy that doesn&amp;#39;t periodically inadvertently optimize&quot;&gt;&lt;del&gt;LUCENE-854&lt;/del&gt;&lt;/a&gt; to describe&lt;br/&gt;
           this).&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;It blocks &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-843&quot; title=&quot;improve how IndexWriter uses RAM to buffer added documents&quot;&gt;&lt;del&gt;LUCENE-843&lt;/del&gt;&lt;/a&gt; (flushing by RAM usage).&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         I think Lucene &quot;out of the box&quot; should give you good indexing&lt;br/&gt;
         performance.  You should not have to do extra tuning to get&lt;br/&gt;
         substantially better performance.  The best way to get that&lt;br/&gt;
         is to &quot;flush by RAM&quot; (with &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-843&quot; title=&quot;improve how IndexWriter uses RAM to buffer added documents&quot;&gt;&lt;del&gt;LUCENE-843&lt;/del&gt;&lt;/a&gt;).  But current merge&lt;br/&gt;
         policy prevents this (due to this issue).&lt;/p&gt;

&lt;p&gt;  2) Can we change the default merge policy?&lt;/p&gt;

&lt;p&gt;     I sure hope so, given the issues above.&lt;/p&gt;

&lt;p&gt;     I think the majority of Lucene users do the simple &quot;create a&lt;br/&gt;
     writer, add/delete docs, close writer, while reader(s) use the&lt;br/&gt;
     same index&quot; type of usage and so would benefit by the gained&lt;br/&gt;
     performance of &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-843&quot; title=&quot;improve how IndexWriter uses RAM to buffer added documents&quot;&gt;&lt;del&gt;LUCENE-843&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-854&quot; title=&quot;Create merge policy that doesn&amp;#39;t periodically inadvertently optimize&quot;&gt;&lt;del&gt;LUCENE-854&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;     I think (but may be wrong!) it&apos;s a minority who use&lt;br/&gt;
     ParallelReader and therefore have a reliance on the specific&lt;br/&gt;
     merge policy we use today?&lt;/p&gt;

&lt;p&gt;Ideally we first commit the &quot;decouple merge policy from IndexWriter&quot;&lt;br/&gt;
(&lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-847&quot; title=&quot;Factor merge policy out of IndexWriter&quot;&gt;&lt;del&gt;LUCENE-847&lt;/del&gt;&lt;/a&gt;), then we would make a new merge policy that resolves this&lt;br/&gt;
issue and &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-854&quot; title=&quot;Create merge policy that doesn&amp;#39;t periodically inadvertently optimize&quot;&gt;&lt;del&gt;LUCENE-854&lt;/del&gt;&lt;/a&gt;, and make it the default policy.  I think this&lt;br/&gt;
policy would look at size (in bytes) of each segment (perhaps&lt;br/&gt;
proportionally reducing # bytes according to pending deletes against&lt;br/&gt;
that segment), and would merge any adjacent segments (not just&lt;br/&gt;
rightmost ones) that are &quot;the most similar&quot; in size.  I think it would&lt;br/&gt;
merge N (configurable) at a time and at no time would inadvertently&lt;br/&gt;
optimize.&lt;/p&gt;

&lt;p&gt;This would mean users of ParallelReader on upgrading to this would&lt;br/&gt;
need to change their merge policy to the legacy &quot;merge by doc count&quot;&lt;br/&gt;
policy.&lt;/p&gt;</comment>
                    <comment id="12520120" author="mikemccand" created="Thu, 16 Aug 2007 00:57:42 +0100"  >
&lt;p&gt;First cut patch.  You have to first apply the most recent patch from&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-847&quot; title=&quot;Factor merge policy out of IndexWriter&quot;&gt;&lt;del&gt;LUCENE-847&lt;/del&gt;&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;  &lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12363880/LUCENE-847.patch.txt&quot; class=&quot;external-link&quot;&gt;https://issues.apache.org/jira/secure/attachment/12363880/LUCENE-847.patch.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;and then apply this patch over it.&lt;/p&gt;

&lt;p&gt;This patch has two merge policies:&lt;/p&gt;

&lt;p&gt;  LogDocMergePolicy&lt;/p&gt;

&lt;p&gt;    This is &quot;backwards compatible&quot; to current merge policy, yet,&lt;br/&gt;
    resolve this &quot;over-merge issue&quot; by not using the current setting&lt;br/&gt;
    of &quot;maxBufferedDocs&quot; when computing levels.  I think it should&lt;br/&gt;
    replace the current LogDocMergePolicy from &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-847&quot; title=&quot;Factor merge policy out of IndexWriter&quot;&gt;&lt;del&gt;LUCENE-847&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;  LogByteSizeMergePolicy&lt;/p&gt;

&lt;p&gt;    Chooses merges according to net size in bytes of all files for a&lt;br/&gt;
    segment.  I think we should make this one the default merge&lt;br/&gt;
    policy, and also change IndexWriter to flush by RAM by default.&lt;/p&gt;

&lt;p&gt;They both subclass from abstract base LogMergePolicy and differ only&lt;br/&gt;
in the &quot;size&quot; method which defines how you measure a segment&apos;s size (#&lt;br/&gt;
docs in that segment or net size in bytes of that segment).&lt;/p&gt;

&lt;p&gt;The gist of the approach is the same as the current merge policy: you&lt;br/&gt;
generally try to merge segments that are &quot;roughly&quot; the same size&lt;br/&gt;
(where size can be doc count or byte size), mergeFactor at a time.&lt;/p&gt;

&lt;p&gt;The big difference is instead of starting from maxBufferedDocs and&lt;br/&gt;
&quot;going up&quot; to determine level, I start from the max segment size (of&lt;br/&gt;
all segments in the index) and &quot;go down&quot; to determine level.  This&lt;br/&gt;
resolves the bug because levels are &quot;self-defined&quot; by the segments,&lt;br/&gt;
rather than by the current value of maxBufferedDocs on IndexWriter.&lt;/p&gt;

&lt;p&gt;I then pick merges exactly the same as the current merge policy: if&lt;br/&gt;
any level has &amp;gt;= mergeFactor segments, we merge them.&lt;/p&gt;

&lt;p&gt;All tests pass, except:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;One assert in testAddIndexesNoOptimize which was relying on the&lt;br/&gt;
    specific invariants of the current merge policy (it&apos;s the same&lt;br/&gt;
    assert that &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-847&quot; title=&quot;Factor merge policy out of IndexWriter&quot;&gt;&lt;del&gt;LUCENE-847&lt;/del&gt;&lt;/a&gt; had changed; this assert is testing&lt;br/&gt;
    particular corner cases of the current merge policy).  Changing&lt;br/&gt;
    the assertEquals to &quot;4&quot; instead of &quot;3&quot; fixes it.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;TestLogDocMergePolicy (added in &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-847&quot; title=&quot;Factor merge policy out of IndexWriter&quot;&gt;&lt;del&gt;LUCENE-847&lt;/del&gt;&lt;/a&gt;) doesn&apos;t compile&lt;br/&gt;
    against the new version above because it&apos;s using methods that&lt;br/&gt;
    don&apos;t exist in the new one.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12520130" author="steven_parkes" created="Thu, 16 Aug 2007 02:10:07 +0100"  >&lt;p&gt;This increases file descriptor usage in some cases, right? In the old scheme, if you set mergeFactor to 10 and maxBufferedDocs to 1000, you&apos;d only get 10 segments with size &amp;lt;= 1000. But with this code, you can&apos;t bound that anymore. If I create single doc segments (perhaps by flushing based on latency), I can get 30 of them?&lt;/p&gt;

&lt;p&gt;Of course, if what we&apos;re trying to do is manage the number of file descriptors, we should just do that, rather than using using maxBufferedDocs as a proxy (with all it&apos;s nasty overmerging behavior).&lt;/p&gt;</comment>
                    <comment id="12520181" author="mikemccand" created="Thu, 16 Aug 2007 10:17:57 +0100"  >
&lt;p&gt;&amp;gt; This increases file descriptor usage in some cases, right? In the&lt;br/&gt;
&amp;gt; old scheme, if you set mergeFactor to 10 and maxBufferedDocs to&lt;br/&gt;
&amp;gt; 1000, you&apos;d only get 10 segments with size &amp;lt;= 1000. But with this&lt;br/&gt;
&amp;gt; code, you can&apos;t bound that anymore. If I create single doc segments&lt;br/&gt;
&amp;gt; (perhaps by flushing based on latency), I can get 30 of them?&lt;/p&gt;

&lt;p&gt;Right, the # segments allowed in the index will be more than it is w/&lt;br/&gt;
the current merge policy if you consistently flush with &lt;span class=&quot;error&quot;&gt;&amp;#91;far&amp;#93;&lt;/span&gt; fewer&lt;br/&gt;
docs than maxBufferedDocs is set to.&lt;/p&gt;

&lt;p&gt;But, this is actually the essense of the bug.  The case we&apos;re trying&lt;br/&gt;
to fix is where you set maxBufferedDocs to something really large (say&lt;br/&gt;
1,000,000) to avoid flushing by doc count, and you setRamBufferSizeMB&lt;br/&gt;
to something like 32 MB.  In this case, the current merge policy would&lt;br/&gt;
just keep merging any set of 10 segments with &amp;lt; 1,000,000 docs each,&lt;br/&gt;
such that eventually all your indexing time is being spent doing&lt;br/&gt;
highly sub-optimal merges.&lt;/p&gt;
</comment>
                    <comment id="12520268" author="steven_parkes" created="Thu, 16 Aug 2007 16:03:09 +0100"  >&lt;p&gt;I understand the merge problem but I&apos;m still concerned about the increased number of file descriptors. Is this a concern?&lt;/p&gt;

&lt;p&gt;It seems like there are ways of approaching this, that might be able to fix both problems?&lt;/p&gt;

&lt;p&gt;For example, right now (pre-fix), if you have maxBufferedDocs set to 1000, mergeFactor set to 10, and add (for the sake of obvious example) 10 single doc segments, it&apos;s going to do a merge to one segment of size 1010, which is not great.&lt;/p&gt;

&lt;p&gt;One solution to this would be in cases like this to merge the small segments to one but not include the big segments. So you get &lt;span class=&quot;error&quot;&gt;&amp;#91;1000 10&amp;#93;&lt;/span&gt; where the last segment keeps growing until it reaches 1000. This does more copies than the current case, but always on small segments, with the advantage of a lower bound on the number of file descriptors?&lt;/p&gt;

&lt;p&gt;Of course, if no one&apos;s worried about this &quot;moderate&quot; (not exactly large, not exactly small) change in file descriptor usage, then it&apos;s not a big deal. It doesn&apos;t impact my work but I&apos;m not sure about the greater community.&lt;/p&gt;</comment>
                    <comment id="12520271" author="yseeley@gmail.com" created="Thu, 16 Aug 2007 16:12:16 +0100"  >&lt;p&gt;Is there a change in filedescriptor use if you don&apos;t use setRamBufferSizeMB?&lt;/p&gt;</comment>
                    <comment id="12520328" author="mikemccand" created="Thu, 16 Aug 2007 19:28:27 +0100"  >
&lt;p&gt;&amp;gt; Is there a change in filedescriptor use if you don&apos;t use setRamBufferSizeMB?&lt;/p&gt;

&lt;p&gt;Yes.  EG, if you set maxBufferedDocs to 1000 but then flush after&lt;br/&gt;
every added doc, and you add 1000 docs, with the current merge policy,&lt;br/&gt;
every 10 flushes you will merge all segments together.  Ie, first&lt;br/&gt;
segment has 10 docs, then 20, 30, 40, 50, ..., 1000.  This is where&lt;br/&gt;
O(N^2) cost on merging comes from.  But, you will never have more than&lt;br/&gt;
10 segments in your index.&lt;/p&gt;

&lt;p&gt;Whereas the new merge policy will make levels (segments of size 100,&lt;br/&gt;
10, 1) and merge only segments from the same level together.  So merge&lt;br/&gt;
cost will be much less (not O(N^2)), but, you will have more max segments&lt;br/&gt;
in the index (up to 1 + (mergeFactor-1) * log_mergeFactor(numDocs)),&lt;br/&gt;
or 28 segments in this example (I think).&lt;/p&gt;

&lt;p&gt;Basically the new merge policy tries to make levels &quot;all the way&lt;br/&gt;
down&quot; rather than forcefully stopping when the levels get smaller than&lt;br/&gt;
maxBufferedDocs, to avoid the O(N^2) merge cost.&lt;/p&gt;

&lt;p&gt;&amp;gt; One solution to this would be in cases like this to merge the small&lt;br/&gt;
&amp;gt; segments to one but not include the big segments. So you get [1000&lt;br/&gt;
&amp;gt; 10] where the last segment keeps growing until it reaches 1000. This&lt;br/&gt;
&amp;gt; does more copies than the current case, but always on small&lt;br/&gt;
&amp;gt; segments, with the advantage of a lower bound on the number of file&lt;br/&gt;
&amp;gt; descriptors?&lt;/p&gt;

&lt;p&gt;I&apos;m not sure that helps?  Because that &quot;small segment&quot; will have to&lt;br/&gt;
grow bit by bit up to 1000 (causing the O(N^2) cost).&lt;/p&gt;

&lt;p&gt;Note that the goal here is to be able to switch to flushing by RAM&lt;br/&gt;
buffer size instead of docCount (and also merge by byte-size of&lt;br/&gt;
segments not doc count), by default, in IndexWriter.  But, even once&lt;br/&gt;
we do that, if you always flush tiny segments the new merge policy&lt;br/&gt;
will still build levels &quot;all the way down&quot;.&lt;/p&gt;

&lt;p&gt;Here&apos;s an idea: maybe we can accept the O(N^2) merge cost, when the&lt;br/&gt;
segments are &quot;small&quot;?  Ie, maybe doing 100 sub-optimal merges (in the&lt;br/&gt;
example above) does not amount to that much actual cost in practice.&lt;br/&gt;
(After all nobody has complained about this &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;.&lt;/p&gt;

&lt;p&gt;I will run some tests.  Clearly at some point the O(N^2) cost will&lt;br/&gt;
dominate your indexing time, but maybe we can set a &quot;rough&quot; docCount&lt;br/&gt;
below which all segments are counted as a single level and not take&lt;br/&gt;
too much of a indexing performance hit.&lt;/p&gt;</comment>
                    <comment id="12520334" author="yseeley@gmail.com" created="Thu, 16 Aug 2007 19:53:06 +0100"  >&lt;p&gt;You may avoid the cost of a bunch of small merges, but then you pay the price in searching performance.  I&apos;m not sure that&apos;s the right tradeoff because if someone wanted to optimize for indexing performance, they would do more in batches.&lt;/p&gt;

&lt;p&gt;How does this work when flushing by MB?  If you set setRamBufferSizeMB(32), are you guaranteed that you never have more than 10 segments less than 32MB (ignoring LEVEL_LOG_SPAN for now) if mergeFactor is 10?&lt;/p&gt;

&lt;p&gt;Almost seems like we need a minSegmentSize parameter too - using setRamBufferSizeMB confuses two different but related issues.&lt;/p&gt;</comment>
                    <comment id="12520336" author="steven_parkes" created="Thu, 16 Aug 2007 20:05:03 +0100"  >&lt;p&gt; 	Here&apos;s an idea: maybe we can accept the O(N^2) merge cost, when the&lt;br/&gt;
	segments are &quot;small&quot;?&lt;/p&gt;

&lt;p&gt;That&apos;s basically the underlying idea I was trying to get at.&lt;/p&gt;</comment>
                    <comment id="12520343" author="mikemccand" created="Thu, 16 Aug 2007 20:42:31 +0100"  >
&lt;p&gt;&amp;gt; You may avoid the cost of a bunch of small merges, but then you pay&lt;br/&gt;
&amp;gt; the price in searching performance. I&apos;m not sure that&apos;s the right&lt;br/&gt;
&amp;gt; tradeoff because if someone wanted to optimize for indexing&lt;br/&gt;
&amp;gt; performance, they would do more in batches.&lt;/p&gt;

&lt;p&gt;Agreed.&lt;/p&gt;

&lt;p&gt;It&apos;s like we would want to run &quot;partial optimize&quot; (ie, merge the tail&lt;br/&gt;
of &quot;small&quot; segments) on demand, only when a reader is about to&lt;br/&gt;
refresh.&lt;/p&gt;

&lt;p&gt;Or here&apos;s another random idea: maybe IndexReaders should load the tail&lt;br/&gt;
of &quot;small segments&quot; into a RAMDirectory, for each one.  Ie, an&lt;br/&gt;
IndexReader is given a RAM buffer &quot;budget&quot; and it spends it on any&lt;br/&gt;
numerous small segments in the index....?&lt;/p&gt;

&lt;p&gt;&amp;gt; How does this work when flushing by MB? If you set&lt;br/&gt;
&amp;gt; setRamBufferSizeMB(32), are you guaranteed that you never have more&lt;br/&gt;
&amp;gt; than 10 segments less than 32MB (ignoring LEVEL_LOG_SPAN for now) if&lt;br/&gt;
&amp;gt; mergeFactor is 10?&lt;/p&gt;

&lt;p&gt;No, we have the same challenge of avoiding O(N^2) merge cost.  When&lt;br/&gt;
merging by &quot;byte size&quot; of the segments, I don&apos;t look at the current&lt;br/&gt;
RAM buffer size of the writer.&lt;/p&gt;

&lt;p&gt;I feel like there should be a strong separation of &quot;flush params&quot; from&lt;br/&gt;
&quot;merge params&quot;.&lt;/p&gt;

&lt;p&gt;&amp;gt; Almost seems like we need a minSegmentSize parameter too - using&lt;br/&gt;
&amp;gt; setRamBufferSizeMB confuses two different but related issues.&lt;/p&gt;

&lt;p&gt;Exactly!  I&apos;m thinking that I add &quot;minSegmentSize&quot; to the&lt;br/&gt;
LogMergePolicy, which is separate from &quot;maxBufferedDocs&quot; and&lt;br/&gt;
&quot;ramBufferSizeMB&quot;.  And, we default it to values that seem like an&lt;br/&gt;
&quot;acceptable&quot; tradeoff of the cost of O(N^2) merging (based on tests I&lt;br/&gt;
will run) vs the cost of slowdown to readers...&lt;/p&gt;

&lt;p&gt;I&apos;ll run some perf tests.  O(N^2) should be acceptable for certain&lt;br/&gt;
segment sizes....&lt;/p&gt;</comment>
                    <comment id="12520344" author="mikemccand" created="Thu, 16 Aug 2007 20:43:11 +0100"  >&lt;p&gt;&amp;gt; &amp;gt; Here&apos;s an idea: maybe we can accept the O(N^2) merge cost, when&lt;br/&gt;
&amp;gt; &amp;gt; the segments are &quot;small&quot;?&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; That&apos;s basically the underlying idea I was trying to get at.&lt;/p&gt;

&lt;p&gt;Ahh, good!  We agree &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="12520351" author="mikemccand" created="Thu, 16 Aug 2007 21:01:53 +0100"  >&lt;p&gt;&amp;gt; Or here&apos;s another random idea: maybe IndexReaders should load the&lt;br/&gt;
&amp;gt; tail of &quot;small segments&quot; into a RAMDirectory, for each one. Ie, an&lt;br/&gt;
&amp;gt; IndexReader is given a RAM buffer &quot;budget&quot; and it spends it on any&lt;br/&gt;
&amp;gt; numerous small segments in the index....?&lt;/p&gt;

&lt;p&gt;Following up on this ... I think IndexReader could load &quot;small tail&lt;br/&gt;
segments&quot; into RAMDirectory and then do a merge on them to make&lt;br/&gt;
search even faster.  It should typically be extremely fast if we set the&lt;br/&gt;
defaults right, and RAM usage should be quite low since merging&lt;br/&gt;
small segments usually gives great compression in net bytes used.&lt;/p&gt;

&lt;p&gt;This would allow us to avoid (or, minimize) the O(N^2) cost on merging&lt;br/&gt;
to ensure that an index is &quot;at all instants&quot; ready for a reader to&lt;br/&gt;
directly load it.  This basically gives us our &quot;merge tail segments on&lt;br/&gt;
demand when a reader refreshes&quot;.&lt;/p&gt;

&lt;p&gt;We can do a combination of these two approaches, whereby the&lt;br/&gt;
IndexWriter is free to make use a &quot;long tail&quot; of segments so it&lt;br/&gt;
doesn&apos;t have O(N^2) slowdown on merge cost, yet a reader pays very&lt;br/&gt;
small (one-time) cost for such segments.&lt;/p&gt;

&lt;p&gt;I think the combination of these two changes should give a net/net&lt;br/&gt;
sizable improvement on &quot;low latency&quot; apps.... because IndexWriter is&lt;br/&gt;
free to make miniscule segments (document by document even) and&lt;br/&gt;
IndexReader (especially combined with &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-743&quot; title=&quot;IndexReader.reopen()&quot;&gt;&lt;del&gt;LUCENE-743&lt;/del&gt;&lt;/a&gt;) can quickly&lt;br/&gt;
re-open and do a &quot;mini-optimize&quot; on the tail segments and have&lt;br/&gt;
great performance.&lt;/p&gt;</comment>
                    <comment id="12520360" author="steven_parkes" created="Thu, 16 Aug 2007 21:33:04 +0100"  >&lt;p&gt;	I think the combination of these two changes should give a net/net&lt;br/&gt;
	sizable improvement on &quot;low latency&quot; apps....&lt;/p&gt;

&lt;p&gt;I think this would be great. It&apos;s always been a pet peeve of mine that even in low pressure/activity environments, there is often a delay from write to read.&lt;/p&gt;

&lt;p&gt;Sounds like this would help take most of the work/risk off the developer.&lt;/p&gt;</comment>
                    <comment id="12520378" author="mikemccand" created="Thu, 16 Aug 2007 22:32:21 +0100"  >&lt;p&gt;&amp;gt; I think this would be great. It&apos;s always been a pet peeve of mine&lt;br/&gt;
&amp;gt; that even in low pressure/activity environments, there is often a&lt;br/&gt;
&amp;gt; delay from write to read.&lt;/p&gt;

&lt;p&gt;I&apos;ll open a new issue.&lt;/p&gt;

&lt;p&gt;&amp;gt; Sounds like this would help take most of the work/risk off the&lt;br/&gt;
&amp;gt; developer.&lt;/p&gt;

&lt;p&gt;Precisely!  Out of the box we can have very low latency from&lt;br/&gt;
IndexWriter flushing single doc segments, and not having to pay the&lt;br/&gt;
O(N^2) merge cost of merging down such segments to be &quot;at all moments&quot;&lt;br/&gt;
ready for an IndexReader to open the index, while IndexReader can load&lt;br/&gt;
such an index (or re-open by loading only the &quot;new&quot; segments) and very&lt;br/&gt;
quickly reduce the # segments so that searching is still fast.&lt;/p&gt;
</comment>
                    <comment id="12520611" author="yseeley@gmail.com" created="Fri, 17 Aug 2007 18:34:56 +0100"  >&lt;p&gt;Merging small segments in the reader seems like a cool idea on it&apos;s own.&lt;br/&gt;
But if it&apos;s an acceptable hit to merge in the reader, why is it not in the writer?&lt;/p&gt;

&lt;p&gt;Think about a writer flushing 10 small segments and a new reader opened each time:&lt;br/&gt;
The reader would do ~10*10/2 merges if it just merged the small segments.&lt;br/&gt;
If the writer were to do the merging instead, it would need to merge ~10 segments.&lt;/p&gt;

&lt;p&gt;Thinking about it anotherway... if there were no separation between reader and writer, and small segments were merged on an open, why not just write out the result so it wouldn&apos;t have to be done again?  Now move &quot;merge on an open&quot; to &quot;merge on the close&quot; and that&apos;s what IndexWriter currently does.  Why is it OK for a reader to pay the price but not the writer?&lt;/p&gt;

&lt;p&gt;Also, would this tail merging on an open be able to reduce the peak number of file descriptors?&lt;br/&gt;
It seems like to do so, the tail would have to be merged &lt;b&gt;before&lt;/b&gt; other index files were opened, further complicating matters.&lt;/p&gt;</comment>
                    <comment id="12520649" author="mikemccand" created="Fri, 17 Aug 2007 20:33:56 +0100"  >&lt;p&gt;&amp;gt; Merging small segments in the reader seems like a cool idea on it&apos;s&lt;br/&gt;
&amp;gt; own.  But if it&apos;s an acceptable hit to merge in the reader, why is&lt;br/&gt;
&amp;gt; it not in the writer?&lt;/p&gt;

&lt;p&gt;Good point.  I think it comes down to how often we expect readers to&lt;br/&gt;
refresh vs writers flushing.&lt;/p&gt;

&lt;p&gt;If indeed it&apos;s 1 to 1 (as the truest &quot;low latency&quot; app would in fact&lt;br/&gt;
be, or a &quot;single writer + reader with no separation&quot;), then the writer&lt;br/&gt;
should merge them because although it&apos;s paying an O(N^2) cost to keep&lt;br/&gt;
the tail &quot;short&quot;, merging on open would pay even more cost.&lt;/p&gt;

&lt;p&gt;But if writer flushes frequently and reader re-opens less frequently&lt;br/&gt;
then it&apos;s better to merge on open.&lt;/p&gt;

&lt;p&gt;Of course, if the O(N^2) cost for IndexWriter to keep a short tail is&lt;br/&gt;
in practice not too costly then we should just leave this in&lt;br/&gt;
IndexWriter.  I still need to run that test for &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-845&quot; title=&quot;If you &amp;quot;flush by RAM usage&amp;quot; then IndexWriter may over-merge&quot;&gt;&lt;del&gt;LUCENE-845&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&amp;gt; Also, would this tail merging on an open be able to reduce the peak&lt;br/&gt;
&amp;gt; number of file descriptors?  It seems like to do so, the tail would&lt;br/&gt;
&amp;gt; have to be merged &lt;b&gt;before&lt;/b&gt; other index files were opened, further&lt;br/&gt;
&amp;gt; complicating matters.&lt;/p&gt;

&lt;p&gt;Right I think to keep peak descriptor usage capped we must merge the&lt;br/&gt;
tail, first, then open the remaining segments, which definitely&lt;br/&gt;
complicate things...&lt;/p&gt;</comment>
                    <comment id="12520655" author="yseeley@gmail.com" created="Fri, 17 Aug 2007 21:12:58 +0100"  >&lt;p&gt;&amp;gt; But if writer flushes frequently and reader re-opens less frequently&lt;br/&gt;
&amp;gt; then it&apos;s better to merge on open.&lt;/p&gt;

&lt;p&gt;Seems like an odd case though, because if readers aren&apos;t opened frequently, then it&apos;s a wast to flush small segments so often (and much slower for the writer than not doing so).&lt;/p&gt;</comment>
                    <comment id="12520667" author="mikemccand" created="Fri, 17 Aug 2007 21:44:35 +0100"  >&lt;p&gt;Agreed.  OK, I think this is a dead end: it adds complexity and won&apos;t&lt;br/&gt;
help in &quot;typical&quot; uses of Lucene.&lt;/p&gt;

&lt;p&gt;So ... my plan of action is to assess the &quot;actual&quot; O(N^2) cost for&lt;br/&gt;
IndexWriter to keep the tail short, add a parameter to LogMergePolicy&lt;br/&gt;
so that it &quot;floors&quot; the level and always merges segments less than&lt;br/&gt;
this floor together, despite the O(N^2) cost.  And then pick a&lt;br/&gt;
reasonable default for this floor.&lt;/p&gt;</comment>
                    <comment id="12526403" author="mikemccand" created="Tue, 11 Sep 2007 11:16:43 +0100"  >&lt;p&gt;In the latest patch on &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-847&quot; title=&quot;Factor merge policy out of IndexWriter&quot;&gt;&lt;del&gt;LUCENE-847&lt;/del&gt;&lt;/a&gt; I&apos;ve added methods to&lt;br/&gt;
LogDocMergePolicy (setMinMergeDocs) and LogByteSizeMergePolicy&lt;br/&gt;
(setMinMergeMB) to set a floor on the segment levels such that all&lt;br/&gt;
segments below this min size are aggressively merged as if they were in&lt;br/&gt;
one level.  This effectively &quot;truncates&quot; what would otherwise be a&lt;br/&gt;
long tail of segment sizes, when you are flushing many tiny segments&lt;br/&gt;
into your index.&lt;/p&gt;

&lt;p&gt;In order to pick reasonable defaults for the min segment size, I ran&lt;br/&gt;
some benchmarks to measure the indexing cost of truncating the tail.&lt;/p&gt;

&lt;p&gt;I processed Wiki content into ~4 KB plain text documents and then&lt;br/&gt;
indexed the first 10,000 docs using this alg:&lt;/p&gt;

&lt;p&gt;  analyzer=org.apache.lucene.analysis.SimpleAnalyzer&lt;br/&gt;
  doc.maker=org.apache.lucene.benchmark.byTask.feeds.LineDocMaker&lt;br/&gt;
  directory=FSDirectory&lt;br/&gt;
  docs.file=/lucene/wiki4K.txt&lt;br/&gt;
  max.buffered = 500&lt;/p&gt;

&lt;p&gt;  ResetSystemErase&lt;br/&gt;
  CreateIndex&lt;br/&gt;
  {AddDoc &amp;gt;: 10000&lt;br/&gt;
  CloseIndex&lt;/p&gt;

&lt;p&gt;  RepSumByName&lt;/p&gt;

&lt;p&gt;I&apos;m using the SerialMergeScheduler.&lt;/p&gt;

&lt;p&gt;I modified contrib/benchmark to always flush a new segment after each&lt;br/&gt;
added document: this simulates the &quot;worst case&quot; of tiny segments, ie,&lt;br/&gt;
lowest latency indexing where every added doc must then be visible to&lt;br/&gt;
searchers.&lt;/p&gt;

&lt;p&gt;Each time is best of 2 runs.  This is run on Linux (2.6.22.1) Core II&lt;br/&gt;
Duo 2.4 Ghz machine with 4 GB RAM, RAID 5 IO system using Java 1.5&lt;br/&gt;
-server.&lt;/p&gt;

&lt;p&gt;    maxBufferedDocs   seconds    slowdown&lt;br/&gt;
    10                40         1.0&lt;br/&gt;
    100               50         1.3&lt;br/&gt;
    200               59         1.5&lt;br/&gt;
    300               64         1.6&lt;br/&gt;
    400               72         1.8&lt;br/&gt;
    500               80         2.0&lt;br/&gt;
    750               97         2.4&lt;br/&gt;
   1000              114         2.9&lt;br/&gt;
   1500              138         3.5&lt;br/&gt;
   2000              169         4.2&lt;br/&gt;
   3000              205         5.1&lt;br/&gt;
   4000              264         6.6&lt;br/&gt;
   5000              320         8.0&lt;br/&gt;
   7500              404        10.1&lt;br/&gt;
  10000              645        16.1&lt;/p&gt;

&lt;p&gt;Here&apos;s my thinking:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;If you are flushing zillions of such tiny segments I think it&apos;s OK&lt;br/&gt;
    to accept a net/net sizable slowdown of your overall indexing&lt;br/&gt;
    speed.  I&apos;ll choose a 4X slowdown &quot;tolerance&quot; to choose default&lt;br/&gt;
    values.  This corresponds roughly to the &quot;2000&quot; line above.&lt;br/&gt;
    However, because I tested on a fairly fast CPU &amp;amp; IO system I&apos;ll&lt;br/&gt;
    multiply the numbers by 0.5.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Given this, I propose we default the minMergeMB&lt;br/&gt;
    (LogByteSizeMergePolicy) to 1.6 MB (avg size of real segments at&lt;br/&gt;
    the 2000 point above was 3.2 MB) and default minMergeDocs&lt;br/&gt;
    (LogDocMergePolicy) to 1000.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Note that when you are flushing large segments (larger than these&lt;br/&gt;
    min size settings) then there is no slowdown at all because the&lt;br/&gt;
    flushed segments are already above the minimum size.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;These are just defaults, so a given application can always change&lt;br/&gt;
their &quot;min merge size&quot; as needed.&lt;/p&gt;</comment>
                    <comment id="12526435" author="yseeley@gmail.com" created="Tue, 11 Sep 2007 12:57:18 +0100"  >&lt;p&gt;Thanks for adding minMergeMB, the default seems fine.&lt;br/&gt;
Shound minMergeDocs default to maxBufferedDocs (that should yield the old behavior)?&lt;br/&gt;
Although 1000 isn&apos;t bad... much better to slow indexing a little in the odd app than to break it by running it out of descriptors.&lt;/p&gt;</comment>
                    <comment id="12526460" author="mikemccand" created="Tue, 11 Sep 2007 15:00:35 +0100"  >&lt;p&gt;&amp;gt; Shound minMergeDocs default to maxBufferedDocs (that should yield&lt;br/&gt;
&amp;gt; the old behavior)?&lt;/p&gt;

&lt;p&gt;Good idea &amp;#8211; I think we could do this dynamically so that whenever&lt;br/&gt;
IndexWriter is flushing by doc count and the merge policy is&lt;br/&gt;
LogDocMergePolicy we &quot;write through&quot; any changes to maxBufferedDocs&lt;br/&gt;
--&amp;gt; LogDocMergePolicy.setMinMergeDocs?  I&apos;ll take that approach to&lt;br/&gt;
keep backwards compatibility.&lt;/p&gt;

&lt;p&gt;&amp;gt; Although 1000 isn&apos;t bad... much better to slow indexing a little in&lt;br/&gt;
&amp;gt; the odd app than to break it by running it out of descriptors.&lt;/p&gt;

&lt;p&gt;Agreed, that&apos;s the right direction to &quot;err&quot; here.&lt;/p&gt;</comment>
                </comments>
                <issuelinks>
                        <issuelinktype id="10032">
                <name>Blocker</name>
                                <outwardlinks description="blocks">
                            <issuelink>
            <issuekey id="12365595">LUCENE-843</issuekey>
        </issuelink>
                    </outwardlinks>
                                                <inwardlinks description="is blocked by">
                            <issuelink>
            <issuekey id="12365696">LUCENE-847</issuekey>
        </issuelink>
                    </inwardlinks>
                            </issuelinktype>
                    </issuelinks>
                <attachments>
                    <attachment id="12363895" name="LUCENE-845.patch" size="13178" author="mikemccand" created="Thu, 16 Aug 2007 00:57:42 +0100" />
                </attachments>
            <subtasks>
        </subtasks>
                <customfields>
                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                <customfieldname>Attachment count</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>1.0</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                <customfieldname>Date of First Response</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>Mon, 26 Mar 2007 16:22:44 +0000</customfieldvalue>

                </customfieldvalues>
            </customfield>
                                                                                                        <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Global Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>12896</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                <customfieldname>Lucene Fields</customfieldname>
                <customfieldvalues>
                        <customfieldvalue key="10121"><![CDATA[New]]></customfieldvalue>
    
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>26884</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                <customfieldname>Time in Status</customfieldname>
                <customfieldvalues>
                    
                </customfieldvalues>
            </customfield>
                            </customfields>
    </item>
</channel>
</rss>