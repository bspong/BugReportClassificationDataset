<!-- 
RSS generated by JIRA (5.2.8#851-sha1:3262fdc28b4bc8b23784e13eadc26a22399f5d88) at Tue Jul 16 13:13:48 UTC 2013

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/LUCENE-1458/LUCENE-1458.xml?field=key&field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>5.2.8</version>
        <build-number>851</build-number>
        <build-date>26-02-2013</build-date>
    </build-info>

<item>
            <title>[LUCENE-1458] Further steps towards flexible indexing</title>
                <link>https://issues.apache.org/jira/browse/LUCENE-1458</link>
                <project id="12310110" key="LUCENE">Lucene - Core</project>
                        <description>&lt;p&gt;I attached a very rough checkpoint of my current patch, to get early&lt;br/&gt;
feedback.  All tests pass, though back compat tests don&apos;t pass due to&lt;br/&gt;
changes to package-private APIs plus certain bugs in tests that&lt;br/&gt;
happened to work (eg call TermPostions.nextPosition() too many times,&lt;br/&gt;
which the new API asserts against).&lt;/p&gt;

&lt;p&gt;[Aside: I think, when we commit changes to package-private APIs such&lt;br/&gt;
that back-compat tests don&apos;t pass, we could go back, make a branch on&lt;br/&gt;
the back-compat tag, commit changes to the tests to use the new&lt;br/&gt;
package private APIs on that branch, then fix nightly build to use the&lt;br/&gt;
tip of that branch?o]&lt;/p&gt;

&lt;p&gt;There&apos;s still plenty to do before this is committable! This is a&lt;br/&gt;
rather large change:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Switches to a new more efficient terms dict format.  This still&lt;br/&gt;
    uses tii/tis files, but the tii only stores term &amp;amp; long offset&lt;br/&gt;
    (not a TermInfo).  At seek points, tis encodes term &amp;amp; freq/prox&lt;br/&gt;
    offsets absolutely instead of with deltas delta.  Also, tis/tii&lt;br/&gt;
    are structured by field, so we don&apos;t have to record field number&lt;br/&gt;
    in every term.&lt;br/&gt;
.&lt;br/&gt;
    On first 1 M docs of Wikipedia, tii file is 36% smaller (0.99 MB&lt;br/&gt;
    -&amp;gt; 0.64 MB) and tis file is 9% smaller (75.5 MB -&amp;gt; 68.5 MB).&lt;br/&gt;
.&lt;br/&gt;
    RAM usage when loading terms dict index is significantly less&lt;br/&gt;
    since we only load an array of offsets and an array of String (no&lt;br/&gt;
    more TermInfo array).  It should be faster to init too.&lt;br/&gt;
.&lt;br/&gt;
    This part is basically done.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Introduces modular reader codec that strongly decouples terms dict&lt;br/&gt;
    from docs/positions readers.  EG there is no more TermInfo used&lt;br/&gt;
    when reading the new format.&lt;br/&gt;
.&lt;br/&gt;
    There&apos;s nice symmetry now between reading &amp;amp; writing in the codec&lt;br/&gt;
    chain &amp;#8211; the current docs/prox format is captured in:
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
FormatPostingsTermsDictWriter/Reader
FormatPostingsDocsWriter/Reader (.frq file) and
FormatPostingsPositionsWriter/Reader (.prx file).
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;    This part is basically done.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Introduces a new &quot;flex&quot; API for iterating through the fields,&lt;br/&gt;
    terms, docs and positions:
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
FieldProducer -&amp;gt; TermsEnum -&amp;gt; DocsEnum -&amp;gt; PostingsEnum
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;    This replaces TermEnum/Docs/Positions.  SegmentReader emulates the&lt;br/&gt;
    old API on top of the new API to keep back-compat.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Next steps:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Plug in new codecs (pulsing, pfor) to exercise the modularity /&lt;br/&gt;
    fix any hidden assumptions.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Expose new API out of IndexReader, deprecate old API but emulate&lt;br/&gt;
    old API on top of new one, switch all core/contrib users to the&lt;br/&gt;
    new API.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Maybe switch to AttributeSources as the base class for TermsEnum,&lt;br/&gt;
    DocsEnum, PostingsEnum &amp;#8211; this would give readers API flexibility&lt;br/&gt;
    (not just index-file-format flexibility).  EG if someone wanted&lt;br/&gt;
    to store payload at the term-doc level instead of&lt;br/&gt;
    term-doc-position level, you could just add a new attribute.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Test performance &amp;amp; iterate.&lt;/li&gt;
&lt;/ul&gt;
</description>
                <environment></environment>
            <key id="12408724">LUCENE-1458</key>
            <summary>Further steps towards flexible indexing</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/newfeature.png">New Feature</type>
                                <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                    <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png">Closed</status>
                    <resolution id="1">Fixed</resolution>
                                <assignee username="mikemccand">Michael McCandless</assignee>
                                <reporter username="mikemccand">Michael McCandless</reporter>
                        <labels>
                    </labels>
                <created>Tue, 18 Nov 2008 10:31:51 +0000</created>
                <updated>Fri, 10 May 2013 11:44:39 +0100</updated>
                    <resolved>Thu, 3 Dec 2009 23:30:30 +0000</resolved>
                            <version>4.0-ALPHA</version>
                                <fixVersion>4.0-ALPHA</fixVersion>
                                <component>core/index</component>
                        <due></due>
                    <votes>1</votes>
                        <watches>7</watches>
                                                    <comments>
                    <comment id="12648613" author="markrmiller@gmail.com" created="Tue, 18 Nov 2008 14:40:35 +0000"  >&lt;p&gt;Hmmm...I think something is missing -  FormatPostingsPositionsReader?&lt;/p&gt;</comment>
                    <comment id="12648627" author="mikemccand" created="Tue, 18 Nov 2008 15:41:06 +0000"  >&lt;p&gt;Woops, sorry... I was missing a bunch of files.  Try this one?&lt;/p&gt;</comment>
                    <comment id="12648727" author="creamyg" created="Tue, 18 Nov 2008 19:52:41 +0000"  >&lt;p&gt;The work on streamlining the term dictionary is excellent, but perhaps we can do better still.  Can we design a format that allows us rely upon the operating system&apos;s virtual memory and avoid caching in process memory altogether?  &lt;/p&gt;

&lt;p&gt;Say that we break up the index file into fixed-width blocks of 1024 bytes.  Most blocks would start with a complete term/pointer pairing, though at the top of each block, we&apos;d need a status byte indicating whether the block contains a continuation from the previous block in order to handle cases where term length exceeds the block size.  &lt;/p&gt;

&lt;p&gt;For Lucy/KinoSearch our plan would be to mmap() on the file, but accessing it as a stream would work, too.  Seeking around the index term dictionary would involve seeking the stream to multiples of the block size and performing binary search, rather than performing binary search on an array of cached terms.  There would be increased processor overhead; my guess is that since the second stage of a term dictionary seek &amp;#8211; scanning through the primary term dictionary &amp;#8211; involves comparatively more processor power than this, the increased costs would be acceptable.&lt;/p&gt;

&lt;p&gt;Advantages:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Multiple forks can all share the same system buffer, reducing per-process memory footprint.&lt;/li&gt;
	&lt;li&gt;The cost to read in the index term dictionary during IndexReader startup drops to zero.&lt;/li&gt;
	&lt;li&gt;The OS caches for the index term dictionaries can either be allowed to warm naturally, or can be nudged into virtual memory via e.g. &quot;cat /path/to/index/*.tis &amp;gt; /dev/null&quot;.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12648739" author="mikemccand" created="Tue, 18 Nov 2008 20:25:49 +0000"  >&lt;blockquote&gt;&lt;p&gt;Can we design a format that allows us rely upon the operating system&apos;s virtual memory and avoid caching in process memory altogether?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Interesting!  I&apos;ve been wondering what you&apos;re up to over on KS, Marvin &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;I&apos;m not sure it&apos;ll be a win in practice: I&apos;m not sure I&apos;d trust the&lt;br/&gt;
OS&apos;s IO cache to &quot;make the right decisions&quot; about what to cache.  Plus&lt;br/&gt;
during that binary search the IO system is loading whole pages into&lt;br/&gt;
the IO cache, even though you&apos;ll only peak at the first few bytes of&lt;br/&gt;
each.&lt;/p&gt;

&lt;p&gt;We could also explore something in-between, eg it&apos;d be nice to&lt;br/&gt;
genericize MultiLevelSkipListWriter so that it could index arbitrary&lt;br/&gt;
files, then we could use that to index the terms dict.  You could&lt;br/&gt;
choose to spend dedicated process RAM on the higher levels of the skip&lt;br/&gt;
tree, and then tentatively trust IO cache for the lower levels.&lt;/p&gt;

&lt;p&gt;I&apos;d like to eventually make the TermsDict index pluggable so one could&lt;br/&gt;
swap in different indexers like this (it&apos;s not now).&lt;/p&gt;</comment>
                    <comment id="12648776" author="mikemccand" created="Tue, 18 Nov 2008 22:10:13 +0000"  >
&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;Attached patch&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;To test whether the new pluggable codec approach is flexible enough, I&lt;br/&gt;
coded up &quot;pulsing&quot; (described in detail in&lt;br/&gt;
&lt;a href=&quot;http://citeseer.ist.psu.edu/cutting90optimizations.html&quot; class=&quot;external-link&quot;&gt;http://citeseer.ist.psu.edu/cutting90optimizations.html&lt;/a&gt;), where&lt;br/&gt;
freq/prox info is inlined into the terms dict if the term freq is &amp;lt; N.&lt;/p&gt;

&lt;p&gt;It was wonderfully simple &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; I just had to create a reader &amp;amp; a writer,&lt;br/&gt;
and then switch the places that read (SegmentReader) and write&lt;br/&gt;
(SegmentMerger, FreqProxTermsWriter) to use the new pulsing codec&lt;br/&gt;
instead of the default one.&lt;/p&gt;

&lt;p&gt;The pulsing codec can &quot;wrap&quot; any other codec, ie, when a term is&lt;br/&gt;
written, if the term&apos;s freq is &amp;lt; N, then it&apos;s inlined into the terms&lt;br/&gt;
dict with the pulsing writer, else it&apos;s fed to the other codec for it&lt;br/&gt;
to do whatever it normally would.  The two codecs are strongly&lt;br/&gt;
decoupled, so we can mix &amp;amp; match pulsing with other codecs like pfor.&lt;/p&gt;

&lt;p&gt;All tests pass with this pulsing codec.&lt;/p&gt;

&lt;p&gt;As a quick test I indexed first 1M docs from Wikipedia, with N=2 (ie&lt;br/&gt;
terms that occur only in one document are inlined into the terms&lt;br/&gt;
dict).  5.4M terms get inlined (only 1 doc) and 2.2M terms are not (&amp;gt;&lt;br/&gt;
1 doc).  The final size of the index (after optimizing) was a bit&lt;br/&gt;
smaller with pulsing (1120 MB vs 1131 MB).&lt;/p&gt;</comment>
                    <comment id="12648781" author="michaelbusch" created="Tue, 18 Nov 2008 22:18:47 +0000"  >&lt;p&gt;I&apos;ll look into this patch soon.&lt;/p&gt;

&lt;p&gt;Just wanted to say: I&apos;m really excited about the progress here, this is cool stuff!&lt;br/&gt;
Great job...&lt;/p&gt;</comment>
                    <comment id="12648835" author="creamyg" created="Wed, 19 Nov 2008 00:19:11 +0000"  >&lt;p&gt;&amp;gt; I&apos;m not sure I&apos;d trust the OS&apos;s IO cache to &quot;make the right decisions&quot; about what to cache.&lt;/p&gt;

&lt;p&gt;In KS and Lucy, at least, we&apos;re focused on optimizing for the use case of dedicated search clusters where each box has enough RAM to fit the entire index/shard &amp;#8211; in which case we won&apos;t have to worry about the OS swapping out those pages.&lt;/p&gt;

&lt;p&gt;I suspect that in many circumstances the term dictionary would be a hot file even if RAM were running short, but I don&apos;t think it&apos;s important to worry about maxing out performance on such systems &amp;#8211; if the term dictionary isn&apos;t hot the posting list files are definitely not hot and search-time responsiveness is already compromised.&lt;/p&gt;

&lt;p&gt;In other words...&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;I trust the OS to do a decent enough job on underpowered systems.&lt;/li&gt;
	&lt;li&gt;High-powered systems should strive to avoid swapping entirely. To aid in that endeavor, we minimize per-process RAM consumption by maximizing our use of mmap and treating the system IO cache backing buffers as interprocess shared memory.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;More on designing with modern virtual memory in mind at &amp;lt;&lt;a href=&quot;http://varnish.projects.linpro.no/wiki/ArchitectNotes&quot; class=&quot;external-link&quot;&gt;http://varnish.projects.linpro.no/wiki/ArchitectNotes&lt;/a&gt;&amp;gt;.&lt;/p&gt;

&lt;p&gt;&amp;gt; Plus during that binary search the IO system is loading whole pages into&lt;br/&gt;
&amp;gt; the IO cache, even though you&apos;ll only peak at the first few bytes of each.&lt;/p&gt;

&lt;p&gt;I&apos;d originally been thinking of mapping only the term dictionary index files. Those are pretty small, and the file itself occupies fewer bytes than the decompressed array of term/pointer pairs. Even better if you have several search app forks and they&apos;re all sharing the same memory mapped system IO buffer.&lt;/p&gt;

&lt;p&gt;But hey, we can simplify even further! How about dispensing with the index file? We can just divide the main dictionary file into blocks and binary search on that.&lt;/p&gt;

&lt;p&gt;Killing off the term dictionary index yields a nice improvement in code and file specification simplicity, and there&apos;s no performance penalty for our primary optimization target use case.&lt;/p&gt;

&lt;p&gt;&amp;gt; We could also explore something in-between, eg it&apos;d be nice to&lt;br/&gt;
&amp;gt; genericize MultiLevelSkipListWriter so that it could index arbitrary&lt;br/&gt;
&amp;gt; files, then we could use that to index the terms dict. You could&lt;br/&gt;
&amp;gt; choose to spend dedicated process RAM on the higher levels of the skip&lt;br/&gt;
&amp;gt; tree, and then tentatively trust IO cache for the lower levels.&lt;/p&gt;

&lt;p&gt;That doesn&apos;t meet the design goals of bringing the cost of opening/warming an IndexReader down to near-zero and sharing backing buffers among multiple forks. It&apos;s also very complicated, which of course bothers me more than it bothers you. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; So I imagine we&apos;ll choose different paths.&lt;/p&gt;

&lt;p&gt;&amp;gt; I&apos;d like to eventually make the TermsDict index pluggable so one could&lt;br/&gt;
&amp;gt; swap in different indexers like this (it&apos;s not now).&lt;/p&gt;

&lt;p&gt;If we treat the term dictionary as a black box, it has to accept a term and return... a blob, I guess.  Whatever calls the lookup needs to know how to handle that blob.&lt;/p&gt;</comment>
                    <comment id="12648839" author="michaelbusch" created="Wed, 19 Nov 2008 00:37:09 +0000"  >&lt;blockquote&gt;
&lt;p&gt;We could also explore something in-between, eg it&apos;d be nice to&lt;br/&gt;
genericize MultiLevelSkipListWriter so that it could index arbitrary&lt;br/&gt;
files, then we could use that to index the terms dict.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Hmm, +1 for generalizing the MultiLevelSkipListWriter/Reader so that we can re-use it for different (custom) posting-list formats easily.&lt;br/&gt;
However, I&apos;m not so sure if it&apos;s the right approach for a dictionary. A skip list is optimized for skipping forward (as the name says), so excellent for positing lists, which are always read from &quot;left to right&quot;. &lt;br/&gt;
However, in the term dictionary you do a binary search for the lookup term. So something like a B+Tree would probably work better. Then you can decide similar to the MultiLevelSkipListWriter how many of the upper levels you want to keep in memory and control memory consumption.&lt;/p&gt;</comment>
                    <comment id="12648971" author="mikemccand" created="Wed, 19 Nov 2008 10:28:39 +0000"  >&lt;blockquote&gt;&lt;p&gt;So something like a B+Tree would probably work better.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I agree, btree is a better fit, though we don&apos;t need insertion &amp;amp; deletion operations since each segment is write once.&lt;/p&gt;</comment>
                    <comment id="12649028" author="mikemccand" created="Wed, 19 Nov 2008 13:12:41 +0000"  >
&lt;blockquote&gt;
&lt;p&gt;In KS and Lucy, at least, we&apos;re focused on optimizing for the use case of dedicated search clusters where each box has enough RAM to fit the entire index/shard - in which case we won&apos;t have to worry about the OS swapping out those pages.&lt;/p&gt;

&lt;p&gt;I suspect that in many circumstances the term dictionary would be a hot file even if RAM were running short, but I don&apos;t think it&apos;s important to worry about maxing out performance on such systems - if the term dictionary isn&apos;t hot the posting list files are definitely not hot and search-time responsiveness is already compromised.&lt;/p&gt;

&lt;p&gt;In other words...&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;I trust the OS to do a decent enough job on underpowered systems.&lt;/li&gt;
	&lt;li&gt;High-powered systems should strive to avoid swapping entirely. To aid in that endeavor, we minimize per-process RAM consumption by maximizing our use of mmap and treating the system IO cache backing buffers as interprocess shared memory.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;These are the two extremes, but, I think most common are all the apps&lt;br/&gt;
in between.  Take a large Jira instance, where the app itself is also&lt;br/&gt;
consuming alot of RAM, doing alot of its own IO, etc., where perhaps&lt;br/&gt;
searching is done infrequently enough relative to other operations&lt;br/&gt;
that the OS may no longer think the pages you hit for the terms index&lt;br/&gt;
are hot enough to keep around.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;More on designing with modern virtual memory in mind at &amp;lt;&lt;a href=&quot;http://varnish.projects.linpro.no/wiki/ArchitectNotes&quot; class=&quot;external-link&quot;&gt;http://varnish.projects.linpro.no/wiki/ArchitectNotes&lt;/a&gt;&amp;gt;.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This is a good read, but I find it overly trusting of VM.&lt;/p&gt;

&lt;p&gt;How can the VM system possibly make good decisions about what to swap&lt;br/&gt;
out?  It can&apos;t know if a page is being used for terms dict index,&lt;br/&gt;
terms dict, norms, stored fields, postings.  LRU is not a good policy,&lt;br/&gt;
because some pages (terms index) are far far more costly to miss than&lt;br/&gt;
others.&lt;/p&gt;

&lt;p&gt;From Java we have even more ridiculous problems: sometimes the OS&lt;br/&gt;
swaps out garbage... and then massive swapping takes place when GC&lt;br/&gt;
runs, swapping back in the garbage only to then throw it away.  Ugh!&lt;/p&gt;

&lt;p&gt;I think we need to aim for &lt;b&gt;consistency&lt;/b&gt;: a given search should not&lt;br/&gt;
suddenly take 10 seconds because the OS decided to swap out a few&lt;br/&gt;
critical structures (like the term index).  Unfortunately we can&apos;t&lt;br/&gt;
really achieve that today, especially from Java.&lt;/p&gt;

&lt;p&gt;I&apos;ve seen my desktop OS (Mac OS X 10.5.5, based on FreeBSD) make&lt;br/&gt;
stupid VM decisions: if I run something that does a single-pass&lt;br/&gt;
through many GB of on-disk data (eg re-encoding a video), it then&lt;br/&gt;
swaps out the vast majority of my apps even though I have 6 GB RAM.  I&lt;br/&gt;
hit tons (many seconds) of swapping just switching back to my mail&lt;br/&gt;
client.  It&apos;s infuriating.  I&apos;ve seen Linux do the same thing, but at&lt;br/&gt;
least Linux let&apos;s you tune this behavior (&quot;swappiness&quot;); I had to&lt;br/&gt;
disable swapping entirely on my desktop.&lt;/p&gt;

&lt;p&gt;Similarly, when a BG merge is burning through data, or say backup&lt;br/&gt;
kicks off and moves many GB, or the simple act of iterating through a&lt;br/&gt;
big postings list, the OS will gleefully evict my terms index or norms&lt;br/&gt;
in order to populate its IO cache with data it will need again for a&lt;br/&gt;
very long time.&lt;/p&gt;

&lt;p&gt;I bet the VM system fails to show graceful degradation: if I don&apos;t&lt;br/&gt;
have enough RAM to hold my entire index, then walking through postings&lt;br/&gt;
lists will evict my terms index and norms, making all searches slower.&lt;/p&gt;

&lt;p&gt;In the ideal world, an IndexReader would be told how much RAM to use.&lt;br/&gt;
It would spend that RAM wisely, eg first on the terms index, second on&lt;br/&gt;
norms, third maybe on select column-stride fields, etc.  It would pin&lt;br/&gt;
these pages so the OS couldn&apos;t swap them out (can&apos;t do this from&lt;br/&gt;
java... though as a workaround we could use a silly thread).  Or, if&lt;br/&gt;
the OS found itself tight on RAM, it would ask the app to free things&lt;br/&gt;
up instead of blindly picking pages to swap out, which does not happen&lt;br/&gt;
today.&lt;/p&gt;

&lt;p&gt;From Java we could try using WeakReference but I fear the&lt;br/&gt;
communication from the OS -&amp;gt; JRE is too weak.  IE I&apos;d want my&lt;br/&gt;
WeakReference cleared only when the OS is threatening to swap out my&lt;br/&gt;
data structure.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&amp;gt; Plus during that binary search the IO system is loading whole pages into&lt;br/&gt;
&amp;gt; the IO cache, even though you&apos;ll only peak at the first few bytes of each.&lt;/p&gt;

&lt;p&gt;I&apos;d originally been thinking of mapping only the term dictionary index files. Those are pretty small, and the file itself occupies fewer bytes than the decompressed array of term/pointer pairs. Even better if you have several search app forks and they&apos;re all sharing the same memory mapped system IO buffer.&lt;/p&gt;

&lt;p&gt;But hey, we can simplify even further! How about dispensing with the index file? We can just divide the main dictionary file into blocks and binary search on that.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;m not convinced this&apos;ll be a win in practice.  You are now paying an&lt;br/&gt;
even higher overhead cost for each &quot;check&quot; of your binary search,&lt;br/&gt;
especially with something like pulsing which inlines more stuff into&lt;br/&gt;
the terms dict.  I agree it&apos;s simpler, but I think that&apos;s trumped by&lt;br/&gt;
the performance hit.&lt;/p&gt;

&lt;p&gt;In Lucene java, the concurrency model we are aiming for is a single&lt;br/&gt;
JVM sharing a single instance of IndexReader.  I do agree, if fork()&lt;br/&gt;
is the basis of your concurrency model then sharing pages becomes&lt;br/&gt;
critical.  However, modern OSs implement copy-on-write sharing of VM&lt;br/&gt;
pages after a fork, so that&apos;s another good path to sharing?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Killing off the term dictionary index yields a nice improvement in code and file specification simplicity, and there&apos;s no performance penalty for our primary optimization target use case.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Have you tried any actual tests swapping these approaches in as your&lt;br/&gt;
terms index impl?  Tests of fully hot and fully cold ends of the&lt;br/&gt;
spectrum would be interesting, but also tests where a big segment&lt;br/&gt;
merge or a backup is running in the background...&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;That doesn&apos;t meet the design goals of bringing the cost of opening/warming an IndexReader down to near-zero and sharing backing buffers among multiple forks.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That&apos;s a nice goal.  Our biggest cost in Lucene is warming the&lt;br/&gt;
FieldCache, used for sorting, function queries, etc.  Column-stride&lt;br/&gt;
fields should go a ways towards improving this.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;It&apos;s also very complicated, which of course bothers me more than it bothers you. So I imagine we&apos;ll choose different paths.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think if we make the pluggable API simple, and capture the&lt;br/&gt;
complexity inside each impl, such that it can be well tested in&lt;br/&gt;
isolation, it&apos;s acceptable.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;If we treat the term dictionary as a black box, it has to accept a term and return... a blob, I guess. Whatever calls the lookup needs to know how to handle that blob. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;In my approach here, the blob is opaque to the terms dict reader: it&lt;br/&gt;
simply seeks to the right spot in the tis file, and then asks the&lt;br/&gt;
codec to decode the entry.  TermsDictReader is entirely unaware of&lt;br/&gt;
what/how is stored there.&lt;/p&gt;</comment>
                    <comment id="12649569" author="creamyg" created="Fri, 21 Nov 2008 01:48:57 +0000"  >&lt;p&gt;&amp;gt; Take a large Jira instance, where the app itself is also&lt;br/&gt;
&amp;gt; consuming alot of RAM, doing alot of its own IO, etc., where perhaps&lt;br/&gt;
&amp;gt; searching is done infrequently enough relative to other operations&lt;br/&gt;
&amp;gt; that the OS may no longer think the pages you hit for the terms index&lt;br/&gt;
&amp;gt; are hot enough to keep around.&lt;/p&gt;

&lt;p&gt;Search responsiveness is already compromised in such a situation, because we&lt;br/&gt;
can all but guarantee that the posting list files have already been evicted&lt;br/&gt;
from cache.  If the box has enough RAM for the large JIRA instance including&lt;br/&gt;
the Lucene index, search responsiveness won&apos;t be a problem.  As soon as you&lt;br/&gt;
start running a little short on RAM, though, there&apos;s no way to stop infrequent&lt;br/&gt;
searches from being sluggish.  &lt;/p&gt;

&lt;p&gt;Nevertheless, the terms index isn&apos;t that big in comparison to, say, the size&lt;br/&gt;
of a posting list for a common term, so the cost of re-heating it isn&apos;t&lt;br/&gt;
astronomical in the grand scheme of things.&lt;/p&gt;

&lt;p&gt;&amp;gt; Similarly, when a BG merge is burning through data, or say backup kicks off&lt;br/&gt;
&amp;gt; and moves many GB, or the simple act of iterating through a big postings&lt;br/&gt;
&amp;gt; list, the OS will gleefully evict my terms index or norms in order to&lt;br/&gt;
&amp;gt; populate its IO cache with data it will need again for a very long time.&lt;/p&gt;

&lt;p&gt;When that background merge finishes, the new files will be hot.  So, if we&lt;br/&gt;
open a new IndexReader right away and that IndexReader uses mmap() to get at&lt;br/&gt;
the file data, new segments be responsive right away.  &lt;/p&gt;

&lt;p&gt;Even better, any IO caches for old segments used by the previous IndexReader&lt;br/&gt;
may still be warm.  All of this without having to decompress a bunch of stream&lt;br/&gt;
data into per-process data structures at IndexReader startup.&lt;/p&gt;

&lt;p&gt;The terms index could indeed get evicted some of the time on busy systems, but&lt;br/&gt;
the point is that the system IO cache usually works in our favor, even under&lt;br/&gt;
load.&lt;/p&gt;

&lt;p&gt;As far as backup daemons blowing up everybody&apos;s cache, that&apos;s stupid,&lt;br/&gt;
pathological behavior: &amp;lt;&lt;a href=&quot;http://kerneltrap.org/node/3000#comment-8573&quot; class=&quot;external-link&quot;&gt;http://kerneltrap.org/node/3000#comment-8573&lt;/a&gt;&amp;gt;.  Such&lt;br/&gt;
apps ought to be calling madvise(ptr, len, MADV_SEQUENTIAL) so that the kernel&lt;br/&gt;
knows it can recycle the cache pages as soon as they&apos;re cleared.&lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt; But hey, we can simplify even further! How about dispensing with the index&lt;br/&gt;
&amp;gt;&amp;gt; file? We can just divide the main dictionary file into blocks and binary&lt;br/&gt;
&amp;gt;&amp;gt; search on that.&lt;br/&gt;
&amp;gt; &lt;br/&gt;
&amp;gt; I&apos;m not convinced this&apos;ll be a win in practice. You are now paying an&lt;br/&gt;
&amp;gt; even higher overhead cost for each &quot;check&quot; of your binary search,&lt;br/&gt;
&amp;gt; especially with something like pulsing which inlines more stuff into&lt;br/&gt;
&amp;gt; the terms dict. I agree it&apos;s simpler, but I think that&apos;s trumped by&lt;br/&gt;
&amp;gt; the performance hit.&lt;/p&gt;

&lt;p&gt;I&apos;m persuaded that we shouldn&apos;t do away with the terms index.  Even if we&apos;re&lt;br/&gt;
operating on a dedicated search box with gobs of RAM, loading entire cache&lt;br/&gt;
pages when we only care about the first few bytes of each is poor use of&lt;br/&gt;
memory bandwidth.  And, just in case the cache does get blown, we&apos;d like to&lt;br/&gt;
keep the cost of rewarming down.&lt;/p&gt;

&lt;p&gt;Nathan Kurz and I brainstormed this subject in a phone call this morning, and&lt;br/&gt;
we came up with a three-file lexicon index design:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;A file which is a solid stack of 64-bit file pointers into the lexicon&lt;br/&gt;
    index term data.  Term data UTF-8 byte length can be determined by&lt;br/&gt;
    subtracting the current pointer from the next one (or the file length at&lt;br/&gt;
    the end).&lt;/li&gt;
	&lt;li&gt;A file which is contains solid UTF-8 term content.  (No string lengths, no&lt;br/&gt;
    file pointers, just character data.)&lt;/li&gt;
	&lt;li&gt;A file which is a solid stack of 64-bit file pointers into the primary&lt;br/&gt;
    lexicon.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Since the integers are already expanded and the raw UTF-8 data can be compared&lt;br/&gt;
as-is, those files can be memory-mapped and used as-is for binary search.&lt;/p&gt;

&lt;p&gt;&amp;gt; In Lucene java, the concurrency model we are aiming for is a single JVM&lt;br/&gt;
&amp;gt; sharing a single instance of IndexReader. &lt;/p&gt;

&lt;p&gt;When I mentioned this to Nate, he remarked that we&apos;re using the OS kernel like&lt;br/&gt;
you&apos;re using the JVM.  &lt;/p&gt;

&lt;p&gt;We don&apos;t keep a single IndexReader around, but we do keep the bulk of its data&lt;br/&gt;
cached so that we can just slap a cheap wrapper around it.&lt;/p&gt;

&lt;p&gt;&amp;gt; I do agree, if fork() is the basis of your concurrency model then sharing&lt;br/&gt;
&amp;gt; pages becomes critical.  However, modern OSs implement copy-on-write sharing&lt;br/&gt;
&amp;gt; of VM pages after a fork, so that&apos;s another good path to sharing?&lt;/p&gt;

&lt;p&gt;Lucy/KS can&apos;t enforce that, and we wouldn&apos;t want to.  It&apos;s very convenient to&lt;br/&gt;
be able to launch a cheap search process.&lt;/p&gt;

&lt;p&gt;&amp;gt; Have you tried any actual tests swapping these approaches in as your&lt;br/&gt;
&amp;gt; terms index impl? &lt;/p&gt;

&lt;p&gt;No &amp;#8211; changing something like this requires a lot of coding, so it&apos;s better to&lt;br/&gt;
do thought experiments first to winnow down the options.&lt;/p&gt;

&lt;p&gt;&amp;gt; Tests of fully hot and fully cold ends of the&lt;br/&gt;
&amp;gt; spectrum would be interesting, but also tests where a big segment&lt;br/&gt;
&amp;gt; merge or a backup is running in the background...&lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt; That doesn&apos;t meet the design goals of bringing the cost of opening/warming&lt;br/&gt;
&amp;gt;&amp;gt; an IndexReader down to near-zero and sharing backing buffers among&lt;br/&gt;
&amp;gt;&amp;gt; multiple forks.&lt;br/&gt;
&amp;gt; &lt;br/&gt;
&amp;gt; That&apos;s a nice goal. Our biggest cost in Lucene is warming the FieldCache, used&lt;br/&gt;
&amp;gt; for sorting, function queries, etc.&lt;/p&gt;

&lt;p&gt;Exactly. It would be nice to add a plug-in indexing component that writes sort&lt;br/&gt;
caches to files that can be memory mapped at IndexReader startup.  There would&lt;br/&gt;
be multiple files: both a solid array of 32-bit integers mapping document&lt;br/&gt;
number to sort order, and the field cache values.  Such a component would&lt;br/&gt;
allow us to move the time it takes to read in a sort cache from&lt;br/&gt;
IndexReader-startup-time to index-time.&lt;/p&gt;

&lt;p&gt;Hmm, maybe we can conflate this with a column-stride field writer and require&lt;br/&gt;
that sort fields have a fixed width?&lt;/p&gt;

&lt;p&gt;&amp;gt; In my approach here, the blob is opaque to the terms dict reader: it&lt;br/&gt;
&amp;gt; simply seeks to the right spot in the tis file, and then asks the&lt;br/&gt;
&amp;gt; codec to decode the entry. TermsDictReader is entirely unaware of&lt;br/&gt;
&amp;gt; what/how is stored there.&lt;/p&gt;

&lt;p&gt;Sounds good.  Basically, a hash lookup.&lt;/p&gt;

&lt;p&gt;In KS, the relevant IndexReader methods no longer take a Term object.  (In&lt;br/&gt;
fact, there IS no Term object any more &amp;#8211; KinoSearch::Index::Term has been&lt;br/&gt;
removed.)  Instead, they take a string field and a generic &quot;Obj&quot;.  &lt;/p&gt;

&lt;p&gt;    Lexicon*&lt;br/&gt;
    SegReader_lexicon(SegReader *self, const CharBuf *field, Obj *term)&lt;/p&gt;
    {
        return (Lexicon*)LexReader_Lexicon(self-&amp;gt;lex_reader, field, term);
    }

&lt;p&gt;I suppose we genericize this by adding a TermsDictReader/LexReader argument to&lt;br/&gt;
the IndexReader constructor?  That way, someone can supply a custom subclass&lt;br/&gt;
that knows how to decode custom dictionary files.&lt;/p&gt;</comment>
                    <comment id="12649646" author="mikemccand" created="Fri, 21 Nov 2008 11:40:56 +0000"  >
&lt;p&gt;OK I created another codec, SepCodec (for lack of a better name) that&lt;br/&gt;
stores doc &amp;amp; frq &amp;amp; skip in 3 separate files (vs 1 for Lucene today),&lt;br/&gt;
as well as positions &amp;amp; payloads in 2 separate files (vs 1 for Lucene&lt;br/&gt;
today).&lt;/p&gt;

&lt;p&gt;The code is still messy &amp;#8211; lots of nocommits all over the place.  I&apos;m&lt;br/&gt;
still iterating.&lt;/p&gt;

&lt;p&gt;Finally, this gets us one step closer to using PFOR!  With this codec,&lt;br/&gt;
the .frq, .doc and .prx are now &quot;pure&quot; streams of ints.&lt;/p&gt;

&lt;p&gt;This codec was more interesting because it adds new files to the file&lt;br/&gt;
format, which required fixing the various interesting places where we&lt;br/&gt;
assume which file extensions belong to a segment.&lt;/p&gt;

&lt;p&gt;In this patch I also created a PostingCodec class, with the 3&lt;br/&gt;
subclasses (so far):&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;DefaultCodec: new terms dict format, but same back-compatible&lt;br/&gt;
    prx/frq format&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;PulsingCodec: new terms dict format, but inlines rare terms into&lt;br/&gt;
    terms dict&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;SepCodec: new terms dict format, and splits doc/frq/skip into&lt;br/&gt;
    3 separate files, and prox/payload into 2 separate files&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;By editing the PostingCodec.getCodec method you can switch all tests&lt;br/&gt;
to use each codec; all tests pass using each codec.&lt;/p&gt;

&lt;p&gt;I built the 1M Wikipedia index, using SepCodec.  Here&apos;s the ls -l:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;-rw-rw-rw-  1 mike  admin    4000004 Nov 20 17:16 _0.fdt
-rw-rw-rw-  1 mike  admin    8000004 Nov 20 17:16 _0.fdx
-rw-rw-rw-  1 mike  admin  303526787 Nov 20 17:34 _n.doc
-rw-rw-rw-  1 mike  admin         33 Nov 20 17:30 _n.fnm
-rw-rw-rw-  1 mike  admin  220470670 Nov 20 17:34 _n.frq
-rw-rw-rw-  1 mike  admin    3000004 Nov 20 17:34 _n.nrm
-rw-rw-rw-  1 mike  admin  651670377 Nov 20 17:34 _n.prx
-rw-rw-rw-  1 mike  admin          0 Nov 20 17:30 _n.pyl
-rw-rw-rw-  1 mike  admin   84963104 Nov 20 17:34 _n.skp
-rw-rw-rw-  1 mike  admin     666999 Nov 20 17:34 _n.tii
-rw-rw-rw-  1 mike  admin   87551274 Nov 20 17:34 _n.tis
-rw-rw-rw-  1 mike  admin         20 Nov 20 17:34 segments.gen
-rw-rw-rw-  1 mike  admin         64 Nov 20 17:34 segments_2
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Some initial observations for SepCodec:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Merging/optimizing was noticeably slower... I think there&apos;s some&lt;br/&gt;
    pending inefficiency in my changes, but it could also simply be&lt;br/&gt;
    that having to step through 3 (.frq, .doc, .prx) files instead of&lt;br/&gt;
    2 (.frq, .prx) for each segment is that much more costly.  (With&lt;br/&gt;
    payloads it&apos;d be 4 files instead of 2).&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Net index size is quite a bit larger (1300 MB vs 1139 MB), I think&lt;br/&gt;
    because we are not efficiently encoding the frq=1 case anymore.&lt;br/&gt;
    PFOR should fix that.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Skip data is just about as large as the terms dict, which&lt;br/&gt;
    surprises me (I had intuitively expected it to be smaller I&lt;br/&gt;
    guess).&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12649968" author="mikemccand" created="Sat, 22 Nov 2008 19:11:37 +0000"  >&lt;blockquote&gt;
&lt;p&gt;Nevertheless, the terms index isn&apos;t that big in comparison to, say, the size&lt;br/&gt;
of a posting list for a common term, so the cost of re-heating it isn&apos;t&lt;br/&gt;
astronomical in the grand scheme of things.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Be careful: it&apos;s the seeking that kills you (until we switch to SSDs&lt;br/&gt;
at which point perhaps most of this discussion is moot!).  Even though&lt;br/&gt;
the terms index net size is low, if re-heating the spots you touch&lt;br/&gt;
incurs 20 separate page misses, you lose.&lt;/p&gt;

&lt;p&gt;Potentially worse than the terms index are norms, if the search hits&lt;br/&gt;
alot of docs.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&amp;gt; Take a large Jira instance...&lt;/p&gt;

&lt;p&gt;Search responsiveness is already compromised in such a situation, because we&lt;br/&gt;
can all but guarantee that the posting list files have already been evicted&lt;br/&gt;
from cache. If the box has enough RAM for the large JIRA instance including&lt;br/&gt;
the Lucene index, search responsiveness won&apos;t be a problem. As soon as you&lt;br/&gt;
start running a little short on RAM, though, there&apos;s no way to stop infrequent&lt;br/&gt;
searches from being sluggish.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;If the term index and norms are pinned (or happen to still be hot), I&lt;br/&gt;
would expect most searches to be OK with this &quot;in the middle&quot; use case&lt;br/&gt;
because the number of seeks you&apos;ll hit should be well contained&lt;br/&gt;
(assuming your posting list isn&apos;t unduly fragmented by the&lt;br/&gt;
filesystem).  Burning through the posting list is a linear scan.&lt;br/&gt;
Queries that simply hit too many docs will always be slow anyways.&lt;/p&gt;

&lt;p&gt;I think at both extremes (way too litle RAM and tons of RAM) both&lt;br/&gt;
approaches (pinned in RAM vs mmap&apos;d) should perfom the same.  It&apos;s the&lt;br/&gt;
cases in between where I think letting VM decide whether critical&lt;br/&gt;
things (terms index, norms) get to stay hot is dangerous.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The terms index could indeed get evicted some of the time on busy systems, but&lt;br/&gt;
the point is that the system IO cache usually works in our favor, even under&lt;br/&gt;
load.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think you&apos;re just more trusting of the IO/VM system.  I think LRU is&lt;br/&gt;
a poor metric.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;As far as backup daemons blowing up everybody&apos;s cache, that&apos;s stupid,&lt;br/&gt;
pathological behavior: &amp;lt;&lt;a href=&quot;http://kerneltrap.org/node/3000#comment-8573&quot; class=&quot;external-link&quot;&gt;http://kerneltrap.org/node/3000#comment-8573&lt;/a&gt;&amp;gt;. Such&lt;br/&gt;
apps ought to be calling madvise(ptr, len, MADV_SEQUENTIAL) so that the kernel&lt;br/&gt;
knows it can recycle the cache pages as soon as they&apos;re cleared.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Excellent!  If only more people knew about this.  And, if only we&lt;br/&gt;
could do this from javaland.  EG SegmentMerger should do this for all&lt;br/&gt;
segment data it&apos;s reading &amp;amp; writing.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Nathan Kurz and I brainstormed this subject in a phone call this morning, and&lt;br/&gt;
we came up with a three-file lexicon index design:&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don&apos;t fully understand this approach.  Would the index file pointers&lt;br/&gt;
point into the full lexicon&apos;s packed utf8 file, or a separate &quot;only&lt;br/&gt;
terms in the index&quot; packed utf8 file?&lt;/p&gt;

&lt;p&gt;We currently materialize individual Strings when we load our index,&lt;br/&gt;
which is bad because of the GC cost, added RAM overhead (&amp;amp; swapping)&lt;br/&gt;
and because for iso8859-1 only terms we are using 2X the space over&lt;br/&gt;
utf8.  So I&apos;d love to eventually do something similar (in RAM) for&lt;br/&gt;
Lucene.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&amp;gt; Have you tried any actual tests swapping these approaches in as your&lt;br/&gt;
&amp;gt; terms index impl?&lt;/p&gt;

&lt;p&gt;No - changing something like this requires a lot of coding, so it&apos;s better to&lt;br/&gt;
do thought experiments first to winnow down the options.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Agreed.  But once you&apos;ve got the mmap-based solution up and running&lt;br/&gt;
it&apos;d be nice to meaure net time doing terms lookup / norms reading,&lt;br/&gt;
for a variety of search use cases, and plot that on a histogram.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;When I mentioned this to Nate, he remarked that we&apos;re using the OS kernel like&lt;br/&gt;
you&apos;re using the JVM.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;True!&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Lucy/KS can&apos;t enforce that, and we wouldn&apos;t want to. It&apos;s very convenient to&lt;br/&gt;
be able to launch a cheap search process.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It seems like the ability to very quickly launch brand new searchers&lt;br/&gt;
is/has become a strong design goal of Lucy/KS.  What&apos;s the driver&lt;br/&gt;
here?  Is it for near-realtime search?  (Which I think may be better&lt;br/&gt;
achieved by having IndexWriter export a reader, rather than using IO&lt;br/&gt;
system as the intermediary).&lt;/p&gt;

&lt;p&gt;If we fix terms index to bulk load arrays (it&apos;s not now) then the cost&lt;br/&gt;
of loading norms &amp;amp; terms index on instantiating a reader should be&lt;br/&gt;
fairly well contained, though not as near zero as Lucy/KS will be.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&amp;gt; That&apos;s a nice goal. Our biggest cost in Lucene is warming the&lt;br/&gt;
&amp;gt; FieldCache, used for sorting, function queries, etc.&lt;/p&gt;

&lt;p&gt;Exactly. It would be nice to add a plug-in indexing component that&lt;br/&gt;
writes sort caches to files that can be memory mapped at IndexReader&lt;br/&gt;
startup. There would be multiple files: both a solid array of 32-bit&lt;br/&gt;
integers mapping document number to sort order, and the field cache&lt;br/&gt;
values. Such a component would allow us to move the time it takes to&lt;br/&gt;
read in a sort cache from IndexReader-startup-time to index-time.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Except I would have IndexReader use its RAM budget to pick &amp;amp; choose&lt;br/&gt;
which of these will be hot, and which would be mmap&apos;d.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Hmm, maybe we can conflate this with a column-stride field writer&lt;br/&gt;
and require that sort fields have a fixed width?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes I think column-stride fields writer should write the docID -&amp;gt; ord&lt;br/&gt;
part of StringIndex to disk, and MultiRangeQuery in &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1461&quot; title=&quot;Cached filter for a single term field&quot;&gt;&lt;del&gt;LUCENE-1461&lt;/del&gt;&lt;/a&gt; would&lt;br/&gt;
then use it.  With enumerated type of fields (far fewer unique terms&lt;br/&gt;
than docs), bit packing will make them compact.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;In KS, the relevant IndexReader methods no longer take a Term&lt;br/&gt;
object. (In fact, there IS no Term object any more -&lt;br/&gt;
KinoSearch::Index::Term has been removed.) Instead, they take a&lt;br/&gt;
string field and a generic &quot;Obj&quot;.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;But you must at least require these Obj&apos;s to know how to compareTo one&lt;br/&gt;
another?  Does this mean using per-field custom sort ordering&lt;br/&gt;
(collator) is straightforward for KS?&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I suppose we genericize this by adding a TermsDictReader/LexReader&lt;br/&gt;
argument to the IndexReader constructor? That way, someone can&lt;br/&gt;
supply a custom subclass that knows how to decode custom dictionary&lt;br/&gt;
files.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Right; that&apos;s what let me create the PulsingCodec here.&lt;/p&gt;

&lt;p&gt;The biggest problem with the &quot;load important stuff into RAM&quot; approach,&lt;br/&gt;
of course, is we can&apos;t actually pin VM pages from java, which means&lt;br/&gt;
the OS will happily swap out my RAM anyway, at which point of course&lt;br/&gt;
we should have used mmap.  Though apparently at least Windows has an&lt;br/&gt;
option to &quot;optimize for services&quot; (= &quot;don&apos;t swap out my RAM&quot; I think)&lt;br/&gt;
vs &quot;optimize for applications&quot;, and Linux lets you tune swappiness.&lt;br/&gt;
But both are global.&lt;/p&gt;</comment>
                    <comment id="12650316" author="creamyg" created="Mon, 24 Nov 2008 20:41:24 +0000"  >&lt;p&gt;&amp;gt;     Nathan Kurz and I brainstormed this subject in a phone call this morning, and&lt;br/&gt;
&amp;gt;     we came up with a three-file lexicon index design:&lt;br/&gt;
&amp;gt; &lt;br/&gt;
&amp;gt; I don&apos;t fully understand this approach. Would the index file pointers&lt;br/&gt;
&amp;gt; point into the full lexicon&apos;s packed utf8 file, or a separate &quot;only&lt;br/&gt;
&amp;gt; terms in the index&quot; packed utf8 file?&lt;/p&gt;

&lt;p&gt;Just the index terms (i.e. every 128th term).  We&apos;re trying to fake up an&lt;br/&gt;
array of strings without having to load anything into process memory.  The&lt;br/&gt;
comparison would go something like this:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;  /* self-&amp;gt;text_lengths, self-&amp;gt;char_data, and self-&amp;gt;lex_file_ptrs are all
   * memory mapped buffers.
   */
  &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; (hi &amp;gt;= lo) {
    &lt;span class=&quot;code-keyword&quot;&gt;const&lt;/span&gt; i32_t mid        = lo + ((hi - lo) / 2);
    &lt;span class=&quot;code-keyword&quot;&gt;const&lt;/span&gt; i64_t offset     = self-&amp;gt;text_lengths[mid];
    &lt;span class=&quot;code-keyword&quot;&gt;const&lt;/span&gt; i64_t mid_len    = self-&amp;gt;text_lengths[mid + 1] - offset;
    &lt;span class=&quot;code-object&quot;&gt;char&lt;/span&gt; *&lt;span class=&quot;code-keyword&quot;&gt;const&lt;/span&gt; mid_text   = self-&amp;gt;char_data + offset;
    &lt;span class=&quot;code-keyword&quot;&gt;const&lt;/span&gt; i32_t comparison = StrHelp_string_diff(target_text, target_len, 
                                                 mid_text, mid_len);
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt;      (comparison &amp;lt; 0) { hi = mid - 1; }
    &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (comparison &amp;gt; 0) { lo = mid + 1; }
    &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; { 
      result = mid; 
      &lt;span class=&quot;code-keyword&quot;&gt;break&lt;/span&gt;;
    }
  }
  offset_into_main_lexicon = self-&amp;gt;lex_file_ptrs[result]
  ...
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;However, perhaps some sort of a B-tree with string prefix compression would be&lt;br/&gt;
better, as per recent suggestions.&lt;/p&gt;

</comment>
                    <comment id="12650377" author="creamyg" created="Mon, 24 Nov 2008 23:18:46 +0000"  >&lt;p&gt;&amp;gt;&amp;gt; Hmm, maybe we can conflate this with a column-stride field writer&lt;br/&gt;
&amp;gt;&amp;gt; and require that sort fields have a fixed width?&lt;br/&gt;
&amp;gt; &lt;br/&gt;
&amp;gt; Yes I think column-stride fields writer should write the docID -&amp;gt; ord&lt;br/&gt;
&amp;gt; part of StringIndex to disk, and MultiRangeQuery in &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1461&quot; title=&quot;Cached filter for a single term field&quot;&gt;&lt;del&gt;LUCENE-1461&lt;/del&gt;&lt;/a&gt; would&lt;br/&gt;
&amp;gt; then use it. With enumerated type of fields (far fewer unique terms&lt;br/&gt;
&amp;gt; than docs), bit packing will make them compact.&lt;/p&gt;

&lt;p&gt;How do you plan on dealing with the ord values changing as segments get &lt;br/&gt;
added?  The addition of a single document triggers the rewriting of the&lt;br/&gt;
entire mapping.&lt;/p&gt;

&lt;p&gt;I was planning on having SortCacheWriter write the out the docID -&amp;gt; ord&lt;br/&gt;
mapping, but with the understanding that there was a relatively high cost so&lt;br/&gt;
the module couldn&apos;t be core.   The idea was to take the cost of iterating over&lt;br/&gt;
the field caches during IndexReader startup, move that to index time, and write&lt;br/&gt;
out a file that could be memory mapped and shared among multiple search apps.&lt;/p&gt;

&lt;p&gt;In theory, if we were to have only per-segment docID -&amp;gt; ord maps, we could&lt;br/&gt;
perform inter-segment collation the same way that it&apos;s handled at the&lt;br/&gt;
MultiSearcher level &amp;#8211; by comparing the original strings.  It wouldn&apos;t be that&lt;br/&gt;
expensive in the grand scheme of things, because most of the work would be&lt;br/&gt;
done by comparing ord values within large segments.&lt;/p&gt;

&lt;p&gt;Unfortunately, that won&apos;t work because segment boundaries are hidden from&lt;br/&gt;
Scorers.&lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt; In KS, the relevant IndexReader methods no longer take a Term&lt;br/&gt;
&amp;gt;&amp;gt; object. (In fact, there IS no Term object any more -&lt;br/&gt;
&amp;gt;&amp;gt; KinoSearch::Index::Term has been removed.) Instead, they take a&lt;br/&gt;
&amp;gt;&amp;gt; string field and a generic &quot;Obj&quot;.&lt;br/&gt;
&amp;gt; &lt;br/&gt;
&amp;gt; But you must at least require these Obj&apos;s to know how to compareTo one&lt;br/&gt;
&amp;gt; another? &lt;/p&gt;

&lt;p&gt;Yes.&lt;/p&gt;

&lt;p&gt;&amp;gt; Does this mean using per-field custom sort ordering (collator) is&lt;br/&gt;
&amp;gt; straightforward for KS?&lt;/p&gt;

&lt;p&gt;That&apos;s one objective.  The implementation is incomplete.&lt;/p&gt;

&lt;p&gt;Another objective is to allow non-string term types, e.g. TimeStamp,&lt;br/&gt;
Float... Hmm... how about FixedWidthText?&lt;/p&gt;</comment>
                    <comment id="12650380" author="creamyg" created="Mon, 24 Nov 2008 23:27:44 +0000"  >&lt;p&gt;&amp;gt;&amp;gt; I suppose we genericize this by adding a TermsDictReader/LexReader&lt;br/&gt;
&amp;gt;&amp;gt; argument to the IndexReader constructor? That way, someone can&lt;br/&gt;
&amp;gt;&amp;gt; supply a custom subclass that knows how to decode custom dictionary&lt;br/&gt;
&amp;gt;&amp;gt; files.&lt;br/&gt;
&amp;gt; &lt;br/&gt;
&amp;gt; Right; that&apos;s what let me create the PulsingCodec here.&lt;/p&gt;

&lt;p&gt;I&apos;m running into an OO design problem because of the SegmentReader/MultiReader&lt;br/&gt;
bifurcation.  If IndexReader were an ordinary class, and we expected all of&lt;br/&gt;
its component parts to perform their own collation of data from multiple&lt;br/&gt;
segments, then the API for overriding individual components would be&lt;br/&gt;
straightforward:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;  reader = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; IndexReader(termsDictReader, postingsReader, fieldsReader);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We can&apos;t do that, though, because there&apos;s logic in IndexReader.open() which&lt;br/&gt;
guards against race conditions with regards to file deletion and index&lt;br/&gt;
modification, and the initialization of the auxiliary reader components would&lt;br/&gt;
happen outside those guards &amp;#8211; possibly resulting in sub-components within an&lt;br/&gt;
IndexReader object reading from different versions of the index.&lt;/p&gt;

&lt;p&gt;Using setters a la reader.setTermsDictReader(termsDictReader) is problematic&lt;br/&gt;
for the same reason.&lt;/p&gt;

&lt;p&gt;Are factory methods the only way to handle adding or replacing components&lt;br/&gt;
within IndexReader?&lt;/p&gt;

&lt;p&gt;KS forces people to subclass Schema to define their index, but up till now&lt;br/&gt;
there hasn&apos;t been anything that would affect the complement of major&lt;br/&gt;
sub-components within IndexReader or InvIndexer (=IndexWriter).  I suppose&lt;br/&gt;
Schema is the right place to put stuff like this, but it seems a lot more&lt;br/&gt;
elaborate than the factory method which returns the index&apos;s default Analyzer.&lt;/p&gt;</comment>
                    <comment id="12650412" author="creamyg" created="Tue, 25 Nov 2008 00:34:07 +0000"  >
&lt;p&gt;&amp;gt; Be careful: it&apos;s the seeking that kills you (until we switch to SSDs&lt;br/&gt;
&amp;gt; at which point perhaps most of this discussion is moot!). Even though&lt;br/&gt;
&amp;gt; the terms index net size is low, if re-heating the spots you touch&lt;br/&gt;
&amp;gt; incurs 20 separate page misses, you lose.&lt;/p&gt;

&lt;p&gt;Perhaps for such situations, we can make it possible to create custom&lt;br/&gt;
HotLexiconReader or HotIndexReader subclasses that slurp term index files and&lt;br/&gt;
what-have-you into process memory.  Implementation would be easy, since we can&lt;br/&gt;
just back the InStreams with malloc&apos;d RAM buffers rather than memory mapped&lt;br/&gt;
system buffers.&lt;/p&gt;

&lt;p&gt;Consider the tradeoffs.  On the one hand, if we rely on memory mapped buffers,&lt;br/&gt;
busy systems may experience sluggish search after long lapses in a worst case&lt;br/&gt;
scenario.  On the other hand, reading a bunch of stuff into process memory&lt;br/&gt;
makes IndexReader a lot heavier, with large indexes imposing consistently &lt;br/&gt;
sluggish startup and a large RAM footprint on each object.&lt;/p&gt;

&lt;p&gt;&amp;gt; It seems like the ability to very quickly launch brand new searchers&lt;br/&gt;
&amp;gt; is/has become a strong design goal of Lucy/KS. What&apos;s the driver&lt;br/&gt;
&amp;gt; here? Is it for near-realtime search? &lt;/p&gt;

&lt;p&gt;Near-realtime search is one of the motivations.  But lightweight IndexReaders&lt;br/&gt;
are more convenient in all sorts of ways.&lt;/p&gt;

&lt;p&gt;Elaborate pre-warming rituals are necessary with heavy IndexReaders whenever&lt;br/&gt;
indexes get modified underneath a persistent search service.  This is&lt;br/&gt;
certainly a problem when you are trying to keep up with real-time insertions,&lt;br/&gt;
but it is also a problem with batch updates or optimization passes.&lt;/p&gt;

&lt;p&gt;With lightweight IndexReaders, you can check whether the index has been&lt;br/&gt;
modified as requests come in, launch a new Searcher if it has, then deal with&lt;br/&gt;
the request after a negligible delay.  You have to warm the system io caches&lt;br/&gt;
when the service starts up (&quot;cat /path/to/index/* &amp;gt; /dev/null&quot;), but after&lt;br/&gt;
that, there&apos;s no more need for background warming.&lt;/p&gt;

&lt;p&gt;Lightweight IndexReaders can also be sprinkled liberally around source code in &lt;br/&gt;
a way that heavy IndexReaders cannot.  For instance, each thread in a &lt;br/&gt;
multi-threaded server can have its own Searcher.&lt;/p&gt;

&lt;p&gt;Launching cheap search processes is also important when writing tools akin to&lt;br/&gt;
the Unix command line &apos;locate&apos; app.  The first time you invoke locate it&apos;s&lt;br/&gt;
slow, but subsequent invocations are nice and quick.  You can only mimic that&lt;br/&gt;
with a lightweight IndexReader.&lt;/p&gt;

&lt;p&gt;And so on... The fact that segment data files are never modified once written&lt;br/&gt;
makes the Lucene/Lucy/KS file format design particularly well suited for&lt;br/&gt;
memory mapping and sharing via the system buffers.  In addition to the reasons&lt;br/&gt;
cited above, intuition tells me that this is the right design decision and&lt;br/&gt;
that there will be other opportunities not yet anticipated.  I don&apos;t see how Lucy&lt;br/&gt;
can deny such advantages to most users for the sake of those few for whom&lt;br/&gt;
term dictionary cache eviction proves to be a problem, especially when we can&lt;br/&gt;
offer those users a remedy.&lt;/p&gt;

&lt;p&gt;&amp;gt; The biggest problem with the &quot;load important stuff into RAM&quot; approach,&lt;br/&gt;
&amp;gt; of course, is we can&apos;t actually pin VM pages from java, which means&lt;br/&gt;
&amp;gt; the OS will happily swap out my RAM anyway, at which point of course&lt;br/&gt;
&amp;gt; we should have used mmap. &lt;/p&gt;

&lt;p&gt;We can&apos;t realistically pin pages from C, either, at least on Unixen.  Modern&lt;br/&gt;
Unixen offer the mlock() command, but it has a crucial limitation &amp;#8211; you have to&lt;br/&gt;
run it as root.  &lt;/p&gt;

&lt;p&gt;Also, there aren&apos;t any madvise() flags that hint to the OS that the mapped&lt;br/&gt;
region should stay hot.  The closest thing is MADV_WILLNEED, which&lt;br/&gt;
communicates &quot;this will be needed soon&quot; &amp;#8211; not &quot;keep this around&quot;.&lt;/p&gt;</comment>
                    <comment id="12650534" author="mikemccand" created="Tue, 25 Nov 2008 11:23:40 +0000"  >&lt;blockquote&gt;
&lt;p&gt;Just the index terms (i.e. every 128th term). We&apos;re trying to fake up an&lt;br/&gt;
array of strings without having to load anything into process memory. The&lt;br/&gt;
comparison would go something like this:&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;OK this makes sense.  We could do something similar in Lucene.  Not&lt;br/&gt;
creating String objects is nice.  I wonder in practice how much time&lt;br/&gt;
we are &quot;typically&quot; spending loading the terms index...&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;However, perhaps some sort of a B-tree with string prefix compression would be&lt;br/&gt;
better, as per recent suggestions.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;B-tree or FST/trie or ... something.&lt;/p&gt;

&lt;p&gt;Actually: I just realized the terms index need not store all suffixes&lt;br/&gt;
of the terms it stores.  Only unique prefixes (ie a simple letter&lt;br/&gt;
trie, not FST).  Because, its goal is to simply find the spot in the&lt;br/&gt;
main lexicon file to seek to and then scan from.  This makes it even&lt;br/&gt;
smaller!&lt;/p&gt;

&lt;p&gt;Though, if we want to do neat things like respelling, wildcard/prefix&lt;br/&gt;
searching, etc., which reduce to graph-intersection problems, we would&lt;br/&gt;
need the suffix and we would need the entire lexicon (not just every&lt;br/&gt;
128th index term) compiled into the FST.&lt;/p&gt;</comment>
                    <comment id="12650542" author="mikemccand" created="Tue, 25 Nov 2008 11:43:41 +0000"  >
&lt;blockquote&gt;
&lt;p&gt;How do you plan on dealing with the ord values changing as segments get&lt;br/&gt;
added? The addition of a single document triggers the rewriting of the&lt;br/&gt;
entire mapping.&lt;/p&gt;

&lt;p&gt;...&lt;/p&gt;

&lt;p&gt;Unfortunately, that won&apos;t work because segment boundaries are hidden from&lt;br/&gt;
Scorers.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This is a big challenge &amp;#8211; presenting a merged docID-&amp;gt;ord map for a&lt;br/&gt;
MultiSegmentReader is very costly.&lt;/p&gt;

&lt;p&gt;I think, just like we are pushing for column-stride / FieldCache to be&lt;br/&gt;
&quot;per segment&quot; instead of one big merged array, we should move in the&lt;br/&gt;
same direction for searching?&lt;/p&gt;

&lt;p&gt;Ie, if one did all searching with MultiSearcher, it should work well.&lt;br/&gt;
Each segment uses its pre-computed (during indexing) docID-&amp;gt;ord&lt;br/&gt;
mapping.  Merge-sorting the results from each searcher ought to be low&lt;br/&gt;
cost since you only need to lookup the string values for the top N&lt;br/&gt;
docs (though care must be taken to not incur N seeks for this... eg&lt;br/&gt;
perhaps each reader, on hitting a doc that makes it into the pqueue,&lt;br/&gt;
should then seek&amp;amp;load the String value from column-stride store?).  An&lt;br/&gt;
optimized index wouldn&apos;t need to read any of the actual string values&lt;br/&gt;
since no results merging is needed.&lt;/p&gt;

&lt;p&gt;For the RangeFilter impl in &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1461&quot; title=&quot;Cached filter for a single term field&quot;&gt;&lt;del&gt;LUCENE-1461&lt;/del&gt;&lt;/a&gt; (which&apos;d use the docID-&amp;gt;order&lt;br/&gt;
per segment, using MultiSearcher), string values are never needed.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&amp;gt; Does this mean using per-field custom sort ordering (collator) is&lt;br/&gt;
&amp;gt; straightforward for KS?&lt;/p&gt;

&lt;p&gt;That&apos;s one objective. The implementation is incomplete.&lt;/p&gt;

&lt;p&gt;Another objective is to allow non-string term types, e.g. TimeStamp,&lt;br/&gt;
Float... Hmm... how about FixedWidthText?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Neat!&lt;/p&gt;</comment>
                    <comment id="12650546" author="mikemccand" created="Tue, 25 Nov 2008 11:52:39 +0000"  >&lt;blockquote&gt;
&lt;p&gt;If IndexReader were an ordinary class, and we expected all of&lt;br/&gt;
its component parts to perform their own collation of data from multiple&lt;br/&gt;
segments, then the API for overriding individual components would be&lt;br/&gt;
straightforward:&lt;/p&gt;

&lt;p&gt;reader = new IndexReader(termsDictReader, postingsReader, fieldsReader);&lt;/p&gt;

&lt;p&gt;We can&apos;t do that, though, because there&apos;s logic in IndexReader.open() which&lt;br/&gt;
guards against race conditions with regards to file deletion and index&lt;br/&gt;
modification, and the initialization of the auxiliary reader components would&lt;br/&gt;
happen outside those guards - possibly resulting in sub-components within an&lt;br/&gt;
IndexReader object reading from different versions of the index.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think you &quot;just&quot; have to have &quot;index version data&quot; that&apos;s&lt;br/&gt;
collectively read/written, atomically, and is then used to init all&lt;br/&gt;
the components.  This is what segments_N is in Lucene (and I think&lt;br/&gt;
&quot;Schema&quot; is in KS/Lucy?): it contains all details that all&lt;br/&gt;
sub-components need.&lt;/p&gt;

&lt;p&gt;If init&apos;ing each sub-component is then costly (opening files,&lt;br/&gt;
slurping things in, etc.) its OK because they are all still loading a&lt;br/&gt;
consistent commit point.&lt;/p&gt;</comment>
                    <comment id="12650558" author="mikemccand" created="Tue, 25 Nov 2008 13:20:33 +0000"  >&lt;blockquote&gt;
&lt;p&gt;&amp;gt; Be careful: it&apos;s the seeking that kills you (until we switch to SSDs&lt;br/&gt;
&amp;gt; at which point perhaps most of this discussion is moot!). Even though&lt;br/&gt;
&amp;gt; the terms index net size is low, if re-heating the spots you touch&lt;br/&gt;
&amp;gt; incurs 20 separate page misses, you lose.&lt;/p&gt;

&lt;p&gt;Perhaps for such situations, we can make it possible to create custom&lt;br/&gt;
HotLexiconReader or HotIndexReader subclasses that slurp term index files and&lt;br/&gt;
what-have-you into process memory. Implementation would be easy, since we can&lt;br/&gt;
just back the InStreams with malloc&apos;d RAM buffers rather than memory mapped&lt;br/&gt;
system buffers.&lt;/p&gt;

&lt;p&gt;Consider the tradeoffs. On the one hand, if we rely on memory mapped buffers,&lt;br/&gt;
busy systems may experience sluggish search after long lapses in a worst case&lt;br/&gt;
scenario. On the other hand, reading a bunch of stuff into process memory&lt;br/&gt;
makes IndexReader a lot heavier, with large indexes imposing consistently&lt;br/&gt;
sluggish startup and a large RAM footprint on each object.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think this is a fabulous solution.  If you make things so pluggable&lt;br/&gt;
that you can choose to swap in &quot;mmap this thing&quot; vs &quot;slurp in this&lt;br/&gt;
thing&quot; and it&apos;s the same interface presented to the consumer, then, we&lt;br/&gt;
don&apos;t need to resolve this debate now &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  Put both out in the field and&lt;br/&gt;
gather data...&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Elaborate pre-warming rituals are necessary with heavy IndexReaders whenever&lt;br/&gt;
indexes get modified underneath a persistent search service. This is&lt;br/&gt;
certainly a problem when you are trying to keep up with real-time insertions,&lt;br/&gt;
but it is also a problem with batch updates or optimization passes.&lt;/p&gt;

&lt;p&gt;With lightweight IndexReaders, you can check whether the index has been&lt;br/&gt;
modified as requests come in, launch a new Searcher if it has, then deal with&lt;br/&gt;
the request after a negligible delay. You have to warm the system io caches&lt;br/&gt;
when the service starts up (&quot;cat /path/to/index/* &amp;gt; /dev/null&quot;), but after&lt;br/&gt;
that, there&apos;s no more need for background warming.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Well ...that cat command can be deadly for a large index, too?  You&apos;ve&lt;br/&gt;
replaced the elaborate pre-warming ritual (= run certain queries that&lt;br/&gt;
you know will populate variou caches) with a cat command that doesn&apos;t&lt;br/&gt;
distinguish what&apos;s important (norms, terms index, certain docID-&amp;gt;ord&lt;br/&gt;
maps, certain column-stride-fields, etc.) from what&apos;s less important.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Lightweight IndexReaders can also be sprinkled liberally around source code in&lt;br/&gt;
a way that heavy IndexReaders cannot. For instance, each thread in a&lt;br/&gt;
multi-threaded server can have its own Searcher.&lt;/p&gt;

&lt;p&gt;Launching cheap search processes is also important when writing tools akin to&lt;br/&gt;
the Unix command line &apos;locate&apos; app. The first time you invoke locate it&apos;s&lt;br/&gt;
slow, but subsequent invocations are nice and quick. You can only mimic that&lt;br/&gt;
with a lightweight IndexReader.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This is indeed nice.  I think the two approaches boil down to &quot;pay up&lt;br/&gt;
front &amp;amp; reuse&quot; (Lucene, slurping) vs &quot;pay as you go &amp;amp; discard&quot;&lt;br/&gt;
(KS/Lucy, mmap&apos;ing).&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;And so on... The fact that segment data files are never modified once written&lt;br/&gt;
makes the Lucene/Lucy/KS file format design particularly well suited for&lt;br/&gt;
memory mapping and sharing via the system buffers. In addition to the reasons&lt;br/&gt;
cited above, intuition tells me that this is the right design decision and&lt;br/&gt;
that there will be other opportunities not yet anticipated. I don&apos;t see how Lucy&lt;br/&gt;
can deny such advantages to most users for the sake of those few for whom&lt;br/&gt;
term dictionary cache eviction proves to be a problem, especially when we can&lt;br/&gt;
offer those users a remedy.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;[BTW the ZFS filesystem gets many of its nice properties for the same&lt;br/&gt;
reason &amp;#8211; &quot;write once&quot;, at the file block level.]&lt;/p&gt;

&lt;p&gt;Lucene java takes advantage of that &apos;write once&apos; nature during&lt;br/&gt;
IndexReader.reopen().  If we can finally push FieldCache, norms,&lt;br/&gt;
docID-&amp;gt;ord to be per-reader then the reopen of a MultiSearcher should&lt;br/&gt;
be alot better than it is today.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&amp;gt; The biggest problem with the &quot;load important stuff into RAM&quot; approach,&lt;br/&gt;
&amp;gt; of course, is we can&apos;t actually pin VM pages from java, which means&lt;br/&gt;
&amp;gt; the OS will happily swap out my RAM anyway, at which point of course&lt;br/&gt;
&amp;gt; we should have used mmap.&lt;/p&gt;

&lt;p&gt;We can&apos;t realistically pin pages from C, either, at least on Unixen. Modern&lt;br/&gt;
Unixen offer the mlock() command, but it has a crucial limitation - you have to&lt;br/&gt;
run it as root.&lt;/p&gt;

&lt;p&gt;Also, there aren&apos;t any madvise() flags that hint to the OS that the mapped&lt;br/&gt;
region should stay hot. The closest thing is MADV_WILLNEED, which&lt;br/&gt;
communicates &quot;this will be needed soon&quot; - not &quot;keep this around&quot;.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Alas.&lt;/p&gt;

&lt;p&gt;The only fallback is gross system-level tunings (&quot;swappiness&quot; on Linux&lt;br/&gt;
and &quot;Adjust for best performance of: Programs/System Cache&quot; on Windows&lt;br/&gt;
Server 2003, at least).&lt;/p&gt;

&lt;p&gt;Or also a silly &quot;keep warm&quot; thread...&lt;/p&gt;</comment>
                    <comment id="12650585" author="creamyg" created="Tue, 25 Nov 2008 14:47:57 +0000"  >&lt;p&gt;&amp;gt; I think you &quot;just&quot; have to have &quot;index version data&quot; that&apos;s&lt;br/&gt;
&amp;gt; collectively read/written, atomically, and is then used to init all&lt;br/&gt;
&amp;gt; the components. This is what segments_N is in Lucene (and I think&lt;br/&gt;
&amp;gt; &quot;Schema&quot; is in KS/Lucy?): it contains all details that all&lt;br/&gt;
&amp;gt; sub-components need.&lt;/p&gt;

&lt;p&gt;The equivalent to segments_N in KinoSearch is snapshot_N.meta, which is&lt;br/&gt;
encoded as JSON.  There&apos;s a KinoSearch::Index::Snapshot class that&apos;s&lt;br/&gt;
responsible for reading/writing it.&lt;/p&gt;

&lt;p&gt;KinoSearch::Schema is for defining your index: global field properties,&lt;br/&gt;
default Analyzer, etc.  It&apos;s similar to Solr&apos;s schema.xml, but implemented as&lt;br/&gt;
an abstract class that users are required to subclass.  Translated to Java,&lt;br/&gt;
the subclassing might look something like this:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;  class MySchema &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; Schema {
    class URLField &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; TextField {
        &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; analyzed() { &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;; }
        &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; indexed() { &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;; }
    }

    void initFields() {
      addField(&lt;span class=&quot;code-quote&quot;&gt;&quot;title&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;text&quot;&lt;/span&gt;);
      addField(&lt;span class=&quot;code-quote&quot;&gt;&quot;content&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;text&quot;&lt;/span&gt;);
      addField(&lt;span class=&quot;code-quote&quot;&gt;&quot;url&quot;&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; URLField());
    }

    Analyzer analyzer() {
      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; PolyAnalyzer(&lt;span class=&quot;code-quote&quot;&gt;&quot;en&quot;&lt;/span&gt;);
    }
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I anticipate that Lucy will adopt both Schema and Snapshot in some form, but&lt;br/&gt;
after discussion.  &lt;/p&gt;

&lt;p&gt;&amp;gt; If init&apos;ing each sub-component is then costly (opening files,&lt;br/&gt;
&amp;gt; slurping things in, etc.) its OK because they are all still loading a&lt;br/&gt;
&amp;gt; consistent commit point.&lt;/p&gt;

&lt;p&gt;So, something like this prospective Lucy code? (Lucy with Java bindings, that is.)&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;  MySchema schema = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; MySchema();
  Snapshot snapshot = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Snapshot((Schema)schema);
  snapShot.readSnapShot(&lt;span class=&quot;code-quote&quot;&gt;&quot;/path/to/index&quot;&lt;/span&gt;);
  MyTermsDictReader termsDictReader = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; MyTermsDictReader(schema, snapshot);
  IndexReader reader = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; IndexReader(schema, snapshot, &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;,
                                       (TermsDictReader)termsDictReader);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;What if index files get deleted out from under that code block?  The user will&lt;br/&gt;
have to implement retry logic.&lt;/p&gt;</comment>
                    <comment id="12650599" author="mikemccand" created="Tue, 25 Nov 2008 15:51:38 +0000"  >
&lt;blockquote&gt;
&lt;p&gt;The equivalent to segments_N in KinoSearch is snapshot_N.meta, which is&lt;br/&gt;
encoded as JSON. There&apos;s a KinoSearch::Index::Snapshot class that&apos;s&lt;br/&gt;
responsible for reading/writing it.&lt;/p&gt;

&lt;p&gt;KinoSearch::Schema is for defining your index: global field properties,&lt;br/&gt;
default Analyzer, etc. It&apos;s similar to Solr&apos;s schema.xml, but implemented as&lt;br/&gt;
an abstract class that users are required to subclass. Translated to Java,&lt;br/&gt;
the subclassing might look something like this:&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;OK got it.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;What if index files get deleted out from under that code block? The&lt;br/&gt;
user will have to implement retry logic.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I would think this &quot;openReader&quot; method would live inside Lucy/KS, and&lt;br/&gt;
would in fact implement its own retry logic (to load the next snapshot&lt;br/&gt;
and try again).  I must be missing some part of the question here...&lt;/p&gt;</comment>
                    <comment id="12650619" author="creamyg" created="Tue, 25 Nov 2008 16:39:45 +0000"  >&lt;p&gt;&amp;gt; I would think this &quot;openReader&quot; method would live inside Lucy/KS, and&lt;br/&gt;
&amp;gt; would in fact implement its own retry logic (to load the next snapshot&lt;br/&gt;
&amp;gt; and try again). I must be missing some part of the question here...&lt;/p&gt;

&lt;p&gt;If the retry code lives inside of IndexReader, then the only way to get the&lt;br/&gt;
IndexReader to use e.g. a subclassed TermsDictReader is to subclass&lt;br/&gt;
IndexReader and override a factory method:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;  class MyIndexReader &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; IndexReader {
    TermsDictReader makeTermsDictReader() {
      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; (TermsDictReader) &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; MyTermsDictReader(invindex, snapshot);
    }
  }

  InvIndex invindex = MySchema.open(&lt;span class=&quot;code-quote&quot;&gt;&quot;/path/to/index&quot;&lt;/span&gt;);
  IndexReader reader = (IndexReader) &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; MyIndexReader(invindex);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I was hoping to avoid forcing the user to subclass IndexReader, but I think&lt;br/&gt;
the need for retry logic during open() precludes that possibility.&lt;/p&gt;</comment>
                    <comment id="12650644" author="mikemccand" created="Tue, 25 Nov 2008 17:45:32 +0000"  >&lt;blockquote&gt;
&lt;p&gt;I was hoping to avoid forcing the user to subclass IndexReader, but I&lt;br/&gt;
think the need for retry logic during open() precludes that&lt;br/&gt;
possibility.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;How about the caller provides a codec instance which when asked will&lt;br/&gt;
return a TermsDictReader &quot;matching&quot; the codec that had been used to&lt;br/&gt;
write the index?&lt;/p&gt;

&lt;p&gt;Then open() implements the retry logic, asking the codec to load each&lt;br/&gt;
part of the index?&lt;/p&gt;

&lt;p&gt;That&apos;s roughly the approach I&apos;m taking here (on next iteriaton of the&lt;br/&gt;
patch, hopefully soon), though I&apos;m only tackling the postings now (not&lt;br/&gt;
yet norms, stored fields, term vectors, fields infos).&lt;/p&gt;</comment>
                    <comment id="12650647" author="creamyg" created="Tue, 25 Nov 2008 17:46:54 +0000"  >&lt;p&gt;&amp;gt;&amp;gt; We&apos;re trying to fake up an array of strings without having to load anything&lt;br/&gt;
&amp;gt;&amp;gt; into process memory.&lt;/p&gt;

&lt;p&gt;&amp;gt; We could do something similar in Lucene. Not creating String objects is&lt;br/&gt;
&amp;gt; nice. &lt;/p&gt;

&lt;p&gt;OK, assume that you slurp all three files.  Here&apos;s the code from above, ported&lt;br/&gt;
from C to Java.  &lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; (hi &amp;gt;= lo) {
  &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;  mid           = lo + ((hi - lo) / 2);
  &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; midTextOffset = textLengths[mid];
  &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; midTextLength = textLengths[mid + 1] - midTextOffset;
  &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; comparison     = StringHelper.compareUTF8Bytes(
                          targetUTF8Bytes, 0, targetLength, 
                          termUTF8bytes, midTextOffset, midTextLength);
  &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt;      (comparison &amp;lt; 0) { hi = mid - 1; }
  &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (comparison &amp;gt; 0) { lo = mid + 1; }
  &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; { 
    result = mid; 
    &lt;span class=&quot;code-keyword&quot;&gt;break&lt;/span&gt;;
  }
}
&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; offsetIntoMainTermDict = mainTermDictFilePointers[result];
...
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Other than the slurping, the only significant difference is the need for the&lt;br/&gt;
comparison routine to take a byte[] array and an offset, rather than a char*&lt;br/&gt;
pointer.&lt;/p&gt;

&lt;p&gt;You can also use FileChannels to memory map this stuff, right?  (Have to be&lt;br/&gt;
careful on 32-bit systems, though.)&lt;/p&gt;

&lt;p&gt;&amp;gt; B-tree or FST/trie or ... something.&lt;/p&gt;

&lt;p&gt;Much to my regret, my tree algorithm vocabulary is limited &amp;#8211; I haven&apos;t spent&lt;br/&gt;
enough time coding such projects that I can intuit sophisticated solutions.&lt;br/&gt;
So I&apos;ll be counting on you, Jason Rutherglen, and Eks Dev to suggest&lt;br/&gt;
appropriate algorithms based on your experience.&lt;/p&gt;

&lt;p&gt;Our segment-based inverted index term dictionary has a few defining&lt;br/&gt;
characteristics.&lt;/p&gt;

&lt;p&gt;First, a lot of tree algorithms are optimized to a greater or lesser extent&lt;br/&gt;
for insertion speed, but we hardly care about that at all.  We can spend all&lt;br/&gt;
the cycles we need at index-time balancing nodes within a segment, and once&lt;br/&gt;
the tree is written out, it will never be updated.&lt;/p&gt;

&lt;p&gt;Second, when we are writing out the term dictionary at index-time, the raw&lt;br/&gt;
data will be fed into the writer in sorted order as iterated values, one&lt;br/&gt;
term/term-info pair at a time.  Ideally, the writer would be able to serialize&lt;br/&gt;
the tree structure during this single pass, but it could also write a&lt;br/&gt;
temporary file during the terms iteration then write a final file afterwards.&lt;br/&gt;
The main limitation is that the writer will never be able to &quot;see&quot; all&lt;br/&gt;
terms at once as an array.&lt;/p&gt;

&lt;p&gt;Third, at read-time we&apos;re going to have one of these trees per segment.  We&apos;d&lt;br/&gt;
really like to be able to conflate them somehow.  KinoSearch actually&lt;br/&gt;
implements a MultiLexicon class which keeps SegLexicons in a PriorityQueue;&lt;br/&gt;
MultiLexicon_Next() advances the queue to the next unique term.  However,&lt;br/&gt;
that&apos;s slow, unwieldy, and inflexible.  Can we do better?&lt;/p&gt;

&lt;p&gt;&amp;gt; Actually: I just realized the terms index need not store all suffixes&lt;br/&gt;
&amp;gt; of the terms it stores. Only unique prefixes (ie a simple letter&lt;br/&gt;
&amp;gt; trie, not FST). Because, its goal is to simply find the spot in the&lt;br/&gt;
&amp;gt; main lexicon file to seek to and then scan from. This makes it even&lt;br/&gt;
&amp;gt; smaller!&lt;/p&gt;

&lt;p&gt;It would be ideal if we could separate the keys from the values and put all&lt;br/&gt;
the keys in a single file.&lt;/p&gt;

&lt;p&gt;&amp;gt; Though, if we want to do neat things like respelling, wildcard/prefix&lt;br/&gt;
&amp;gt; searching, etc., which reduce to graph-intersection problems, we would&lt;br/&gt;
&amp;gt; need the suffix and we would need the entire lexicon (not just every&lt;br/&gt;
&amp;gt; 128th index term) compiled into the FST.&lt;/p&gt;

&lt;p&gt;The main purpose of breaking out a separate index structure is to avoid binary&lt;br/&gt;
searching over the large primary file.  There&apos;s nothing special about the&lt;br/&gt;
extra file &amp;#8211; in fact, it&apos;s a drawback that it doesn&apos;t include all terms.  If&lt;br/&gt;
we can jam all the data we need to binary search against into the front of the&lt;br/&gt;
file, but include the data for all terms in an infrequently-accessed tail, we&lt;br/&gt;
win.&lt;/p&gt;</comment>
                    <comment id="12650722" author="creamyg" created="Tue, 25 Nov 2008 20:27:36 +0000"  >&lt;p&gt;&amp;gt; How about the caller provides a codec instance which when asked will&lt;br/&gt;
&amp;gt; return a TermsDictReader &quot;matching&quot; the codec that had been used to&lt;br/&gt;
&amp;gt; write the index?&lt;/p&gt;

&lt;p&gt;OK, it makes sense to have the user access these capabilities via a single&lt;br/&gt;
handle at both index-time and search-time.  However, for Lucy/KS, the handle&lt;br/&gt;
should definitely be specified via the Schema subclass rather than via&lt;br/&gt;
constructor argument.&lt;/p&gt;

&lt;p&gt;&quot;Codec&quot; isn&apos;t really the right name for this, though.  &quot;IndexComponent&quot;,&lt;br/&gt;
maybe?  Lucy would have three main index components by default:&lt;br/&gt;
LexiconComponent, PostingsComponent, StorageComponent.  &lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-comment&quot;&gt;// If Lucy&apos;s Schema class were implemented in Java instead of C...
&lt;/span&gt;&lt;span class=&quot;code-keyword&quot;&gt;abstract&lt;/span&gt; class Schema &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; Obj {
  LexiconComponent lexiconComponent() { &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; LexiconComponent(); }
  PostingsComponent postingsComponent() { &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; PostingsComponent(); }
  StorageComponent storageComponent() { &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; StorageComponent(); }
  ...
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Auxiliary IndexComponents might include TermVectorsComponent,&lt;br/&gt;
SortCacheComponent, ColumnStrideComponent, RTreeComponent, etc.&lt;/p&gt;

&lt;p&gt;Here&apos;s example code for overriding the default LexiconComponent:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-comment&quot;&gt;// Implements term dictionary as a hash table with term texts as keys.
&lt;/span&gt;class HashLexiconComponent &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; LexiconComponent {
  LexiconReader makeReader(InvIndex invindex, Snapshot snapshot) {
    SegInfos segInfos = Snapshot.getSegInfos();
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (segInfos.size == 1) { 
      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; (LexiconReader) &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; SegHashLexiconReader(invindex, snapshot);
    }
    &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; (LexiconReader) &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; MultiHashLexiconReader(invindex, snapshot);
    }
  }

  LexiconWriter makeWriter(InvIndex invindex, SegInfo segInfo) {
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; (LexiconWriter) &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; HashLexiconWriter(invindex, segInfo);
  }
}

&lt;span class=&quot;code-comment&quot;&gt;// [User code]
&lt;/span&gt;class MySchema &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; Schema {
  LexiconComponent lexiconComponent() {
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; (LexiconComponent) &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; HashLexiconComponent();
  }
  ...
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                    <comment id="12650854" author="creamyg" created="Wed, 26 Nov 2008 03:37:57 +0000"  >&lt;p&gt;&amp;gt; I think, just like we are pushing for column-stride / FieldCache to be&lt;br/&gt;
&amp;gt; &quot;per segment&quot; instead of one big merged array, we should move in the&lt;br/&gt;
&amp;gt; same direction for searching?&lt;/p&gt;

&lt;p&gt;Algorithmically speaking, it would definitely help this specific task, and&lt;br/&gt;
that&apos;s a BIG FAT PLUS.  This, plus memory mapping and writing the DocID -&amp;gt; ord&lt;br/&gt;
map at index-time, allows us to totally eliminate the current cost of loading&lt;br/&gt;
sort caches at IndexReader startup.  The question is, how easy is it to&lt;br/&gt;
refactor our search OO hierarchy to support it?&lt;/p&gt;

&lt;p&gt;If our goal is minimal impact to the current model, we worry only about the&lt;br/&gt;
TopFieldDocs search() method.  We can hack in per-segment bookending via doc&lt;br/&gt;
number to the hit collection routine, initializing the TopFieldDocCollector&lt;br/&gt;
each segment (either creating a new one or popping all the collected docs).&lt;/p&gt;

&lt;p&gt;But does it make sense to be more aggressive?  Should Searchers run hit&lt;br/&gt;
collection against individual segments?  Should Scorers only be compiled&lt;br/&gt;
against single segments?&lt;/p&gt;

&lt;p&gt;Maybe so.  I implemented pruning (early termination) in KS, and it had to be&lt;br/&gt;
done per segment.  This is because you have to sort the documents within a&lt;br/&gt;
segment according to the primary criteria you want to prune on (typically doc&lt;br/&gt;
boost).  I&apos;ve since ripped out that code because it was adding too much&lt;br/&gt;
complexity, but maybe there would have been less complexity if segments were&lt;br/&gt;
closer to the foreground.&lt;/p&gt;</comment>
                    <comment id="12650855" author="creamyg" created="Wed, 26 Nov 2008 03:40:57 +0000"  >&lt;p&gt;&amp;gt; Well ...that cat command can be deadly for a large index, too? &lt;/p&gt;

&lt;p&gt;It will be costly for a large index, and it wouldn&apos;t be appropriate in all&lt;br/&gt;
cases.  The use case I was thinking of was: dedicated server with gobs of RAM.&lt;br/&gt;
The index could either be updated often or not updated at all.  Pre-existing&lt;br/&gt;
segments stay warm on such a box, and the writer would leave the latest&lt;br/&gt;
segment hot, so the cat command would only be needed once, at the startup of&lt;br/&gt;
the persistent service.&lt;/p&gt;</comment>
                    <comment id="12650959" author="mikemccand" created="Wed, 26 Nov 2008 11:22:36 +0000"  >&lt;blockquote&gt;
&lt;p&gt;OK, assume that you slurp all three files. Here&apos;s the code from above, ported&lt;br/&gt;
from C to Java.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Looks good!&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;You can also use FileChannels to memory map this stuff, right? (Have to be&lt;br/&gt;
careful on 32-bit systems, though.)&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Yes.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;First, a lot of tree algorithms are optimized to a greater or lesser extent&lt;br/&gt;
for insertion speed, but we hardly care about that at all. We can spend all&lt;br/&gt;
the cycles we need at index-time balancing nodes within a segment, and once&lt;br/&gt;
the tree is written out, it will never be updated.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Right, neither inserts nor deletes matter to us.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Second, when we are writing out the term dictionary at index-time, the raw&lt;br/&gt;
data will be fed into the writer in sorted order as iterated values, one&lt;br/&gt;
term/term-info pair at a time. Ideally, the writer would be able to serialize&lt;br/&gt;
the tree structure during this single pass, but it could also write a&lt;br/&gt;
temporary file during the terms iteration then write a final file afterwards.&lt;br/&gt;
The main limitation is that the writer will never be able to &quot;see&quot; all&lt;br/&gt;
terms at once as an array.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Lucene differs from Lucy/KS in this.  For Lucene, when flushing a&lt;br/&gt;
new segment, we can assume you can see all Terms in RAM at once.  We&lt;br/&gt;
don&apos;t make use of this today (it&apos;s a simple iteration that&apos;s given to&lt;br/&gt;
the consumer), but we could.  In Lucene, when RAM is full, we flush a&lt;br/&gt;
real segment (but KS flushes a &quot;run&quot; which I think is more of a raw&lt;br/&gt;
dump, ie, you don&apos;t build lexicon trees during that?).&lt;/p&gt;

&lt;p&gt;However, for both Lucene and Lucy/KS, during merging one cannot assume&lt;br/&gt;
the entire lexicon can be in RAM at once.  But then, during merging&lt;br/&gt;
you could in theory merge trees not expanded terms.&lt;/p&gt;

&lt;p&gt;I think for starters at least we should stick with the simple&lt;br/&gt;
shared-prefix-compression we have today.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Third, at read-time we&apos;re going to have one of these trees per segment. We&apos;d&lt;br/&gt;
really like to be able to conflate them somehow. KinoSearch actually&lt;br/&gt;
implements a MultiLexicon class which keeps SegLexicons in a PriorityQueue;&lt;br/&gt;
MultiLexicon_Next() advances the queue to the next unique term. However,&lt;br/&gt;
that&apos;s slow, unwieldy, and inflexible. Can we do better?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Continuing the move towards pushing searching closer to the segments&lt;br/&gt;
(ie, using MultiSearcher instead of MultiReader), I think we should&lt;br/&gt;
not try to conflate the terms dict?&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;It would be ideal if we could separate the keys from the values and put all&lt;br/&gt;
the keys in a single file.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Why not inline the value with the key?  The pointer to the value just&lt;br/&gt;
consumes extra space.  I think &quot;value&quot; in this context is the long&lt;br/&gt;
offset into the main terms dict file, which then stores the &quot;real&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;opaque&amp;#93;&lt;/span&gt; value&quot; for each term.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&amp;gt; Though, if we want to do neat things like respelling, wildcard/prefix&lt;br/&gt;
&amp;gt; searching, etc., which reduce to graph-intersection problems, we would&lt;br/&gt;
&amp;gt; need the suffix and we would need the entire lexicon (not just every&lt;br/&gt;
&amp;gt; 128th index term) compiled into the FST.&lt;/p&gt;

&lt;p&gt;The main purpose of breaking out a separate index structure is to avoid binary&lt;br/&gt;
searching over the large primary file. There&apos;s nothing special about the&lt;br/&gt;
extra file - in fact, it&apos;s a drawback that it doesn&apos;t include all terms. If&lt;br/&gt;
we can jam all the data we need to binary search against into the front of the&lt;br/&gt;
file, but include the data for all terms in an infrequently-accessed tail, we&lt;br/&gt;
win.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;And... if your terms index is in RAM, to minimize its net size and&lt;br/&gt;
decode cost on loading.&lt;/p&gt;</comment>
                    <comment id="12650961" author="mikemccand" created="Wed, 26 Nov 2008 11:31:51 +0000"  >&lt;blockquote&gt;
&lt;p&gt;OK, it makes sense to have the user access these capabilities via a single&lt;br/&gt;
handle at both index-time and search-time. However, for Lucy/KS, the handle&lt;br/&gt;
should definitely be specified via the Schema subclass rather than via&lt;br/&gt;
constructor argument.&lt;/p&gt;

&lt;p&gt;&quot;Codec&quot; isn&apos;t really the right name for this, though. &quot;IndexComponent&quot;,&lt;br/&gt;
maybe? Lucy would have three main index components by default:&lt;br/&gt;
LexiconComponent, PostingsComponent, StorageComponent.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Well, maybe both?  Ie, each of these IndexComponents could have many&lt;br/&gt;
different codecs to write/read the data to/from the index.  So when I&lt;br/&gt;
implement PostingsComponent, when writing a segment I could choose my&lt;br/&gt;
own codec; when reading it, I retrieve the matching codec to decode&lt;br/&gt;
it.&lt;/p&gt;

&lt;p&gt;Subclassing Schema seems like the right approach.&lt;/p&gt;</comment>
                    <comment id="12650964" author="mikemccand" created="Wed, 26 Nov 2008 11:38:58 +0000"  >&lt;blockquote&gt;
&lt;p&gt;&amp;gt; I think, just like we are pushing for column-stride / FieldCache to be&lt;br/&gt;
&amp;gt; &quot;per segment&quot; instead of one big merged array, we should move in the&lt;br/&gt;
&amp;gt; same direction for searching?&lt;/p&gt;

&lt;p&gt;Algorithmically speaking, it would definitely help this specific task, and&lt;br/&gt;
that&apos;s a BIG FAT PLUS. This, plus memory mapping and writing the DocID -&amp;gt; ord&lt;br/&gt;
map at index-time, allows us to totally eliminate the current cost of loading&lt;br/&gt;
sort caches at IndexReader startup. The question is, how easy is it to&lt;br/&gt;
refactor our search OO hierarchy to support it?&lt;/p&gt;

&lt;p&gt;If our goal is minimal impact to the current model, we worry only about the&lt;br/&gt;
TopFieldDocs search() method. We can hack in per-segment bookending via doc&lt;br/&gt;
number to the hit collection routine, initializing the TopFieldDocCollector&lt;br/&gt;
each segment (either creating a new one or popping all the collected docs).&lt;/p&gt;

&lt;p&gt;But does it make sense to be more aggressive? Should Searchers run hit&lt;br/&gt;
collection against individual segments? Should Scorers only be compiled&lt;br/&gt;
against single segments?&lt;/p&gt;

&lt;p&gt;Maybe so. I implemented pruning (early termination) in KS, and it had to be&lt;br/&gt;
done per segment. This is because you have to sort the documents within a&lt;br/&gt;
segment according to the primary criteria you want to prune on (typically doc&lt;br/&gt;
boost). I&apos;ve since ripped out that code because it was adding too much&lt;br/&gt;
complexity, but maybe there would have been less complexity if segments were&lt;br/&gt;
closer to the foreground.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think the plus&apos;s are substantial here.  Not having to materialize&lt;br/&gt;
one massive array of norms, of FieldCache/column-stride values, of&lt;br/&gt;
docID-&amp;gt;ord values, is very important because these are at least linear&lt;br/&gt;
cost (more for the docID-&amp;gt;ord) in # docs in the index.  Reopening a&lt;br/&gt;
searcher on a large index is very costly in Lucene now because of&lt;br/&gt;
these materializations.&lt;/p&gt;

&lt;p&gt;We need to think more about the tradeoffs here...&lt;/p&gt;</comment>
                    <comment id="12650967" author="mikemccand" created="Wed, 26 Nov 2008 11:45:45 +0000"  >&lt;blockquote&gt;
&lt;p&gt;&amp;gt; Well ...that cat command can be deadly for a large index, too?&lt;/p&gt;

&lt;p&gt;It will be costly for a large index, and it wouldn&apos;t be appropriate in all&lt;br/&gt;
cases. The use case I was thinking of was: dedicated server with gobs of RAM.&lt;br/&gt;
The index could either be updated often or not updated at all. Pre-existing&lt;br/&gt;
segments stay warm on such a box, and the writer would leave the latest&lt;br/&gt;
segment hot, so the cat command would only be needed once, at the startup of&lt;br/&gt;
the persistent service.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Ahh OK.  But that cat command is basically just a different, more&lt;br/&gt;
global, implemenation of &quot;warming&quot;.&lt;/p&gt;

&lt;p&gt;So eg you&apos;d still need to coordinate so that the new searcher isn&apos;t&lt;br/&gt;
used until warming finishes, right?  In Lucene, since warming is explicit&lt;br/&gt;
and under direct programmatic control, we know when warming is done.&lt;br/&gt;
I guess you could also do a system call to do the cat command,&lt;br/&gt;
blocking cutover to the new searcher until it completes.&lt;/p&gt;</comment>
                    <comment id="12651003" author="creamyg" created="Wed, 26 Nov 2008 14:04:56 +0000"  >&lt;p&gt;&amp;gt; Not having to materialize one massive array of norms, of&lt;br/&gt;
&amp;gt; FieldCache/column-stride values, of docID-&amp;gt;ord values, is very important&lt;br/&gt;
&amp;gt; because these are at least linear cost (more for the docID-&amp;gt;ord) in # docs&lt;br/&gt;
&amp;gt; in the index. Reopening a searcher on a large index is very costly in Lucene&lt;br/&gt;
&amp;gt; now because of these materializations.&lt;br/&gt;
&amp;gt; &lt;br/&gt;
&amp;gt; We need to think more about the tradeoffs here...&lt;/p&gt;

&lt;p&gt;Let&apos;s continue the discussion of segment-centric searching on java-dev, since it it&apos;s &lt;br/&gt;
only tangentially related to flexible indexing.&lt;/p&gt;</comment>
                    <comment id="12651015" author="creamyg" created="Wed, 26 Nov 2008 14:38:25 +0000"  >&lt;p&gt;&amp;gt; So eg you&apos;d still need to coordinate so that the new searcher isn&apos;t&lt;br/&gt;
&amp;gt; used until warming finishes, right? &lt;/p&gt;

&lt;p&gt;...&lt;/p&gt;

&lt;p&gt;&amp;gt; I guess you could also do a system call to do the cat command,&lt;br/&gt;
&amp;gt; blocking cutover to the new searcher until it completes.&lt;/p&gt;


&lt;p&gt;Warming is only needed once, at search service startup.  The idea is to get &lt;br/&gt;
the whole index into the system IO cache.&lt;/p&gt;

&lt;p&gt;Once all segment data is in the IO cache, we assume that it stays there,&lt;br/&gt;
because this is a beefy dedicated search box with more than enough RAM to fit&lt;br/&gt;
the entire index/shard.&lt;/p&gt;

&lt;p&gt;Say that we add a new segment to the index, either by running an&lt;br/&gt;
index-writing process locally, or via rsync.  (Assume for the purposes of&lt;br/&gt;
argument that the local indexing process doesn&apos;t require much RAM &amp;#8211; which &lt;br/&gt;
is true with KS &amp;#8211; and so won&apos;t have the side effect of nudging existing&lt;br/&gt;
segments out of IO cache.) &lt;/p&gt;

&lt;p&gt;Now, say that our search service checks at the beginning of each request to&lt;br/&gt;
see if the index has been modified.  If it has, it opens a new searcher from&lt;br/&gt;
scratch &amp;#8211; which takes almost no time, because we&apos;re memory mapping rather&lt;br/&gt;
than slurping.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; (newRequest()) {
  &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (indexHasBeenUpdated()) {
    searcher = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; IndexSearcher(&lt;span class=&quot;code-quote&quot;&gt;&quot;/path/to/index&quot;&lt;/span&gt;);
  }
  ...
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After an abrupt cutover to the new searcher, we process the search request.  &lt;br/&gt;
Is the new search sluggish in any way?  No, because all the segments used &lt;br/&gt;
by the new searcher are &quot;hot&quot;.  Older segments are hot because they were &lt;br/&gt;
in use by the prior searcher, and the new segment is hot because it was &lt;br/&gt;
just written.&lt;/p&gt;

&lt;p&gt;Therefore, we don&apos;t need to worry about managing cutover to a new searcher.&lt;br/&gt;
We can just discard the old one and replace it with the new one.&lt;/p&gt;</comment>
                    <comment id="12651067" author="creamyg" created="Wed, 26 Nov 2008 17:18:52 +0000"  >&lt;p&gt;&amp;gt; Well, maybe both? Ie, each of these IndexComponents could have many&lt;br/&gt;
&amp;gt; different codecs to write/read the data to/from the index. So when I&lt;br/&gt;
&amp;gt; implement PostingsComponent, when writing a segment I could choose my&lt;br/&gt;
&amp;gt; own codec; when reading it, I retrieve the matching codec to decode&lt;br/&gt;
&amp;gt; it.&lt;/p&gt;

&lt;p&gt;Yes, both &amp;#8211; that sounds good.  However, I&apos;m not sure whether you&apos;re proposing&lt;br/&gt;
the creation of a class named &quot;Codec&quot;, which I think we should avoid unless&lt;br/&gt;
all of our &quot;codecs&quot; can descend from it.  So: PostingsCodec, TermsDictCodec&lt;br/&gt;
(or LexiconCodec, for Lucy/KS), and so on would be base classes.&lt;/p&gt;

&lt;p&gt;&amp;gt; Subclassing Schema seems like the right approach.&lt;/p&gt;

&lt;p&gt;Groovy. How are you going to handle it in Lucene?  I think you just have to&lt;br/&gt;
require the end user to be consistent about supplying the necessary arguments&lt;br/&gt;
to the IndexReader and IndexWriter constructors.&lt;/p&gt;

&lt;p&gt;How do we handle auxiliary IndexComponents?  I&apos;ve long wanted to implement an&lt;br/&gt;
RTreeComponent for geographic searching, so I&apos;ll use that as an example.&lt;/p&gt;

&lt;p&gt;At index-time, I think we just create an array of SegDataWriter objects and&lt;br/&gt;
feed each document to each writer in turn.  The SegDataWriter abstract base&lt;br/&gt;
class will define all the necessary abstract methods: addDoc(),&lt;br/&gt;
addSegment(SegReader) (for Lucy/KS), various commands related to merging (for&lt;br/&gt;
Lucene), finish()/close(), and so on.  RTreeWriter would simply subclass&lt;br/&gt;
SegDataWriter.&lt;/p&gt;

&lt;p&gt;At search-time, things get a little trickier.  Say we hand our Searcher object&lt;br/&gt;
an RTreeRadiusQuery.  At some point, the RTreeRadiusQuery will need to be&lt;br/&gt;
compiled to an RTreeRadiusScorer, which will involve accessing an RTreeReader&lt;br/&gt;
which presumably resides within an IndexReader.  However, right now,&lt;br/&gt;
IndexReader hides all of its inner readers and provides access through&lt;br/&gt;
specific methods, e.g. IndexReader.document(int docNum), which ultimately&lt;br/&gt;
hands off to FieldsReader internally.  This model doesn&apos;t scale with the&lt;br/&gt;
addition of arbitrary IndexComponents.&lt;/p&gt;

&lt;p&gt;The only thing I can thing of is an IndexReader.getReader(String name) method.&lt;/p&gt;</comment>
                    <comment id="12651078" author="mikemccand" created="Wed, 26 Nov 2008 17:57:50 +0000"  >&lt;blockquote&gt;&lt;p&gt;Warming is only needed once, at search service startup.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Ahh, got it.  Lucene must warm for each reopened searcher (though that warming cost will eventually be in proportion to what&apos;s changed in the index), but KS/Lucy should be fine doing zero warming except for the very first searcher startup (eg after rebooting the machine).&lt;/p&gt;</comment>
                    <comment id="12651082" author="mikemccand" created="Wed, 26 Nov 2008 18:10:35 +0000"  >&lt;blockquote&gt;
&lt;p&gt;&amp;gt; So: PostingsCodec, TermsDictCodec (or LexiconCodec, for Lucy/KS), and&lt;br/&gt;
&amp;gt; so on would be base classes.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Right: separate codec base classes for each component.  Back to the&lt;br/&gt;
video analogy: a typical video has a &quot;audio&quot; component and a &quot;video&quot;&lt;br/&gt;
component.  AudioCodec would be the base class for all the various&lt;br/&gt;
audio codecs, and likewise for VideoCodec.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&amp;gt; I think you just have to require the end user to be consistent about&lt;br/&gt;
&amp;gt; supplying the necessary arguments to the IndexReader and IndexWriter&lt;br/&gt;
&amp;gt; constructors.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Right.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&amp;gt; How do we handle auxiliary IndexComponents? I&apos;ve long wanted to implement an&lt;br/&gt;
&amp;gt; RTreeComponent for geographic searching, so I&apos;ll use that as an example.&lt;/p&gt;

&lt;p&gt;&amp;gt; At index-time, I think we just create an array of SegDataWriter objects and&lt;br/&gt;
&amp;gt; feed each document to each writer in turn.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think that&apos;s right.  In Lucene we now have an indexing chain&lt;br/&gt;
(package private), so that you can &quot;tap in&quot; at whatever point is&lt;br/&gt;
appropriate &amp;#8211; you could handle the whole doc yourself (like&lt;br/&gt;
SegDataWriter); you could be fed one field at a time; you could tap in&lt;br/&gt;
after inversion so you get one token at a time, etc.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&amp;gt; At search-time, things get a little trickier.&lt;br/&gt;
&amp;gt; ...&lt;br/&gt;
&amp;gt; The only thing I can thing of is an IndexReader.getReader(String&lt;br/&gt;
&amp;gt; name) method.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I haven&apos;t thought enough about how to handle this at search time.&lt;br/&gt;
IR.getReader seems fine, though, you&apos;d need to open each&lt;br/&gt;
IndexComponent up front inside the retry loop, right?&lt;/p&gt;</comment>
                    <comment id="12651138" author="creamyg" created="Wed, 26 Nov 2008 20:50:56 +0000"  >&lt;p&gt;&amp;gt; In Lucene we now have an indexing chain&lt;br/&gt;
&amp;gt; (package private), so that you can &quot;tap in&quot; at whatever point is&lt;br/&gt;
&amp;gt; appropriate - you could handle the whole doc yourself (like&lt;br/&gt;
&amp;gt; SegDataWriter); you could be fed one field at a time; you could tap in&lt;br/&gt;
&amp;gt; after inversion so you get one token at a time, etc.&lt;/p&gt;

&lt;p&gt;That&apos;s pretty nice.  It occurred to me to try something like that, but I got a&lt;br/&gt;
little lost.  &lt;/p&gt;

&lt;p&gt;The fact that the Doc object in KS uses the host language&apos;s native hashtable&lt;br/&gt;
and string implementations for field data complicates an already complicated&lt;br/&gt;
matter.  It&apos;s hard to abstract out access to field data so that the KS/Lucy&lt;br/&gt;
core, which knows nothing about the host language, can see it, yet still&lt;br/&gt;
maintain peak performance in the addDoc() loop.&lt;/p&gt;

&lt;p&gt;In any case, I don&apos;t anticipate intractable implementation troubles with&lt;br/&gt;
adding IndexComponents at index-time.&lt;/p&gt;

&lt;p&gt;&amp;gt; IR.getReader seems fine, though, you&apos;d need to open each&lt;br/&gt;
&amp;gt; IndexComponent up front inside the retry loop, right?&lt;/p&gt;

&lt;p&gt;Sure, startup&apos;s easy.  I think we just add Schema.auxiliaryComponents(),&lt;br/&gt;
which returns an array of IndexComponents.  The default would be to return&lt;br/&gt;
null or an empty array, but subclasses could override it.&lt;/p&gt;

&lt;p&gt;Where we have problems, though, is with remote searching or multi-searching.&lt;br/&gt;
You can&apos;t ask a Searchable for its inner IndexReader, because it might not&lt;br/&gt;
have one.  That means that you can&apos;t &quot;see&quot; information pertaining to a custom&lt;br/&gt;
IndexComponent until you&apos;re at the level of the individual machine &amp;#8211;&lt;br/&gt;
aggregate information, like docFreq across an entire collection spanning&lt;br/&gt;
multiple indexes, wouldn&apos;t be available to searches which use custom&lt;br/&gt;
components.&lt;/p&gt;

&lt;p&gt;The only remedy would be to subclass all your Searchables &amp;#8211; the local&lt;br/&gt;
IndexSearcher, the RemoteSearchable that wraps it, and the MultiSearcher that&lt;br/&gt;
aggregates results &amp;#8211; to drill down into the correct IndexReader and pass data&lt;br/&gt;
back up the chain.  Basically, you&apos;d have to duplicate e.g. the call chain&lt;br/&gt;
that fetches documents.&lt;/p&gt;</comment>
                    <comment id="12676293" author="mikemccand" created="Tue, 24 Feb 2009 14:22:22 +0000"  >
&lt;p&gt;New patch attached (still plenty more to do...):&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Updated to current trunk (747391).&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;All tests pass, but back-compat tests don&apos;t compile...&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Switched the new &quot;4d iteration API&quot; (Fields -&amp;gt; Terms -&amp;gt; Docs -&amp;gt;&lt;br/&gt;
    Positions) to subclass AttributeSource; this way codecs can add in&lt;br/&gt;
    their own attrs.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Added PostingsCodecs class, that holds all PostingCodec instances&lt;br/&gt;
    your index may make use of, and changed segments_N format to&lt;br/&gt;
    record which codec was used per segment.  So, an index can have&lt;br/&gt;
    mixed codecs (though for a single IndexWriter session, the same&lt;br/&gt;
    codec is used when writing new segments).&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;I cutover TermScorer to use the new API; I still need to cutover&lt;br/&gt;
    other queries, segment merging, etc.&lt;/li&gt;
&lt;/ul&gt;

</comment>
                    <comment id="12681296" author="mikemccand" created="Thu, 12 Mar 2009 12:51:59 +0000"  >&lt;p&gt;Clearing fix version.&lt;/p&gt;</comment>
                    <comment id="12742278" author="michaelbusch" created="Wed, 12 Aug 2009 11:13:48 +0100"  >&lt;p&gt;I took Mike&apos;s latest patch and updated it to current trunk.&lt;br/&gt;
It applies cleanly and compiles fine.&lt;/p&gt;

&lt;p&gt;Some test cases fail. The problem is in SegmentReader in termsIndexIsLoaded() and loadTermsIndex(). I&apos;ll take a look tomorrow, I need to understand the latest changes we made in the different IndexReaders better (and now it&apos;s getting quite late here...)&lt;/p&gt;</comment>
                    <comment id="12742444" author="mikemccand" created="Wed, 12 Aug 2009 17:47:02 +0100"  >&lt;p&gt;Thanks for modernizing the patch Michael!  I&apos;ll get back to this one soon... I&apos;d really love to get PForDelta working as a codec.  It&apos;s a great test case since it&apos;s block-based, ie, very different from the other codecs.&lt;/p&gt;</comment>
                    <comment id="12748538" author="michaelbusch" created="Thu, 27 Aug 2009 20:51:20 +0100"  >&lt;blockquote&gt;
&lt;p&gt;Switches to a new more efficient terms dict format. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This is nice! Maybe we should break this whole issue into smaller pieces? We could start with the dictionary. The changes you made here are really cool already. We could further separate the actual TermsDictReader from the terms index with a clean API (I think you put actually a TODO comment into your patch). Then we can have different terms index implementations in the future, e.g. one that uses a tree. We could also make SegmentReader a bit cleaner: if opened just for merging it would not create a terms index reader at all; only if cloned for an external reader we would instantiate the terms index lazily. Currently this is done by setting the divisor to -1.&lt;/p&gt;</comment>
                    <comment id="12748617" author="michaelbusch" created="Fri, 28 Aug 2009 00:29:54 +0100"  >&lt;p&gt;In the current patch the choice of the Codec is index-wide, right? So I can&apos;t specify different codecs for different fields. Please correct me if I&apos;m wrong.&lt;/p&gt;</comment>
                    <comment id="12748666" author="michaelbusch" created="Fri, 28 Aug 2009 05:06:53 +0100"  >&lt;p&gt;Oups, didn&apos;t want to steal this from you, Mike. Wanted to hit the &quot;Watch&quot; button instead...&lt;/p&gt;</comment>
                    <comment id="12748765" author="mikemccand" created="Fri, 28 Aug 2009 10:36:00 +0100"  >&lt;blockquote&gt;&lt;p&gt;Maybe we should break this whole issue into smaller pieces? We could start with the dictionary. The changes you made here are really cool already.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yeah the issue is very large now.  I&apos;ll think about how to break it&lt;br/&gt;
up.&lt;/p&gt;

&lt;p&gt;I agree: the new default terms dict codec is a good step forward.&lt;br/&gt;
Rather than load a separate TermInfo instance for every indexed term&lt;br/&gt;
(costly in object overhead, and, because we store Term[] as well we&lt;br/&gt;
are wasting space storing many duplicate String field pointers in a&lt;br/&gt;
row), we only store the String and the long offset into the index file&lt;br/&gt;
as two arrays.  It&apos;s a sizable memory savings for indexes with many&lt;br/&gt;
terms.&lt;/p&gt;

&lt;p&gt;This was a nice side-effect of genericizing things, because the&lt;br/&gt;
TermInfo class had to be made private to the codec since it&apos;s storing&lt;br/&gt;
things like proxOffset, freqOffset, etc., which is particular to how&lt;br/&gt;
the Lucene&apos;s default codec stores postings.&lt;/p&gt;

&lt;p&gt;But, it&apos;s somewhat tricky to break out only this change... eg it&apos;s&lt;br/&gt;
also coupled with the change to strongly separate field from term&lt;br/&gt;
text, and, to remove TermInfo reliance.  Ie, the new terms dict has a&lt;br/&gt;
separate per-field class, and within that per-field class it has the&lt;br/&gt;
String[] termText and long[] index offsets.  I guess we could make a&lt;br/&gt;
drop-in class that tries to emulate TermInfosReader/SegmentTermEnum&lt;br/&gt;
even though it separates into per-field, internally.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;We could further separate the actual TermsDictReader from the terms index with a clean API (I think you put actually a TODO comment into your patch).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Actually the whole terms dict writing/reading is itself pluggable, so&lt;br/&gt;
your codec could provide its own.  Ie, Lucene &quot;just&quot; needs a&lt;br/&gt;
FieldsConsumer (for writing) and a FieldsProducer (for reading).&lt;/p&gt;

&lt;p&gt;But it sounds like you&apos;re proposing making a strong decoupling of&lt;br/&gt;
terms index from terms dict?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Then we can have different terms index implementations in the future, e.g. one that uses a tree.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;+1&lt;/p&gt;

&lt;p&gt;Or, an FST.  FST is more compelling than tree since it also compresses&lt;br/&gt;
suffixes.  FST is simply a tree in the front plus a tree in the back&lt;br/&gt;
(in reverse), where the &quot;output&quot; of a given term&apos;s details appears in&lt;br/&gt;
the middle, on an edge that is &quot;unique&quot; to each term, as you traverse&lt;br/&gt;
the graph.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;We could also make SegmentReader a bit cleaner: if opened just for merging it would not create a terms index reader at all; only if cloned for an external reader we would instantiate the terms index lazily. Currently this is done by setting the divisor to -1.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Right.  Somehow we should genericize the &quot;I don&apos;t need the terms&lt;br/&gt;
index at all&quot; when opening a SegmentReader.  Passing -1 is sort of&lt;br/&gt;
hackish.  Though I do prefer passing up front your intentions, rather&lt;br/&gt;
than loading lazily (&lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1609&quot; title=&quot;Eliminate synchronization contention on initial index reading in TermInfosReader ensureIndexIsRead &quot;&gt;&lt;del&gt;LUCENE-1609&lt;/del&gt;&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;We could eg pass &quot;requirements&quot; when asking the codec for the terms&lt;br/&gt;
dict reader.  EG if I don&apos;t state that RANDOM_ACCESS is required (and&lt;br/&gt;
only say LINEAR_SCAN) then the codec internally can make itself more&lt;br/&gt;
efficient based on that.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;In the current patch the choice of the Codec is index-wide, right? So I can&apos;t specify different codecs for different fields. Please correct me if I&apos;m wrong.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The Codec is indeed index-wide, however, because the field vs term&lt;br/&gt;
text are strongly separated, it&apos;s completely within a Codec&apos;s control&lt;br/&gt;
to return a different reader/writer for different fields.  So it ought&lt;br/&gt;
to work fine... eg one in theory could make a &quot;PerFieldCodecWrapper&quot;.&lt;br/&gt;
But, I haven&apos;t yet tried this with any codecs.  It would make a good&lt;br/&gt;
test case though... I&apos;ll write down to make a test case for this.&lt;/p&gt;

&lt;p&gt;Also, it&apos;s fine if an index has used different codecs over time when&lt;br/&gt;
writing, as long as when reading you provide a PostingsCodecs&lt;br/&gt;
instance that&apos;s able to &lt;span class=&quot;error&quot;&gt;&amp;#91;correctly&amp;#93;&lt;/span&gt; retrieve those codecs to read those&lt;br/&gt;
segments.&lt;/p&gt;
</comment>
                    <comment id="12749426" author="michaelbusch" created="Mon, 31 Aug 2009 09:45:08 +0100"  >&lt;blockquote&gt;
&lt;p&gt;But it sounds like you&apos;re proposing making a strong decoupling of&lt;br/&gt;
terms index from terms dict?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Right.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Right. Somehow we should genericize the &quot;I don&apos;t need the terms&lt;br/&gt;
index at all&quot; when opening a SegmentReader. Passing -1 is sort of&lt;br/&gt;
hackish. Though I do prefer passing up front your intentions, rather&lt;br/&gt;
than loading lazily (&lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1609&quot; title=&quot;Eliminate synchronization contention on initial index reading in TermInfosReader ensureIndexIsRead &quot;&gt;&lt;del&gt;LUCENE-1609&lt;/del&gt;&lt;/a&gt;).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;m a bit confused. Doesn&apos;t the IndexWriter open SegmentReaders&lt;br/&gt;
usually with termsIndexDivisor=-1 for merge, and maybe later with&lt;br/&gt;
a termsIndexDivisor&amp;gt;0 when IndexWriter#getReader() is called?&lt;br/&gt;
That&apos;s what I meant with loading lazily. &lt;/p&gt;

&lt;p&gt;I thought that&apos;s why it&apos;d be good to separate the terms index from&lt;br/&gt;
the terms dict. For merge we&apos;d open the dict reader only, and then&lt;br/&gt;
if getReader() is called we&apos;d open the terms index reader and give&lt;br/&gt;
its reference to the dict reader.&lt;/p&gt;

&lt;p&gt;I admit that I didn&apos;t follow the NRT changes as closely as I should&lt;br/&gt;
have, so I might be missing things here.&lt;/p&gt;</comment>
                    <comment id="12749429" author="michaelbusch" created="Mon, 31 Aug 2009 09:58:09 +0100"  >&lt;blockquote&gt;
&lt;p&gt;The Codec is indeed index-wide, however, because the field vs term&lt;br/&gt;
text are strongly separated, it&apos;s completely within a Codec&apos;s control&lt;br/&gt;
to return a different reader/writer for different fields. So it ought&lt;br/&gt;
to work fine... eg one in theory could make a &quot;PerFieldCodecWrapper&quot;.&lt;br/&gt;
But, I haven&apos;t yet tried this with any codecs. It would make a good&lt;br/&gt;
test case though... I&apos;ll write down to make a test case for this.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;OK I see now. Did you think about possibly extending the field API&lt;br/&gt;
to specify the codec? And then to store the Codec name in the &lt;br/&gt;
fieldinfos (which we&apos;d want to make extensible too, as briefly &lt;br/&gt;
discussed in &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1597&quot; title=&quot;New Document and Field API&quot;&gt;&lt;del&gt;LUCENE-1597&lt;/del&gt;&lt;/a&gt;) instead of the dictionary?&lt;/p&gt;</comment>
                    <comment id="12749434" author="mikemccand" created="Mon, 31 Aug 2009 10:18:48 +0100"  >&lt;blockquote&gt;
&lt;p&gt;I&apos;m a bit confused. Doesn&apos;t the IndexWriter open SegmentReaders&lt;br/&gt;
usually with termsIndexDivisor=-1 for merge, and maybe later with&lt;br/&gt;
a termsIndexDivisor&amp;gt;0 when IndexWriter#getReader() is called?&lt;br/&gt;
That&apos;s what I meant with loading lazily.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Right, it does.  This is the one case (internal to Lucene, only) where&lt;br/&gt;
loading lazily is still necessary.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I thought that&apos;s why it&apos;d be good to separate the terms index from&lt;br/&gt;
the terms dict. For merge we&apos;d open the dict reader only, and then&lt;br/&gt;
if getReader() is called we&apos;d open the terms index reader and give&lt;br/&gt;
its reference to the dict reader.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;OK got it.  I think this makes sense.&lt;/p&gt;

&lt;p&gt;The separation in the current approach is already quite strong, in&lt;br/&gt;
that the terms dict writer/reader maintains its own String[] indexText&lt;br/&gt;
and long[] indexOffset and then &quot;defers&quot; to its child component just&lt;br/&gt;
what is stored in each terms dict entry.  So each child can store&lt;br/&gt;
whatever it wants in the terms dict entry (eg the pulsing codec&lt;br/&gt;
inlines low-freq postings).&lt;/p&gt;

&lt;p&gt;If we make pluggable how the indexText/indexOffset is stored/loaded in&lt;br/&gt;
memory/used, then we have a stronger separation/pluggability on the&lt;br/&gt;
index.  EG even before FST for the index we should switch to blocks of&lt;br/&gt;
char[] instead of separate Strings, for indexText.&lt;/p&gt;</comment>
                    <comment id="12749437" author="michaelbusch" created="Mon, 31 Aug 2009 10:22:41 +0100"  >&lt;blockquote&gt;
&lt;p&gt;EG even before FST for the index we should switch to blocks of&lt;br/&gt;
char[] instead of separate Strings, for indexText.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I totally agree. I made a similar change (from String objects to &lt;br/&gt;
char[] blocks) on some other code (not Lucene) and the savings &lt;br/&gt;
in memory and garbage collection were tremendous!&lt;/p&gt;</comment>
                    <comment id="12751232" author="mikemccand" created="Fri, 4 Sep 2009 01:10:19 +0100"  >&lt;p&gt;I attached a .tar.bz2 of src/* with my current state &amp;#8211; too hard to&lt;br/&gt;
keep svn in sync / patchable right now.  Changes:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Factored out the terms dict index, so it&apos;s now &quot;pluggable&quot; (though&lt;br/&gt;
    I&apos;ve only created one impl, so far)&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Cutover SegmentMerger to flex API&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Changed terms to be stored in RAM as byte[] (not char[]), when&lt;br/&gt;
    reading.  These are UTF8 bytes, but in theory eventually we could&lt;br/&gt;
    allow generic bytes here (there are not that many places that try&lt;br/&gt;
    to decode them as UTF8).  I think this is a good step towards&lt;br/&gt;
    allowing generic terms.  It also saves 50% RAM for simple ascii&lt;br/&gt;
    terms w/ the terms index.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Changed terms index to use shared byte[] blocks&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Broke sources out into &quot;codecs&quot; subdir of oal.index.  Right now I&lt;br/&gt;
    have &quot;preflex&quot; (only provides reader, to read old index format),&lt;br/&gt;
    &quot;standard&quot; (new terms dict &amp;amp; index, but otherwise same&lt;br/&gt;
    freq/prox/skip/payloads encoding), &quot;pulsing&quot; (inlines low-freq&lt;br/&gt;
    terms directly into terms dict) and &quot;sep&quot; (seperately stores docs,&lt;br/&gt;
    frq, prox, skip, payloads, as a pre-cursor to using pfor to encode&lt;br/&gt;
    doc/frq/prox).&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The patch is very rough... core &amp;amp; core-test compile, but most tests&lt;br/&gt;
fail.  It&apos;s very much still a work in progress...&lt;/p&gt;</comment>
                    <comment id="12754128" author="mikemccand" created="Fri, 11 Sep 2009 14:49:31 +0100"  >&lt;p&gt;New patch &amp;amp; src.tar.bz2 attached.  All tests, including back-compat, pass.&lt;/p&gt;

&lt;p&gt;There are still zillions of nocommits to resolve.&lt;/p&gt;

&lt;p&gt;Some of the changes:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Got all tests to pass.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Separated out a non-enum Fields/Terms API.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Improved byte[] block allocation in the new terms index so that&lt;br/&gt;
    the blocks are shared across fields (important when there are&lt;br/&gt;
    zillions of fields each of which has few index terms)&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Changed TermsEnum.docs() API to accept a new bit set interface&lt;br/&gt;
    (currently called Bits) skipDocs.  This is towards eventual&lt;br/&gt;
    support for random access filters.  I also added Bits&lt;br/&gt;
    IndexReader.getDeletedDocs().&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Next step is to get the other codecs (sep, pulsing) to pass all tests,&lt;br/&gt;
then to make a pfor codec!  I also need to perf test all of these&lt;br/&gt;
changes...&lt;/p&gt;</comment>
                    <comment id="12754200" author="yseeley@gmail.com" created="Fri, 11 Sep 2009 17:27:48 +0100"  >&lt;blockquote&gt;&lt;p&gt;Changed terms to be stored in RAM as byte[] (not char[]),&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yay!  This will be important for NumericField too since it uses 7 bits per char and will probably account for the majority of terms in the index in many applications.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I attached a .tar.bz2 of src/* with my current state - too hard to keep svn in sync / patchable right now.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Could a git branch make things easier for mega-features like this?&lt;/p&gt;</comment>
                    <comment id="12754250" author="mikemccand" created="Fri, 11 Sep 2009 18:45:39 +0100"  >&lt;blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Changed terms to be stored in RAM as byte[] (not char[]),&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yay! This will be important for NumericField too since it uses 7 bits per char and will probably account for the majority of terms in the index in many applications.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It&apos;s actually byte[] both in how the terms dict index stores the terms&lt;br/&gt;
in RAM (using shared byte[] blocks) and also in how terms are&lt;br/&gt;
represented throughout the flex API.  EG TermsEnum API returns&lt;br/&gt;
a TermRef from its next() method.  TermRef holds byte[]/offset/length.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Could a git branch make things easier for mega-features like this?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Maybe &amp;#8211; though I don&apos;t have much experience w/ git.  If people are&lt;br/&gt;
interested in working together on this then I think it&apos;d be worth&lt;br/&gt;
exploring?&lt;/p&gt;</comment>
                    <comment id="12754557" author="mikemccand" created="Sat, 12 Sep 2009 17:41:41 +0100"  >&lt;p&gt;Attached patch.&lt;/p&gt;

&lt;p&gt;All tests pass with all 3 codecs (standard = just like today&apos;s index format; pulsing = terms that occur in only 1 doc are inlined into terms dict; sep = separate files for doc, freq, prx, payload, skip data).&lt;/p&gt;</comment>
                    <comment id="12754791" author="jasonrutherglen" created="Mon, 14 Sep 2009 01:17:43 +0100"  >&lt;p&gt;Mike,&lt;/p&gt;

&lt;p&gt;Maybe a directed acyclic word graph would work well as an alternative dictionary implementation?  &lt;/p&gt;</comment>
                    <comment id="12754887" author="mikemccand" created="Mon, 14 Sep 2009 10:24:08 +0100"  >&lt;blockquote&gt;&lt;p&gt;Maybe a directed acyclic word graph would work well as an alternative dictionary implementation?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think that&apos;d be great.  In particular, an FST (DAG that shares prefix &amp;amp; suffix and &quot;outputs&quot; the per-term data in the middle of the graph) should be a good savings in most normal term distributions.&lt;/p&gt;

&lt;p&gt;Flexible indexing makes the terms dict &amp;amp; terms dict index pluggable, so we are free to experiment with alternative impls.  I&apos;ve only taken some baby steps to improve on the current terms dict index (by switching to shared byte[] blocks, instead of a separate TermInfo / String instance per indexed term).&lt;/p&gt;</comment>
                    <comment id="12758783" author="mikemccand" created="Wed, 23 Sep 2009 18:10:59 +0100"  >&lt;p&gt;New patch attached.  All tests pass.&lt;/p&gt;

&lt;p&gt;I haven&apos;t quite made it to PForDelta yet, but it&apos;s very close!&lt;/p&gt;

&lt;p&gt;The sep codec was the first step (uses separate files for doc, frq,&lt;br/&gt;
pos, payload, skip).&lt;/p&gt;

&lt;p&gt;Then, in this patch, the big change was to create new&lt;br/&gt;
IntIndexInput/Output abstract classes, that only expose reading &amp;amp;&lt;br/&gt;
writing ints.  I then fixed the sep codec to use this class for doc,&lt;br/&gt;
frq and pos files.&lt;/p&gt;

&lt;p&gt;The trickiest part was abstracting away just what a &quot;file pointer&quot;&lt;br/&gt;
is.  In Lucene we assume in many places this is the long file offset,&lt;br/&gt;
but I needed to change this to file-offset plus within-block-offset,&lt;br/&gt;
for int-block based files.&lt;/p&gt;

&lt;p&gt;Once I did that, I created a FixedIntBlockIndexInput/Output, which&lt;br/&gt;
reads &amp;amp; writes the ints in blocks of a specified size.  They are&lt;br/&gt;
abstract classes and require a subclass to do the actual encode/decode&lt;br/&gt;
of a given block.  To test it I created a simple class that just&lt;br/&gt;
writes multiple vInts.  All tests also pass with this newly added&lt;br/&gt;
(&quot;intblock&quot;) codec.&lt;/p&gt;

&lt;p&gt;So the next step is to hook up PforDelta...&lt;/p&gt;</comment>
                    <comment id="12758968" author="john.wang@gmail.com" created="Thu, 24 Sep 2009 02:57:47 +0100"  >&lt;p&gt;This is awesome!&lt;br/&gt;
Feel free to take code from Kamikaze for the p4delta stuff.&lt;br/&gt;
The impl in Kamikaze assumes no decompression at load time, e.g. the Docset can be traversed in compressed form.&lt;/p&gt;</comment>
                    <comment id="12759083" author="mikemccand" created="Thu, 24 Sep 2009 11:11:23 +0100"  >
&lt;blockquote&gt;
&lt;p&gt;Feel free to take code from Kamikaze for the p4delta stuff.&lt;br/&gt;
The impl in Kamikaze assumes no decompression at load time, e.g. the Docset can be traversed in compressed form.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Thanks John.  I&apos;ve been starting with &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1410&quot; title=&quot;PFOR implementation&quot;&gt;&lt;del&gt;LUCENE-1410&lt;/del&gt;&lt;/a&gt; for now, but we can easily swap in any p4 impl, or any other int compression method.  All that&apos;s needed in the subclass is to implement encodeBlock (in the writer) and decodeBlock (in the reader).  The intblock codec takes care of the rest.&lt;/p&gt;

&lt;p&gt;Kamikaze looks like great stuff!&lt;/p&gt;

&lt;p&gt;What variation on p4 is Kamikaze using?&lt;/p&gt;

&lt;p&gt;Keeping the p4 data compressed is interesting... when you implement AND/OR/NOT on p4, do you have a shortcut that traverses the compressed form while applying the operator?  Or do you do the full decode and then 2nd pass to apply the operator?&lt;/p&gt;</comment>
                    <comment id="12759110" author="john.wang@gmail.com" created="Thu, 24 Sep 2009 14:09:08 +0100"  >&lt;p&gt;Hi Mike:&lt;/p&gt;

&lt;p&gt;     We have been using Kamikaze in our social graph engine in addition to our search system. A person&apos;s network can be rather large, decompressing it in memory some network operation is not feasible for us, hence we made the requirement for the DocIdSetIterator to be able to walk to DocIdSet&apos;s P4Delta implementation in compressed form.&lt;/p&gt;

&lt;p&gt;     We do not decode the p4delta set and make a second pass for boolean set operations, we cannot afford it in both memory cost and latency. The P4Delta set adheres to the DocIdSet/Iterator api, and the And/Or/Not is performed on that level of abstraction using next() and skipTo methods.&lt;/p&gt;

&lt;p&gt;-John&lt;/p&gt;</comment>
                    <comment id="12759112" author="john.wang@gmail.com" created="Thu, 24 Sep 2009 14:13:45 +0100"  >&lt;p&gt;Just a FYI: Kamikaze was originally started as our sandbox for Lucene contributions until 2.4 is ready. (we needed the DocIdSet/Iterator abstraction that was migrated from Solr) &lt;/p&gt;

&lt;p&gt;It has three components:&lt;/p&gt;

&lt;p&gt;1) P4Delta&lt;br/&gt;
2) Logical boolean operations on DocIdSet/Iterators (I have created a jira ticket and a patch for Lucene awhile ago with performance numbers. It is significantly faster than DisjunctionScorer)&lt;br/&gt;
3) algorithm to determine which DocIdSet implementations to use given some parameters, e.g. miniD,maxid,id count etc. It learns and adjust from the application behavior if not all parameters are given.&lt;/p&gt;

&lt;p&gt;So please feel free to incorporate anything you see if or move it to contrib.&lt;/p&gt;</comment>
                    <comment id="12759116" author="john.wang@gmail.com" created="Thu, 24 Sep 2009 14:28:57 +0100"  >&lt;p&gt;Hi Uwe:&lt;/p&gt;

&lt;p&gt;     Thanks for the pointer to the isCacheable method. We will defn incorporate it.&lt;/p&gt;

&lt;p&gt;-John&lt;/p&gt;</comment>
                    <comment id="12759664" author="mikemccand" created="Fri, 25 Sep 2009 18:58:47 +0100"  >&lt;p&gt;Attached patch.  This includes the pfor impl from &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1410&quot; title=&quot;PFOR implementation&quot;&gt;&lt;del&gt;LUCENE-1410&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;PforDelta is working!  I added another codec (pfordelta).  It uses the&lt;br/&gt;
sep codec to separately store freq, doc, pos, and then uses PforDelta&lt;br/&gt;
to encode the ints (as fixed-size blocks).&lt;/p&gt;

&lt;p&gt;However, there are a couple test failures&lt;br/&gt;
(TestIndexWriter.testNegativePositions,&lt;br/&gt;
TestPositionIncrement.testPayloadsPos0) due to PforDelta not properly&lt;br/&gt;
encoding -1 (it&apos;s returned as 255).  Lucene normally doesn&apos;t write&lt;br/&gt;
negative ints, except for the special case of a 0 position increment&lt;br/&gt;
in the initial token(s), in which case due to the bug in &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1542&quot; title=&quot;Lucene can incorrectly set the position of tokens that start a field with positonInc 0.&quot;&gt;&lt;del&gt;LUCENE-1542&lt;/del&gt;&lt;/a&gt;&lt;br/&gt;
we write a -1 if you&apos;ve called IndexWriter.setAllowMinus1Position.&lt;br/&gt;
However, that&apos;s deprecated and will be removed shortly at which point&lt;br/&gt;
the pfordelta codec will pass all tests.&lt;/p&gt;</comment>
                    <comment id="12759891" author="mikemccand" created="Sat, 26 Sep 2009 13:52:31 +0100"  >&lt;p&gt;I wrote up first cut of the toplevel design of this patch, in the wiki: &lt;a href=&quot;http://wiki.apache.org/lucene-java/FlexibleIndexing&quot; class=&quot;external-link&quot;&gt;http://wiki.apache.org/lucene-java/FlexibleIndexing&lt;/a&gt;.&lt;/p&gt;</comment>
                    <comment id="12759910" author="john.wang@gmail.com" created="Sat, 26 Sep 2009 16:32:49 +0100"  >&lt;p&gt;Hi Mike:&lt;/p&gt;

&lt;p&gt;     Truly awesome work!&lt;/p&gt;

&lt;p&gt;     Quick question, are codecs per index or per field? From the wiki, it seems to be per index, if so, is it possible to make it per field?&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;

&lt;p&gt;-John&lt;/p&gt;</comment>
                    <comment id="12760031" author="mikemccand" created="Sun, 27 Sep 2009 15:19:38 +0100"  >&lt;p&gt;The codec is per segment.  However, we ask the codec for&lt;br/&gt;
Terms/TermsEnum by fields, so it should be simple to make a Codec that&lt;br/&gt;
dispatches to field-specific Codecs.&lt;/p&gt;</comment>
                    <comment id="12761429" author="mikemccand" created="Fri, 2 Oct 2009 01:32:58 +0100"  >&lt;p&gt;Attached current patch.  All tests pass:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Cutover merging to flex API.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Cutover FieldCache to flex API.  This got tricky, because terms&lt;br/&gt;
    are now UTF8 byte[].  First, we have a back-compat issue (I&lt;br/&gt;
    changed FieldCache&apos;s parsers to take TermRef not String).  Second,&lt;br/&gt;
    parsing float/double from byte[] is tricky.  I just punted and&lt;br/&gt;
    made a new String(), and then called parseDouble/parseFloat, which&lt;br/&gt;
    is slow (but, NumericFields don&apos;t do this &amp;#8211; they are easy to&lt;br/&gt;
    parse straight from byte[], I think).  Net/net this should be&lt;br/&gt;
    faster loading the FieldCache now.  Also, later we can make a&lt;br/&gt;
    String/StringIndex FieldCache variant that keeps things as byte[].&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Cutover CheckIndex to flex API.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Removed the codec-owned extensions from IndexFileNames; added&lt;br/&gt;
    methods to quey a Codec for all file extensions it may write.  As&lt;br/&gt;
    part of this there is a minor (I think) runtime change whereby&lt;br/&gt;
    Directory.copy or new RamDirectory(Directory) will now copy all&lt;br/&gt;
    files not just index-related files.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I&apos;m now working towards getting this committable.  While PforDelta&lt;br/&gt;
works, I think we should move its codec over to &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1410&quot; title=&quot;PFOR implementation&quot;&gt;&lt;del&gt;LUCENE-1410&lt;/del&gt;&lt;/a&gt; and get it&lt;br/&gt;
working well, separately, after this is committed.&lt;/p&gt;

&lt;p&gt;Still need to cutover more stuff (queries, AllTermDocs, etc.) to flex&lt;br/&gt;
API, get the ThreadLocal cache carried over, fix a bunch of nocommits,&lt;br/&gt;
remove debugging, do perf testing &amp;amp; fix issues, add some more tests,&lt;br/&gt;
etc.&lt;/p&gt;</comment>
                    <comment id="12762159" author="mikemccand" created="Mon, 5 Oct 2009 13:19:44 +0100"  >&lt;p&gt;New patch attached.  All tests pass.  The changes are mostly cutting&lt;br/&gt;
many things over to the flex API.  Still many nocommits to address,&lt;br/&gt;
but I&apos;m getting closer!&lt;/p&gt;

&lt;p&gt;I haven&apos;t &quot;svn up&quot;d to all the recent the deprecations removals /&lt;br/&gt;
generics additions.  Kinda dreading doing so &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; I think I&apos;ll wait&lt;br/&gt;
until all deprecations are gone and then bite the bullet...&lt;/p&gt;

&lt;p&gt;Cutting over all the MultiTermQuery subclasses was nice because all&lt;br/&gt;
the places where we get a TermEnum &amp;amp; iterate, checking if .field() is&lt;br/&gt;
still our field, are now cleaner because with the flex API the&lt;br/&gt;
TermsEnum you get is already only for your requested field.&lt;/p&gt;</comment>
                    <comment id="12762203" author="yseeley@gmail.com" created="Mon, 5 Oct 2009 15:59:38 +0100"  >&lt;p&gt;Sounding cool!  I haven&apos;t had time to look at the code too much... but I j ust wanted to mention two features I&apos;ve had in the back of my mind for a while that seem to have multiple use cases.&lt;/p&gt;

&lt;p&gt;1) How many terms in a field?&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;If the tii/TermInfos were exposed, this could be estimated.&lt;/li&gt;
	&lt;li&gt;Perhaps this could just be stored in FieldInfos... should be easy to track during indexing?&lt;/li&gt;
	&lt;li&gt;MultiTermQuery could also use this to switch impls&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;2) Convert back and forth between a term number and a term.&lt;br/&gt;
Solr has code to do this... stores every 128th term in memory as an index, and uses that to convert back and forth.  This is very much like the internals of TermInfos... would be nice to expose some of that.&lt;/p&gt;</comment>
                    <comment id="12762224" author="john.wang@gmail.com" created="Mon, 5 Oct 2009 16:48:40 +0100"  >&lt;p&gt;Hi Yonik:&lt;/p&gt;

&lt;p&gt;     These are indeed useful features. &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1922&quot; title=&quot;exposing the ability to get the number of unique term count per field&quot;&gt;&lt;del&gt;LUCENE-1922&lt;/del&gt;&lt;/a&gt; addresses 1), perhaps, we can add 2) to the same issue to track?&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;

&lt;p&gt;-John&lt;/p&gt;</comment>
                    <comment id="12762282" author="mikemccand" created="Mon, 5 Oct 2009 19:05:02 +0100"  >&lt;blockquote&gt;&lt;p&gt;1) How many terms in a field?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Actually I&apos;ve already added this one (Terms.getUniqueTermCount), but I&lt;br/&gt;
didn&apos;t punch it through to IndexReader.  I&apos;ll do that.  The standard&lt;br/&gt;
codec (new &quot;default&quot; codec when writing segments) already records this&lt;br/&gt;
per field, so it&apos;s trivial to expose.&lt;/p&gt;

&lt;p&gt;However, some impls may throw UOE (eg a composite IndexReader).&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;2) Convert back and forth between a term number and a term.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I agree this would be useful.  I did have ord() in early iterations of&lt;br/&gt;
the TermsEnum API, but it wasn&apos;t fully implemented and I stripped it&lt;br/&gt;
when I switched to &quot;just finish it already&quot; mode &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; We could think&lt;br/&gt;
about adding it back, though you&apos;d also presumably need seek(int ord)&lt;br/&gt;
as well?  (And docFreq(String field, int ord) sugar exposed in&lt;br/&gt;
IndexReader?).&lt;/p&gt;</comment>
                    <comment id="12762292" author="yseeley@gmail.com" created="Mon, 5 Oct 2009 19:27:50 +0100"  >&lt;blockquote&gt;&lt;p&gt;I agree this would be useful. I did have ord() in early iterations of the TermsEnum API, but it wasn&apos;t fully implemented and I stripped it when I switched to &quot;just finish it already&quot; mode&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;A &quot;complete&quot; implementation seems hard (i.e. across multiple segments also)... but it still seems useful even if it&apos;s only at the segment level.  So perhaps just on SegmentTermEnum, and uses would have to cast to access?&lt;/p&gt;

&lt;p&gt;Exposing the term index array (i.e. every 128th term) as an expert-subject-to-change warning would let people implement variants themselves at least.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;you&apos;d also presumably need seek(int ord)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yep.&lt;/p&gt;</comment>
                    <comment id="12762406" author="gsingers" created="Mon, 5 Oct 2009 22:59:13 +0100"  >&lt;p&gt;I haven&apos;t followed too closely (even though it is one of my favorite issues) but I figured while Yonik was throwing out ideas, I&apos;d add that one of the obvious use cases for flexible indexing is altering scoring.  One of the common statistics one needs to implement some more advanced scoring approaches is the average document length.  Is this patch far enough along that I could take a look at it and think about how one might do this?&lt;/p&gt;</comment>
                    <comment id="12762456" author="markrmiller@gmail.com" created="Tue, 6 Oct 2009 00:58:39 +0100"  >&lt;blockquote&gt;&lt;p&gt;I haven&apos;t &quot;svn up&quot;d to all the recent the deprecations removals / generics additions. Kinda dreading doing so  &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&apos;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Come on old man, stop clinging to emacs &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; I&apos;ve got a meditation technique for that &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;Sounds like some annoyance, and I think I made a comment there - and I&apos;m a man of my word... or child of my word - take your pick.&lt;/p&gt;

&lt;p&gt;To trunk. Since you likely have moved on, don&apos;t worry - this was good practice - I&apos;ll do it again sometime if you&apos;d like. I may have mis merged something little or something. I went fairly quick (I think it took like 30 or 40 min - was hoping to do it faster, but eh - sometimes I like to grind).&lt;/p&gt;

&lt;p&gt;I didn&apos;t really look at the code, but some stuff I noticed:&lt;/p&gt;

&lt;p&gt;java 6 in pfor Arrays.copy&lt;/p&gt;

&lt;p&gt;skiplist stuff in codecs still have package of index - not sure what is going on there - changed them&lt;/p&gt;

&lt;p&gt;in IndexWriter: &lt;br/&gt;
+          // Mark: read twice?&lt;br/&gt;
           segmentInfos.read(directory);&lt;br/&gt;
+        segmentInfos.read(directory, codecs);&lt;/p&gt;

&lt;p&gt;Core tests pass, but I didn&apos;t wait for contrib or back compat.&lt;/p&gt;</comment>
                    <comment id="12762497" author="markrmiller@gmail.com" created="Tue, 6 Oct 2009 05:06:49 +0100"  >&lt;p&gt;eh - even if you have moved on, if I&apos;m going to put up a patch, might as well do it right - here is another:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;removed a boatload of unused imports&lt;/li&gt;
	&lt;li&gt;removed DefaultSkipListWriter/Reader - I accidently put them back in&lt;/li&gt;
	&lt;li&gt;removed an unused field or two (not all)&lt;/li&gt;
	&lt;li&gt;paramaterized LegacySegmentMergeQueue.java&lt;/li&gt;
	&lt;li&gt;Fixed the double read I mentioned in previous comment in IndexWriter&lt;/li&gt;
	&lt;li&gt;TermRef defines an equals (that throws UOE) and not hashCode - early stuff I guess but odd since no class extends it. Added a hashCode that throws UOE anyway.&lt;/li&gt;
	&lt;li&gt;fixed bug in TermRangeTermsEnum: lowerTermRef = new TermRef(lowerTermText); to lowerTermRef = new TermRef(this.lowerTermText);&lt;/li&gt;
	&lt;li&gt;Fixed Remote contrib test to work with TermRef for fieldcache parser (since you don&apos;t include contrib in the tar)&lt;/li&gt;
	&lt;li&gt;Missed a StringBuffer to StringBuilder in MultiTermQuery.toString&lt;/li&gt;
	&lt;li&gt;had missed removing deprecated IndexReader.open(final Directory directory) and deprecated IndexReader.open(final IndexCommit commit)&lt;/li&gt;
	&lt;li&gt;Paramertized some stuff in ParrallelReader that made sense - what the heck&lt;/li&gt;
	&lt;li&gt;added a nocommit or two on unread fields with a comment that made it look like they were/will be used&lt;/li&gt;
	&lt;li&gt;Looks like SegmentTermPositions.java may have been screwy in last patch - ensure its now a deleted file - same with TermInfosWriter.java&lt;/li&gt;
	&lt;li&gt;You left getEnum(IndexReader reader) in the MultiTerm queries, but no in PrefixQuery - just checkin&apos;.&lt;/li&gt;
	&lt;li&gt;Missed removing listAll from FileSwitchDirectory - gone&lt;/li&gt;
	&lt;li&gt;cleaned up some white space nothings in the patch&lt;/li&gt;
	&lt;li&gt;I guess TestBackwardsCompatibility.java has been removed from trunk or something? kept it here for now.&lt;/li&gt;
	&lt;li&gt;looks like i missed merging in a change to TestIndexWriter.java#assertNoUnreferencedFiles - done&lt;/li&gt;
	&lt;li&gt;doubled checked my merge work&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;core and contrib tests pass&lt;/p&gt;

</comment>
                    <comment id="12762573" author="mikemccand" created="Tue, 6 Oct 2009 10:53:48 +0100"  >&lt;p&gt;Whoa thanks for the sudden sprint Mark!&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Come on old man, stop clinging to emacs&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Hey!  I&apos;m not so old &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; But yeah I still cling to emacs.  Hey, I know&lt;br/&gt;
people who still cling to vi!&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I didn&apos;t really look at the code, but some stuff I noticed:&lt;/p&gt;

&lt;p&gt;java 6 in pfor Arrays.copy&lt;/p&gt;

&lt;p&gt;skiplist stuff in codecs still have package of index - not sure what is going on there - changed them&lt;/p&gt;

&lt;p&gt;in IndexWriter: &lt;br/&gt;
+ // Mark: read twice?&lt;br/&gt;
segmentInfos.read(directory);&lt;br/&gt;
+ segmentInfos.read(directory, codecs);&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Excellent catches!  All of these are not right.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;(since you don&apos;t include contrib in the tar)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Gak, sorry.  I have a bunch of mods there, cutting over to flex API.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;You left getEnum(IndexReader reader) in the MultiTerm queries, but no in PrefixQuery - just checkin&apos;.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Woops, for back compat I think we need to leave it in (it&apos;s a&lt;br/&gt;
protected method), deprecated.  I&apos;ll put it back if you haven&apos;t.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I guess TestBackwardsCompatibility.java has been removed from trunk or something? kept it here for now.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Eek, it shouldn&apos;t be &amp;#8211; indeed it is.  When did that happen?  We&lt;br/&gt;
should fix this (separately from this issue!).&lt;/p&gt;

&lt;p&gt;Do you have more fixes coming?  If so, I&apos;ll let you sprint some more; else, I&apos;ll merge in, add contrib &amp;amp; back-compat branch, and post new patch!  Thanks &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="12762576" author="mikemccand" created="Tue, 6 Oct 2009 11:08:55 +0100"  >&lt;blockquote&gt;&lt;p&gt;One of the common statistics one needs to implement some more advanced scoring approaches is the average document length. Is this patch far enough along that I could take a look at it and think about how one might do this?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Well, thinking through how you&apos;d do this... likely you&apos;d want to store&lt;br/&gt;
the avg length (in tokens), eg as a single float per field per&lt;br/&gt;
segment, right?  The natural place to store this would be in the&lt;br/&gt;
FieldInfos, I think?.  Unfortunately, this patch doesn&apos;t yet add&lt;br/&gt;
extensibility to FieldInfos.&lt;/p&gt;

&lt;p&gt;And you&apos;d need a small customization to the indexing chain to&lt;br/&gt;
compute this when indexing new docs, which is already doable today&lt;br/&gt;
(though, package private).&lt;/p&gt;

&lt;p&gt;But then on merging segments, you&apos;d need an extensions point, which we&lt;br/&gt;
don&apos;t have today, to recompute the avg.  Hmm: how would you handle&lt;br/&gt;
deleted docs?  Would you want to go back to the field length for every&lt;br/&gt;
doc &amp;amp; recompute the average?  (Which&apos;d mean you need to per doc per&lt;br/&gt;
field length, not just the averages).&lt;/p&gt;

&lt;p&gt;Unfortunately, this patch doesn&apos;t yet address things like customizing&lt;br/&gt;
what&apos;s stored in FieldInfo or SegmentInfo, nor customizing what&lt;br/&gt;
happens during merging (though it takes us a big step closer to this).&lt;br/&gt;
I think we need both of these to &quot;finish&quot; flexible indexing, but I&apos;m&lt;br/&gt;
thinking at this point that these should really be tackled in followon&lt;br/&gt;
issue(s).  This issue is already ridiculously massive.&lt;/p&gt;</comment>
                    <comment id="12762590" author="thetaphi" created="Tue, 6 Oct 2009 12:43:04 +0100"  >&lt;blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;I guess TestBackwardsCompatibility.java has been removed from trunk or something? kept it here for now.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Eek, it shouldn&apos;t be - indeed it is. When did that happen? We&lt;br/&gt;
should fix this (separately from this issue!).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;My fault, I removed it during the remove backwards tests on Saturday. If we do not remove DateTools/DateField for 3.0 (we may need to leave it in for index compatibility), I will restore, these tests, too. It&apos;s easy with TortoiseSVN and you can also preserve the history (using svn:mergeinfo prop).&lt;/p&gt;

&lt;p&gt;I have this on my list when going forward with removing the old TokenStream API.&lt;/p&gt;</comment>
                    <comment id="12762592" author="mikemccand" created="Tue, 6 Oct 2009 13:01:35 +0100"  >&lt;blockquote&gt;&lt;p&gt;It&apos;s easy with TortoiseSVN and you can also preserve the history (using svn:mergeinfo prop).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Ahh &amp;#8211; can you do this for TestBackwardsCompatibility?  I restored it, but, lost all history.  Thanks.&lt;/p&gt;</comment>
                    <comment id="12762600" author="thetaphi" created="Tue, 6 Oct 2009 13:31:46 +0100"  >&lt;p&gt;Done. I also did it for the BW branch, but didn&apos;t create a tag yet. The next tag creation for the next bigger patch is enough (no need to do it now).&lt;/p&gt;

&lt;p&gt;What I have done: svn copy from the older revision to the same path &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="12762633" author="mikemccand" created="Tue, 6 Oct 2009 15:14:28 +0100"  >&lt;blockquote&gt;&lt;p&gt;What I have done: svn copy from the older revision to the same path&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Excellent, thanks!  It had a few problems (was still trying to deprecated APIs, some of which were gone) &amp;#8211; I just committed fixes.&lt;/p&gt;</comment>
                    <comment id="12762641" author="yseeley@gmail.com" created="Tue, 6 Oct 2009 15:26:27 +0100"  >&lt;blockquote&gt;&lt;p&gt;likely you&apos;d want to store the avg length (in tokens), eg as a single float per field per segment, right?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think we might want to store fundamentals instead:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;total number of tokens indexed for that field in the entire segment&lt;/li&gt;
	&lt;li&gt;total number of documents that contain the field in the entire segment&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Both of these seem really easy to keep track of?&lt;br/&gt;
I also think we&apos;d just ignore deleted docs (i.e. don&apos;t change the stats) just as idf does today.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The natural place to store this would be in the FieldInfos, I think?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;yep.&lt;/p&gt;
</comment>
                    <comment id="12762653" author="mikemccand" created="Tue, 6 Oct 2009 16:06:34 +0100"  >&lt;p&gt;Uber-patch attached: started from Mark&apos;s patch (thanks!), added my contrib &amp;amp; back-compat branch changes.  All tests pass.&lt;/p&gt;

&lt;p&gt;Also, I removed pfor from this issue.  I&apos;ll attach the pfor codec to &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1410&quot; title=&quot;PFOR implementation&quot;&gt;&lt;del&gt;LUCENE-1410&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Note that I didn&apos;t use &quot;svn move&quot; in generating the patch, so that the patch can be applied cleanly.  When it &lt;span class=&quot;error&quot;&gt;&amp;#91;finally&amp;#93;&lt;/span&gt; comes time to commit for real, I&apos;ll svn move so we preserve history.&lt;/p&gt;</comment>
                    <comment id="12762828" author="markrmiller@gmail.com" created="Wed, 7 Oct 2009 02:01:20 +0100"  >&lt;blockquote&gt;&lt;p&gt;Hey! I&apos;m not so old  But yeah I still cling to emacs. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;can you say both of those things in the same breath? Just how long did it take to get that phd...&lt;/p&gt;

&lt;p&gt;I&apos;d look it up and guestimate your age, but I think MIT still has my ip blocked from back when I was applying to colleges. So I&apos;m going with the &quot;uses emacs&quot; guestimate.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Hey, I know people who still cling to vi!&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;vi is the only one I can half way use - I know 3 commands - edit mode, leave edit mode, and save. And every now and then I accidently delete a whole line. When I make a change that I don&apos;t want to save, I have to kill the power.&lt;/p&gt;

&lt;p&gt;The patch is in a bit of an unpatchable state &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; I think I know what editor to blame...Pico!&lt;/p&gt;

&lt;p&gt;Our old friend, the $id is messing up WildcardTermEnum - no problem, I can fix that...&lt;/p&gt;

&lt;p&gt;But also, NumericUtils is unpatched, Codec is missing, along with most of the classes from the codecs packages! This looks like my work &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;My only conclusion is that your one of those guys that can write the whole program once without even running it - and then it works perfectly on the first go. Thats the only way I can explain those classes in the wrong package previously as well &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; No bug hunting tonight &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="12762831" author="markrmiller@gmail.com" created="Wed, 7 Oct 2009 02:15:32 +0100"  >&lt;p&gt;nope - something else - looking through the patch I see the files I want - a second attempt at patching has gone over better.&lt;/p&gt;

&lt;p&gt;A couple errors still, but stuff I think I can fix so that I can at least look over. False alarm. My patcher wonked out or something. I can resolve the few errors that popped up this time. Sweet.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;edit&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;Just for reference - not sure what happened the first time - my patch preview looked the same both times (was only complaining about the $id), but completely failed on attempt one and worked on attempt two - the only issue now appears to be you have half switch deletedDocs to Bits from BitVector - but only have way, so its broken in a dozen places. Not sure what you are doing about size() and what not, so I&apos;m just gonna read around.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;edit&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;Yes - I found it - BitVector was supposed to implement Bits - which was in the patch ... this patch just did not want to apply. I guess it was right, but Eclipse just did not want it to take ...&lt;/p&gt;</comment>
                    <comment id="12762842" author="markrmiller@gmail.com" created="Wed, 7 Oct 2009 03:02:55 +0100"  >&lt;p&gt;Bah - all this huffing an puffing over the patch and I&apos;m too sick to stay up late anyway.&lt;/p&gt;

&lt;p&gt;Have you started benching at all? I&apos;m seeing like a 40-50% drop in same reader search benches with standard, sep, and pulsing. Like 80% with intblock.&lt;/p&gt;</comment>
                    <comment id="12762960" author="mikemccand" created="Wed, 7 Oct 2009 10:28:10 +0100"  >&lt;p&gt;Mark is there anything wrong w/ the patch?  Did you get it working?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Have you started benching at all? I&apos;m seeing like a 40-50% drop in same reader search benches with standard, sep, and pulsing. Like 80% with intblock.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I haven&apos;t but it sounds like you have!  I&apos;ll get to it soon... but one thing I know is missing is the equivalent of the &quot;terminfo cache&quot; so that when a query 1) looks up docFreq of the term (to compute its weight), and 2) looks up the freq/prox offsets, that 2nd lookup is cached.&lt;/p&gt;

&lt;p&gt;IntBlock is expected to be slow &amp;#8211; it naively encodes one int at a time using vInt.  Ie, it&apos;s just a &quot;test&quot; codec, meant to be the base for real block-based codecs like pfor.&lt;/p&gt;</comment>
                    <comment id="12763020" author="markrmiller@gmail.com" created="Wed, 7 Oct 2009 13:01:13 +0100"  >&lt;blockquote&gt;&lt;p&gt;Mark is there anything wrong w/ the patch? Did you get it working?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I got it working - it didn&apos;t apply cleanly, but perhaps that was just me. It was a weird situation - I get a preview of whats going to happen with complaints, and it only complained about the $id issue in wildcardtermenum - the half the patch failed. A second attempt and it only complained about that again - but then it missed making BitVector implement Bits - could just be ghosts in my machine. I wouldn&apos;t worry about it till someone else complains. In any case, I got it working in my case by just fixing the $id issue and adding implements Bits to BitVector.&lt;/p&gt;</comment>
                    <comment id="12763097" author="markrmiller@gmail.com" created="Wed, 7 Oct 2009 16:30:39 +0100"  >&lt;blockquote&gt;&lt;p&gt;I haven&apos;t but it sounds like you have!&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Nothing serious &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; Just began trying to understand the code a bit more, so started with playing around with the different Codecs. Which lead to just quickly trying out the micro bench with each of em.&lt;/p&gt;</comment>
                    <comment id="12763105" author="mikemccand" created="Wed, 7 Oct 2009 17:01:50 +0100"  >&lt;p&gt;New patch attached.  All tests pass.&lt;/p&gt;

&lt;p&gt;I simplified the TermsEnum.seek API, and added ord to the API.  The&lt;br/&gt;
ord is a long, but the standard codec (and, I think, Lucene today)&lt;br/&gt;
internally use an int...&lt;/p&gt;</comment>
                    <comment id="12763714" author="yseeley@gmail.com" created="Thu, 8 Oct 2009 22:28:59 +0100"  >&lt;p&gt;Another for theTermsEnum wishlist: the ability to seek to the term &lt;b&gt;before&lt;/b&gt; the given term... useful for finding the largest value in a field, etc.&lt;/p&gt;

&lt;p&gt;I imagine &quot;at or before&quot; semantics would also work (like the current semantics of TermEnum in reverse)&lt;/p&gt;</comment>
                    <comment id="12763722" author="markrmiller@gmail.com" created="Thu, 8 Oct 2009 22:53:31 +0100"  >&lt;p&gt;Okay, I just tried a toy cache with standard - its not perfect because the tests have a bunch that end up finding one doc short, and I don&apos;t turn off the cache for any reason (the old one terns it off when returning the segmenttermenum, but I didn&apos;t even try to understand that with the new stuff). But that appears to get the majority of the perf back. Went from about 3500 r/s to 7500 - the old is 8400.&lt;/p&gt;

&lt;p&gt;This stuff is so cool by the way.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;edit&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;whew - emphasis on toy - its hard to do this right with docsreader &lt;/p&gt;</comment>
                    <comment id="12763764" author="mikemccand" created="Fri, 9 Oct 2009 01:06:31 +0100"  >&lt;blockquote&gt;&lt;p&gt;its hard to do this right with docsreader&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I was thinking something along the lines of adding a &quot;captureState&quot; to DocsProducer.Reader, that returns an opaque object, and then adding a corresponding seek that accepts that object.  It would chain to the positions reader.&lt;/p&gt;

&lt;p&gt;Then StandardTermsDictReader would hold the thread private cache, using this API.&lt;/p&gt;</comment>
                    <comment id="12763771" author="markrmiller@gmail.com" created="Fri, 9 Oct 2009 01:47:15 +0100"  >&lt;p&gt;Well thats reassuring - I think I was on the right path then. I&apos;ve got the thread private cache, and I was initially just capturing in&apos;s position so I could set it before calling readTerm after pulling from the cache - so I knew I had an issue with the positions reader in there too (the position of it in readTerm) - but didn&apos;t see the cleanest path to set and capture that without modifying the reader like you said - but I wasn&apos;t even sure I was on the right path, so thats about where I gave up &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;Your comment makes me feel a little less dumb about it all though.&lt;/p&gt;</comment>
                    <comment id="12763946" author="mikemccand" created="Fri, 9 Oct 2009 10:54:23 +0100"  >&lt;p&gt;No problem &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  Please post the patch once you have it working!  We&apos;ll need to implement captureState/seek for the other codes too.  The pulsing case will be interesting since it&apos;s state will hold the actual postings for the low freq case.&lt;/p&gt;

&lt;p&gt;BTW I think an interesting codec would be one that pre-loads postings into RAM, storing them uncompressed (eg docs/positions as simple int[]) or slightly compressed (stored as packed bits).  This should be a massive performance win at the expense of sizable RAM consumption, ie it makes the same tradeoff as contrib/memory and contrib/instantiated.&lt;/p&gt;</comment>
                    <comment id="12763956" author="mikemccand" created="Fri, 9 Oct 2009 11:26:53 +0100"  >
&lt;blockquote&gt;
&lt;p&gt;Another for theTermsEnum wishlist: the ability to seek to the term before the given term... useful for finding the largest value in a field, etc.&lt;br/&gt;
I imagine &quot;at or before&quot; semantics would also work (like the current semantics of TermEnum in reverse)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Right now seek(TermRef seekTerm) stops at the earliest term that&apos;s &amp;gt;=&lt;br/&gt;
seekTerm.&lt;/p&gt;

&lt;p&gt;It sounds like you&apos;re asking for a variant of seek that&apos;d stop at the&lt;br/&gt;
latest term that&apos;s &amp;lt;= seekTerm?&lt;/p&gt;

&lt;p&gt;How would you use this to seek to the last term in a field?  With the&lt;br/&gt;
flex API, the TermsEnum only works with a single field&apos;s terms.  So I&lt;br/&gt;
guess we&apos;d need TermRef constants, eg TermRef.FIRST and TermRef.LAST,&lt;br/&gt;
that &quot;act like&quot; -infinity / +infinity.&lt;/p&gt;</comment>
                    <comment id="12763984" author="mikemccand" created="Fri, 9 Oct 2009 13:07:16 +0100"  >&lt;p&gt;Actually, FIRST/LAST could be achieved with seek-by-ord (plus getUniqueTermCount()).  Though that&apos;d only work for TermsEnum impls that support ords.&lt;/p&gt;</comment>
                    <comment id="12764020" author="yseeley@gmail.com" created="Fri, 9 Oct 2009 14:39:24 +0100"  >&lt;blockquote&gt;&lt;p&gt;How would you use this to seek to the last term in a field?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It&apos;s not just last in a field, since one may be looking for last out of any given term range (the highest value of a trie int is not the last value encoded in that field).&lt;br/&gt;
So if you had a trie based field, one would find the highest value via seekAtOrBefore(triecoded(MAXINT))&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Actually, FIRST/LAST could be achieved with seek-by-ord (plus getUniqueTermCount()).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Ahhh... right, prev could be implemented like so:&lt;/p&gt;

&lt;p&gt;int ord = seek(triecoded(MAXINT))).ord&lt;br/&gt;
seek(ord-1)&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Though that&apos;d only work for TermsEnum impls that support ords. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;As long as ord is supported at the segment level, it&apos;s doable.&lt;/p&gt;</comment>
                    <comment id="12764050" author="markrmiller@gmail.com" created="Fri, 9 Oct 2009 16:24:34 +0100"  >&lt;p&gt;hmm - I think I&apos;m close. Everything passes except for omitTermsTest, LazyProxTest, and for some odd reason the multi term tests. Getting close though.&lt;/p&gt;

&lt;p&gt;My main concern at the moment is the state capturing. It seems I have to capture the state before readTerm in next() - but I might not use that state if there are multiple next calls before the hit. So thats a lot of wasted capturing. Have to deal with that somehow.&lt;/p&gt;

&lt;p&gt;Doing things more correctly like this, the gain is much less significant. What really worries me is that my hack test was still slower than the old - and that skipped a bunch of necessary work, so its almost a better than best case here - I think you might need more gains elsewhere to get back up to speed.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;edit&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;Hmm - still no equivalent of the cached enum for one I guess.&lt;br/&gt;
And at the least, since you only cache when the scan is great than one, you can at least skip one capture there...&lt;/p&gt;</comment>
                    <comment id="12764060" author="mikemccand" created="Fri, 9 Oct 2009 16:54:23 +0100"  >&lt;blockquote&gt;&lt;p&gt;It seems I have to capture the state before readTerm in next() &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Wait, how come?  It seems like we should only cache if we find exactly the requested term (ie, where we return SeekStatus.FOUND)?  So you should only have to capture the state once, there?&lt;/p&gt;

&lt;p&gt;Hmm I wonder whether we should also cache the seek(ord) calls?&lt;/p&gt;</comment>
                    <comment id="12764073" author="markrmiller@gmail.com" created="Fri, 9 Oct 2009 17:06:31 +0100"  >&lt;p&gt;Hmm - I must have something off then. I&apos;ve never been into this stuff much before.&lt;/p&gt;

&lt;p&gt;on a cache hit, I&apos;m still calling docs.readTerm(entry.freq, entry.isIndex) - I&apos;m just caching the freq, isIndex, and the positions with a CurrentState object. The captureCurrentState now telescopes down capturing the state of each object &lt;/p&gt;

&lt;p&gt;Perhaps I&apos;m off there - because if I do that, it seems I have to capture the state right before the call to readTerm in next() - otherwise readTerm will move everything forward before I can grab it when I actually put the state into the cache - when its FOUND.&lt;/p&gt;

&lt;p&gt;I may be all wet though - no worries - I&apos;m really just playing around trying to learn some of this - only way I learn to is to code.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Hmm I wonder whether we should also cache the seek(ord) calls?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I was wondering about that, but hand&apos;t even got to thinking about it &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="12764078" author="michaelbusch" created="Fri, 9 Oct 2009 17:24:47 +0100"  >&lt;p&gt;I added this cache originally because it seemed the easiest to improve the term lookup performance. &lt;/p&gt;

&lt;p&gt;Now we&apos;re adding the burden of implementing such a cache to every codec, right? Maybe instead we should improve the search runtime to not call idf() twice for every term?&lt;/p&gt;</comment>
                    <comment id="12764079" author="mikemccand" created="Fri, 9 Oct 2009 17:25:23 +0100"  >&lt;blockquote&gt;&lt;p&gt;on a cache hit, I&apos;m still calling docs.readTerm(entry.freq, entry.isIndex) &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Hmm... I think your cache might be one level too low?  I think we want the cache to live in StandardTermsDictReader.  Only the seek(TermRef) method interacts with the cache for now (until we maybe add ord as well).&lt;/p&gt;

&lt;p&gt;So, seek first checks if that term is in cache, and if so pulls the opaque state and asks the docsReader to restore to that state.  Else, it does the normal seek, but then if the exact term is found, it calls docsReader.captureState and stores it in the cache.&lt;/p&gt;

&lt;p&gt;Make sure the cache lives high enough to be shared by different TermsEnum instances.  I think it should probably live in StandardTermsDictReader.FieldReader.  There is one instance of that per field.&lt;/p&gt;</comment>
                    <comment id="12764085" author="mikemccand" created="Fri, 9 Oct 2009 17:30:14 +0100"  >&lt;blockquote&gt;&lt;p&gt;Now we&apos;re adding the burden of implementing such a cache to every codec, right?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I suspect most codecs will reuse the StandardTermsDictReader, ie, they will usually only change the docs/positions/payloads format.  So each codec will only have to implement capture/restoreState.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Maybe instead we should improve the search runtime to not call idf() twice for every term?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Oh I didn&apos;t realize we call idf() twice per term &amp;#8211; we should separately just fix that.  Where are we doing that?&lt;/p&gt;

&lt;p&gt;(I thought the two calls were first for idf() and then 2nd when it&apos;s time to get the actual TermDocs/Positions to step through).&lt;/p&gt;</comment>
                    <comment id="12764089" author="michaelbusch" created="Fri, 9 Oct 2009 17:41:08 +0100"  >&lt;blockquote&gt;
&lt;p&gt;Oh I didn&apos;t realize we call idf() twice per term&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Hmm I take that back. I looked in &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1195&quot; title=&quot;Performance improvement for TermInfosReader&quot;&gt;&lt;del&gt;LUCENE-1195&lt;/del&gt;&lt;/a&gt; again:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Currently we have a bottleneck for multi-term queries: the dictionary lookup is being done&lt;br/&gt;
twice for each term. The first time in Similarity.idf(), where searcher.docFreq() is called.&lt;br/&gt;
The second time when the posting list is opened (TermDocs or TermPositions). &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Hmm something&apos;s wrong with my memory this morning! Maybe the lack of caffeine &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="12764114" author="markrmiller@gmail.com" created="Fri, 9 Oct 2009 18:40:41 +0100"  >&lt;p&gt;Ah - okay - that helps. I think the cache itself is currently around the right level (StandardTermsDictReader, and it gets hit pretty hard), but I thought it was funky I still had to make that read call - I think I see how it should work without that now, but just queuing up the docsReader to where it should be correctly. We will see. Vacation till Tuesday - don&apos;t let me stop you from doing it correctly if its on your timeline. Just playing over here - and I don&apos;t have a lot of time to play really.&lt;/p&gt;</comment>
                    <comment id="12764241" author="mikemccand" created="Fri, 9 Oct 2009 23:46:52 +0100"  >&lt;p&gt;New patch attached.  All tests pass.&lt;/p&gt;

&lt;p&gt;A few small changes (eg sync&apos;d to trunk) but the biggest change is a&lt;br/&gt;
new test case (TestExternalCodecs) that contains two new codecs:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;RAMOnlyCodec &amp;#8211; like instantiated, it writes and reads all&lt;br/&gt;
    postings into RAM in dedicated classes&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;PerFieldCodecWrapper &amp;#8211; dispatches by field name to different&lt;br/&gt;
    codecs (this was asked about a couple times)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The test indexes one field using the standard codec, and the other&lt;br/&gt;
using the RAMOnlyCodec.  It also verifies one can in fact make a&lt;br/&gt;
custom codec external to oal.index.&lt;/p&gt;</comment>
                    <comment id="12764531" author="markrmiller@gmail.com" created="Mon, 12 Oct 2009 03:34:30 +0100"  >&lt;p&gt;Okay, after all that poking around in the dark, tonight I decided to actually try turning on the DEBUG stuff you have and figuring out how things actually work &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; Always too lazy to open that instruction manual till I&apos;ve wasted plenty of time spinning in circles.&lt;/p&gt;

&lt;p&gt;So I&apos;ve got it working -&lt;/p&gt;

&lt;p&gt;When it was working like 99% I benched the speed at 6300-6500 r/s with the samerdr bench as compared to 9500-11000 with the trunk version I had checked out.&lt;/p&gt;

&lt;p&gt;But that last 1% meant adding two TermRef clones, and that dropped things to about 5800 or so.&lt;/p&gt;

&lt;p&gt;I&apos;m sure I might have a few wasteful instructions and/or there can be a little more eeked out, but I think it will still come up short.&lt;/p&gt;

&lt;p&gt;I dont see seek(ord) being called using eclipse (other than in tests), but it may be missing it? So I&apos;m not really sure if it needs to be cached or not - no code to test it with at the moment.&lt;/p&gt;</comment>
                    <comment id="12764737" author="michaelbusch" created="Mon, 12 Oct 2009 17:19:36 +0100"  >&lt;p&gt;Shall we create a flexible-indexing branch and commit this? &lt;/p&gt;

&lt;p&gt;The downside of course is that we&apos;d have to commit patches to trunk and this branch until 3.0 is out. Or we could use svn&apos;s new branch merging capabilities, which I haven&apos;t tried out yet.&lt;/p&gt;</comment>
                    <comment id="12764799" author="mikemccand" created="Mon, 12 Oct 2009 20:32:27 +0100"  >&lt;blockquote&gt;&lt;p&gt;Shall we create a flexible-indexing branch and commit this?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think this is a good idea.&lt;/p&gt;

&lt;p&gt;But I haven&apos;t played heavily w/ svn &amp;amp; branching.  EG if we branch now, and trunk moves fast (which it still is w/ deprecation removals), are we going to have conflicts?  Or... is svn good about merging branches?&lt;/p&gt;</comment>
                    <comment id="12764800" author="mikemccand" created="Mon, 12 Oct 2009 20:34:23 +0100"  >&lt;blockquote&gt;&lt;p&gt;I dont see seek(ord) being called using eclipse (other than in tests), but it may be missing it?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yeah this won&apos;t be used yet &amp;#8211; we only just added it (and only to the flex API).  I guess wait on caching it for now?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I&apos;m sure I might have a few wasteful instructions and/or there can be a little more eeked out, but I think it will still come up short.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;OK we&apos;ve got some work to do &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  Which queries in particular are slower?&lt;/p&gt;</comment>
                    <comment id="12764822" author="markrmiller@gmail.com" created="Mon, 12 Oct 2009 21:44:30 +0100"  >&lt;p&gt;Havn&apos;t gotten that far yet &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; Still just doing quick standard micro benches of each. I think I&apos;ve got it around 6500 now - perhaps a little higher.&lt;/p&gt;

&lt;p&gt;I&apos;ll post the patch fairly soon - still struggling merging with your latest and trunk.&lt;/p&gt;

&lt;p&gt;I think I&apos;ve got it all except an issue with one of the contribs - must have gotten a little mis merge. Also your new external codecs test through a monkey wrench in - pulsing isn&apos;t setup to work with the cache yet - I&apos;m punting on that for now.&lt;/p&gt;</comment>
                    <comment id="12764831" author="mikemccand" created="Mon, 12 Oct 2009 21:59:07 +0100"  >&lt;blockquote&gt;&lt;p&gt;pulsing isn&apos;t setup to work with the cache yet - I&apos;m punting on that for now.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;OK that&apos;s fine for now.  The cache should gracefully handle codecs that don&apos;t implement &quot;captureState&quot; by simply not caching them.&lt;/p&gt;</comment>
                    <comment id="12764959" author="markrmiller@gmail.com" created="Tue, 13 Oct 2009 06:54:41 +0100"  >&lt;p&gt;Here is my patch. I won&apos;t say its 100% polished and done, but I believe its in initial working order. This is a good check point time for me for various reasons.&lt;/p&gt;

&lt;p&gt;Simple LRU cache for Standard Codec - meant to replace TermInfo cache.&lt;/p&gt;

&lt;p&gt;Merged with latest patch from Mike + to trunk&lt;/p&gt;

&lt;p&gt;Some other little random stuff that I remember:&lt;/p&gt;

&lt;p&gt;PrefixTermsEnum is deprecated - sees itself - fixed&lt;/p&gt;

&lt;p&gt;WildcardQuery should have @see WildcardTermsEnums - fixed&lt;/p&gt;

&lt;p&gt;some stuff in preflex is already deprecated but not all?&lt;/p&gt;

&lt;p&gt;StandardDocsReader - freqStart is always 0 - left it in, but doesn&apos;t do anything at the moment&lt;/p&gt;

&lt;p&gt;backcompattests missing termref - fixed&lt;/p&gt;

&lt;p&gt;note: currently, with the testThreadSafety test in TestIndexReaderReopen appears to have some Garbage Collection issues with Java6 - not really seeing them with Java5 though - will investigate more.&lt;/p&gt;

&lt;p&gt;I&apos;ve got the latest tag updated too - but there appear to be some odditties with it (unrelated to this patch), so leaving out for now.&lt;/p&gt;</comment>
                    <comment id="12765129" author="markrmiller@gmail.com" created="Tue, 13 Oct 2009 17:11:23 +0100"  >&lt;p&gt;Latest to trunk - still issues with GC and the reopen thread safety test (unless the test is run in isolation).&lt;/p&gt;

&lt;p&gt;Must be a tweak needed, but I&apos;m not sure what. I&apos;m closing the thread locals when the StandardTermsDictReader is closed - I don&apos;t see a way to improve on that yet.&lt;/p&gt;</comment>
                    <comment id="12765149" author="markrmiller@gmail.com" created="Tue, 13 Oct 2009 18:00:43 +0100"  >&lt;p&gt;Whoops - double check the wrong index splitter test - the multi pass one is throwing a null pointer exception for me - don&apos;t think its related to this patch, but I havn&apos;t checked.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;edit&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;Okay, just checked - it is this patch. Looks like perhaps something to do with LegacyFieldsEnum? Something that isnt being hit by core tests at the moment (I didnt run through all the backcompat tests with this yet, since that failed)&lt;/p&gt;</comment>
                    <comment id="12765204" author="markrmiller@gmail.com" created="Tue, 13 Oct 2009 20:52:53 +0100"  >&lt;p&gt;Looks pretty simple - the field is not getting set with LegacyFieldsEnum.&lt;/p&gt;</comment>
                    <comment id="12765234" author="mikemccand" created="Tue, 13 Oct 2009 22:07:01 +0100"  >&lt;p&gt;OK I think I&apos;ve committed Mark&apos;s last patch onto this branch:&lt;/p&gt;

&lt;p&gt;  &lt;a href=&quot;https://svn.apache.org/repos/asf/lucene/java/branches/flex_1458&quot; class=&quot;external-link&quot;&gt;https://svn.apache.org/repos/asf/lucene/java/branches/flex_1458&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;and I also branched the 2.9 back-compat branch and committed the last back compat patch:&lt;/p&gt;

&lt;p&gt;  &lt;a href=&quot;https://svn.apache.org/repos/asf/lucene/java/branches/flex_1458_2_9_back_compat_tests&quot; class=&quot;external-link&quot;&gt;https://svn.apache.org/repos/asf/lucene/java/branches/flex_1458_2_9_back_compat_tests&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Mark can you check it out &amp;amp; see if I missed anything?&lt;/p&gt;</comment>
                    <comment id="12765237" author="thetaphi" created="Tue, 13 Oct 2009 22:22:35 +0100"  >&lt;p&gt;By the way, a lot of these PriorityQueues can be generified like in trunk to remove the unneeded casts in lessThan, pop, insert,... everywhere.&lt;/p&gt;</comment>
                    <comment id="12766339" author="mikemccand" created="Fri, 16 Oct 2009 01:08:34 +0100"  >&lt;p&gt;I just committed some small improvements to the ThreadLocal cache; all&lt;br/&gt;
tests pass at 512M heap limit again.&lt;/p&gt;

&lt;p&gt;I think the reason why TestIndexReaderReopen was hitting the limit is&lt;br/&gt;
because its testThreadSafety test opens many (344) IndexReaders at&lt;br/&gt;
once, without closing them until the very end, and the standard codec&lt;br/&gt;
is now using more starting RAM per reader because 1) the terms index&lt;br/&gt;
uses a fixed minimal block size for the byte[], and 2) the new terms&lt;br/&gt;
info cache is less RAM efficient.&lt;/p&gt;

&lt;p&gt;I&apos;ve made some progress to &quot;scale down&quot; better:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Don&apos;t create a 1024 sized cache when total # terms is less than&lt;br/&gt;
    that&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Cache a single thread-private TermsEnum, to re-use for docFreq&lt;br/&gt;
    lookups&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Reduced what&apos;s stored in each cache entry&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Made StandardDocsReader subclass CacheEntry to store its own&lt;br/&gt;
    stuff; saves one extra object per entry.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12766350" author="markrmiller@gmail.com" created="Fri, 16 Oct 2009 01:38:51 +0100"  >&lt;blockquote&gt;&lt;p&gt;// nocommit &amp;#8211; why scanCnt &amp;gt; 1?&lt;br/&gt;
            //if (docs.canCaptureState() &amp;amp;&amp;amp; scanCnt &amp;gt; 1) {&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;My mistake - an early mess up when I was copying from preflix caching code - I saw it doing this - but its doing it with the cached enum - I should have been looking below where it doesn&apos;t do that. Just a left over from early on when I was kind of shooting in the dark.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;edit&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;I also had messed with it a bit - tried 0 and 2 - neither appeared to affect the micro bench samerdrsearch results. Seemed odd. Adding the cache did help those results, so I&apos;d expect that changing that would affect things more.&lt;/p&gt;</comment>
                    <comment id="12766359" author="markrmiller@gmail.com" created="Fri, 16 Oct 2009 01:56:39 +0100"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    &lt;span class=&quot;code-comment&quot;&gt;// nocommit -- not needed?  we don&apos;t need to sync since
&lt;/span&gt;    &lt;span class=&quot;code-comment&quot;&gt;// only one thread works with &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;?
&lt;/span&gt;
    /*
    @Override
    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;synchronized&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; put(&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; key, &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; value) {
      &lt;span class=&quot;code-comment&quot;&gt;// TODO Auto-generated method stub
&lt;/span&gt;      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;super&lt;/span&gt;.put(key, value);
    }
    
    @Override
    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;synchronized&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; get(&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; key) {
      &lt;span class=&quot;code-comment&quot;&gt;// TODO Auto-generated method stub
&lt;/span&gt;      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;super&lt;/span&gt;.get(key);
    }
    */
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Whoops! I&apos;m sorry! I wondered why I didn&apos;t have to replace all to get rid of that when I updated - I didn&apos;t mean to commit that! That was just part of my experimenting with the RAM blowout issue - was just making sure everything still worked without each thread having its own cache. That means the ThreadResources was out of whack too - I did have it as a member of the SegmentTermsEnum - I&apos;m sorry - totally didn&apos;t mean to commit that!&lt;/p&gt;

&lt;p&gt;&lt;b&gt;edit&lt;/b&gt; Also the stuff with the threadResourceSet and setting to null - just trying to figure out the mem issue - I did a bunch of debugging things and they all got caught up in a merge. Yuck.&lt;/p&gt;</comment>
                    <comment id="12766362" author="markrmiller@gmail.com" created="Fri, 16 Oct 2009 02:08:20 +0100"  >&lt;p&gt;  // nocommit &amp;#8211; wonder if simple double-barrel LRU cache&lt;br/&gt;
  // would be better&lt;/p&gt;

&lt;p&gt;  Yeah - haven&apos;t considered anything about the cache being used - really just took the same cache that was being used to cache terminfos. The only reason I changed to my own impl over SimpleLRUCache was that I wanted to reuse the removed entry.&lt;/p&gt;


&lt;p&gt;  // nocommit &amp;#8211; we should not init cache w/ full&lt;br/&gt;
  // capacity?  init it at 0, and only start evicting&lt;br/&gt;
  // once #entries is over our max&lt;/p&gt;

&lt;p&gt;  Same here - I took the same thing the old cache was doing.&lt;br/&gt;
  Do we want to start it at 0 though? Perhaps a little higher? Doesn&apos;t it keep rehashing to roughly double the size? That could be a lot of resizing ...&lt;/p&gt;</comment>
                    <comment id="12766367" author="markrmiller@gmail.com" created="Fri, 16 Oct 2009 02:28:34 +0100"  >&lt;p&gt;Hmm - I&apos;m still getting the heap space issue I think - its always been somewhat intermittent - sometimes it doesn&apos;t happen - usually it happens when you run all the tests - sometimes not though. Same when you run the test class individually - usually to sometimes it doesn&apos;t happen - and then usually to sometimes it does.&lt;/p&gt;</comment>
                    <comment id="12766481" author="mikemccand" created="Fri, 16 Oct 2009 10:21:30 +0100"  >&lt;p&gt;OK thank for addressing the new nocommits &amp;#8211; you wanna remove them &amp;amp; commit as you find/comment on them?  Can be our means of communicating through the branch &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;For now, I don&apos;t think we need to explore improvements to the TermInfo cache (starting @ smaller size, simplistic double barrel LRU cache) &amp;#8211; we can simply mimic trunk for now; such improvements are orthogonal here.  Maybe switch those nocommits to TODOs instead?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Hmm - I&apos;m still getting the heap space issue I think&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Sigh.  I think we have more work to do to &quot;scale down&quot; RAM used by IndexReader for a smallish index.&lt;/p&gt;</comment>
                    <comment id="12766482" author="mikemccand" created="Fri, 16 Oct 2009 10:23:04 +0100"  >&lt;blockquote&gt;&lt;p&gt;you wanna remove them &amp;amp; commit as you find/comment on them?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Woops, I see you already did!  Thanks.&lt;/p&gt;</comment>
                    <comment id="12766562" author="markrmiller@gmail.com" created="Fri, 16 Oct 2009 16:39:59 +0100"  >&lt;p&gt;just committed an initial stab at pulsing cache support - could prob use your love again &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;Oddly, the reopen test passed no problem and this adds more to the cache - perhaps I was seeing a ghost last night ...&lt;/p&gt;

&lt;p&gt;I&apos;ll know before too long.&lt;/p&gt;</comment>
                    <comment id="12766832" author="markrmiller@gmail.com" created="Sat, 17 Oct 2009 05:30:18 +0100"  >&lt;p&gt;Almost got an initial rough stab at the sep codec cache done - just have to get two more tests to pass involving the payload&apos;s state.&lt;/p&gt;</comment>
                    <comment id="12766913" author="markrmiller@gmail.com" created="Sat, 17 Oct 2009 14:36:14 +0100"  >&lt;p&gt;Hey Mike: you tweaked a couple little things with the standard cache capture state (showing that I&apos;m a cheater and getting stuff to work that I haven&apos;t yet fully understood &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; My specialty ) - what worries me is that they look like important little pieces if they are correct, but all tests passed without them. Hopefully we can get some tests in that catch these little off bys.&lt;/p&gt;</comment>
                    <comment id="12766917" author="markrmiller@gmail.com" created="Sat, 17 Oct 2009 15:07:15 +0100"  >&lt;p&gt;Okay, first pass for sep cache support is in - def needs to be trimmed down - heap issue with reopen everytime - I&apos;m using a state object with the Index objects though, and I&apos;m sure that can be done away with - though I guess a clone is not really much better and there is no access to their guts at the moment. Works for a first pass though.&lt;/p&gt;</comment>
                    <comment id="12766922" author="mikemccand" created="Sat, 17 Oct 2009 15:34:29 +0100"  >&lt;blockquote&gt;&lt;p&gt;you tweaked a couple little things with the standard cache capture state&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Actually I think I just moved things around?  EG I made it the StandardTermsDictReader&apos;s job to seek the termsIn file, I moved docCount &quot;up&quot;, and I made a single cache entry.  I think I also removed a few attrs that we didn&apos;t need to store... and downgraded skipOffset from long -&amp;gt; int (it&apos;s int on trunk).&lt;/p&gt;</comment>
                    <comment id="12766925" author="markrmiller@gmail.com" created="Sat, 17 Oct 2009 15:41:30 +0100"  >&lt;blockquote&gt;&lt;p&gt;Actually I think I just moved things around? EG I made it the StandardTermsDictReader&apos;s job to seek the termsIn file, I moved docCount &quot;up&quot;, and I made a single cache entry. I think I also removed a few attrs that we didn&apos;t need to store... and downgraded skipOffset from long -&amp;gt; int (it&apos;s int on trunk).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Okay - that makes me feel a little better - I knew there was some unneccessary stuff, just hadn&apos;t gone through and figured out what could be stripped yet (there is likely the same thing with the new caches, but I don&apos;t think as much).&lt;/p&gt;

&lt;p&gt;They main thing I saw that made me worry that I didn&apos;t think I had was:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
          posReader.positions.seekPending = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;;
          posReader.positions.skipOffset = posReader.proxOffset;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;But perhaps I was just accomplishing the same thing in a different manner? I&apos;d have to go back and look - I just don&apos;t think I knew enough to set either of those correctly - but seeing it helped me figure out what the heck was wrong with the final payloads piece in Sep &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="12766940" author="mikemccand" created="Sat, 17 Oct 2009 18:08:04 +0100"  >&lt;p&gt;Ahh, I just changed your seek to be a lazy seek, in case the caller won&apos;t use the positions; though I think setting skipPosCount=0 (which I also added) should have been necessary even with the non-lazy seek.  Probably we could get the TestCodecs test to tickle that bug, if we get a DocsEnum, get PositionsEnum, read a few docs but NOT the positions, then seek to a term we had already seeked to (so it uses the cache) then try to read positions.  The positions should be wrong because skipPosCount will carry over a non-zero value.&lt;/p&gt;</comment>
                    <comment id="12767056" author="mikemccand" created="Sun, 18 Oct 2009 14:05:24 +0100"  >&lt;p&gt;I just committed fix for a major memory cost during TestIndexReaderReopen.&lt;/p&gt;

&lt;p&gt;The new  terms dict index uses fixed byte[] blocks to hold the UTF8 bytes, of size 32 KB currently.  But for a tiny segment this is very wasteful.  So I fixed it to trim down the last byte[] block to free up the unused space.  I think TestIndexReaderReopen should no longer hit OOMs.&lt;/p&gt;</comment>
                    <comment id="12767068" author="markrmiller@gmail.com" created="Sun, 18 Oct 2009 15:44:02 +0100"  >&lt;p&gt;Nice! Sep and Pulsing still need to be trimmed down though - or we consider their bloat acceptable (they still don&apos;t pass). Sep especially should be pretty trimable I think. Pulsing is more of an issue because of the Document caching...&lt;/p&gt;</comment>
                    <comment id="12767071" author="mikemccand" created="Sun, 18 Oct 2009 16:12:20 +0100"  >&lt;blockquote&gt;&lt;p&gt;Pulsing is more of an issue because of the Document caching...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yeah, we probably need to measure cache size by RAM usage not shear count.  And, make it settable when you instantiate the codec.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Sep and Pulsing still need to be trimmed down though &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Are they causing OOMs with TestIndexReaderReopen?  (I haven&apos;t tried yet).&lt;/p&gt;</comment>
                    <comment id="12767073" author="markrmiller@gmail.com" created="Sun, 18 Oct 2009 16:15:14 +0100"  >&lt;blockquote&gt;&lt;p&gt;Are they causing OOMs with TestIndexReaderReopen? (I haven&apos;t tried yet).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes - they both def need polish too - I just got them working (passing all the tests), but havn&apos;t really finished them.&lt;/p&gt;</comment>
                    <comment id="12774666" author="mikemccand" created="Sat, 7 Nov 2009 20:50:23 +0000"  >&lt;p&gt;I just committed contrib/benchmark/sortBench.py on the branch, to run&lt;br/&gt;
perf tests comparing trunk to flex.&lt;/p&gt;

&lt;p&gt;You have to apply patches from &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-2042&quot; title=&quot;Allow controllable printing of the hits&quot;&gt;&lt;del&gt;LUCENE-2042&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-2043&quot; title=&quot;Fix CommitIndexTask to also commit IndexReader changes&quot;&gt;&lt;del&gt;LUCENE-2043&lt;/del&gt;&lt;/a&gt; (until we&lt;br/&gt;
resync branch).&lt;/p&gt;

&lt;p&gt;First edit the TRUNK_DIR and FLEX_DIR up top, and WIKI_FILE (it&lt;br/&gt;
requires wiki export &amp;#8211; all tests run against it), then run with &quot;-run&lt;br/&gt;
XXX&quot; to test performance.&lt;/p&gt;

&lt;p&gt;It first creates the 5M doc index, for trunk and for flex, with&lt;br/&gt;
multiple commit points holding higher pctg of deletions (0, 0.1%, 1%,&lt;br/&gt;
10%), and then tests speed of various queries against it.&lt;/p&gt;

&lt;p&gt;I also fixed a bug in the standard codec&apos;s terms index reader.&lt;/p&gt;</comment>
                    <comment id="12774692" author="mikemccand" created="Sun, 8 Nov 2009 00:03:08 +0000"  >&lt;p&gt;Initial results.  Performance is quite catastrophically bad for the MultiTermQueries!  Something silly must be up....&lt;/p&gt;

&lt;p&gt;JAVA:&lt;br/&gt;
java version &quot;1.5.0_19&quot;&lt;br/&gt;
Java(TM) 2 Runtime Environment, Standard Edition (build 1.5.0_19-b02)&lt;br/&gt;
Java HotSpot(TM) Server VM (build 1.5.0_19-b02, mixed mode)&lt;/p&gt;


&lt;p&gt;OS:&lt;br/&gt;
SunOS rhumba 5.11 snv_111b i86pc i386 i86pc Solaris&lt;/p&gt;

&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Query&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Deletes %&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Tot hits&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;QPS old&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;QPS new&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Pct change&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;body:&lt;span class=&quot;error&quot;&gt;&amp;#91;tec TO tet&amp;#93;&lt;/span&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;body:&lt;span class=&quot;error&quot;&gt;&amp;#91;tec TO tet&amp;#93;&lt;/span&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;3.06&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.23&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-92.5%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;body:&lt;span class=&quot;error&quot;&gt;&amp;#91;tec TO tet&amp;#93;&lt;/span&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;body:&lt;span class=&quot;error&quot;&gt;&amp;#91;tec TO tet&amp;#93;&lt;/span&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2.87&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.22&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-92.3%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;body:&lt;span class=&quot;error&quot;&gt;&amp;#91;tec TO tet&amp;#93;&lt;/span&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;body:&lt;span class=&quot;error&quot;&gt;&amp;#91;tec TO tet&amp;#93;&lt;/span&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2.85&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.22&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-92.3%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;body:&lt;span class=&quot;error&quot;&gt;&amp;#91;tec TO tet&amp;#93;&lt;/span&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;body:&lt;span class=&quot;error&quot;&gt;&amp;#91;tec TO tet&amp;#93;&lt;/span&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2.83&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.23&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-91.9%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;22.15&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;23.87&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;7.8%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;19.89&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;21.72&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;9.2%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;19.47&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;21.55&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;10.7%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;19.82&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;21.13&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;6.6%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;23.54&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;25.97&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;10.3%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;21.12&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;23.56&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;11.6%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;21.37&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;23.27&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;8.9%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;21.55&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;23.10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;7.2%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1 +2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1 +2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;7.13&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;6.97&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-2.2%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1 +2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1 +2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;6.40&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;6.77&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;5.8%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1 +2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1 +2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;6.41&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;6.64&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;3.6%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1 +2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1 +2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;6.65&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;6.98&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;5.0%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1 -2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1 -2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;7.78&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;7.95&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;2.2%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1 -2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1 -2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;7.11&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;7.31&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;2.8%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1 -2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1 -2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;7.18&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;7.27&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;1.3%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1 -2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1 -2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;7.11&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;7.70&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;8.3%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1 2 3 -4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1 2 3 -4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5.03&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4.91&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-2.4%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1 2 3 -4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1 2 3 -4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4.62&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4.39&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-5.0%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1 2 3 -4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1 2 3 -4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4.72&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4.67&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-1.1%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1 2 3 -4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1 2 3 -4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4.78&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4.74&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-0.8%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;real*&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;real*&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;28.40&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.19&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-99.3%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;real*&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;real*&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;26.23&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.20&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-99.2%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;real*&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;real*&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;26.04&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.20&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-99.2%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;real*&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;real*&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;26.83&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.20&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-99.3%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;world economy&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;world economy&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;18.82&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;17.83&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-5.3%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;world economy&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;world economy&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;18.64&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;17.99&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-3.5%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;world economy&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;world economy&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;18.97&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;18.35&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-3.3%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;world economy&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;world economy&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;19.59&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;18.12&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-7.5%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
</comment>
                    <comment id="12774767" author="mikemccand" created="Sun, 8 Nov 2009 13:12:04 +0000"  >&lt;p&gt;Committed fixes addressing silly slowness.  You also need &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-2044&quot; title=&quot;Allow random seed to be set in DeleteByPercentTask&quot;&gt;&lt;del&gt;LUCENE-2044&lt;/del&gt;&lt;/a&gt; patch, until we sync up with trunk again, to run sortBench.py.&lt;/p&gt;

&lt;p&gt;Part of the slowness was from MTQ queries incorrectly running the TermsEnum to exhaustion, instead of stopping when they hit their upperTerm.  But, another part of the slowness was because sortBench.py was actually incorrectly testing flex branch against a trunk index.  This is definitely something we have to test (it&apos;s what people will see when they use flex to search existing indexes &amp;#8211; flex API emulated on the current index format), so, we&apos;ll have to address that slowness as well, but for now I want to test pure flex (flex API on a flex index).&lt;/p&gt;</comment>
                    <comment id="12774768" author="mikemccand" created="Sun, 8 Nov 2009 13:16:14 +0000"  >&lt;p&gt;OK new numbers after the above commits:&lt;/p&gt;

&lt;p&gt;JAVA:&lt;br/&gt;
java version &quot;1.5.0_19&quot;&lt;br/&gt;
Java(TM) 2 Runtime Environment, Standard Edition (build 1.5.0_19-b02)&lt;br/&gt;
Java HotSpot(TM) Server VM (build 1.5.0_19-b02, mixed mode)&lt;/p&gt;


&lt;p&gt;OS:&lt;br/&gt;
SunOS rhumba 5.11 snv_111b i86pc i386 i86pc Solaris&lt;/p&gt;


&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Query&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Deletes %&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Tot hits&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;QPS old&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;QPS new&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Pct change&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;body:&lt;span class=&quot;error&quot;&gt;&amp;#91;tec TO tet&amp;#93;&lt;/span&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1934684&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;3.13&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;3.96&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;26.5%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;body:&lt;span class=&quot;error&quot;&gt;&amp;#91;tec TO tet&amp;#93;&lt;/span&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1932754&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2.98&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;3.62&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;21.5%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;body:&lt;span class=&quot;error&quot;&gt;&amp;#91;tec TO tet&amp;#93;&lt;/span&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1915224&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2.97&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;3.62&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;21.9%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;body:&lt;span class=&quot;error&quot;&gt;&amp;#91;tec TO tet&amp;#93;&lt;/span&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1741255&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2.96&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;3.61&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;22.0%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;real*&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;389378&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;27.80&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;28.73&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;3.3%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;real*&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;389005&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;26.74&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;28.93&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;8.2%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;real*&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;385434&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;26.61&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;29.04&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;9.1%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;real*&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;350404&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;26.32&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;29.29&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;11.3%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1170209&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;21.81&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;22.27&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;2.1%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1169068&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;20.41&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;21.47&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;5.2%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1158528&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;20.42&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;21.41&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;4.8%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1053269&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;20.52&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;21.39&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;4.2%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1088727&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;23.29&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;23.86&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;2.4%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1087700&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;21.67&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;22.92&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;5.8%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1077788&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;21.77&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;22.80&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;4.7%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;980068&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;21.90&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;23.04&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;5.2%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1 +2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;700793&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;7.25&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;6.65&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-8.3%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1 +2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;700137&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;6.58&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;6.33&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-3.8%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1 +2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;693756&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;6.50&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;6.32&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-2.8%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1 +2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;630953&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;6.73&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;6.37&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-5.3%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1 -2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;469416&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;8.11&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;7.27&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-10.4%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1 -2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;468931&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;7.02&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;6.61&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-5.8%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1 -2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;464772&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;7.27&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;6.75&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-7.2%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1 -2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;422316&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;7.28&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;6.99&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-4.0%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1 2 3 -4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1104704&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4.80&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4.46&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-7.1%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1 2 3 -4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1103583&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4.74&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4.40&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-7.2%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1 2 3 -4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1093634&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4.72&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4.45&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-5.7%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1 2 3 -4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;994046&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4.79&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4.63&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-3.3%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;world economy&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;985&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;19.43&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;16.79&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-13.6%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;world economy&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;984&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;18.71&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;16.59&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-11.3%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;world economy&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;970&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;19.65&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;16.86&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-14.2%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;world economy&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;884&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;19.69&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;17.25&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-12.4%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;



&lt;p&gt;The term range query &amp;amp; preifx query are now a bit faster; boolean queries are somewhat slower; the phrase query shows the biggest slowdown...&lt;/p&gt;</comment>
                    <comment id="12774785" author="markrmiller@gmail.com" created="Sun, 8 Nov 2009 15:56:59 +0000"  >&lt;p&gt;I&apos;ll merge up when I figure out how -&lt;/p&gt;

&lt;p&gt;merge does not like the restoration of RussianLowerCaseFilter or the move of PatternAnalyzer. Not really sure why not yet. I&apos;ll try and play with it tonight.&lt;/p&gt;</comment>
                    <comment id="12774787" author="mikemccand" created="Sun, 8 Nov 2009 16:03:57 +0000"  >&lt;p&gt;Yikes!  That sounds challenging.&lt;/p&gt;</comment>
                    <comment id="12774848" author="markrmiller@gmail.com" created="Mon, 9 Nov 2009 02:26:46 +0000"  >&lt;p&gt;Indeed - the merging has been quite challenging - its a bit unfair really - one of these days we will have to switch - I&apos;ll write the flexible indexing stuff, and you start doing the hard tasks &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;I&apos;ll commit the merge in a bit when the tests finish - might not get to the back compat branch if its needed till tomorrow night though.&lt;/p&gt;</comment>
                    <comment id="12774849" author="markrmiller@gmail.com" created="Mon, 9 Nov 2009 03:05:16 +0000"  >&lt;p&gt;I still get OOM&apos;s on the reopen test every so often. Many times I don&apos;t, then sometimes I do.&lt;/p&gt;</comment>
                    <comment id="12774933" author="mikemccand" created="Mon, 9 Nov 2009 10:46:48 +0000"  >&lt;blockquote&gt;&lt;p&gt;I&apos;ll write the flexible indexing stuff, and you start doing the hard tasks&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Don&apos;t you just have to press one button in your IDE? &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I still get OOM&apos;s on the reopen test every so often. Many times I don&apos;t, then sometimes I do.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Hmm... I&apos;ll try to dig.  This is with the standard codec, or, eg pulsing or intblock?&lt;/p&gt;</comment>
                    <comment id="12774957" author="markrmiller@gmail.com" created="Mon, 9 Nov 2009 13:15:28 +0000"  >&lt;blockquote&gt;&lt;p&gt;Don&apos;t you just have to press one button in your IDE? &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Ouch - thats like claiming all it takes to drive a porsche carrera gt is pushing the accelerator &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Hmm... I&apos;ll try to dig. This is with the standard codec, or, eg pulsing or intblock?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;m talking standard - sep and pulsing def blow up - they still need some work in that regard - but you have gotten standard pretty darn close - it usually doesn&apos;t blow - but sometimes it still seems to (I guess depending on random factors in the test). intblock is still cachless, so I don&apos;t think it ever blows.&lt;/p&gt;</comment>
                    <comment id="12775017" author="mikemccand" created="Mon, 9 Nov 2009 16:27:56 +0000"  >&lt;p&gt;I removed all the &quot;if (Codec.DEBUG)&quot; lines a local checkout and re-ran sortBench.py &amp;#8211; looks like flex is pretty close to trunk now (on OpenSolaris, Java 1.5, at least):&lt;/p&gt;

&lt;p&gt;JAVA:&lt;br/&gt;
java version &quot;1.5.0_19&quot;&lt;br/&gt;
Java(TM) 2 Runtime Environment, Standard Edition (build 1.5.0_19-b02)&lt;br/&gt;
Java HotSpot(TM) Server VM (build 1.5.0_19-b02, mixed mode)&lt;/p&gt;


&lt;p&gt;OS:&lt;br/&gt;
SunOS rhumba 5.11 snv_111b i86pc i386 i86pc Solaris&lt;/p&gt;

&lt;p&gt;Index /x/lucene/wiki.baseline.nd5M already exists...&lt;br/&gt;
Index /x/lucene/wiki.flex.nd5M already exists...&lt;/p&gt;



&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Query&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Deletes %&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Tot hits&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;QPS old&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;QPS new&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Pct change&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;body:&lt;span class=&quot;error&quot;&gt;&amp;#91;tec TO tet&amp;#93;&lt;/span&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1934684&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2.95&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4.04&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;36.9%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;body:&lt;span class=&quot;error&quot;&gt;&amp;#91;tec TO tet&amp;#93;&lt;/span&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1932754&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2.86&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;3.73&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;30.4%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;body:&lt;span class=&quot;error&quot;&gt;&amp;#91;tec TO tet&amp;#93;&lt;/span&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1915224&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2.88&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;3.69&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;28.1%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;body:&lt;span class=&quot;error&quot;&gt;&amp;#91;tec TO tet&amp;#93;&lt;/span&gt;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1741255&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2.86&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;3.74&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;30.8%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;real*&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;389378&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;26.85&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;28.74&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;7.0%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;real*&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;389005&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;25.83&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;26.96&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;4.4%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;real*&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;385434&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;25.55&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;27.15&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;6.3%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;real*&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;350404&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;25.38&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;28.10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;10.7%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1170209&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;21.75&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;21.80&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;0.2%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1169068&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;20.39&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;22.02&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;8.0%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1158528&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;20.35&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;21.88&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;7.5%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1053269&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;20.48&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;21.96&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;7.2%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1088727&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;23.37&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;23.42&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;0.2%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1087700&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;21.61&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;23.49&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;8.7%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1077788&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;21.85&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;23.46&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;7.4%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;980068&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;21.93&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;23.66&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;7.9%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1 +2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;700793&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;7.29&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;7.32&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;0.4%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1 +2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;700137&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;6.58&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;6.70&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;1.8%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1 +2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;693756&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;6.60&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;6.68&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;1.2%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1 +2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;630953&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;6.73&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;6.92&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;2.8%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1 -2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;469416&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;8.07&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;7.69&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-4.7%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1 -2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;468931&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;7.02&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;7.46&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;6.3%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1 -2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;464772&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;7.31&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;7.12&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-2.6%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1 -2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;422316&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;7.28&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;7.60&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;4.4%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1 2 3 -4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1104704&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4.83&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4.52&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-6.4%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1 2 3 -4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1103583&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4.73&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4.48&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-5.3%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1 2 3 -4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1093634&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4.75&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4.46&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-6.1%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1 2 3 -4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;994046&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4.87&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4.65&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-4.5%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;world economy&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;985&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;19.50&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;20.11&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;3.1%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;world economy&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;984&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;18.65&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;19.76&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;6.0%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;world economy&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;970&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;19.56&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;18.71&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;red&quot;&gt;-4.3%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;world economy&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;884&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;19.58&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;20.19&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;font color=&quot;green&quot;&gt;3.1%&lt;/font&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
</comment>
                    <comment id="12778364" author="markrmiller@gmail.com" created="Mon, 16 Nov 2009 14:51:02 +0000"  >&lt;p&gt;I&apos;ve got a big merge coming - after a recent merge I noticed a bunch of things didn&apos;t merge at all - so I started looking back and saw a few things that didn&apos;t merge properly previously as well. So I&apos;m working on a file by file line by line update that should be ready fairly soon.&lt;/p&gt;</comment>
                    <comment id="12778374" author="thetaphi" created="Mon, 16 Nov 2009 15:36:06 +0000"  >&lt;p&gt;If you are merging, you should simplky replace the old 2.9 BW branch by the new 3.0 one I recently created for trunk.&lt;/p&gt;</comment>
                    <comment id="12778393" author="markrmiller@gmail.com" created="Mon, 16 Nov 2009 16:59:35 +0000"  >&lt;p&gt;Simply ? &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; What about the part where I have to merge in the flexible indexing backward compat changes into the new branch after first figuring out what changes those are &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; Okay, its not unsimple, but this backward branch stuff is my least favorite part.&lt;/p&gt;</comment>
                    <comment id="12778548" author="markrmiller@gmail.com" created="Mon, 16 Nov 2009 21:25:51 +0000"  >&lt;p&gt;Merged up - I&apos;ve gotto say - that was a nasty one. I think things are more in sync then there were though.&lt;/p&gt;</comment>
                    <comment id="12778586" author="mikemccand" created="Mon, 16 Nov 2009 22:06:09 +0000"  >&lt;p&gt;Thanks Mark!  Hopefully, once 3.0 is out the door, the merging becomes a little less crazy.  I was dreading carrying this through 3.0 and I&apos;m very glad you stepped in &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="12780207" author="mikemccand" created="Thu, 19 Nov 2009 19:10:32 +0000"  >&lt;p&gt;I just committed a nice change on the flex branch: all term data in&lt;br/&gt;
DocumentsWriter&apos;s RAM buffer is now stored as UTF8 bytes.  Previously&lt;br/&gt;
they were stored as char.&lt;/p&gt;

&lt;p&gt;I think this is a good step forward:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Single-byte UTF8 characters (ascii, including terms created by&lt;br/&gt;
    NumericField) now take half the RAM, which should lead to faster&lt;br/&gt;
    indexing (better RAM efficiency so less frequent flushing)&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;I now use the 0xff byte marker to mark the end of the term, which&lt;br/&gt;
    never appears in UTF-8; this should mean 0xffff is allowed again&lt;br/&gt;
    (though we shouldn&apos;t advertise it)&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Merging &amp;amp; flushing should be a tad faster since the terms data now&lt;br/&gt;
    remains as UTF8 the whole time&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;TermsConsumer now takes a TermRef (previously it took a char[] +&lt;br/&gt;
offset), which makes it nicely symmetic with TermsEnum.&lt;/p&gt;

&lt;p&gt;Also I cleaned up the &quot;nocommit not reads&quot; &amp;#8211; thanks Mark!&lt;/p&gt;</comment>
                    <comment id="12781024" author="mikemccand" created="Sat, 21 Nov 2009 18:36:49 +0000"  >&lt;p&gt;I just committed changes to flex branch to make it possible for the&lt;br/&gt;
codec to override how merging happens.&lt;/p&gt;

&lt;p&gt;Basically I refactored SegmentMerger&apos;s postings merging code&lt;br/&gt;
(mergeTermInfos, appendPostings) onto Fields/Terms/Docs/PositionsConsumer,&lt;br/&gt;
so that the base class provides a default impl for merging at each&lt;br/&gt;
level but the codec can override if it wants.  This should make issues&lt;br/&gt;
like &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-2082&quot; title=&quot;Performance improvement for merging posting lists&quot;&gt;LUCENE-2082&lt;/a&gt; easy for a codec to implement.&lt;/p&gt;</comment>
                    <comment id="12781287" author="rcmuir" created="Mon, 23 Nov 2009 02:49:54 +0000"  >&lt;p&gt;edit: change supp char to &amp;lt;suppl. char&amp;gt; so erik can index this one too &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;Mike, this change to byte[] in TermRef will break backwards compatibility, without some special attention paid to the utf-16 to utf-8 conversion.&lt;/p&gt;

&lt;p&gt;imagine FuzzyQuery on a string starting with &amp;lt;suppl. char&amp;gt;, prefix of 1.&lt;br/&gt;
this will create a prefix of U+D866, which is an unpaired lead surrogate.&lt;br/&gt;
This is perfectly ok though, because we are not going to write it to UTF-8 form, it is just being used as an intermediary processing.&lt;br/&gt;
before, this would work just fine, because everything was an internal unicode string, so startsWith() would work just fine.&lt;/p&gt;

&lt;p&gt;now it will no longer work, because it must be downconverted to UTF-8 byte[]. &lt;br/&gt;
Whether you use getBytes() or UnicodeUtil, it will be replaced by U+FFFD, and the same code will not work.&lt;br/&gt;
the standard provides that this kind of processing is ok for internal unicode strings, see CH3 D89.&lt;/p&gt;</comment>
                    <comment id="12781289" author="rcmuir" created="Mon, 23 Nov 2009 02:58:30 +0000"  >&lt;p&gt;here is a workaround you will not like.&lt;br/&gt;
in the impl for FuzzyTermsEnum etc, we must not use TermRef.startsWith in its current state due to this issue, if the prefix ends with unpaired surrogate.&lt;br/&gt;
in this case the String must be materialized each time from TermRef for comparison.&lt;/p&gt;

&lt;p&gt;this is an example, where using byte[] will start to make things a bit complicated. It is not really a fault in TermRef, it is due to how the enums are currently implemented,&lt;br/&gt;
they will either need additional checks or we will need special unicode conversion so we can use things like TermRef.startsWith safely.&lt;/p&gt;

&lt;p&gt;edit: actually i do think now this is a fault in TermRef/TermsEnum api. how do i seek to U+D866 in the term dictionary? I can do this with trunk...&lt;br/&gt;
it is not possible with the flex branch, because you cannot represent this in UTF-8 byte[]&lt;/p&gt;</comment>
                    <comment id="12781296" author="rcmuir" created="Mon, 23 Nov 2009 04:08:21 +0000"  >&lt;p&gt;test that passes on trunk, fails on branch.&lt;/p&gt;</comment>
                    <comment id="12781353" author="mikemccand" created="Mon, 23 Nov 2009 09:59:28 +0000"  >&lt;blockquote&gt;&lt;p&gt;how do i seek to U+D866 in the term dictionary? I can do this with trunk...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;But, that&apos;s an unpaired surrogate?  Ie, not a valid unicode character?&lt;br/&gt;
It&apos;s nice that the current API let&apos;s you seek based on an unpaired&lt;br/&gt;
surrogate, but that&apos;s not valid use of the API, right?&lt;/p&gt;

&lt;p&gt;I guess if we want we can assert that the incoming TermRef is actually valid&lt;br/&gt;
unicode...&lt;/p&gt;</comment>
                    <comment id="12781364" author="rcmuir" created="Mon, 23 Nov 2009 11:11:55 +0000"  >&lt;p&gt;Michael, it is a valid unicode String though, this is ok, and such things are supported by the unicode standard.&lt;/p&gt;

&lt;p&gt;also, perhaps it would help convince you if i instead wrote the code as .terms(&quot;��&quot;.charAt(0));&lt;br/&gt;
previously, naive treatment of text like this would work correctly, now with byte it cannot.&lt;br/&gt;
I hope you can start to see how many east asian applications will break because of this.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.unicode.org/notes/tn12/&quot; class=&quot;external-link&quot;&gt;http://www.unicode.org/notes/tn12/&lt;/a&gt;&lt;/p&gt;</comment>
                    <comment id="12781367" author="rcmuir" created="Mon, 23 Nov 2009 11:28:08 +0000"  >&lt;p&gt;same test, coded in a slightly different way, to show how this can commonly happen.&lt;/p&gt;

&lt;p&gt;Michael, I urge you to reconsider this. Please read Ch2 and 3 of the unicode standard if you want to do this.&lt;br/&gt;
The problem is, this substring, it is a valid unicode String. it is true it cannot be converted into valid utf-8, but &lt;br/&gt;
its perfectly reasonable to use code units for internal processing like this, I am not attempting to write this data into the index or anything!&lt;/p&gt;

&lt;p&gt;I think data from TermRef for merging or writing to IndexWriter, is completely different from data being used to search!&lt;br/&gt;
I know you want an elegant encapsulation of both, but I think its a broken design.&lt;/p&gt;

&lt;p&gt;I don&apos;t just make this up to be annoying, i have applications that will break because of this.&lt;/p&gt;</comment>
                    <comment id="12781401" author="mikemccand" created="Mon, 23 Nov 2009 13:39:41 +0000"  >&lt;blockquote&gt;&lt;p&gt;perhaps it would help convince you if i instead wrote the code as .terms(&quot;��&quot;.charAt(0));&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I realize a java String can easily contain an unpaired surrogate (eg,&lt;br/&gt;
your test case) since it operates in code units not code points, but,&lt;br/&gt;
that&apos;s not valid unicode, right?&lt;/p&gt;

&lt;p&gt;I mean you can&apos;t in general send such a string off to a library that&lt;br/&gt;
works w/ unicode (like Lucene) and expect the behavior to be well&lt;br/&gt;
defined.  Yes, it&apos;s neat that Lucene allows that today, but I don&apos;t&lt;br/&gt;
see that it&apos;s &quot;supposed to&quot;.&lt;/p&gt;

&lt;p&gt;When we encounter an unpaired surrogate during indexing, we replace it&lt;br/&gt;
w/ the replacement char.  Why shouldn&apos;t we do the same when&lt;br/&gt;
searching/reading the index?&lt;/p&gt;

&lt;p&gt;What should we do during searching if the unpaired surrogate is inside&lt;br/&gt;
the string (not at the end)?  Why should that be different?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Please read Ch2 and 3 of the unicode standard if you want to do this.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Doesn&apos;t this apply here?  In &quot;3.2 Conformance&quot;&lt;br/&gt;
(&lt;a href=&quot;http://www.unicode.org/versions/Unicode5.0.0/ch03.pdf&quot; class=&quot;external-link&quot;&gt;http://www.unicode.org/versions/Unicode5.0.0/ch03.pdf&lt;/a&gt;) is this first&lt;br/&gt;
requirement (C1):&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;A process shall not interpret a high-surrogate code point or a&lt;br/&gt;
    low-surrogate code point as an abstract character.&lt;/li&gt;
&lt;/ul&gt;


&lt;blockquote&gt;&lt;p&gt;I hope you can start to see how many east asian applications will break because of this.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;But how would a search application based on an east asian language&lt;br/&gt;
actually create such a term?  In what situation would an unpaired&lt;br/&gt;
surrogate find its way down to TermEnum?&lt;/p&gt;

&lt;p&gt;Eg when users enter searches, they enter whole unicode chars (code&lt;br/&gt;
points) at once (not code units / unpaired surrogates)?  I realize an&lt;br/&gt;
app could programmatically construct eg a PrefixQuery that has an&lt;br/&gt;
unpaired surrogate... but couldn&apos;t they just as easily pair it up&lt;br/&gt;
before sending it to Lucene?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;i have applications that will break because of this.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;OK, can you shed some more light on how/when your apps do this?&lt;/p&gt;</comment>
                    <comment id="12781420" author="rcmuir" created="Mon, 23 Nov 2009 15:08:32 +0000"  >&lt;blockquote&gt;
&lt;p&gt;I realize a java String can easily contain an unpaired surrogate (eg,&lt;br/&gt;
your test case) since it operates in code units not code points, but,&lt;br/&gt;
that&apos;s not valid unicode, right?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;it is valid unicode. it is a valid &quot;Unicode String&quot;. This is different than a Term stored in the index, which will be stored as UTF-8, and thus purports to be in a valid unicode encoding form.&lt;/p&gt;

&lt;p&gt;However,&lt;br/&gt;
the conformance clauses do not prevent processes from operating on code&lt;br/&gt;
unit sequences that do not purport to be in a Unicode character encoding form.&lt;br/&gt;
For example, for performance reasons a low-level string operation may simply&lt;br/&gt;
operate directly on code units, without interpreting them as characters. See,&lt;br/&gt;
especially, the discussion under D89.&lt;/p&gt;

&lt;p&gt;D89:&lt;br/&gt;
Unicode strings need not contain well-formed code unit sequences under all conditions.&lt;br/&gt;
This is equivalent to saying that a particular Unicode string need not be in a Unicode&lt;br/&gt;
encoding form.&lt;br/&gt;
&#8226; For example, it is perfectly reasonable to talk about an operation that takes the&lt;br/&gt;
two Unicode 16-bit strings, &amp;lt;004D D800&amp;gt; and &amp;lt;DF02 004D&amp;gt;, each of which&lt;br/&gt;
contains an ill-formed UTF-16 code unit sequence, and concatenates them to&lt;br/&gt;
form another Unicode string &amp;lt;004D D800 DF02 004D&amp;gt;, which contains a wellformed&lt;br/&gt;
UTF-16 code unit sequence. The first two Unicode strings are not in&lt;br/&gt;
UTF-16, but the resultant Unicode string is.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;But how would a search application based on an east asian language&lt;br/&gt;
actually create such a term? In what situation would an unpaired&lt;br/&gt;
surrogate find its way down to TermEnum?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I gave an example already, where they use FuzzyQuery with say a prefix of one. &lt;br/&gt;
with the current code, even in the flex branch!!! this will create a lead surrogate prefix.&lt;br/&gt;
There is code in the lucene core that does things like this (which I plan to fix, and also try to preserve back compat!)&lt;br/&gt;
This makes it impossible to preserve back compat.&lt;/p&gt;

&lt;p&gt;There is also probably a lot of non-lucene east asian code that does similar things.&lt;br/&gt;
For example, someone with data from Hong Kong almost certainly encounters suppl. characters, because&lt;br/&gt;
they are part of Big5-HKSCS. They may not be smart enough to know about this situation, i.e. they might take a string, substring(0, 1) and do a prefix query.&lt;br/&gt;
right now this will work!&lt;/p&gt;

&lt;p&gt;This is part of the idea that for most operations (such as prefix), in java, supplementary characters work rather transparently.&lt;br/&gt;
If we do this, upgrading lucene to support for unicode 4.0 will be significantly more difficult.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;OK, can you shed some more light on how/when your apps do this?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes, see &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1606&quot; title=&quot;Automaton Query/Filter (scalable regex)&quot;&gt;&lt;del&gt;LUCENE-1606&lt;/del&gt;&lt;/a&gt;. This library uses UTF-16 intervals for transitions, which works fine because for its matching purposes, this is transparent.&lt;br/&gt;
So there is no need for it to be aware of suppl. characters. If we make this change, I will need to refactor/rewrite a lot of this code, most likely the underlying DFA library itself.&lt;br/&gt;
This is working in production for me, on chinese text outside of the BMP with lucene right now. With this change, it will no longer work, and the enumerator will most likely go into an infinite loop!&lt;/p&gt;

&lt;p&gt;The main difference here is semantics, before IndexReader.terms() accepted as input any Unicode String. Now it would tighten that restriction to only any interchangeable UTF-8 string. Yet the input being used, will not be stored as UTF-8 anywhere, and most certainly will not be interchanged! The paper i sent on UTF-16 mentions problems like this, because its very reasonable and handy to use code units for processing, since suppl. characters are so rare.&lt;/p&gt;</comment>
                    <comment id="12781545" author="rcmuir" created="Mon, 23 Nov 2009 19:03:58 +0000"  >&lt;p&gt;attached is a patch that provides a workaround for the back compat issue.&lt;br/&gt;
in my opinion it does not hurt performance (though, you should optimize this)&lt;br/&gt;
when opening a TermEnum with IndexReader.terms(Term), the deprecated API, &lt;br/&gt;
in LegacyTermEnum(Term t), if the term ends with a lead surrogate, tack on \uDC00 to emulate the old behavior.&lt;/p&gt;

&lt;p&gt;with this patch, my testcase passes.&lt;/p&gt;

&lt;p&gt;we might be able to workaround these issues in similar ways for better backwards compatibility, at the same time preserving performance.&lt;br/&gt;
I think we should mention somewhere in the docs that the new api behaves a bit differently though, so people know to fix their code.&lt;/p&gt;</comment>
                    <comment id="12781582" author="mikemccand" created="Mon, 23 Nov 2009 19:45:27 +0000"  >&lt;blockquote&gt;&lt;p&gt;if the term ends with a lead surrogate, tack on \uDC00 to emulate the old behavior.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;OK I think this is a good approach, in the &quot;emulate old on flex&quot; layer, and then in the docs for TermRef call out that the incoming String cannot contain unpaired surrogates?&lt;/p&gt;

&lt;p&gt;Can you commit this, along with your test? Thanks!&lt;/p&gt;</comment>
                    <comment id="12781589" author="rcmuir" created="Mon, 23 Nov 2009 19:58:52 +0000"  >&lt;blockquote&gt;&lt;p&gt;OK I think this is a good approach, in the &quot;emulate old on flex&quot; layer, and then in the docs for TermRef call out that the incoming String cannot contain unpaired surrogates?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Just so you know, its not perfect back compat though. &lt;br/&gt;
For perfect back compat I would have to iterate thru the string looking for unpaired surrogates.. at which point you truncate after, and tack on \uDC00 if its a high surrogate.&lt;br/&gt;
If its an unpaired low surrogate, I am not actually sure what the old API would do? My guess would be to replace with U+F000, but it depends how this was being handled before.&lt;/p&gt;

&lt;p&gt;the joys of UTF-16 vs UTF-8 binary order...&lt;/p&gt;

&lt;p&gt;I didnt do any of this, because in my opinion fixing just the &quot;trailing lead surrogate&quot; case is all we should worry about, especially since the lucene core itself does this.&lt;/p&gt;

&lt;p&gt;I&apos;ll commit the patch and test, we can improve it in the future if you are worried about these corner-corner-corner cases, no problem.&lt;/p&gt;</comment>
                    <comment id="12781603" author="rcmuir" created="Mon, 23 Nov 2009 20:29:07 +0000"  >&lt;p&gt;the patch and test are in revision 883485.&lt;br/&gt;
I added some javadocs to TermRef where it takes a String constructor as well.&lt;/p&gt;</comment>
                    <comment id="12781617" author="rcmuir" created="Mon, 23 Nov 2009 21:06:18 +0000"  >&lt;p&gt;Mike, what to do about MultiTermQueries now?&lt;br/&gt;
they still have some problems, especially with regards to doing &apos;startsWith&apos; some constant prefix, which might be unpaired lead surrogate (lucene problem)&lt;/p&gt;

&lt;p&gt;I guess we need to specialize this case in their FilteredTermEnum (not TermsEnum), and if they are doing this stupid behavior, return null from getTermsEnum() ?&lt;br/&gt;
and force it to the old TermEnum which has some back compat shims for this case?&lt;/p&gt;</comment>
                    <comment id="12781624" author="rcmuir" created="Mon, 23 Nov 2009 21:15:03 +0000"  >&lt;p&gt;Also, I am curious in general if we support any old index formats that might contain unpaired surrogates or \uFFFF in the term text.&lt;/p&gt;

&lt;p&gt;This will be good to know when trying to fix unicode 4 issues, especially if we are doing things like compareTo() or startsWith() on the raw bytes.&lt;/p&gt;</comment>
                    <comment id="12781635" author="mikemccand" created="Mon, 23 Nov 2009 21:30:00 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-510&quot; title=&quot;IndexOutput.writeString() should write length in bytes&quot;&gt;&lt;del&gt;LUCENE-510&lt;/del&gt;&lt;/a&gt; (fixed in 2.4 release) cutover new indexes to UTF8.&lt;/p&gt;

&lt;p&gt;Before 2.4, here&apos;s what IndexOutput.writeString looked like:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void writeChars(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; s, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; start, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; length)
       &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
    &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; end = start + length;
    &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; i = start; i &amp;lt; end; i++) {
      &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; code = (&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;)s.charAt(i);
      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (code &amp;gt;= 0x01 &amp;amp;&amp;amp; code &amp;lt;= 0x7F)
	writeByte((&lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;)code);
      &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (((code &amp;gt;= 0x80) &amp;amp;&amp;amp; (code &amp;lt;= 0x7FF)) || code == 0) {
	writeByte((&lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;)(0xC0 | (code &amp;gt;&amp;gt; 6)));
	writeByte((&lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;)(0x80 | (code &amp;amp; 0x3F)));
      } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
	writeByte((&lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;)(0xE0 | (code &amp;gt;&amp;gt;&amp;gt; 12)));
	writeByte((&lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;)(0x80 | ((code &amp;gt;&amp;gt; 6) &amp;amp; 0x3F)));
	writeByte((&lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;)(0x80 | (code &amp;amp; 0x3F)));
      }
    }
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;which I think can represent unpaired surrogates &amp;amp; \uFFFF just fine?&lt;/p&gt;</comment>
                    <comment id="12781636" author="yseeley@gmail.com" created="Mon, 23 Nov 2009 21:30:02 +0000"  >&lt;p&gt;In general, I think things like unpaired surrogates should be undefined, giving us more room to optimize.&lt;/p&gt;</comment>
                    <comment id="12781638" author="mikemccand" created="Mon, 23 Nov 2009 21:35:34 +0000"  >&lt;p&gt;Also, on the flex branch I believe \uFFFF is no longer &quot;reserved&quot; by Lucene, but we should not advertise that!  Terms data is stored in DocumentsWriter as UTF8 bytes, and I use 0xff byte (an invalid UTF8 byte) as end marker.&lt;/p&gt;</comment>
                    <comment id="12781677" author="mikemccand" created="Mon, 23 Nov 2009 22:29:35 +0000"  >&lt;blockquote&gt;
&lt;p&gt;the patch and test are in revision 883485.&lt;br/&gt;
I added some javadocs to TermRef where it takes a String constructor as well.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Thanks Robert!&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Mike, what to do about MultiTermQueries now?&lt;br/&gt;
they still have some problems, especially with regards to doing &apos;startsWith&apos; some constant prefix, which might be unpaired lead surrogate (lucene problem)&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Maybe open a new issue for this?  Or, don&apos;t we already have an issue open to fix how various queries handle surrogates?  Or I guess we could fix such queries to pair up the surrogate (add \uDC00)?&lt;/p&gt;</comment>
                    <comment id="12781683" author="rcmuir" created="Mon, 23 Nov 2009 22:53:09 +0000"  >&lt;blockquote&gt;&lt;p&gt;In general, I think things like unpaired surrogates should be undefined, giving us more room to optimize. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This is not an option I feel, when Lucene is the one creating the problem (i.e. our multitermqueries that are unaware of utf-32 boundaries).&lt;/p&gt;</comment>
                    <comment id="12781689" author="rcmuir" created="Mon, 23 Nov 2009 22:56:23 +0000"  >&lt;blockquote&gt;&lt;p&gt;Maybe open a new issue for this? Or, don&apos;t we already have an issue open to fix how various queries handle surrogates? Or I guess we could fix such queries to pair up the surrogate (add \uDC00)?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Mike, I have an issue open, for trunk. But it is not such a problem on trunk, because they work &quot;as expected&quot; in UTF-16 space&lt;br/&gt;
The move to byte[] creates the problem really, because then the existing problems in trunk, that happened to work, start to completely fail in UTF-8 space.&lt;br/&gt;
and unfortunately, we can&apos;t use the \uDC00 trick for startsWith &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="12781713" author="mikemccand" created="Tue, 24 Nov 2009 00:21:19 +0000"  >&lt;p&gt;Well, for starters can&apos;t we just toString() the TermRef on every compare?  Then we&apos;re back in UTF16 space.&lt;/p&gt;

&lt;p&gt;It&apos;s not as good as flex can be (ie doing the checks in UTF8 space), but it should still be faster than trunk today, so this shouldn&apos;t block flex landing, right?&lt;/p&gt;</comment>
                    <comment id="12781717" author="rcmuir" created="Tue, 24 Nov 2009 00:44:11 +0000"  >&lt;p&gt;this one is more serious.&lt;br/&gt;
the change to byte[] changes the sort order of lucene (at least TermEnum)&lt;/p&gt;

&lt;p&gt;attached is a test that passes on trunk, fails on branch.&lt;br/&gt;
in trunk, things sort in UTF-16 binary order.&lt;br/&gt;
in branch, things sort in UTF-8 binary order.&lt;br/&gt;
these are different...&lt;/p&gt;</comment>
                    <comment id="12781720" author="rcmuir" created="Tue, 24 Nov 2009 00:55:18 +0000"  >&lt;p&gt;Mike, if it means anything, I prefer the new behavior... real codepoint order &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
But this is a compat problem I think.&lt;/p&gt;</comment>
                    <comment id="12781859" author="mikemccand" created="Tue, 24 Nov 2009 10:38:06 +0000"  >&lt;blockquote&gt;
&lt;p&gt;in trunk, things sort in UTF-16 binary order.&lt;br/&gt;
in branch, things sort in UTF-8 binary order.&lt;br/&gt;
these are different...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Ugh!  In the back of my mind I almost remembered this... I think this&lt;br/&gt;
was one reason why I didn&apos;t do this back in &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-843&quot; title=&quot;improve how IndexWriter uses RAM to buffer added documents&quot;&gt;&lt;del&gt;LUCENE-843&lt;/del&gt;&lt;/a&gt; (I think we had&lt;br/&gt;
discussed this already, then... though maybe I&apos;m suffering from d&#233;j&#224;&lt;br/&gt;
vu).  I could swear at one point I had that fixup logic implemented in&lt;br/&gt;
a UTF-8/16 comparison method...&lt;/p&gt;

&lt;p&gt;UTF-8 sort order (what flex branch has switched to) is true unicode&lt;br/&gt;
codepoint sort order, while UTF-16 is not when there are surrogate&lt;br/&gt;
pairs as well as high (&amp;gt;= U+E000) unicode chars.  Sigh....&lt;/p&gt;

&lt;p&gt;So this is definitely a back compat problem.  And, unfortunately, even&lt;br/&gt;
if we like the true codepoint sort order, it&apos;s not easy to switch to&lt;br/&gt;
in a back-compat manner because if we write new segments into an old&lt;br/&gt;
index, SegmentMerger will be in big trouble when it tries to merge two&lt;br/&gt;
segments that had sorted the terms differently.&lt;/p&gt;

&lt;p&gt;I would also prefer true codepoint sort order... but we can&apos;t break&lt;br/&gt;
back compat.&lt;/p&gt;

&lt;p&gt;Though it would be nice to let the codec control the sort order &amp;#8211; eg&lt;br/&gt;
then (I think?) the ICU/CollationKeyFilter workaround wouldn&apos;t be&lt;br/&gt;
needed.&lt;/p&gt;

&lt;p&gt;Fortunately the problem is isolated to how we sort the buffered&lt;br/&gt;
postings when it&apos;s time to flush a new segment, so I think w/ the&lt;br/&gt;
appropriate fixup logic (eg your comment at&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1606?focusedCommentId=12781746&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#action_12781746&quot; class=&quot;external-link&quot;&gt;https://issues.apache.org/jira/browse/LUCENE-1606?focusedCommentId=12781746&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#action_12781746&lt;/a&gt;)&lt;br/&gt;
when comparing terms in oal.index.TermsHashPerField.comparePostings&lt;br/&gt;
during that sort, we can get back to UTF-16 sort order.&lt;/p&gt;</comment>
                    <comment id="12781874" author="rcmuir" created="Tue, 24 Nov 2009 11:22:01 +0000"  >&lt;blockquote&gt;
&lt;p&gt;Though it would be nice to let the codec control the sort order - eg&lt;br/&gt;
then (I think?) the ICU/CollationKeyFilter workaround wouldn&apos;t be&lt;br/&gt;
needed.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I like this idea by the way, &quot;flexible sorting&quot;.  although i like codepoint order better than code unit order, i hate binary order in general to be honest. &lt;/p&gt;

&lt;p&gt;its nice we have &apos;indexable&apos;/fast collation right now, but its maybe not what users expect either (binary keys encoded into text).&lt;/p&gt;</comment>
                    <comment id="12781899" author="mikemccand" created="Tue, 24 Nov 2009 13:02:51 +0000"  >&lt;blockquote&gt;&lt;p&gt;i hate binary order in general to be honest.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;But binary order in this case is code point order.&lt;/p&gt;</comment>
                    <comment id="12781904" author="rcmuir" created="Tue, 24 Nov 2009 13:15:42 +0000"  >&lt;p&gt;Mike, I guess I mean i&apos;d prefer UCA order, which isn&apos;t just the order codepoints happened to randomly appear on charts, but is actually designed for sorting and ordering things &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="12781917" author="mikemccand" created="Tue, 24 Nov 2009 13:33:57 +0000"  >&lt;blockquote&gt;&lt;p&gt;Mike, I guess I mean i&apos;d prefer UCA order, which isn&apos;t just the order codepoints happened to randomly appear on charts, but is actually designed for sorting and ordering things &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Ahh, gotchya.  Well if we make the sort order pluggable, you could do that...&lt;/p&gt;</comment>
                    <comment id="12781923" author="rcmuir" created="Tue, 24 Nov 2009 13:39:58 +0000"  >&lt;blockquote&gt;&lt;p&gt;Ahh, gotchya. Well if we make the sort order pluggable, you could do that...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;yes, then we could consider getting rid of the Collator/Locale-based range queries / sorts and things like that completely... which have performance problems.&lt;br/&gt;
you would have a better way to do it... &lt;/p&gt;

&lt;p&gt;but if you change the sort order, any part of lucene sensitive to it might break... maybe its dangerous.&lt;/p&gt;

&lt;p&gt;maybe if we do it, it needs to be exposed properly so other components can change their behavior&lt;/p&gt;</comment>
                    <comment id="12781927" author="mikemccand" created="Tue, 24 Nov 2009 13:43:56 +0000"  >&lt;p&gt;Yes, this (customizing comparator for termrefs) would definitely be very advanced stuff...  you&apos;d have to create your own codec to do it.  And we&apos;d default to UTF16 sort order for back compat.&lt;/p&gt;</comment>
                    <comment id="12781935" author="rcmuir" created="Tue, 24 Nov 2009 13:56:59 +0000"  >&lt;blockquote&gt;&lt;p&gt;Yes, this (customizing comparator for termrefs) would definitely be very advanced stuff... you&apos;d have to create your own codec to do it. And we&apos;d default to UTF16 sort order for back compat.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Agreed, changing the sort order breaks a lot of things (not just some crazy seeking around code that I write)&lt;/p&gt;

&lt;p&gt;i.e. if &apos;ch&apos; is a character in some collator and sorts b, before c (completely made up example, there are real ones like this though)&lt;br/&gt;
Then even prefixquery itself will fail!&lt;/p&gt;

&lt;p&gt;edit: better example is french collation, where the weight of accent marks is done in reverse order. &lt;br/&gt;
prefix query would make assumptions based on the prefix, which are wrong.&lt;/p&gt;</comment>
                    <comment id="12781938" author="thetaphi" created="Tue, 24 Nov 2009 14:00:40 +0000"  >&lt;p&gt;...not to talk about TermRangeQueries and NumericRangeQueries. They rely on String.compareTo like the current terms dict.&lt;/p&gt;</comment>
                    <comment id="12781947" author="dmsmith" created="Tue, 24 Nov 2009 14:21:16 +0000"  >&lt;blockquote&gt;&lt;p&gt;Yes, this (customizing comparator for termrefs) would definitely be very advanced stuff... you&apos;d have to create your own codec to do it. And we&apos;d default to UTF16 sort order for back compat.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;For those of us working on texts in all different kinds of languages, it should not be very advanced stuff. It should be stock Lucene. A default UCA comparator would be good. And a way to provide a locale sensitive UCA comparator would also be good.&lt;/p&gt;

&lt;p&gt;My use case is that each Lucene index typically has a single language or at least has a dominant language.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;...not to talk about TermRangeQueries and NumericRangeQueries. They rely on String.compareTo like the current terms dict.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I think that String.compareTo works correctly on UCA collation keys.&lt;/p&gt;</comment>
                    <comment id="12781953" author="rcmuir" created="Tue, 24 Nov 2009 14:32:46 +0000"  >&lt;blockquote&gt;&lt;p&gt;I think that String.compareTo works correctly on UCA collation keys.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;No, because UCA collation keys are bytes &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
You are right that byte comparison on these keys works though.&lt;br/&gt;
But if we change the sort order like this, various components are not looking at keys, instead they are looking at the term text themselves.&lt;/p&gt;

&lt;p&gt;I guess what I am saying is that there is a lot of assumptions in lucene right now, (prefixquery was my example) that look at term text and assume it is sorted in binary order.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;It should be stock Lucene&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;as much as I agree with you that default UCA should be &quot;stock lucene&quot; (with the capability to use an alternate locale or even tailored collator), this creates some practical problems, as mentioned above.&lt;br/&gt;
also the practical problem that collation in the JDK is poop and we would want ICU for good performance...&lt;/p&gt;</comment>
                    <comment id="12782015" author="rcmuir" created="Tue, 24 Nov 2009 16:36:21 +0000"  >&lt;blockquote&gt;
&lt;p&gt;So this is definitely a back compat problem. And, unfortunately, even&lt;br/&gt;
if we like the true codepoint sort order, it&apos;s not easy to switch to&lt;br/&gt;
in a back-compat manner because if we write new segments into an old&lt;br/&gt;
index, SegmentMerger will be in big trouble when it tries to merge two&lt;br/&gt;
segments that had sorted the terms differently.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Mike, I think it goes well beyond this. &lt;br/&gt;
I think sort order is an exceptional low-level case that can trickle all the way up high into the application layer (including user perception itself), and create bugs.&lt;br/&gt;
Does a non-technical user in Hong Kong know how many code units each ideograph they enter are? &lt;br/&gt;
Should they care? They will just not understand if things are in different order.&lt;/p&gt;

&lt;p&gt;I think we are stuck with UTF-16 without a huge effort, which would not be worth it in any case.&lt;/p&gt;</comment>
                    <comment id="12783471" author="mikemccand" created="Sun, 29 Nov 2009 20:39:04 +0000"  >&lt;p&gt;OK I finally worked out a solution for the UTF16 sort order problem&lt;br/&gt;
(just committed).&lt;/p&gt;

&lt;p&gt;I added a TermRef.Comparator class, for comparing TermRefs, and I&lt;br/&gt;
removed TermRef.compareTo, and fixed all low-level places in Lucene&lt;br/&gt;
that rely on sort order of terms to use this new API instead.&lt;/p&gt;

&lt;p&gt;I changed the Terms/TermsEnum/TermsConsumer API, adding a&lt;br/&gt;
getTermComparator(), ie, the codec now determines the sort order for&lt;br/&gt;
terms in each field.  For the core codecs (standard, pulsing,&lt;br/&gt;
intblock) I default to UTF16 sort order, for back compat, but you&lt;br/&gt;
could easily instantiate it yourself and use a different term sort.&lt;/p&gt;

&lt;p&gt;I changed TestExternalCodecs to test this new capability, by sorting 2&lt;br/&gt;
of its fields in reversed unicode code point order.&lt;/p&gt;

&lt;p&gt;While this means your codec is now completely free to define the&lt;br/&gt;
term sort order per field, in general Lucene queries will not behave&lt;br/&gt;
right if you do this, so it&apos;s obviously a very advanced use case.&lt;/p&gt;

&lt;p&gt;I also changed (yet again!) how DocumentsWriter encodes the terms&lt;br/&gt;
bytes, to record the length (in bytes) of the term, up front, followed by the&lt;br/&gt;
term bytes (vs the trailing 0xff that I had switched to).  The length&lt;br/&gt;
is a 1 or 2 byte vInt, ie if it&apos;s &amp;lt; 128 it&apos;s 1 byte, else 2 bytes.&lt;br/&gt;
This approach means the TermRef.Collector doesn&apos;t have to deal with&lt;br/&gt;
0xff&apos;s (which was messy).&lt;/p&gt;

&lt;p&gt;I think this also means that, to the flex API, a term is actually&lt;br/&gt;
opaque &amp;#8211; it&apos;s just a series of bytes.  It need not be UTF8 bytes.&lt;br/&gt;
However, all of analysis, and then how TermsHash builds up these&lt;br/&gt;
byte[]s, and what queries do with these bytes, is clearly still very&lt;br/&gt;
much Unicode/UTF8.  But one could, in theory (I haven&apos;t tested this!)&lt;br/&gt;
separately use the flex API to build up a segment whose terms are&lt;br/&gt;
arbitrary byte[]&apos;s, eg maybe you want to use 4 bytes to encode int&lt;br/&gt;
values, and then interact with those terms at search time&lt;br/&gt;
using the flex API.&lt;/p&gt;</comment>
                    <comment id="12783475" author="thetaphi" created="Sun, 29 Nov 2009 21:20:05 +0000"  >&lt;p&gt;Hi Mike,&lt;/p&gt;

&lt;p&gt;I looked into your commit, looks good. You are right with your comment in NRQ, it will only work with UTF-8 or UTF-16. Ideally NRQ would simply not use string terms at all and work directly on the byte[], which should then be ordered in binary order.&lt;/p&gt;

&lt;p&gt;Two things:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;The legacy NumericRangeTermEnum can be removed completely and the protected getEnum() should simply throw UOE. NRQ cannot be subclassed and nobody can call this method (maybe only classes in same package, but thats not supported). So the enum with the nocommit mark can be removed&lt;/li&gt;
	&lt;li&gt;I changed the logic in the TermEnum in trunk and 3.0 (it no longer works recursive, see &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-2087&quot; title=&quot;Remove recursion in NumericRangeTermEnum&quot;&gt;&lt;del&gt;LUCENE-2087&lt;/del&gt;&lt;/a&gt;). We  should change this here, too. This makes also the enum simplier (and it looks more like the Automaton one). The methods in trunk 3.0 setEnum() and endEnum() both throw now UOE.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I will look into these two changes tomorrow and change the code.&lt;/p&gt;

&lt;p&gt;Uwe&lt;/p&gt;</comment>
                    <comment id="12783481" author="rcmuir" created="Sun, 29 Nov 2009 21:29:53 +0000"  >&lt;blockquote&gt;&lt;p&gt;Ideally NRQ would simply not use string terms at all and work directly on the byte[], which should then be ordered in binary order.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;but isn&apos;t this what it does already with the TermsEnum api? the TermRef itself is just byte[], and NRQ precomputes all the TermRef&apos;s it needs up front, there is no unicode conversion there.&lt;/p&gt;

&lt;p&gt;edit: btw Uwe, and the comparator is be essentially just comparing bytes, the 0xee/0xef &quot;shifting&quot; should never take place with NRQ because those bytes will never be in a numeric field...&lt;/p&gt;</comment>
                    <comment id="12783482" author="thetaphi" created="Sun, 29 Nov 2009 21:39:02 +0000"  >&lt;p&gt;Robert: I know, because of that I said it works with UTF-8/UTF-16 comparator. It would &lt;b&gt;not&lt;/b&gt; work with a reverse comparator as Mike uses in the test.&lt;/p&gt;

&lt;p&gt;With directly on bytes[] I meant that it could not use chars at all and directly encode the numbers into byte[] with the full 8 bits per byte. The resulting byte[] would be never UTF-8, but if the new TermRef API would be able to handle this and also the TokenStreams, it would be fine. Only the terms format would change.&lt;/p&gt;</comment>
                    <comment id="12783485" author="rcmuir" created="Sun, 29 Nov 2009 22:04:50 +0000"  >&lt;blockquote&gt;&lt;p&gt;With directly on bytes[] I meant that it could not use chars at all and directly encode the numbers into byte[] with the full 8 bits per byte. The resulting byte[] would be never UTF-8, but if the new TermRef API would be able to handle this and also the TokenStreams, it would be fine. Only the terms format would change.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Uwe, it looks like you can do this now (with the exception of tokenstreams). &lt;/p&gt;

&lt;p&gt;A partial solution for you which does work with tokenstreams, you could use indexablebinarystring which won&apos;t change between any unicode sort order... (it will not encode in any unicode range where there is a difference between the UTF-8/UTF32 and UTF-16). With this you could just compare bytes also, but you still would not have the &quot;full 8 bits per byte&quot;&lt;/p&gt;</comment>
                    <comment id="12783488" author="thetaphi" created="Sun, 29 Nov 2009 22:15:04 +0000"  >&lt;blockquote&gt;&lt;p&gt;A partial solution for you which does work with tokenstreams, you could use indexablebinarystring which won&apos;t change between any unicode sort order... (it will not encode in any unicode range where there is a difference between the UTF-8/UTF32 and UTF-16). With this you could just compare bytes also, but you still would not have the &quot;full 8 bits per byte&quot;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This would not change anything, only would make the format incompatible. With 7bits/char the currently UTF-8 coded index is the smallest possible one (even IndexableBinaryString would cost more bytes in the index, because if you would use 14 of the 16 bits/char, most chars would take 3 bytes in index because of UTF-8 vs. 2 bytes with the current encoding. Only the char[]/String representation would take less space than currently. See the discussion with Yonik about this and why we have choosen 7 bits/char. Also en-/decoding is much faster).&lt;/p&gt;

&lt;p&gt;For the TokenStreams: The idea is to create an additional Attribute: BinaryTermAttribute that holds byte[]. If some tokenstream uses this attribute instead of TermAttribute, the indexer would choose to write the bytes directly to the index. NumericTokenStream could use this attribute and encode the numbers directly to byte[] with 8 bits/byte. &amp;#8211; the new AttributeSource API was created just because of such customizations (not possible with Token).&lt;/p&gt;</comment>
                    <comment id="12783489" author="rcmuir" created="Sun, 29 Nov 2009 22:17:53 +0000"  >&lt;p&gt;Uwe you are right that the terms would be larger but they would have a more distinct alphabet (byte range) and might compare faster... I don&apos;t know which one is most important to NRQ really.&lt;/p&gt;

&lt;p&gt;yeah I agree that encoding directly to byte[] is the way to go though, this would be nice for collation too...&lt;/p&gt;</comment>
                    <comment id="12783490" author="thetaphi" created="Sun, 29 Nov 2009 22:18:53 +0000"  >&lt;p&gt;As the codec is per field, we could also add an Attribute to TokenStream that holds the codec (the default is Standard). The indexer just uses the codec for the field from the TokenStream. NTS would use a NumericCodec (just thinking...) - will go sleeping now.&lt;/p&gt;</comment>
                    <comment id="12783491" author="thetaphi" created="Sun, 29 Nov 2009 22:23:29 +0000"  >&lt;blockquote&gt;&lt;p&gt;Uwe you are right that the terms would be larger but they would have a more distinct alphabet (byte range) and might compare faster... I don&apos;t know which one is most important to NRQ really. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The new TermsEnum directly compares the byte[] arrays. Why should they compare faster when encoded by IndexableBinaryStringTools? Less bytes are faster to compare (it&apos;s one CPU instruction if optimized a very native x86/x64 loop). It may be faster if we need to decode to char[] but thats not the case (in flex branch).&lt;/p&gt;</comment>
                    <comment id="12783492" author="mikemccand" created="Sun, 29 Nov 2009 22:27:53 +0000"  >&lt;blockquote&gt;&lt;p&gt;I changed the logic in the TermEnum in trunk and 3.0 (it no longer works recursive, see &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-2087&quot; title=&quot;Remove recursion in NumericRangeTermEnum&quot;&gt;&lt;del&gt;LUCENE-2087&lt;/del&gt;&lt;/a&gt;). We should change this here, too.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Mark has been periodically re-syncing changes down from trunk... we should probably just let this change come in through his process (else I think we cause more conflicts).&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The legacy NumericRangeTermEnum can be removed completely and the protected getEnum() should simply throw UOE. NRQ cannot be subclassed and nobody can call this method (maybe only classes in same package, but thats not supported). So the enum with the nocommit mark can be removed&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Ahh excellent.  Wanna commit that when you get a chance?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Ideally NRQ would simply not use string terms at all and work directly on the byte[], which should then be ordered in binary order.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That&apos;d be great!&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;With directly on bytes[] I meant that it could not use chars at all and directly encode the numbers into byte[] with the full 8 bits per byte. The resulting byte[] would be never UTF-8, but if the new TermRef API would be able to handle this and also the TokenStreams, it would be fine. Only the terms format would change.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Right, this is a change in analysis -&amp;gt; DocumentsWriter &amp;#8211; somehow we have to allow a Token to carry a byte[] and that is directly indexes as the opaque term.  At search time NRQ is all byte[] already (unlike other queries, which are new String()&apos;ing for every term on the enum).&lt;/p&gt;</comment>
                    <comment id="12783493" author="rcmuir" created="Sun, 29 Nov 2009 22:28:22 +0000"  >&lt;blockquote&gt;&lt;p&gt;Why should they compare faster when encoded by IndexableBinaryStringTools?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;because it compares from left to right, so even if the terms are 10x as long, if they differ 2x as quick its better? &lt;/p&gt;

&lt;p&gt;I hear what you are saying about ASCII-only encoding, but if NRQ&apos;s model is always best, why do we have two separate &quot;encode byte[] into char[]&quot; models in lucene, one that NRQ is using, and one that collation is using!?&lt;/p&gt;</comment>
                    <comment id="12783494" author="mikemccand" created="Sun, 29 Nov 2009 22:30:11 +0000"  >&lt;blockquote&gt;&lt;p&gt;The idea is to create an additional Attribute: BinaryTermAttribute that holds byte[]. If some tokenstream uses this attribute instead of TermAttribute, the indexer would choose to write the bytes directly to the index. NumericTokenStream could use this attribute and encode the numbers directly to byte[] with 8 bits/byte. - the new AttributeSource API was created just because of such customizations (not possible with Token).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This sounds like an interesting approach!  We&apos;d have to work out some details... eg you presumably can&apos;t mix char[] term and byte[] term in the same field.&lt;/p&gt;</comment>
                    <comment id="12783496" author="thetaphi" created="Sun, 29 Nov 2009 22:39:48 +0000"  >&lt;blockquote&gt;&lt;p&gt;because it compares from left to right, so even if the terms are 10x as long, if they differ 2x as quick its better? &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;It would not compare faster because in UTF-8 encoding, only 7 bits are used for encoding the chars. The 8th bit is just a marker (simply spoken). If this marker is always 0 or always 1 does not make a difference, in UTF-8 only 7 bits/byte are used for data. And with UTF-8 in the 3rd byte more bits are unused!&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I hear what you are saying about ASCII-only encoding, but if NRQ&apos;s model is always best, why do we have two separate &quot;encode byte[] into char[]&quot; models in lucene, one that NRQ is using, and one that collation is using!?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I do not know who made this IndexableBinaryStrings encoding, but it would not work for NRQ at all with current trunk (too complicated during indexing and decoding, because for NRQ, we also need to decode such char[] very fast for populating the FieldCache). But as discussed with Yonik (do not know the issue), the ASCII only encoding should always perform better (but needs more memory in trunk, as char[] is used during indexing &amp;#8211; I think because of that it was added). So the difference is not speed, its memory consumption.&lt;/p&gt;</comment>
                    <comment id="12783499" author="rcmuir" created="Sun, 29 Nov 2009 23:04:12 +0000"  >&lt;blockquote&gt;&lt;p&gt;It would not compare faster because in UTF-8 encoding, only 7 bits are used for encoding the chars&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;yeah you are right I dont think it will be faster on average (i was just posing the question because i dont really know NRQ), and you will waste 4 bits by using the first bit at the minimum.&lt;/p&gt;

&lt;p&gt;i am just always trying to improve collation too, so that&apos;s why I am bugging you. I guess hopefully soon we have byte[] and can do it properly, and speed up both.&lt;/p&gt;</comment>
                    <comment id="12783509" author="rcmuir" created="Mon, 30 Nov 2009 00:28:36 +0000"  >&lt;p&gt;fwiw here is a patch to use the algorithm from the unicode std for utf8 in utf16 sort order.&lt;br/&gt;
they claim it is fast because there is no conditional branching... who knows&lt;/p&gt;</comment>
                    <comment id="12783584" author="thetaphi" created="Mon, 30 Nov 2009 09:14:38 +0000"  >&lt;p&gt;I rewrote the NumericRangeTermsEnum, see revision 885360.&lt;/p&gt;

&lt;p&gt;Changed: Simplify and optimize NumericRangeTermEnum:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;the range split logic only seeks forward (an assert verifies this), so the iterator can be reused (like Automaton)&lt;/li&gt;
	&lt;li&gt;removed the iteration by not using setEnum() &lt;span class=&quot;error&quot;&gt;&amp;#91;throws UOE&amp;#93;&lt;/span&gt;, see &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-2087&quot; title=&quot;Remove recursion in NumericRangeTermEnum&quot;&gt;&lt;del&gt;LUCENE-2087&lt;/del&gt;&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;removed TermEnum, as class cannot be subclassed - so no BW break!!!; getEnum() throws UOE.&lt;/li&gt;
	&lt;li&gt;seek() cannot work for this TermsEnum, so throw UOE (is not needed for MTQ at the moment)&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12783596" author="mikemccand" created="Mon, 30 Nov 2009 10:26:59 +0000"  >&lt;p&gt;Thanks Uwe!&lt;/p&gt;</comment>
                    <comment id="12783598" author="mikemccand" created="Mon, 30 Nov 2009 10:36:11 +0000"  >&lt;blockquote&gt;
&lt;p&gt;fwiw here is a patch to use the algorithm from the unicode std for utf8 in utf16 sort order.&lt;br/&gt;
they claim it is fast because there is no conditional branching... who knows&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;We could try to test to see if we see a difference in practice...&lt;/p&gt;

&lt;p&gt;For term text without surrogate content, the branch always goes one way, so the CPU ought to predict it well and it may turn out to be faster using branching.&lt;/p&gt;

&lt;p&gt;With surrogates, likely the lookup approach is faster since the branch has good chance of going either way.&lt;/p&gt;

&lt;p&gt;However, the lookup approach adds 256 bytes to CPUs memory cache, which I&apos;m not thrilled about.  We have other places that do the same (NORM_TABLE in Similarity, scoreCache in TermScorer), that I think are much more warranted to make the time vs cache line tradeoff since they deal with a decent amount of CPU.&lt;/p&gt;

&lt;p&gt;Or maybe worrying about cache lines from way up in javaland is just silly &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;I guess at this point I&apos;d lean towards keeping the branch based comparator.&lt;/p&gt;</comment>
                    <comment id="12783654" author="rcmuir" created="Mon, 30 Nov 2009 13:41:05 +0000"  >&lt;blockquote&gt;&lt;p&gt;We could try to test to see if we see a difference in practice...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;it is also very wierd to me that the method you are using is the one being used in ICU... if this one is faster why isnt ICU using it?&lt;br/&gt;
its also sketchy that the table as described in the unicode std doesn&apos;t even work anyway as described... so is anyone using it?&lt;/p&gt;

&lt;p&gt;I like your reasoning, lets leave it alone for now... other things to work on that will surely help.&lt;/p&gt;</comment>
                    <comment id="12784106" author="thetaphi" created="Tue, 1 Dec 2009 07:54:54 +0000"  >&lt;p&gt;To prevent problems like yesterday, he is the patch I applied yesterday to the flex branch (for completeness).&lt;/p&gt;</comment>
                    <comment id="12784509" author="markrmiller@gmail.com" created="Tue, 1 Dec 2009 23:07:56 +0000"  >&lt;p&gt;I&apos;m going to commit the latest merge to trunk in a bit.&lt;/p&gt;

&lt;p&gt;In a recent commit, NumericRangeQuery was changed to return UnsupportedOperationException for getEnum - I think thats going to be a back compat break? For now I&apos;ve commented out the back compat test and put a nocommit comment:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  @Override
  &lt;span class=&quot;code-comment&quot;&gt;// nocommit: I think &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; needs to be implemented &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; back compat? When done, 
&lt;/span&gt;  &lt;span class=&quot;code-comment&quot;&gt;// the back compat test &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; it in TestNumericRangeQuery32 should be uncommented.
&lt;/span&gt;  &lt;span class=&quot;code-keyword&quot;&gt;protected&lt;/span&gt; FilteredTermEnum getEnum(&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; IndexReader reader) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
    &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; UnsupportedOperationException(&lt;span class=&quot;code-quote&quot;&gt;&quot;not implemented&quot;&lt;/span&gt;);
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I think we need to go back to returning the Enum? But I&apos;m not sure why this change was made, so ...&lt;/p&gt;</comment>
                    <comment id="12784510" author="thetaphi" created="Tue, 1 Dec 2009 23:14:12 +0000"  >&lt;p&gt;It is not a break: you cannot extend NumericRangeQuery (it&apos;s final), so you can never call that method (protected). Only if you put your class that may call this method into the same package, but that&apos;s illegal and not backed by bw compatibility (The BW test is exactly such a case, just comment it out in BW branch - I added this test for explicit enum testing, we should have this in flex trunk, too).&lt;/p&gt;

&lt;p&gt;(I explained that in the commit and Mike already wrote that in the comment). So please keep the code clean and do not re-add this TE.&lt;/p&gt;</comment>
                    <comment id="12784519" author="markrmiller@gmail.com" created="Tue, 1 Dec 2009 23:23:03 +0000"  >&lt;blockquote&gt;&lt;p&gt;Mike already wrote that in the comment&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;In what comment? Would be helpful to have it in a comment above getEnum.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;just comment it out in BW branch&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Thats what I&apos;ll do. Did the BW branch pass when you did it? If not, it would be helpful to commit that fix too, or call out the break loudly in this thread - its difficult to keep up on everything and track all of this down for these merges.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;So please keep the code clean and do not re-add this TE.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Oh, I had no plans to do it myself &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; I just commented out the BW compat test and put the comment you see above.&lt;/p&gt;</comment>
                    <comment id="12784520" author="markrmiller@gmail.com" created="Tue, 1 Dec 2009 23:24:57 +0000"  >&lt;p&gt;Though I do wonder ... if its not a break, why do we have the method there throwing UnsupportedExceptionOperation ... why isn&apos;t it just removed?&lt;/p&gt;</comment>
                    <comment id="12784528" author="thetaphi" created="Tue, 1 Dec 2009 23:31:37 +0000"  >&lt;blockquote&gt;&lt;p&gt;In what comment? Would be helpful to have it in a comment above getEnum.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Will do! It&apos;s in the log message not comment.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Did the BW branch pass when you did it?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think so, at least in my checkout. I think the TermEnum test was added after 3.0?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Though I do wonder ... if its not a break, why do we have the method there throwing UnsupportedExceptionOperation ... why isn&apos;t it just removed? &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I did not look into the super class, which just returns null. I thought it was abstract.&lt;/p&gt;</comment>
                    <comment id="12784532" author="thetaphi" created="Tue, 1 Dec 2009 23:35:47 +0000"  >&lt;p&gt;Mark: The updated backwards branch does not pass because of this (I did not update my checkout, the Enum test was added before 3.0). So the test should be commented out there, too (but you said, you would do this). Else, I will do tomorrow, I am tired, I would produce to many errors - sorry.&lt;/p&gt;</comment>
                    <comment id="12784536" author="thetaphi" created="Tue, 1 Dec 2009 23:49:13 +0000"  >&lt;p&gt;I updated my commit comment above, so it&apos;s clear what I have done (copied from commit log message).&lt;/p&gt;</comment>
                    <comment id="12784537" author="markrmiller@gmail.com" created="Tue, 1 Dec 2009 23:49:57 +0000"  >&lt;blockquote&gt;&lt;p&gt;Else, I will do tomorrow, I am tired, I would produce to many errors - sorry.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;No problem - I got it now - just wasn&apos;t sure. Thats why I brought it up &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;It&apos;s in the log message not comment.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yup - thats fine, no big deal. Was just saying it would be easier on me if there was a comment over it - I&apos;ve got it now though - I&apos;ll just remove that method.&lt;/p&gt;</comment>
                    <comment id="12784548" author="thetaphi" created="Wed, 2 Dec 2009 00:01:59 +0000"  >&lt;blockquote&gt;&lt;p&gt;I&apos;ll just remove that method.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;In my opinion the super method should throw UOE. If somebody misses to override either getTermsEnum() or getEnum() he will get a good message describing the problem, not just an NPE. The default impl of getTermsEnum() to return null is fine, because rewrite then delegates to getEnum(). If that also returns null, you get NPE.&lt;/p&gt;

&lt;p&gt;We had the same problem with Filter.bits() after deprecation in 2.x - it was not solved very good. In the 2.9 TS BW layer / DocIdSetIterator bw layer it was done correctly.&lt;/p&gt;</comment>
                    <comment id="12784555" author="thetaphi" created="Wed, 2 Dec 2009 00:08:53 +0000"  >&lt;p&gt;This is what I am thinking about for BW and delegation between getEnum() and getTermsEnum().&lt;/p&gt;</comment>
                    <comment id="12784563" author="markrmiller@gmail.com" created="Wed, 2 Dec 2009 00:28:01 +0000"  >&lt;p&gt;Okay - thats sounds like a good idea - I&apos;ll leave it for after the merge is done though.&lt;/p&gt;</comment>
                    <comment id="12784811" author="markrmiller@gmail.com" created="Wed, 2 Dec 2009 13:20:09 +0000"  >&lt;p&gt;I&apos;ve put the merge on hold for a bit - will try and come back to it tonight. Ive got to figure out why this BW compat test is failing, and haven&apos;t seen an obvious reason yet:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
junit.framework.AssertionFailedError: expected:&amp;lt;&amp;gt; but was:&amp;lt;&amp;gt;
	at org.apache.lucene.search.TestWildcard.testEmptyTerm(TestWildcard.java:108)
	at org.apache.lucene.util.LuceneTestCase.runBare(LuceneTestCase.java:208)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Pipe in if you know. Hard to debug or run this test singular in Eclipse (because of how BW compat tests work), so its a slow slog to trouble shoot and I haven&apos;t had time yet.&lt;/p&gt;</comment>
                    <comment id="12784818" author="mikemccand" created="Wed, 2 Dec 2009 13:37:25 +0000"  >&lt;p&gt;I think that test failure was from my fix of BooleanQuery to take coord into account in equals &amp;amp; hashCode (&lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-2092&quot; title=&quot;BooleanQuery.hashCode and equals ignore isCoordDisabled&quot;&gt;&lt;del&gt;LUCENE-2092&lt;/del&gt;&lt;/a&gt;)?  I hit exactly that same failure, and it required a fix on back-compat branch to just pass in &quot;true&quot; to the &quot;new BooleanQuery()&quot; done just before the assert.  Does that explain it?&lt;/p&gt;</comment>
                    <comment id="12784819" author="mikemccand" created="Wed, 2 Dec 2009 13:38:09 +0000"  >&lt;p&gt;And, thanks for taking over on merging trunk down!  I&apos;m especially looking forward to getting the faster unit tests (&lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1844&quot; title=&quot;Speed up junit tests&quot;&gt;&lt;del&gt;LUCENE-1844&lt;/del&gt;&lt;/a&gt;).&lt;/p&gt;</comment>
                    <comment id="12784823" author="thetaphi" created="Wed, 2 Dec 2009 13:51:16 +0000"  >&lt;p&gt;I have seen your change in the tests, too. The test just checks that no clauses are generated. In my opinion, it should  not compare to a empty BQ instance, instead just assert bq.clauses().size()==0.&lt;/p&gt;</comment>
                    <comment id="12784825" author="mikemccand" created="Wed, 2 Dec 2009 13:54:57 +0000"  >&lt;blockquote&gt;&lt;p&gt;In my opinion, it should not compare to a empty BQ instance, instead just assert bq.clauses().size()==0.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;+1, that&apos;d be a good improvement &amp;#8211; I&apos;ll do that.&lt;/p&gt;</comment>
                    <comment id="12784829" author="thetaphi" created="Wed, 2 Dec 2009 14:06:00 +0000"  >&lt;p&gt;I rewrote to:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void testEmptyTerm() &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
	RAMDirectory indexStore = getIndexStore(&lt;span class=&quot;code-quote&quot;&gt;&quot;field&quot;&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;[]{&lt;span class=&quot;code-quote&quot;&gt;&quot;nowildcard&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;nowildcardx&quot;&lt;/span&gt;});
	IndexSearcher searcher = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; IndexSearcher(indexStore, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;);

	MultiTermQuery wq = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; WildcardQuery(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Term(&lt;span class=&quot;code-quote&quot;&gt;&quot;field&quot;&lt;/span&gt;, &quot;&quot;));
	wq.setRewriteMethod(MultiTermQuery.SCORING_BOOLEAN_QUERY_REWRITE);
	assertMatches(searcher, wq, 0);
	Query q = searcher.rewrite(wq);
	assertTrue(q &lt;span class=&quot;code-keyword&quot;&gt;instanceof&lt;/span&gt; BooleanQuery);
	assertEquals(0, ((BooleanQuery) q).clauses().size());
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                    <comment id="12784873" author="mikemccand" created="Wed, 2 Dec 2009 15:22:48 +0000"  >&lt;p&gt;Looks great &amp;#8211; can/did you commit?&lt;/p&gt;</comment>
                    <comment id="12784876" author="markrmiller@gmail.com" created="Wed, 2 Dec 2009 15:27:57 +0000"  >&lt;blockquote&gt;&lt;p&gt;Does that explain it?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That was my initial guess and try - but neither true nor false fixed it.&lt;/p&gt;

&lt;p&gt;Looks like Uwes fix with side step the issue though? Sounds good to me &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="12784878" author="thetaphi" created="Wed, 2 Dec 2009 15:28:44 +0000"  >&lt;p&gt;I can do this, but according to Mark, only with a new issue and patch... Just joking &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;/p&gt;</comment>
                    <comment id="12784903" author="markrmiller@gmail.com" created="Wed, 2 Dec 2009 17:08:27 +0000"  >&lt;p&gt;Interesting ... after many, many runs without seeing that testreopen gc overhead limit exceeded, I just hit it again randomly.&lt;/p&gt;</comment>
                    <comment id="12784904" author="markrmiller@gmail.com" created="Wed, 2 Dec 2009 17:12:29 +0000"  >&lt;blockquote&gt;&lt;p&gt;I can do this, but according to Mark, only with a new issue and patch... Just joking &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I put it in the BW branch, but not the flex branch yet.&lt;/p&gt;

&lt;p&gt;Yeah, I&apos;m a hardass, but I&apos;m not in charge - just giving my opinion &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; And I like how most things are fairly loose - I just worry about going to far down a road it will be hard to come back from - usually its so easy to get consensus, its easy to ignore it - but I think thats dangerous.&lt;/p&gt;

&lt;p&gt;And yes, I get that your just kidding, but for good reason - I don&apos;t mean to come off as the abrasive one, but sometimes I think someone has to, and since I&apos;m already in that hole anyway ...&lt;/p&gt;</comment>
                    <comment id="12785052" author="thetaphi" created="Wed, 2 Dec 2009 23:14:03 +0000"  >&lt;p&gt;I put the better test into trunk/trunk BW. I could also put it into 3.0 and 2.9, but I do not think that is needed &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="12785058" author="thetaphi" created="Wed, 2 Dec 2009 23:36:33 +0000"  >&lt;p&gt;Mike: When fixing the NRQ test Mark merged, I found a problem/inconsistency with FilteredTermsEnum:&lt;/p&gt;

&lt;p&gt;Normal usage of a termsEnum is that it is positioned on the first term (e.g. after calling getTermsEnum()). Normally you have a do-while-loop and call next() at the end, which is fine. Most code using TermsEnums first checks inside the do-while &quot;if (term()==null)&quot; and then break (incorrect positioned or exhausted termsenum). As the call to term() does not check the returned term, it may contain an term, that should normally be filtered. The same happens if you call term() after it is exhausted. The FilteredTermsEnum should return null for term() and docFreq() if the enum is empty or exhausted. I have seen that you added empty() to it, but for consistency the FilteredTermsEnum should return null/-1.&lt;/p&gt;

&lt;p&gt;I fixed the test to check for empty() (sorry for two commits, the assertNull check was wrong, I changed before committing).&lt;/p&gt;

&lt;p&gt;Opinions?&lt;/p&gt;</comment>
                    <comment id="12785299" author="mikemccand" created="Thu, 3 Dec 2009 13:02:44 +0000"  >&lt;blockquote&gt;&lt;p&gt;Interesting ... after many, many runs without seeing that testreopen gc overhead limit exceeded, I just hit it again randomly.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Sheesh this one is annoying &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;Oh, I see &amp;#8211; we still need to cutover the standard codec&apos;s terms dict hash to use DBLRU instead of LinkedHashMap; that should fix it.  And actually after we do that we should re-run perf tests of the MTQs &amp;#8211; LinkedHashMap caused serious GC problems when I was testing automaton query.&lt;/p&gt;</comment>
                    <comment id="12785301" author="markrmiller@gmail.com" created="Thu, 3 Dec 2009 13:12:40 +0000"  >&lt;p&gt;Cool - was actually thinking about looking if you had done that yet last night (unrelatedly)&lt;/p&gt;

&lt;p&gt;&lt;b&gt;edit&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;Heh - though I should have known you handn&apos;t considering those classes came in on the merge - just confused about what has gotten down outside of merging I guess - I know there is an issue or two and for some reason thought this was one of them.&lt;/p&gt;</comment>
                    <comment id="12785303" author="thetaphi" created="Thu, 3 Dec 2009 13:20:28 +0000"  >&lt;p&gt;One thing I came along long time ago, but now with a new API it get&apos;s interesting again:&lt;/p&gt;

&lt;p&gt;DocsEnum should extend DocIdSetIterator, that would make it simplier to use and implement e.g. in MatchAllDocQuery.Scorer, FieldCacheRangeFilter and so on. You could e.g. write a filter for all documents that simply returns the docs enumeration from IndexReader.&lt;/p&gt;

&lt;p&gt;So it should be an abstract class that extends DocIdSetIterator. It has the same methods, only some methods must be a little bit renamed. The problem is, because java does not support multiple inheritace, we cannot also extends attributesource &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; Would DocIdSetIterator be an interface it would work (this is one of the cases where interfaces for really simple patterns can be used, like iterators).&lt;/p&gt;

&lt;p&gt;&lt;b&gt;EDIT&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;Maybe an idea would be to provide a method asDocIdSetIterator(), if the multiple inheritance cannot be fixed. Or have the AttributeSource as a member field, which would be good, as it only needs to be created on first access then (because constructing an AttributeSource is costly). getAttributes() returning it and dynamically instantiating would be an idea. The same applies for TermsEnum, it should be separated for lazy init.&lt;/p&gt;</comment>
                    <comment id="12785305" author="mikemccand" created="Thu, 3 Dec 2009 13:23:14 +0000"  >&lt;blockquote&gt;&lt;p&gt;Cool - was actually thinking about looking if you had done that yet last night (unrelatedly)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Feel free to fix it!&lt;/p&gt;</comment>
                    <comment id="12785308" author="mikemccand" created="Thu, 3 Dec 2009 13:26:03 +0000"  >&lt;blockquote&gt;&lt;p&gt;DocsEnum should extend DocIdSetIterator&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It&apos;d be great if we could find a way to do this without a big hairball of back compat code &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  They are basically the same, except DocsEnum lets you get freq() for each doc, get the PositionsEnum positions(), and also provides a bulk read API (w/ default impl).&lt;/p&gt;</comment>
                    <comment id="12785310" author="mikemccand" created="Thu, 3 Dec 2009 13:27:35 +0000"  >&lt;blockquote&gt;&lt;p&gt;getAttributes() returning it and dynamically instantiating would be an idea. The same applies for TermsEnum, it should be separated for lazy init.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That&apos;s a good point (avoid cost of creating the AttributeSource) &amp;#8211; that makes complete sense.&lt;/p&gt;</comment>
                    <comment id="12785312" author="markrmiller@gmail.com" created="Thu, 3 Dec 2009 13:29:32 +0000"  >&lt;p&gt;RE: the terms cache&lt;/p&gt;

&lt;p&gt;Should we still try and do the reuse stuff, or should we just drop it and use the cache as it is now? (eg reusing the object that is removed, if one is removed) Looks like that would be harder to get done now.&lt;/p&gt;</comment>
                    <comment id="12785314" author="thetaphi" created="Thu, 3 Dec 2009 13:30:53 +0000"  >&lt;blockquote&gt;&lt;p&gt;It&apos;d be great if we could find a way to do this without a big hairball of back compat code&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;DocsEnum is a new class, why not fit it from the beginning as DocIdSetIterator? In my opinion, as pointed out above, the AttributeSource stuff should go in as a lazy-init member behind getAttributes() / attributes().&lt;/p&gt;

&lt;p&gt;So I would define it as:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;abstract&lt;/span&gt; class DocsEnum &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; DocIdSetIterator {
  &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; AttributeSource atts = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; freq()
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; DontKnowClassName positions()
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; AttributeSource attributes() {
   &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (atts==&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) atts=&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; AttributeSource();
   &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; atts;
  }
  ...&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt; impl of the bulk access using the &lt;span class=&quot;code-keyword&quot;&gt;abstract&lt;/span&gt; methods from DocIdSetIterator
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                    <comment id="12785338" author="thetaphi" created="Thu, 3 Dec 2009 14:27:12 +0000"  >&lt;p&gt;Here the patch with refactoring DocsEnum.&lt;/p&gt;

&lt;p&gt;With this patch MatchAllDocsQuery is very simple to implement now as a ConstantScoreQuery on top of a Filter that returns the DocsEnum of the supplied IndexReader as iterator. Really cool.&lt;/p&gt;</comment>
                    <comment id="12785343" author="thetaphi" created="Thu, 3 Dec 2009 14:36:29 +0000"  >&lt;p&gt;Updated patch: &lt;/p&gt;

&lt;p&gt;I did a search on &quot;AttributeSource&quot; in index package. I now also replaced the &quot;extends AttributeSource&quot; by a lazy init in in FieldsEnum and PositionsEnum. So all enums have an attributes() method that lazy inits an AttributeSource. When attributes get interesting a custom DocsEnum could just use attributes().addAttribute(XYZ.class) in its ctor and store the reference locally. attributes() is final (to be safe, when called by ctor).&lt;/p&gt;

&lt;p&gt;Eventually add an Interface AttributeAble &lt;b&gt;g&lt;/b&gt; that is implemented by all these enums and anywhere else using AttributeSource that may need to be lazy init.&lt;/p&gt;</comment>
                    <comment id="12785356" author="mikemccand" created="Thu, 3 Dec 2009 15:28:25 +0000"  >&lt;blockquote&gt;&lt;p&gt;Should we still try and do the reuse stuff, or should we just drop it and use the cache as it is now?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;How about starting w/o reuse but leave a TODO saying we could/should investigate?&lt;/p&gt;</comment>
                    <comment id="12785360" author="mikemccand" created="Thu, 3 Dec 2009 15:39:01 +0000"  >&lt;p&gt;Patch looks good Uwe!&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;MatchAllDocsQuery is very simple to implement now as a ConstantScoreQuery on top of a Filter that returns the DocsEnum of the supplied IndexReader as iterator. Really cool.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Sweet!  Wait, using AllDocsEnum you mean?&lt;/p&gt;</comment>
                    <comment id="12785362" author="mikemccand" created="Thu, 3 Dec 2009 15:40:00 +0000"  >&lt;blockquote&gt;&lt;p&gt;How about starting w/o reuse but leave a TODO saying we could/should investigate?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Actually, scratch that &amp;#8211; reuse is too hard in DBLRU &amp;#8211; I would say just no reuse now.  Trunk doesn&apos;t reuse either...&lt;/p&gt;</comment>
                    <comment id="12785365" author="thetaphi" created="Thu, 3 Dec 2009 15:52:18 +0000"  >&lt;blockquote&gt;&lt;p&gt;Sweet! Wait, using AllDocsEnum you mean?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes, but this class is package private and unused! AllTermDocs is used by SegmentReader to support termDocs(null), but not AllDocsEnum. There is no method in IndexReader that returns all docs?&lt;/p&gt;

&lt;p&gt;The matchAllDocs was just an example, there are more use cases, e.g. a TermsFilter (that is the non-scoring TermQuery variant): Just use the DocsEnum of this term as the DicIdSetIterator.&lt;/p&gt;</comment>
                    <comment id="12785377" author="mikemccand" created="Thu, 3 Dec 2009 16:12:36 +0000"  >&lt;blockquote&gt;&lt;p&gt;There is no method in IndexReader that returns all docs?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Not yet (in flex API) &amp;#8211; we can add it?  IndexReader.allDocs(Bits skipDocs)?  Or we could make AllDocsEnum public?  Hmm.&lt;/p&gt;</comment>
                    <comment id="12785631" author="mikemccand" created="Thu, 3 Dec 2009 23:30:30 +0000"  >&lt;p&gt;We will continue work under new issues &amp;#8211; this one has gotten too big!&lt;/p&gt;</comment>
                    <comment id="12785992" author="mikemccand" created="Fri, 4 Dec 2009 16:36:26 +0000"  >&lt;p&gt;Hmm, somehow in the last merge, we lost the fixes for &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1558&quot; title=&quot;Make IndexReader/Searcher ctors readOnly=true by default&quot;&gt;&lt;del&gt;LUCENE-1558&lt;/del&gt;&lt;/a&gt; (defaulting readOnly=true for IndexReader)... IndexSearcher looks like it didn&apos;t lose the change though.&lt;/p&gt;</comment>
                    <comment id="12785998" author="markrmiller@gmail.com" created="Fri, 4 Dec 2009 16:54:44 +0000"  >&lt;p&gt;Its not surprising - the merge command sucks from what I can tell &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; Which is why I had to go line by line a merge or two ago to catch everything that had been dropped.&lt;/p&gt;

&lt;p&gt;I expected I&apos;d have to do it again, but its a lot of effort to do every time.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;edit&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;by line by line, I mean I go through a diff of every file comparing trunk and the flex branch - I&apos;ll do it again soon.&lt;/p&gt;</comment>
                    <comment id="12786015" author="mikemccand" created="Fri, 4 Dec 2009 17:31:30 +0000"  >&lt;p&gt;Thanks Mark!  IndexReader.open looks good now.&lt;/p&gt;</comment>
                    <comment id="12794557" author="mikemccand" created="Fri, 25 Dec 2009 11:15:59 +0000"  >&lt;p&gt;This issue is &quot;continuing&quot; under &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-2111&quot; title=&quot;Wrapup flexible indexing&quot;&gt;&lt;del&gt;LUCENE-2111&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                </comments>
                <issuelinks>
                        <issuelinktype id="10030">
                <name>Reference</name>
                                <outwardlinks description="relates to">
                            <issuelink>
            <issuekey id="12439796">LUCENE-2025</issuekey>
        </issuelink>
                    </outwardlinks>
                                            </issuelinktype>
                    </issuelinks>
                <attachments>
                    <attachment id="12421280" name="LUCENE-1458-back-compat.patch" size="22416" author="mikemccand" created="Mon, 5 Oct 2009 13:19:44 +0100" />
                    <attachment id="12421088" name="LUCENE-1458-back-compat.patch" size="22416" author="mikemccand" created="Fri, 2 Oct 2009 01:32:58 +0100" />
                    <attachment id="12420583" name="LUCENE-1458-back-compat.patch" size="16324" author="mikemccand" created="Fri, 25 Sep 2009 18:58:47 +0100" />
                    <attachment id="12420388" name="LUCENE-1458-back-compat.patch" size="16086" author="mikemccand" created="Wed, 23 Sep 2009 18:10:59 +0100" />
                    <attachment id="12419393" name="LUCENE-1458-back-compat.patch" size="15195" author="mikemccand" created="Sat, 12 Sep 2009 17:41:41 +0100" />
                    <attachment id="12419302" name="LUCENE-1458-back-compat.patch" size="15195" author="mikemccand" created="Fri, 11 Sep 2009 14:49:31 +0100" />
                    <attachment id="12426780" name="LUCENE-1458-DocIdSetIterator.patch" size="22977" author="thetaphi" created="Thu, 3 Dec 2009 14:36:29 +0000" />
                    <attachment id="12426779" name="LUCENE-1458-DocIdSetIterator.patch" size="21501" author="thetaphi" created="Thu, 3 Dec 2009 14:27:12 +0000" />
                    <attachment id="12426603" name="LUCENE-1458-MTQ-BW.patch" size="1729" author="thetaphi" created="Wed, 2 Dec 2009 00:08:53 +0000" />
                    <attachment id="12426515" name="LUCENE-1458-NRQ.patch" size="12448" author="thetaphi" created="Tue, 1 Dec 2009 07:54:54 +0000" />
                    <attachment id="12421994" name="LUCENE-1458.patch" size="904287" author="markrmiller@gmail.com" created="Tue, 13 Oct 2009 17:11:23 +0100" />
                    <attachment id="12421952" name="LUCENE-1458.patch" size="898856" author="markrmiller@gmail.com" created="Tue, 13 Oct 2009 06:54:41 +0100" />
                    <attachment id="12421785" name="LUCENE-1458.patch" size="931065" author="mikemccand" created="Fri, 9 Oct 2009 23:46:52 +0100" />
                    <attachment id="12421535" name="LUCENE-1458.patch" size="916228" author="mikemccand" created="Wed, 7 Oct 2009 17:01:50 +0100" />
                    <attachment id="12421431" name="LUCENE-1458.patch" size="907576" author="mikemccand" created="Tue, 6 Oct 2009 16:06:34 +0100" />
                    <attachment id="12421382" name="LUCENE-1458.patch" size="1048405" author="markrmiller@gmail.com" created="Tue, 6 Oct 2009 05:06:49 +0100" />
                    <attachment id="12421355" name="LUCENE-1458.patch" size="1039087" author="markrmiller@gmail.com" created="Tue, 6 Oct 2009 00:58:39 +0100" />
                    <attachment id="12416297" name="LUCENE-1458.patch" size="368692" author="michaelbusch" created="Wed, 12 Aug 2009 11:13:48 +0100" />
                    <attachment id="12400861" name="LUCENE-1458.patch" size="379076" author="mikemccand" created="Tue, 24 Feb 2009 14:22:22 +0000" />
                    <attachment id="12394409" name="LUCENE-1458.patch" size="269330" author="mikemccand" created="Fri, 21 Nov 2008 11:40:56 +0000" />
                    <attachment id="12394194" name="LUCENE-1458.patch" size="192975" author="mikemccand" created="Tue, 18 Nov 2008 22:10:13 +0000" />
                    <attachment id="12394175" name="LUCENE-1458.patch" size="170932" author="mikemccand" created="Tue, 18 Nov 2008 15:41:06 +0000" />
                    <attachment id="12394157" name="LUCENE-1458.patch" size="119027" author="mikemccand" created="Tue, 18 Nov 2008 10:32:31 +0000" />
                    <attachment id="12426377" name="LUCENE-1458_rotate.patch" size="4015" author="rcmuir" created="Mon, 30 Nov 2009 00:28:36 +0000" />
                    <attachment id="12425918" name="LUCENE-1458_sortorder_bwcompat.patch" size="3260" author="rcmuir" created="Tue, 24 Nov 2009 00:44:11 +0000" />
                    <attachment id="12421281" name="LUCENE-1458.tar.bz2" size="2025097" author="mikemccand" created="Mon, 5 Oct 2009 13:19:44 +0100" />
                    <attachment id="12421089" name="LUCENE-1458.tar.bz2" size="2030763" author="mikemccand" created="Fri, 2 Oct 2009 01:32:58 +0100" />
                    <attachment id="12420582" name="LUCENE-1458.tar.bz2" size="1928837" author="mikemccand" created="Fri, 25 Sep 2009 18:58:47 +0100" />
                    <attachment id="12420387" name="LUCENE-1458.tar.bz2" size="1918872" author="mikemccand" created="Wed, 23 Sep 2009 18:10:59 +0100" />
                    <attachment id="12419392" name="LUCENE-1458.tar.bz2" size="1913203" author="mikemccand" created="Sat, 12 Sep 2009 17:41:41 +0100" />
                    <attachment id="12419303" name="LUCENE-1458.tar.bz2" size="1916847" author="mikemccand" created="Fri, 11 Sep 2009 14:49:31 +0100" />
                    <attachment id="12418566" name="LUCENE-1458.tar.bz2" size="1890686" author="mikemccand" created="Fri, 4 Sep 2009 01:10:19 +0100" />
                    <attachment id="12425869" name="LUCENE-1458_termenum_bwcompat.patch" size="1279" author="rcmuir" created="Mon, 23 Nov 2009 19:03:58 +0000" />
                    <attachment id="12425829" name="UnicodeTestCase.patch" size="1682" author="rcmuir" created="Mon, 23 Nov 2009 11:28:08 +0000" />
                    <attachment id="12425795" name="UnicodeTestCase.patch" size="1699" author="rcmuir" created="Mon, 23 Nov 2009 04:08:21 +0000" />
                </attachments>
            <subtasks>
        </subtasks>
                <customfields>
                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                <customfieldname>Attachment count</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>35.0</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                <customfieldname>Date of First Response</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>Tue, 18 Nov 2008 14:40:35 +0000</customfieldvalue>

                </customfieldvalues>
            </customfield>
                                                                                                        <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Global Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>12293</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                <customfieldname>Lucene Fields</customfieldname>
                <customfieldvalues>
                        <customfieldvalue key="10121"><![CDATA[New]]></customfieldvalue>
    
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>26269</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                <customfieldname>Time in Status</customfieldname>
                <customfieldvalues>
                    
                </customfieldvalues>
            </customfield>
                            </customfields>
    </item>
</channel>
</rss>