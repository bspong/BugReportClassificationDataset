<!-- 
RSS generated by JIRA (5.2.8#851-sha1:3262fdc28b4bc8b23784e13eadc26a22399f5d88) at Tue Jul 16 13:12:56 UTC 2013

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/LUCENE-847/LUCENE-847.xml?field=key&field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>5.2.8</version>
        <build-number>851</build-number>
        <build-date>26-02-2013</build-date>
    </build-info>

<item>
            <title>[LUCENE-847] Factor merge policy out of IndexWriter</title>
                <link>https://issues.apache.org/jira/browse/LUCENE-847</link>
                <project id="12310110" key="LUCENE">Lucene - Core</project>
                        <description>&lt;p&gt;If we factor the merge policy out of IndexWriter, we can make it pluggable, making it possible for apps to choose a custom merge policy and for easier experimenting with merge policy variants.&lt;/p&gt;</description>
                <environment></environment>
            <key id="12365696">LUCENE-847</key>
            <summary>Factor merge policy out of IndexWriter</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                    <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png">Closed</status>
                    <resolution id="1">Fixed</resolution>
                                <assignee username="steven_parkes">Steven Parkes</assignee>
                                <reporter username="steven_parkes">Steven Parkes</reporter>
                        <labels>
                    </labels>
                <created>Fri, 23 Mar 2007 19:15:20 +0000</created>
                <updated>Thu, 2 May 2013 03:29:06 +0100</updated>
                    <resolved>Tue, 18 Sep 2007 10:40:39 +0100</resolved>
                                            <fixVersion>2.3</fixVersion>
                                <component>core/index</component>
                        <due></due>
                    <votes>0</votes>
                        <watches>3</watches>
                                                    <comments>
                    <comment id="12483719" author="steven_parkes" created="Fri, 23 Mar 2007 19:24:21 +0000"  >&lt;p&gt;Here&apos;s a first cut at a factored merge policy.&lt;/p&gt;

&lt;p&gt;It&apos;s not polished. Sparsely commented and there are probably a few changes that should be backed out.&lt;/p&gt;

&lt;p&gt;It factors a merge policy interface out of IndexWriter and creates an implementation of the existing merge policy.&lt;/p&gt;

&lt;p&gt;Actually, it&apos;s a tweak on the existing merge policy. Currently the merge policy is implemented in ways that assume certain things about the existing list of segments. The factored version doesn&apos;t make these assumptions. It simplifies the interface but I&apos;m not yet sure if there are bad side effects. Among other things I want to run performance tests.&lt;/p&gt;

&lt;p&gt;There is part of a pass at a concurrent version of the current merge policy. It&apos;s not complete. I&apos;ve been pushing it to see if I understand the issues around concurrent merges. Interesting topics are 1) how to control the merges 2) how/when to cascade merges if they are happening in a parallel and 3) how to handle synchronization of IndexWriter#segmentInfos. That last one in particular is a bit touchy.&lt;/p&gt;

&lt;p&gt;I did a quick implementation of KS&apos;s fib merge policy but it&apos;s incomplete in that IndexWriter won&apos;t merge non-contiguous segment lists, but I think I can fix that fairly easily with no major side effects. The factored merge policy makes this plug in pretty clean ...&lt;/p&gt;</comment>
                    <comment id="12483737" author="cutting" created="Fri, 23 Mar 2007 20:25:51 +0000"  >&lt;p&gt;How public should such an API be?  Should the interface be public?  Should the implementations?  The most conservative approach would be to make it all package private, to give more leeway for evolving the update API.  But that also decreases the utility.  Thoughts?&lt;/p&gt;</comment>
                    <comment id="12483742" author="steven_parkes" created="Fri, 23 Mar 2007 20:45:01 +0000"  >&lt;p&gt;Visibility is one of those things I haven&apos;t cleaned up yet.&lt;/p&gt;

&lt;p&gt;Client code is gonna want to create and set merge policies. And it&apos;ll want to set &quot;external&quot; merge policy parameters. That&apos;s all probably not controversial.&lt;/p&gt;

&lt;p&gt;As for other stuff, I tend to leave things open, but I know that&apos;s debatable and don&apos;t have a strong opinion in this case.&lt;/p&gt;

&lt;p&gt;In fact, there a few things here that are fairly subtle/important. The relationship/protocol between the writer and policy is pretty strong. This can be seen in the strawman concurrent merge code where the merge policy holds state and relies on being called from a synchronized writer method.   If that goes forward anything like it is, it would argue for tightening that api up some. Chris suggested a way to make the writer&amp;lt;&amp;gt;polcy relationship &quot;atomic&quot;. I didn&apos;t add the code (yet) but I&apos;m not against it.&lt;/p&gt;




</comment>
                    <comment id="12483929" author="mikemccand" created="Sun, 25 Mar 2007 13:46:09 +0100"  >&lt;p&gt;Steven, I looked through the patch quickly.  It looks great!  First&lt;br/&gt;
some general comments and then I&apos;ll add more specifics as&lt;br/&gt;
separate comments.&lt;/p&gt;

&lt;p&gt;Can you open separate issues for the other new and interesting merge&lt;br/&gt;
policies here?  I think the refactoring of merge policy plus creation&lt;br/&gt;
of the default policy that is identical to today&apos;s merge policy, which&lt;br/&gt;
should be a fairly quick and low-risk operation, would then remain&lt;br/&gt;
under this issue?&lt;/p&gt;

&lt;p&gt;Then, iterating / vetting / debugging the new interesting merge&lt;br/&gt;
policies can take longer under their own separate issues and time&lt;br/&gt;
frame.&lt;/p&gt;

&lt;p&gt;On staging I think we could first do this issue (decouple MergePolicy&lt;br/&gt;
from writer), then &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-845&quot; title=&quot;If you &amp;quot;flush by RAM usage&amp;quot; then IndexWriter may over-merge&quot;&gt;&lt;del&gt;LUCENE-845&lt;/del&gt;&lt;/a&gt; because it blocks &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-843&quot; title=&quot;improve how IndexWriter uses RAM to buffer added documents&quot;&gt;&lt;del&gt;LUCENE-843&lt;/del&gt;&lt;/a&gt; (which&lt;br/&gt;
would then be fixing LogarithmicMergePolicy to use segment sizes&lt;br/&gt;
instead of docs counts as basis for determing levels) then &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-843&quot; title=&quot;improve how IndexWriter uses RAM to buffer added documents&quot;&gt;&lt;del&gt;LUCENE-843&lt;/del&gt;&lt;/a&gt;&lt;br/&gt;
(performance improvements for how writer uses RAM)?&lt;/p&gt;

</comment>
                    <comment id="12483930" author="mikemccand" created="Sun, 25 Mar 2007 13:46:33 +0100"  >&lt;p&gt;My first comment, which I fear will be the most controversial feedback&lt;br/&gt;
here &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;, is a whitespace style question: I&apos;m not really a fan of&lt;br/&gt;
&quot;cancerous whitespace&quot; where every ( [ etc has its own whitespace&lt;br/&gt;
around it.&lt;/p&gt;

&lt;p&gt;I generally prefer minimal whitespace within reason (ie as long as it&lt;br/&gt;
does not heavily hurt readability).  The thing is I don&apos;t know that&lt;br/&gt;
Lucene has settled on this / if anyone else shares my opinion?  It&lt;br/&gt;
does seem that &quot;two space indentation&quot; is the standard, which I agree&lt;br/&gt;
with, but I don&apos;t know if whitespace style has otherwise been agreed&lt;br/&gt;
on?  Many people will say it&apos;s unimportant to agree on whitespace but&lt;br/&gt;
I feel it&apos;s actually quite important.&lt;/p&gt;</comment>
                    <comment id="12483931" author="mikemccand" created="Sun, 25 Mar 2007 13:47:27 +0100"  >&lt;p&gt;OK some specific comments, only on the refactoring (ie I haven&apos;t&lt;br/&gt;
really looked at the new merge policies yet):&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;I think maxBufferedDocs should not be exposed in any *MergePolicy&lt;br/&gt;
    classes or interfaces?  I&apos;m planning on deprecating this param&lt;br/&gt;
    with &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-843&quot; title=&quot;improve how IndexWriter uses RAM to buffer added documents&quot;&gt;&lt;del&gt;LUCENE-843&lt;/del&gt;&lt;/a&gt; when we switch by default to &quot;buffering by RAM&lt;br/&gt;
    usage&quot; and it really relates to &quot;how/when should writer flush its&lt;br/&gt;
    RAM buffer&quot;.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;I also think &quot;minMergeDocs&quot; (which today is one and the same as&lt;br/&gt;
    maxBufferedDocs in IndexWriter but conceptually could be a&lt;br/&gt;
    different configuration) also should not appear in the MergePolicy&lt;br/&gt;
    interface.  I think it should only appear in&lt;br/&gt;
    LogarithmicMergePolicy?&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    If we remove these from the MergePolicy interface then maybe we&lt;br/&gt;
    don&apos;t need MergePolicyBase?  (Just to makes things simpler).&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;I think we should not create a LegacyMergePolicy interface.  But I&lt;br/&gt;
    realize you need this so the deprecated methods in IndexWriter&lt;br/&gt;
    (setMergeFactor, setMaxBufferedDocs, setMaxMergeDocs, etc.) can be&lt;br/&gt;
    implemented.  How about instead these methods will only work if&lt;br/&gt;
    the current merge policy is the LogarithmicMergePolicy?  You can&lt;br/&gt;
    check if the current mergePolicy is an instanceof&lt;br/&gt;
    LogarithmicMergePolicy and then throw eg an IllegalStateException&lt;br/&gt;
    if it&apos;s not?&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Ie, going forward, with new and interesting merge policies,&lt;br/&gt;
    developers should interact with their merge policy to configure&lt;br/&gt;
    it.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;I was a little spooked by this change to TestAddIndexesNoOptimize:&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;assertEquals(2, writer.getSegmentCount());&lt;br/&gt;
      +    assertEquals(3, writer.getSegmentCount());&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    I think with just the refactoring, there should not need to be any&lt;br/&gt;
    changes to unit tests right?&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;It&apos;s interesting that you&apos;ve pulled &quot;useCompoundFile&quot; into the&lt;br/&gt;
    LegacyMergePolicy.  I&apos;m torn on whether it belongs in MergePolicy&lt;br/&gt;
    at all, since this is really a file format issue?&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    For example, newly written segments (no longer a &quot;merge&quot; with&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-843&quot; title=&quot;improve how IndexWriter uses RAM to buffer added documents&quot;&gt;&lt;del&gt;LUCENE-843&lt;/del&gt;&lt;/a&gt;) must also know whether to write in compound file&lt;br/&gt;
    format.  If we make interesting file format changes in the future&lt;br/&gt;
    that are configurable by the developer we wouldn&apos;t want to change&lt;br/&gt;
    all MergePolicy classes to propogate that.  It feels like using&lt;br/&gt;
    compound file or not should remain only in IndexWriter?&lt;/p&gt;</comment>
                    <comment id="12485054" author="ningli" created="Thu, 29 Mar 2007 04:21:07 +0100"  >&lt;p&gt;Here is a patch for concurrent merge as discussed in:&lt;br/&gt;
&lt;a href=&quot;http://www.gossamer-threads.com/lists/lucene/java-dev/45651?search_string=concurrent%20merge;#45651&quot; class=&quot;external-link&quot;&gt;http://www.gossamer-threads.com/lists/lucene/java-dev/45651?search_string=concurrent%20merge;#45651&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I put it under this issue because it helps design and verify a factored merge policy which would provide good support for concurrent merge.&lt;/p&gt;

&lt;p&gt;As described before, a merge thread is started when a writer is created and stopped when the writer is closed. The merge process consists of three steps: first, create a merge task/spec; then, carry out the actual merge; finally, &quot;commit&quot; the merged segment (replace segments it merged in segmentInfos), but only after appropriate deletes are applied. The first and last steps are fast and synchronous. The second step is where concurrency is achieved. Does it make sense to capture them as separate steps in the factored merge policy?&lt;/p&gt;

&lt;p&gt;As discussed in &lt;a href=&quot;http://www.gossamer-threads.com/lists/lucene/java-dev/45651?search_string=concurrent%20merge;#45651:&quot; class=&quot;external-link&quot;&gt;http://www.gossamer-threads.com/lists/lucene/java-dev/45651?search_string=concurrent%20merge;#45651:&lt;/a&gt; documents can be buffered while segments are merged, but no more than maxBufferedDocs can be buffered at any time. So this version provides limited concurrency. The main goal is to achieve short ingestion hiccups, especially when the ingestion rate is low. After the factored merge policy, we could provide different versions of concurrent merge policies which provide different levels of concurrency. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;All unit tests pass. If IndexWriter is replaced with IndexWriterConcurrentMerge, all unit tests pass except the following:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;TestAddIndexesNoOptimize and TestIndexWriter*&lt;br/&gt;
    This is because they check segment sizes expecting all merges are done. These tests pass if these checks are performed after the concurrent merges finish. The modified tests (with waits for concurrent merges to finish) are in TestIndexWriterConcurrentMerge*.&lt;/li&gt;
	&lt;li&gt;testExactFieldNames in TestBackwardCompatibility and testDeleteLeftoverFiles in TestIndexFileDeleter&lt;br/&gt;
    In both cases, file name segments_a is expected, but the actual is segments_7. This is because with concurrent merge, if compound file is used, only the compound version is &quot;committed&quot; (added to segmentInfos), not the non-compound version, thus the lower segments generation number.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Cheers,&lt;br/&gt;
Ning&lt;/p&gt;</comment>
                    <comment id="12490192" author="steven_parkes" created="Thu, 19 Apr 2007 23:41:58 +0100"  >&lt;p&gt;Here are some numbers comparing the load performance for the factored vs. non-factored merge policies.&lt;/p&gt;

&lt;p&gt;The setup uses enwiki, loads 200K documents, and uses 4 different combinations of maxBufferedDocs and mergeFactor (just the default from the standard benchmark, not because I necessarily thought it was a good idea.)&lt;/p&gt;

&lt;p&gt;The factored merge policy seems to be on the order of 1% slower loading than the non-factored version ... and I&apos;m not sure why, so I&apos;m going to check into this. The factored version does more examination of segment list than the non-factored version, so there&apos;s compute overhead, but I would expect that to be swamped by I/O Maybe that&apos;s not a good assumption? Or it might be doing different merges for reasons I haven&apos;t considered, which I&apos;m going to check.&lt;/p&gt;

&lt;p&gt;Relating this to some of the merge discussions, I&apos;m going to look at monitoring both the number of merges taking place and the size of those merges. I think that&apos;s helpful in understand different candidate merge policies, in addition to absolute difference in runtime.&lt;/p&gt;

&lt;p&gt;I also think histogramming  the per-doc cost would also be interesting, since mitigating the long delay at cascading merges is at least one goal of a concurrent merge policy.&lt;/p&gt;

&lt;p&gt;And all this doesn&apos;t even consider testing the recent stuff on merging multiple indexes. That&apos;s an area where the factored merge policy differs (because of the simpler interface.)&lt;/p&gt;

&lt;p&gt;I&apos;m curious if anyone is surprised by these numbers, the 60 docs/sec, in particular. This machine is a dual dual-core xeon, writing to a single local disk.  My dual opty achieved ~85-100 docs/sec on a three disk SATA3 RAID5 array.&lt;/p&gt;

&lt;p&gt;Non-factored (current) merge policy&lt;/p&gt;

&lt;p&gt;     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt; ------------&amp;gt; Report sum by Prefix (MAddDocs) and Round (8 about 8 out of 33)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt; Operation       round mrg buf   runCnt   recsPerRun        rec/s  elapsedSec    avgUsedMem    avgTotalMem&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt; MAddDocs_200000     0  10  10        1       200000         41.6    4,804.11    11,758,928     12,591,104&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt; MAddDocs_200000 -   1 100  10 -  -   1 -  -  200000 -  -  - 50.0 -  4,000.25 -  34,831,992 -   52,563,968&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt; MAddDocs_200000     2  10 100        1       200000         49.9    4,004.95    42,158,232     60,444,672&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt; MAddDocs_200000 -   3 100 100 -  -   1 -  -  200000 -  -  - 57.9 -  3,455.97 -  45,646,680 -   61,083,648&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt; MAddDocs_200000     4  10  10        1       200000         44.9    4,458.66    36,928,616     61,083,648&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt; MAddDocs_200000 -   5 100  10 -  -   1 -  -  200000 -  -  - 50.4 -  3,965.98 -  47,855,064 -   61,083,648&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt; MAddDocs_200000     6  10 100        1       200000         49.7    4,023.51    52,506,448     64,217,088&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt; MAddDocs_200000 -   7 100 100 -  -   1 -  -  200000 -  -  - 57.9 -  3,451.39 -  64,466,128 -   73,220,096&lt;/p&gt;

&lt;p&gt;Factored (new) merge policy&lt;/p&gt;

&lt;p&gt;     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt; ------------&amp;gt; Report sum by Prefix (MAddDocs) and Round (8 about 8 out of 33)&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt; Operation       round mrg buf   runCnt   recsPerRun        rec/s  elapsedSec    avgUsedMem    avgTotalMem&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt; MAddDocs_200000     0  10  10        1       200000         41.4    4,828.25    10,477,976     12,386,304&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt; MAddDocs_200000 -   1 100  10 -  -   1 -  -  200000 -  -  - 50.4 -  3,968.27 -  38,333,544 -   46,170,112&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt; MAddDocs_200000     2  10 100        1       200000         50.3    3,973.52    33,539,824     63,860,736&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt; MAddDocs_200000 -   3 100 100 -  -   1 -  -  200000 -  -  - 58.6 -  3,413.87 -  44,580,528 -   87,781,376&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt; MAddDocs_200000     4  10  10        1       200000         45.3    4,411.50    57,850,104     87,781,376&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt; MAddDocs_200000 -   5 100  10 -  -   1 -  -  200000 -  -  - 51.0 -  3,921.48 -  62,793,432 -   87,781,376&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt; MAddDocs_200000     6  10 100        1       200000         50.4    3,969.87    49,625,496     93,966,336&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;java&amp;#93;&lt;/span&gt; MAddDocs_200000 -   7 100 100 -  -   1 -  -  200000 -  -  - 58.7 -  3,409.51 -  68,100,288 -  129,572,864&lt;/p&gt;</comment>
                    <comment id="12518006" author="steven_parkes" created="Mon, 6 Aug 2007 21:11:28 +0100"  >&lt;p&gt;Here&apos;s an update to the patch. I wouldn&apos;t say it&apos;s ready to be committed, but I think it&apos;s significantly closer than it was.&lt;/p&gt;

&lt;p&gt;The concurrent and other misc. stuff have been pulled out (that part still needs work, figuring out how to get the concurrency right.)&lt;/p&gt;

&lt;p&gt;The new patch works against trunk, which means it handles docswriter and is more compatible with merging by # of docs or merging by ram (or size, to be more accurate?)&lt;/p&gt;

&lt;p&gt;My take on the migration path here was that we could well be going towards merging by size but need to keep merging by # docs for parallel index cases. The current patch still only does merging by # docs.&lt;/p&gt;

&lt;p&gt;I think I commented on a couple of other things dev, but to reiterate:&lt;/p&gt;

&lt;p&gt;There&apos;s a small change in the test results because the new merge policy simplifies the treatatement of addIndexes operations. The change is understood and shouldn&apos;t be a problem.&lt;/p&gt;

&lt;p&gt;useCompoundFile is delegated to the merge policy so a smart merge policy could make decisions looking at the state of all segments rather than all-or-nothing. There are a couple of fixme&apos;s in IndexWriter related to this and the segments being created by the docswriter.&lt;/p&gt;

&lt;p&gt;I&apos;m going to look at that, plus the concurrent stuff: Ning&apos;s stuff plus by old approach (which has to change, given the new docswriter stuff).&lt;/p&gt;</comment>
                    <comment id="12518013" author="steven_parkes" created="Mon, 6 Aug 2007 21:25:56 +0100"  >&lt;p&gt;For the time being, the patch also contains some of the code from &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-971&quot; title=&quot;Create enwiki indexable data as line-per-article rather than file-per-article&quot;&gt;&lt;del&gt;LUCENE-971&lt;/del&gt;&lt;/a&gt; since that&apos;s how I test it.&lt;/p&gt;</comment>
                    <comment id="12518162" author="mikemccand" created="Tue, 7 Aug 2007 15:40:06 +0100"  >&lt;p&gt;This looks great Steve!&lt;/p&gt;

&lt;p&gt;More specific feeedback soon, but ... in thinking about concurrency&lt;br/&gt;
(and from reading your comments about it in LogDocMergePolicy), I&lt;br/&gt;
think we ideally would like concurrency to be fully independent of the&lt;br/&gt;
merge policy.&lt;/p&gt;

&lt;p&gt;Ie, just like you can take any shell command and choose to run it in&lt;br/&gt;
the background by sticking an &quot;&amp;amp;&quot; on the end, I should be able to take&lt;br/&gt;
my favorite MergePolicy instance X and &quot;wrap&quot; it inside a &quot;concurrent&lt;br/&gt;
merge policy wrapper&quot;.  Eg, instantiate ConcurrentMergePolicy(X), and&lt;br/&gt;
then ConcurrentMergePolicy would take the merges requested by X and do&lt;br/&gt;
them in the background.&lt;/p&gt;

&lt;p&gt;I think with one change to your MergePolicy API &amp;amp; control flow, we&lt;br/&gt;
could make this work very well: instead of requiring the MergePolicy&lt;br/&gt;
to call IndexWriter.merge, and do the cascading, it should just return&lt;br/&gt;
the one MergeSpecification that should be done right now.  This would&lt;br/&gt;
mean the &quot;MergePolicy.merge&quot; method would return null if no merge is&lt;br/&gt;
necessary right now, and would return a MergeSpecification if a merge&lt;br/&gt;
is required.&lt;/p&gt;

&lt;p&gt;This way, it is IndexWriter that would execute the merge.  When the&lt;br/&gt;
merge is done, IndexWriter would then call the MergePolicy again to&lt;br/&gt;
give it a chance to &quot;cascade&quot;.  This simplifies the locking because&lt;br/&gt;
IndexWriter can synchronize on SegmentInfos when it calls&lt;br/&gt;
&quot;MergePolicy.merge&quot; and so MergePolicy no longer has to deal with this&lt;br/&gt;
complexity (that SegmentInfos change during merge).&lt;/p&gt;

&lt;p&gt;Then, with this change, we could make a ConcurrentMergePolicy that&lt;br/&gt;
could (I think) easily &quot;wrap&quot; itself around another MergePolicy X,&lt;br/&gt;
intercepting the calls to &quot;merge&quot;.  When the inner MergePolicy wants&lt;br/&gt;
to do a merge, the ConcurrentMergePolicy would in turn kick off that&lt;br/&gt;
merge in the BG but then return null to the IndexWriter allowing&lt;br/&gt;
IndexWriter to return to its caller, etc.&lt;/p&gt;

&lt;p&gt;Then, this also simplifies MergePolicy implementations because you no&lt;br/&gt;
longer have to deal w/ thread safety issues around driving your own&lt;br/&gt;
merges, cascading merges, dealing with sneaky SegmentInfos changing&lt;br/&gt;
while doing the merge, etc....&lt;/p&gt;</comment>
                    <comment id="12518165" author="steven_parkes" created="Tue, 7 Aug 2007 15:58:35 +0100"  >&lt;p&gt;	I&lt;br/&gt;
	think we ideally would like concurrency to be fully independent of the&lt;br/&gt;
	merge policy.&lt;/p&gt;

&lt;p&gt;I thought of that, too, while taking a fresh look at things again. It&apos;s my current approach, though I&apos;m not yet sure there won&apos;t be stumbling blocks. More soon, hopefully.&lt;/p&gt;

&lt;p&gt;	I think with one change to your MergePolicy API &amp;amp; control flow, we&lt;br/&gt;
	could make this work very well: instead of requiring the MergePolicy&lt;br/&gt;
	to call IndexWriter.merge, and do the cascading, it should just return&lt;br/&gt;
	the one MergeSpecification that should be done right now.&lt;/p&gt;

&lt;p&gt;Hmm ... interesting idea. I thought about it briefly, though I didn&apos;t pursue it (see below). It would end up changing the possible space of merge policies subtly. You 	wouldn&apos;t be able to have any state in the algorithm. Arguably this is a good thing. There is also a bit more overhead, since starting the computation of potential merges from scratch each time could imply a little more computation, but I suspect this is not significant.&lt;/p&gt;

&lt;p&gt;	When the inner MergePolicy wants&lt;br/&gt;
	to do a merge, the ConcurrentMergePolicy would in turn kick off that&lt;br/&gt;
	merge in the BG but then return null to the IndexWriter allowing&lt;br/&gt;
	IndexWriter to return to its caller, etc.&lt;/p&gt;

&lt;p&gt;I&apos;m a little unsure here. Are you saying the ConcurrentMergePolicy does the merges itself, rather than using the writer? That&apos;s going to mean a synchronization dance between the CMP and the writer. There&apos;s no question but that there has to be some synch dance, but my current thinking was to try to keep as cleanly within one class, IW, as I could.&lt;/p&gt;</comment>
                    <comment id="12518184" author="mikemccand" created="Tue, 7 Aug 2007 17:34:44 +0100"  >
&lt;p&gt;Some more feedback:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Is the separate IndexMerger interface really necessary?  Can&apos;t we&lt;br/&gt;
    just use IndexWriter directly?  It&apos;s somewhat awkward/forced now,&lt;br/&gt;
    because the interface has getters for ramBufferSizeMB and&lt;br/&gt;
    maxBufferedDocs that are really a &quot;writer&quot; (flushing) thing not a&lt;br/&gt;
    &quot;merging&quot; thing.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    While LogDocMergePolicy does need &quot;maxBufferedDocs&quot;, I think,&lt;br/&gt;
    instead, in IndexWriter&apos;s &quot;setMaxBufferedDocs()&quot; it should &quot;write&lt;br/&gt;
    through&quot; to the LogDocMergePolicy if that is the merge policy in&lt;br/&gt;
    use (and LogDocMergePolicy should store its own private&lt;br/&gt;
    &quot;minMergeDocs&quot;).&lt;/p&gt;

&lt;p&gt;    I think the three getters may not even be needed (based on&lt;br/&gt;
    comments below), in which case it seems like we shouldn&apos;t be&lt;br/&gt;
    creating a new interface.&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;In LogDocMergePolicy, it seems like the checking that&apos;s done for&lt;br/&gt;
    whether a SegmentInfo is in a different directory, as well as the&lt;br/&gt;
    subsequent copy to move it over to the IndexWriter&apos;s directory,&lt;br/&gt;
    should not live in the MergePolicy?&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Otherwise, every MergePolicy is going to have to duplicate this&lt;br/&gt;
    code.  Not to mention, we may someday create a more efficient way&lt;br/&gt;
    to copy than running a single-segment merge (which is a very&lt;br/&gt;
    inefficient, but, we only do it in addIndexes* I think).  I&apos;d like&lt;br/&gt;
    to capture this in one place (IndexWriter).&lt;/p&gt;

&lt;p&gt;    EG, the writer could have its own &quot;copyExternalSegments&quot; method&lt;br/&gt;
    which is called in addIndexes* and also optimize(), after the&lt;br/&gt;
    merge policy has done its merge, which does the check for wrong&lt;br/&gt;
    directory and subsequent copy.&lt;/p&gt;

&lt;p&gt;    I think this would mean IndexMerger.getDirectory() is not really&lt;br/&gt;
    needed.&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;The &quot;checkOptimize&quot; method in LogDocMergePolicy seems like it&lt;br/&gt;
    belongs back in IndexWriter: I think we don&apos;t want every&lt;br/&gt;
    MergePolicy having to replicate that tricky while condition.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    Maybe we could change MergePolicy.merge to take a boolean &quot;forced&quot;&lt;br/&gt;
    which, if true, means that the MergePolicy must now pick a merge&lt;br/&gt;
    even if it didn&apos;t think it was time to.  This would let us move&lt;br/&gt;
    that tricky while condition logic back into IndexWriter.&lt;/p&gt;

&lt;p&gt;    Also, I think at some point we may want to have an optimize()&lt;br/&gt;
    method that takes an int parameter stating the max # segments in&lt;br/&gt;
    the resulting index.  This would allow you to optimize down to &amp;lt;=&lt;br/&gt;
    N segments w/o paying full cost of a complete &quot;only one segment&quot;&lt;br/&gt;
    optimize.  If we had a &quot;forced&quot; boolean then we could build such&lt;br/&gt;
    an optimize method in the future, whereas as it stands now it&lt;br/&gt;
    would not be so easy to retrofit previously created MergePolicy&lt;br/&gt;
    classes to do this.&lt;/p&gt;

&lt;p&gt;And some more minor feedback:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;I love the simplification of addIndexesNoOptimize &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  Though (same&lt;br/&gt;
    comment as above) I think we should move that final &quot;copy if&lt;br/&gt;
    different directory&quot; step back in IndexWriter.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;There are some minor things that should not be committed eg the&lt;br/&gt;
    added &quot;infoStream = null&quot; in IndexFileDeleter.  I typically try to&lt;br/&gt;
    put a comment &quot;// nocommit&quot; above such changes as I make them to&lt;br/&gt;
    remind myself and keep them from slipping in.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;In the deprecated IndexWriter methods you&apos;re doing a hard cast to&lt;br/&gt;
    LogDocMergePolicy which gives a bad result if you&apos;re using a&lt;br/&gt;
    different merge policy; maybe catch the class cast exception (or,&lt;br/&gt;
    better, check upfront if it&apos;s an instanceof) and raise a more&lt;br/&gt;
    reasonable exception if not?&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;IndexWriter around line 1908 has for loop that has commented out&lt;br/&gt;
    &quot;System.err.println&quot;; we should just comment out/remove for loop&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;These commented out synchronized spook me a bit:&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;      /* synchronized(segmentInfos) */ {&lt;/p&gt;

&lt;p&gt;    Are they needed in these contexts?  Is this only once we have&lt;br/&gt;
    concurrent merging?  (This ties back to the first feedback to&lt;br/&gt;
    simplify MergePolicy API so that this kind of locking is only&lt;br/&gt;
    needed inside IndexWriter).&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Can we support non-contiguous merges?  If I understand it&lt;br/&gt;
    correctly, the MergeSpecification can express such a merge, it&apos;s&lt;br/&gt;
    just that the current IndexMerger (IndexWriter) cannot execute it,&lt;br/&gt;
    right?  So we are at least not precluding fixing this in the&lt;br/&gt;
    future.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;It confuses me that MergePolicy has a method &quot;merge(...)&quot; &amp;#8211; can&lt;br/&gt;
    we rename it to &quot;maybeMerge(..)&quot; or &quot;checkForMerge(...)&quot;?  Ie,&lt;br/&gt;
    this method determines whether a merge is necessary and, if so, it&lt;br/&gt;
    then asks IndexMerger to in fact execute the merge (or, returns&lt;br/&gt;
    the spec)?&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Instead of IndexWriter.releaseMergePolicy() can we have&lt;br/&gt;
    IndexWriter only close the merge policy if it was the one that had&lt;br/&gt;
    created it?  (Similar to how IndexWriter closes the dir if it has&lt;br/&gt;
    opened it from a String or File, but does not close it if it was&lt;br/&gt;
    passed in).&lt;/li&gt;
&lt;/ul&gt;

</comment>
                    <comment id="12518186" author="mikemccand" created="Tue, 7 Aug 2007 17:47:06 +0100"  >&lt;p&gt;&amp;gt; &amp;gt; I think we ideally would like concurrency to be fully independent of&lt;br/&gt;
&amp;gt; &amp;gt; the merge policy.&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; I thought of that, too, while taking a fresh look at things&lt;br/&gt;
&amp;gt; again. It&apos;s my current approach, though I&apos;m not yet sure there won&apos;t&lt;br/&gt;
&amp;gt; be stumbling blocks. More soon, hopefully.&lt;/p&gt;

&lt;p&gt;Well I think the current MergePolicy API (where the &quot;merge&quot; method&lt;br/&gt;
calls IndexWriter.merge itself, must cascade itself, etc.) makes it&lt;br/&gt;
hard to build a generic ConcurrentMergePolicy &quot;wrapper&quot; that you could&lt;br/&gt;
use to make any MergePolicy concurrent &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/help_16.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;.  How would you do it?&lt;/p&gt;

&lt;p&gt;EG I&apos;m working on a new MergePolicy for &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-845&quot; title=&quot;If you &amp;quot;flush by RAM usage&amp;quot; then IndexWriter may over-merge&quot;&gt;&lt;del&gt;LUCENE-845&lt;/del&gt;&lt;/a&gt;, which would be&lt;br/&gt;
nice to run concurrently, but I&apos;d really rather not have to figure out&lt;br/&gt;
how to build my own concurrency/locking/etc in it.  Ideally&lt;br/&gt;
&quot;concurrency&quot; is captured as a single wrapper class that we all can&lt;br/&gt;
re-use on top of any MergePolicy.  I think we can do that with the&lt;br/&gt;
proposed simplification.&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; I think with one change to your MergePolicy API &amp;amp; control flow, we&lt;br/&gt;
&amp;gt; &amp;gt; could make this work very well: instead of requiring the MergePolicy&lt;br/&gt;
&amp;gt; &amp;gt; to call IndexWriter.merge, and do the cascading, it should just&lt;br/&gt;
&amp;gt; &amp;gt; return the one MergeSpecification that should be done right now.&lt;/p&gt;

&lt;p&gt;&amp;gt; Hmm ... interesting idea. I thought about it briefly, though I&lt;br/&gt;
&amp;gt; didn&apos;t pursue it (see below). It would end up changing the possible&lt;br/&gt;
&amp;gt; space of merge policies subtly. You wouldn&apos;t be able to have any&lt;br/&gt;
&amp;gt; state in the algorithm. Arguably this is a good thing. There is also&lt;br/&gt;
&amp;gt; a bit more overhead, since starting the computation of potential&lt;br/&gt;
&amp;gt; merges from scratch each time could imply a little more computation,&lt;br/&gt;
&amp;gt; but I suspect this is not significant.&lt;/p&gt;

&lt;p&gt;I think you can still have state (as instance variables in your&lt;br/&gt;
class)?  How would this simplification restrict the space of merge&lt;br/&gt;
policies?&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; When the inner MergePolicy wants to do a merge, the&lt;br/&gt;
&amp;gt; &amp;gt; ConcurrentMergePolicy would in turn kick off that merge in the BG but&lt;br/&gt;
&amp;gt; &amp;gt; then return null to the IndexWriter allowing IndexWriter to return to&lt;br/&gt;
&amp;gt; &amp;gt; its caller, etc.&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; I&apos;m a little unsure here. Are you saying the ConcurrentMergePolicy&lt;br/&gt;
&amp;gt; does the merges itself, rather than using the writer? That&apos;s going&lt;br/&gt;
&amp;gt; to mean a synchronization dance between the CMP and the&lt;br/&gt;
&amp;gt; writer. There&apos;s no question but that there has to be some synch&lt;br/&gt;
&amp;gt; dance, but my current thinking was to try to keep as cleanly within&lt;br/&gt;
&amp;gt; one class, IW, as I could.&lt;/p&gt;

&lt;p&gt;Oh, no: ConcurrentMergePolicy would still call IndexWriter.merge(spec),&lt;br/&gt;
just with a separate thread.  And so all synchronization required is&lt;br/&gt;
still inside IndexWriter (I think?).&lt;/p&gt;

&lt;p&gt;In fact, if we stick with the current MergePolicy API, aren&apos;t you&lt;br/&gt;
going to have to put some locking into eg the LogDocMergePolicy when&lt;br/&gt;
concurrent merges might be happening?  With the new approach,&lt;br/&gt;
IndexWriter could invoke MergePolicy.merge under a&lt;br/&gt;
&quot;synchronized(segmentInfos)&quot;, and then each MergePolicy doesn&apos;t have&lt;br/&gt;
to deal with locking at all.&lt;/p&gt;</comment>
                    <comment id="12518210" author="steven_parkes" created="Tue, 7 Aug 2007 18:54:53 +0100"  >&lt;p&gt;    Is the separate IndexMerger interface really necessary?&lt;/p&gt;

&lt;p&gt;I wrestled with this, so in the past, it wouldn&apos;t have taken much to convince me otherwise. The reason for the extra interface is I was hoping to discourage or create a little extra friction for merge policies in terms of looking too much into the internals of IndexWriter.&lt;/p&gt;

&lt;p&gt;As an example, it&apos;s not a good idea for merge policies to be able to access IndexWriter#segmentInfos directly. (That&apos;s a case I would like to solve by making segmentInfos private, but I haven&apos;t looked at that completely yet and even beyond that case, I&apos;d still like merge policies to have a very clean interface with IWs.)&lt;/p&gt;

&lt;p&gt;It feels kinda weird for me to be arguing for constraints since I work mostly in dynamic languages that have none of this stuff. But it reflects my goal that merge policies simply be algorithms, not real workers.&lt;/p&gt;

&lt;p&gt;Moreover, I think it may be useful for implementing concurrency (see below).&lt;/p&gt;

&lt;p&gt;    While LogDocMergePolicy does need &quot;maxBufferedDocs&quot;, I think,&lt;br/&gt;
    instead, in IndexWriter&apos;s &quot;setMaxBufferedDocs()&quot; it should &quot;write&lt;br/&gt;
    through&quot; to the LogDocMergePolicy if that is the merge policy in&lt;br/&gt;
    use (and LogDocMergePolicy should store its own private&lt;br/&gt;
    &quot;minMergeDocs&quot;).&lt;/p&gt;

&lt;p&gt;The thing here is that the merge policy has nothing to do with max buffered docs, right? The code for buffering docs for the first segment is wholly in the IndexWriter. LogDocMergePolicy happens to need it (in its current incarnation) in order to handle the way the log levels are computed. This could, of course, be changed. There&apos;s nothing that says a merge policy has to look at these values, just that they&apos;re available should the merge policy want to look.&lt;/p&gt;

&lt;p&gt;I guess my idea was that the index writer was responsible for handling the initial segment (with DocsWriter, if it wants) and also to provide an indication to the merge policies how it was handling them.&lt;/p&gt;

&lt;p&gt;It&apos;s possible to have the merge policy influence the first segment size but that opens up a lot of issues. Does every merge policy then have to know how to trade between buffering by doc count and buffering by ram? I was hoping to avoid that.&lt;/p&gt;

&lt;p&gt;I&apos;m not all that happy with this the way it is, but supporting both by-doc and by-ram is messy but seems necessary. This was my take on making it least messy?&lt;/p&gt;

&lt;p&gt;    In LogDocMergePolicy, it seems like the checking that&apos;s done for&lt;br/&gt;
    whether a SegmentInfo is in a different directory, as well as the&lt;br/&gt;
    subsequent copy to move it over to the IndexWriter&apos;s directory,&lt;br/&gt;
    should not live in the MergePolicy?&lt;/p&gt;

&lt;p&gt;I see two parts to this.&lt;/p&gt;

&lt;p&gt;First, I hesitate to make it not possible for merge policy to see the directory information, i.e., remove IndexMerger#getDirectory(). Copying a segment is one way to get it into the current directory, but merging with other segments does to. A merge policy could decide to go ahead and merge a bunch of segments that are in other directories rather than just copy them individually. Taking away getDirectory() removes that option.&lt;/p&gt;

&lt;p&gt;As to how to handle the case where single segments are copied, I guess my main reason for leaving that in the merge policy would be for simplicity. Seems nicer to have all segment amalgamation management in one place, rather than some in one class and some in another. Could be factored into an optional base merge policy for derived classes to use as they might like.&lt;/p&gt;

&lt;p&gt;    The &quot;checkOptimize&quot; method in LogDocMergePolicy seems like it&lt;br/&gt;
    belongs back in IndexWriter: I think we don&apos;t want every&lt;br/&gt;
    MergePolicy having to replicate that tricky while condition.&lt;/p&gt;

&lt;p&gt;The reason for not doing this was I can imagine different merge policies having a different model of what optimize means. I can imagine some policies that would not optimize everything down to a single segment but instead obeyed a max segment size. But we could factor the default conditional into an optional base class, as above.&lt;/p&gt;

&lt;p&gt;It is an ugly conditional that there might be better way to formulate, so that policies don&apos;t have to look at the grody details like hasSeparateNorms. But I&apos;d still like the merge policies to be able to decide what optimize means at a high level.&lt;/p&gt;

&lt;p&gt;    Maybe we could change MergePolicy.merge to take a boolean &quot;forced&quot;&lt;br/&gt;
    which, if true, means that the MergePolicy must now pick a merge&lt;br/&gt;
    even if it didn&apos;t think it was time to.  This would let us move&lt;br/&gt;
    that tricky while condition logic back into IndexWriter.&lt;/p&gt;

&lt;p&gt;I didn&apos;t follow this. forced == optimize? If not, what does pick a merge mean? Not sure what LogDoc should do for merge(force=true) if it thinks everything is fine?&lt;/p&gt;

&lt;p&gt;    Also, I think at some point we may want to have an optimize()&lt;br/&gt;
    method that takes an int parameter stating the max # segments in&lt;br/&gt;
    the resulting index.&lt;/p&gt;

&lt;p&gt;I think this is great functionality for a merge policy, but what about just making that part of the individual merge policy interface, rather than linked to IndexWriter? That was one goal of making a factored merge policy: that you could do these tweaks without changing IndexWriter.&lt;/p&gt;

&lt;p&gt;    This would allow you to optimize down to &amp;lt;=&lt;br/&gt;
    N segments w/o paying full cost of a complete &quot;only one segment&quot;&lt;br/&gt;
    optimize.  If we had a &quot;forced&quot; boolean then we could build such&lt;br/&gt;
    an optimize method in the future, whereas as it stands now it&lt;br/&gt;
    would not be so easy to retrofit previously created MergePolicy&lt;br/&gt;
    classes to do this.&lt;/p&gt;

&lt;p&gt;I haven&apos;t looked at how difficult it would be to make LogDoc sufficiently derivable to allow a derived class to add this tweak. If I could, would it be enough?&lt;/p&gt;

&lt;p&gt;    There are some minor things that should not be committed eg the&lt;br/&gt;
    added &quot;infoStream = null&quot; in IndexFileDeleter.  I typically try to&lt;br/&gt;
    put a comment &quot;// nocommit&quot; above such changes as I make them to&lt;br/&gt;
    remind myself and keep them from slipping in.&lt;/p&gt;

&lt;p&gt;You&apos;re right and thanks for the idea. Obvious now.&lt;/p&gt;

&lt;p&gt;    In the deprecated IndexWriter methods you&apos;re doing a hard cast to&lt;br/&gt;
    LogDocMergePolicy which gives a bad result if you&apos;re using a&lt;br/&gt;
    different merge policy; maybe catch the class cast exception (or,&lt;br/&gt;
    better, check upfront if it&apos;s an instanceof) and raise a more&lt;br/&gt;
    reasonable exception if not?&lt;/p&gt;

&lt;p&gt;Agreed.&lt;/p&gt;

&lt;p&gt;    IndexWriter around line 1908 has for loop that has commented out&lt;br/&gt;
    &quot;System.err.println&quot;; we should just comment out/remove for loop&lt;/p&gt;

&lt;p&gt;The whole loop will be gone before commit but I didn&apos;t want to delete it yet since I might need to turn it back on for more debugging.  It should, of course, have a &quot;// nocommit&quot; comment.&lt;/p&gt;

&lt;p&gt;    These commented out synchronized spook me a bit:&lt;/p&gt;

&lt;p&gt;      /* synchronized(segmentInfos) */ {&lt;/p&gt;

&lt;p&gt;This is from my old code. I left it in there as a hint as I work on the concurrent stuff again. It&apos;s only a weak hint, though, because things have changed a lot since that code was even partially functional. Ignore it. It won&apos;t go into the serial patch and anything for &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-870&quot; title=&quot;add concurrent merge policy&quot;&gt;&lt;del&gt;LUCENE-870&lt;/del&gt;&lt;/a&gt; will have to have its own justification.&lt;/p&gt;

&lt;p&gt;    Can we support non-contiguous merges?  If I understand it&lt;br/&gt;
    correctly, the MergeSpecification can express such a merge, it&apos;s&lt;br/&gt;
    just that the current IndexMerger (IndexWriter) cannot execute it,&lt;br/&gt;
    right?  So we are at least not precluding fixing this in the&lt;br/&gt;
    future.&lt;/p&gt;

&lt;p&gt;As far as I&apos;ve seen so far, there are no barriers to non-contiguous merges. Maybe something will crop up that is, but in what I&apos;ve done, I haven&apos;t seen any.&lt;/p&gt;

&lt;p&gt;    It confuses me that MergePolicy has a method &quot;merge(...)&quot; &amp;#8211; can&lt;br/&gt;
    we rename it to &quot;maybeMerge(..)&quot; or &quot;checkForMerge(...)&quot;?&lt;/p&gt;

&lt;p&gt;I suppose. I&apos;m not a big fan of the &quot;maybeFoo&quot; style of naming. I think of &quot;merge&quot; like &quot;optimize&quot;: make it so / idempotent. But I&apos;m certainly willing to write whatever people find clearest. &lt;/p&gt;

&lt;p&gt;    Instead of IndexWriter.releaseMergePolicy() can we have&lt;br/&gt;
    IndexWriter only close the merge policy if it was the one that had&lt;br/&gt;
    created it?  (Similar to how IndexWriter closes the dir if it has&lt;br/&gt;
    opened it from a String or File, but does not close it if it was&lt;br/&gt;
    passed in).&lt;/p&gt;

&lt;p&gt;This precludes&lt;/p&gt;

&lt;p&gt;	iw.setMergePolicy(new MyMergePolicy(...));&lt;br/&gt;
      ...&lt;br/&gt;
	iw.close();&lt;/p&gt;

&lt;p&gt;You&apos;re always going to have to&lt;/p&gt;

&lt;p&gt;	MergePolicy mp = new MyMergePolicy(...);&lt;br/&gt;
	iw.setMergePolicy(mp);&lt;br/&gt;
      ...&lt;br/&gt;
      iw.close();&lt;br/&gt;
      mp.close();&lt;/p&gt;

&lt;p&gt;The implementation&apos;s much cleaner using the semantics you describe, but I was thinking it&apos;d be better to optimize for the usability of the common client code case?&lt;/p&gt;

&lt;p&gt;	Well I think the current MergePolicy API (where the &quot;merge&quot; method&lt;br/&gt;
	calls IndexWriter.merge itself, must cascade itself, etc.) makes it&lt;br/&gt;
	hard to build a generic ConcurrentMergePolicy &quot;wrapper&quot; that you could&lt;br/&gt;
	use to make any MergePolicy concurrent &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/help_16.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;.  How would you do it?&lt;/p&gt;

&lt;p&gt;I really haven&apos;t had time to go heads down on this (the old concurrent merge policy was a derived class rather than a wrapper class). But I was thinking that perhaps ConurrentMergePolicy would actually wrap IndexWriter as well as the serial merge policy, i.e., implement IndexMerger (my biggest argument for IM at this point). But I haven&apos;t looked deeply at whether this will work but I think it has at least a chance.&lt;/p&gt;

&lt;p&gt;I should know more about this is a day or two.&lt;/p&gt;

&lt;p&gt;	I think you can still have state (as instance variables in your&lt;br/&gt;
	class)?  How would this simplification restrict the space of merge&lt;br/&gt;
	policies?&lt;/p&gt;

&lt;p&gt;s/state/stack state/. Yeah, you can always unwind your loops and lift your recursions, put all that stack state into instance variables. But, well, yuck. I&apos;d like to make it easy to write simple merge policies and take up the heavy lifting elsewhere. Hopefully there will be more merge policies than index writers.&lt;/p&gt;

&lt;p&gt;	Oh, no: ConcurrentMergePolicy would still call IndexWriter.merge(spec),&lt;br/&gt;
	just with a separate thread.  And so all synchronization required is&lt;br/&gt;
	still inside IndexWriter (I think?).&lt;/p&gt;

&lt;p&gt;That&apos;s my idea.&lt;/p&gt;

&lt;p&gt;The synchronization is still tricky, since parts of segmentInfos are getting changed at various times and there are references and/or copies of it other places. And as Ning pointed out to me, we also have to deal with buffered delete terms. I&apos;d say I got about 80% of the way there on the last go around. I&apos;m hoping to get all the way this time.&lt;/p&gt;

&lt;p&gt;	In fact, if we stick with the current MergePolicy API, aren&apos;t you&lt;br/&gt;
	going to have to put some locking into eg the LogDocMergePolicy when&lt;br/&gt;
	concurrent merges might be happening?&lt;/p&gt;

&lt;p&gt;Yes and no. If CMP implements IndexMerger, I think we might be okay? In the previous iteration, I used derivation so that ConcurrentLogDocMergePolicy derived from the serial version but had the necessary threading. I agree that a wrapper is better solution if it can be made to work.&lt;/p&gt;</comment>
                    <comment id="12518222" author="steven_parkes" created="Tue, 7 Aug 2007 19:35:49 +0100"  >&lt;p&gt;On a related note, Mike, there a few FIXME&apos;s in IW related to useCompoundFile: it doesn&apos;t exist in IW anymore (other than as a deprecated feature). The goal was to allow merge policies to decide when to use compound files, perhaps on a segment-by-segment basis. That all works fine for merge operations.&lt;/p&gt;

&lt;p&gt;But there&apos;s also the case of new segments, what format they should be in. These are segments that are going to be created by IW (via DocsWriter?) My stab at this was to have IW ask the merge policy. Since this isn&apos;t a merge, per say, the IW passes to the merge policy the current set of segment infos and the new segment info, asking what format the new segment info should use. So MergePolicy has&lt;/p&gt;

&lt;p&gt;	boolean useCompoundFile(SegmentInfos segments, SegmentInfo newSegment);&lt;/p&gt;

&lt;p&gt;Looking at IW, with the new DocsWriter stuff, it looks like there isn&apos;t a segmentInfo object for the new segment at the time the predicate is being called. Would it be possible to make one? Something like DocumentsWriter#getDocStoreSegmentInfo() analogous to DocumentsWriter#getDocStoreSegment()? It could be an object just thrown away.&lt;/p&gt;

&lt;p&gt;Is this a bad idea?&lt;/p&gt;</comment>
                    <comment id="12518237" author="mikemccand" created="Tue, 7 Aug 2007 20:47:51 +0100"  >&lt;p&gt;&amp;gt; Looking at IW, with the new DocsWriter stuff, it looks like there&lt;br/&gt;
&amp;gt; isn&apos;t a segmentInfo object for the new segment at the time the&lt;br/&gt;
&amp;gt; predicate is being called. Would it be possible to make one?&lt;br/&gt;
&amp;gt; Something like DocumentsWriter#getDocStoreSegmentInfo() analogous to&lt;br/&gt;
&amp;gt; DocumentsWriter#getDocStoreSegment()? It could be an object just&lt;br/&gt;
&amp;gt; thrown away.&lt;/p&gt;

&lt;p&gt;Hmmm: it looks like you&apos;re calling&lt;br/&gt;
&quot;mergePolicy.useCompoundFile(segmentInfos,null)&quot; twice: once inside&lt;br/&gt;
flushDocStores and immediately thereafter when flushDocStores returns&lt;br/&gt;
into the flush() code.  Maybe you should change flushDocStores to&lt;br/&gt;
return whether or not the flushed files are in compound format&lt;br/&gt;
instead?&lt;/p&gt;

&lt;p&gt;Since flushDocStores() is flushing only the &quot;doc store&quot; index files&lt;br/&gt;
(stored fields &amp;amp; term vectors) it&apos;s not a real &quot;segment&quot; so it&apos;s a&lt;br/&gt;
somewhat forced fit to make a SegmentInfo in this case.  I guess we&lt;br/&gt;
could make a &quot;largely empty&quot; SegmentInfo and fill in what we can, but&lt;br/&gt;
that&apos;s somewhat dangerous (eg methods like files() would have to be&lt;br/&gt;
fixed to deal with this).&lt;/p&gt;

&lt;p&gt;Maybe, instead, we could use one of the SegmentInfo instances from a&lt;br/&gt;
segment that refers to this doc store segment?  This would just mean&lt;br/&gt;
stepping through all SegmentInfo&apos;s and finding the first one (say)&lt;br/&gt;
whose docStoreSegment equals the one we are now flushing?  Still it&lt;br/&gt;
would be good to differentiate this case (creating compound file for&lt;br/&gt;
doc store files vs for a real segment) to MergePolicy somehow (maybe&lt;br/&gt;
add a boolean arg &quot;isDocStore&quot; or some such?).&lt;/p&gt;</comment>
                    <comment id="12518251" author="steven_parkes" created="Tue, 7 Aug 2007 21:50:37 +0100"  >&lt;p&gt;Ah. I understand better now. I have to admit, I haven&apos;t kept up to date on some of the deeper file stuff in &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-843&quot; title=&quot;improve how IndexWriter uses RAM to buffer added documents&quot;&gt;&lt;del&gt;LUCENE-843&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;It seems to me there&apos;s quite a bit of difference between segment files and doc store files. Since doc store files can be referred to by multiple segments, they can get quite large. I don&apos;t have any trouble imaging that a merge policy might want to CFS 10MB segments but not 10GB doc stores?&lt;/p&gt;

&lt;p&gt;I&apos;m thinking maybe a MergePolicy#useCompoundDocStore( SegmentInfos ) makes sense? The naive case would still just use the static setting we have now, but we could think about a better implementation:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Maybe never cfs doc store files? Is that an unreasonable default? It just strikes me that there should be far fewer of these so that we don&apos;t need to and on the other end, if they are big, CFS&apos;ing them is going to be expensive.&lt;/li&gt;
	&lt;li&gt;Do something smart but easy depending on number and size&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12518263" author="mikemccand" created="Tue, 7 Aug 2007 22:37:47 +0100"  >&lt;p&gt;&amp;gt; I&apos;m thinking maybe a MergePolicy#useCompoundDocStore( SegmentInfos )&lt;br/&gt;
&amp;gt; makes sense? The naive case would still just use the static setting&lt;br/&gt;
&amp;gt; we have now, but we could think about a better implementation:&lt;/p&gt;

&lt;p&gt;I think adding that new method to MergePolicy is great!  And, just&lt;br/&gt;
using the same &quot;useCompoundFile&quot; as normal segmetns is good for&lt;br/&gt;
starters (and, this matches what&apos;s done today).&lt;/p&gt;</comment>
                    <comment id="12518435" author="mikemccand" created="Wed, 8 Aug 2007 13:48:18 +0100"  >&lt;p&gt;New feedback:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Are you going to fix all unit tests that call the now-deprecated&lt;br/&gt;
    APIs?  (You should still leave a few tests using the deprecated&lt;br/&gt;
    APIs to make sure they in fact continue to work, but most tests&lt;br/&gt;
    should not use the deprecated APIs).&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Responses to previous feedback:&lt;/p&gt;

&lt;p&gt;&amp;gt; As an example, it&apos;s not a good idea for merge policies to be able to&lt;br/&gt;
&amp;gt; access IndexWriter#segmentInfos directly. (That&apos;s a case I would&lt;br/&gt;
&amp;gt; like to solve by making segmentInfos private, but I haven&apos;t looked&lt;br/&gt;
&amp;gt; at that completely yet and even beyond that case, I&apos;d still like&lt;br/&gt;
&amp;gt; merge policies to have a very clean interface with IWs.)&lt;/p&gt;

&lt;p&gt;Agreed, but the solution to that is to make segmentInfos private, not&lt;br/&gt;
to make a whole new interface.  Ie, this is an IndexWriter problem, so&lt;br/&gt;
we should fix it in IndexWriter.&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; While LogDocMergePolicy does need &quot;maxBufferedDocs&quot;, I think,&lt;br/&gt;
&amp;gt; &amp;gt; instead, in IndexWriter&apos;s &quot;setMaxBufferedDocs()&quot; it should &quot;write&lt;br/&gt;
&amp;gt; &amp;gt; through&quot; to the LogDocMergePolicy if that is the merge policy in&lt;br/&gt;
&amp;gt; &amp;gt; use (and LogDocMergePolicy should store its own private&lt;br/&gt;
&amp;gt; &amp;gt; &quot;minMergeDocs&quot;).&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; The thing here is that the merge policy has nothing to do with max&lt;br/&gt;
&amp;gt; buffered docs, right? The code for buffering docs for the first&lt;br/&gt;
&amp;gt; segment is wholly in the IndexWriter. LogDocMergePolicy happens to&lt;br/&gt;
&amp;gt; need it (in its current incarnation) in order to handle the way the&lt;br/&gt;
&amp;gt; log levels are computed. This could, of course, be changed. There&apos;s&lt;br/&gt;
&amp;gt; nothing that says a merge policy has to look at these values, just&lt;br/&gt;
&amp;gt; that they&apos;re available should the merge policy want to look.&lt;/p&gt;

&lt;p&gt;Exactly: these settings decide when a segment is flushed, so, why put&lt;br/&gt;
them into IndexMerger interface?  They shouldn&apos;t have anything to with&lt;br/&gt;
merging; I think they should be removed.&lt;/p&gt;

&lt;p&gt;For &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-845&quot; title=&quot;If you &amp;quot;flush by RAM usage&amp;quot; then IndexWriter may over-merge&quot;&gt;&lt;del&gt;LUCENE-845&lt;/del&gt;&lt;/a&gt; I&apos;m working on a replacement for LogDocMergePolicy that&lt;br/&gt;
does not use maxBufferedDocs.&lt;/p&gt;

&lt;p&gt;&amp;gt; I guess my idea was that the index writer was responsible for&lt;br/&gt;
&amp;gt; handling the initial segment (with DocsWriter, if it wants) and also&lt;br/&gt;
&amp;gt; to provide an indication to the merge policies how it was handling&lt;br/&gt;
&amp;gt; them.&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; It&apos;s possible to have the merge policy influence the first segment&lt;br/&gt;
&amp;gt; size but that opens up a lot of issues. Does every merge policy then&lt;br/&gt;
&amp;gt; have to know how to trade between buffering by doc count and&lt;br/&gt;
&amp;gt; buffering by ram? I was hoping to avoid that.&lt;/p&gt;

&lt;p&gt;Yeah, I don&apos;t think merge policy should dictate flushing either;&lt;br/&gt;
especially because app logic above IndexWriter can already easily call&lt;br/&gt;
flush() if necessary.&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; In LogDocMergePolicy, it seems like the checking that&apos;s done for&lt;br/&gt;
&amp;gt; &amp;gt; whether a SegmentInfo is in a different directory, as well as the&lt;br/&gt;
&amp;gt; &amp;gt; subsequent copy to move it over to the IndexWriter&apos;s directory,&lt;br/&gt;
&amp;gt; &amp;gt; should not live in the MergePolicy?&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; I see two parts to this.&lt;br/&gt;
&amp;gt; &lt;br/&gt;
&amp;gt; First, I hesitate to make it not possible for merge policy to see&lt;br/&gt;
&amp;gt; the directory information, i.e., remove&lt;br/&gt;
&amp;gt; IndexMerger#getDirectory(). Copying a segment is one way to get it&lt;br/&gt;
&amp;gt; into the current directory, but merging with other segments does&lt;br/&gt;
&amp;gt; to. A merge policy could decide to go ahead and merge a bunch of&lt;br/&gt;
&amp;gt; segments that are in other directories rather than just copy them&lt;br/&gt;
&amp;gt; individually. Taking away getDirectory() removes that option.&lt;/p&gt;

&lt;p&gt;Agreed, a &quot;sophisticated&quot; merge policy would go and merge segments in&lt;br/&gt;
other directories.  But, it should not have to.&lt;/p&gt;

&lt;p&gt;I&apos;m not proposing making it &quot;not possible&quot;; I&apos;m proposing the merge&lt;br/&gt;
policy is given IndexWriter at which point it can getDirectory() from&lt;br/&gt;
it.  (Ie the extra interface solely for this purpose is overkill).&lt;/p&gt;

&lt;p&gt;&amp;gt; As to how to handle the case where single segments are copied, I&lt;br/&gt;
&amp;gt; guess my main reason for leaving that in the merge policy would be&lt;br/&gt;
&amp;gt; for simplicity. Seems nicer to have all segment amalgamation&lt;br/&gt;
&amp;gt; management in one place, rather than some in one class and some in&lt;br/&gt;
&amp;gt; another. Could be factored into an optional base merge policy for&lt;br/&gt;
&amp;gt; derived classes to use as they might like.&lt;/p&gt;

&lt;p&gt;I don&apos;t see this as simpler: I see it as making the MergePolicy&lt;br/&gt;
writer&apos;s job more complex.  I also see it as substantial duplicated&lt;br/&gt;
code (I just had to copy/paste a bunch of code in working on my&lt;br/&gt;
MergePolicy in &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-845&quot; title=&quot;If you &amp;quot;flush by RAM usage&amp;quot; then IndexWriter may over-merge&quot;&gt;&lt;del&gt;LUCENE-845&lt;/del&gt;&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;I think factoring into a base class is an OK solution, but, it&lt;br/&gt;
shouldn&apos;t be MergePolicy&apos;s job to remember to call this final &quot;move&lt;br/&gt;
any segments in the wrong directory over&quot; code.  As long as its in one&lt;br/&gt;
place and people don&apos;t have to copy/paste code between MergePolicy&lt;br/&gt;
sources.&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; The &quot;checkOptimize&quot; method in LogDocMergePolicy seems like it&lt;br/&gt;
&amp;gt; &amp;gt; belongs back in IndexWriter: I think we don&apos;t want every&lt;br/&gt;
&amp;gt; &amp;gt; MergePolicy having to replicate that tricky while condition.&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; The reason for not doing this was I can imagine different merge&lt;br/&gt;
&amp;gt; policies having a different model of what optimize means. I can&lt;br/&gt;
&amp;gt; imagine some policies that would not optimize everything down to a&lt;br/&gt;
&amp;gt; single segment but instead obeyed a max segment size. But we could&lt;br/&gt;
&amp;gt; factor the default conditional into an optional base class, as&lt;br/&gt;
&amp;gt; above.&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; It is an ugly conditional that there might be better way to&lt;br/&gt;
&amp;gt; formulate, so that policies don&apos;t have to look at the grody details&lt;br/&gt;
&amp;gt; like hasSeparateNorms. But I&apos;d still like the merge policies to be&lt;br/&gt;
&amp;gt; able to decide what optimize means at a high level.&lt;/p&gt;

&lt;p&gt;Agreed: I too don&apos;t want to preclude variants to optimize like&lt;br/&gt;
&quot;optimize to at most N segments&quot;.  (Maybe we should add that method,&lt;br/&gt;
now, to IndexWriter, and fix MergePolicy to work with this?).&lt;/p&gt;

&lt;p&gt;So, yes, please at least factor this out into a base class.  In&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-845&quot; title=&quot;If you &amp;quot;flush by RAM usage&amp;quot; then IndexWriter may over-merge&quot;&gt;&lt;del&gt;LUCENE-845&lt;/del&gt;&lt;/a&gt; this was another copy/paste for me (ick).  I think there&lt;br/&gt;
should in fact be a default optimize() in the base class that does&lt;br/&gt;
what current IndexWriter now does so that a MergePolicy need not&lt;br/&gt;
implement optimize at all.&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; Maybe we could change MergePolicy.merge to take a boolean &quot;forced&quot;&lt;br/&gt;
&amp;gt; &amp;gt; which, if true, means that the MergePolicy must now pick a merge&lt;br/&gt;
&amp;gt; &amp;gt; even if it didn&apos;t think it was time to. This would let us move&lt;br/&gt;
&amp;gt; &amp;gt; that tricky while condition logic back into IndexWriter.&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; I didn&apos;t follow this. forced == optimize? If not, what does pick a&lt;br/&gt;
&amp;gt; merge mean? Not sure what LogDoc should do for merge(force=true) if&lt;br/&gt;
&amp;gt; it thinks everything is fine?&lt;/p&gt;

&lt;p&gt;No, forced would mean the merge policy must do a merge; whereas,&lt;br/&gt;
normally, it&apos;s free not to do a merge until it wants to.  Instead of&lt;br/&gt;
boolean argument we could have two methods, one called &quot;merge&quot; (you&lt;br/&gt;
must merge) and one called &quot;maybeMerge&quot; or &quot;checkForMerges&quot;.&lt;/p&gt;

&lt;p&gt;Ie, optimize is really a series of forced merges: we are merging&lt;br/&gt;
segments from different levels, N times, until we are down to 1&lt;br/&gt;
segment w/ no deletes, norms, etc.&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; Also, I think at some point we may want to have an optimize()&lt;br/&gt;
&amp;gt; &amp;gt; method that takes an int parameter stating the max # segments in&lt;br/&gt;
&amp;gt; &amp;gt; the resulting index.&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; I think this is great functionality for a merge policy, but what&lt;br/&gt;
&amp;gt; about just making that part of the individual merge policy&lt;br/&gt;
&amp;gt; interface, rather than linked to IndexWriter? That was one goal of&lt;br/&gt;
&amp;gt; making a factored merge policy: that you could do these tweaks&lt;br/&gt;
&amp;gt; without changing IndexWriter.&lt;/p&gt;

&lt;p&gt;Well, it&apos;s sort of awkward if you want to vary that max # segments.&lt;br/&gt;
Say during the day you optimize down to 15 segments every time you&lt;br/&gt;
update the index, but then at night you want to optimize down to 5.&lt;br/&gt;
If we don&apos;t add method to IndexWriter you then must have instance var&lt;br/&gt;
on your MergePolicy that you set, then you call optimize.  It&apos;s not&lt;br/&gt;
clean since really it should be a parameter.&lt;/p&gt;

&lt;p&gt;And, with the merge/maybeMerge separation above, every merge policy&lt;br/&gt;
could have a default implementation for optimize(int maxNumSegments)&lt;br/&gt;
(in MergePolicy base class or in IndexWriter).&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; Can we support non-contiguous merges? If I understand it&lt;br/&gt;
&amp;gt; &amp;gt; correctly, the MergeSpecification can express such a merge, it&apos;s&lt;br/&gt;
&amp;gt; &amp;gt; just that the current IndexMerger (IndexWriter) cannot execute it,&lt;br/&gt;
&amp;gt; &amp;gt; right? So we are at least not precluding fixing this in the&lt;br/&gt;
&amp;gt; &amp;gt; future.&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; As far as I&apos;ve seen so far, there are no barriers to non-contiguous&lt;br/&gt;
&amp;gt; merges. Maybe something will crop up that is, but in what I&apos;ve done,&lt;br/&gt;
&amp;gt; I haven&apos;t seen any.&lt;/p&gt;

&lt;p&gt;Wait: there is a barrier, right?  In IndexWriter.replace we don&apos;t do&lt;br/&gt;
the right thing with non-contiguous merges?  What I&apos;m asking is: is&lt;br/&gt;
that the only barrier?  Ie MergePolicy API will not need to change in&lt;br/&gt;
the future once we fix IndexWriter.replace to handle non-contiguous&lt;br/&gt;
merges?&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; It confuses me that MergePolicy has a method &quot;merge(...)&quot; &amp;#8211; can&lt;br/&gt;
&amp;gt; &amp;gt; we rename it to &quot;maybeMerge(..)&quot; or &quot;checkForMerge(...)&quot;?&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; I suppose. I&apos;m not a big fan of the &quot;maybeFoo&quot; style of naming. I&lt;br/&gt;
&amp;gt; think of &quot;merge&quot; like &quot;optimize&quot;: make it so / idempotent. But I&apos;m&lt;br/&gt;
&amp;gt; certainly willing to write whatever people find clearest.&lt;/p&gt;

&lt;p&gt;I&apos;m not wed to &quot;maybeMerge()&quot; but I really don&apos;t like &quot;merge&quot; &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  It&apos;s&lt;br/&gt;
overloaded now.&lt;/p&gt;

&lt;p&gt;EG IndexMerger interface has a method called &quot;merge&quot; that is named&lt;br/&gt;
correctly because it will specifically go a do the requested merge.&lt;br/&gt;
So does IndexWriter.&lt;/p&gt;

&lt;p&gt;Then, you have other &lt;span class=&quot;error&quot;&gt;&amp;#91;overloaded&amp;#93;&lt;/span&gt; methods in LogDocMergePolicy called&lt;br/&gt;
&quot;merge&quot; that are named appropriately (they will do a specific merge).&lt;/p&gt;

&lt;p&gt;How about &quot;checkForMerges()&quot;?&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; Instead of IndexWriter.releaseMergePolicy() can we have&lt;br/&gt;
&amp;gt; &amp;gt; IndexWriter only close the merge policy if it was the one that had&lt;br/&gt;
&amp;gt; &amp;gt; created it? (Similar to how IndexWriter closes the dir if it has&lt;br/&gt;
&amp;gt; &amp;gt; opened it from a String or File, but does not close it if it was&lt;br/&gt;
&amp;gt; &amp;gt; passed in).&lt;br/&gt;
&amp;gt; &lt;br/&gt;
&amp;gt; This precludes&lt;br/&gt;
&amp;gt; &lt;br/&gt;
&amp;gt; iw.setMergePolicy(new MyMergePolicy(...));&lt;br/&gt;
&amp;gt;      ...&lt;br/&gt;
&amp;gt; iw.close();&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; The implementation&apos;s much cleaner using the semantics you describe,&lt;br/&gt;
&amp;gt; but I was thinking it&apos;d be better to optimize for the usability of the&lt;br/&gt;
&amp;gt; common client code case? &lt;/p&gt;

&lt;p&gt;The thing is, that method leaves IndexWriter in a broken state (null&lt;br/&gt;
mergePolicy).  What if you keep adding docs after that then suddenly&lt;br/&gt;
hit an NPE?&lt;/p&gt;

&lt;p&gt;Also, I&apos;m OK if people need to separately close their MergePolicy&lt;br/&gt;
instances: this is an advanced use of Lucene so it&apos;s OK to expect that&lt;br/&gt;
(&quot;simple things should be simple; complex things should be possible&quot;).&lt;/p&gt;

&lt;p&gt;Maybe we could add a &quot;setMergePolicy(MergePolicy policy, boolean&lt;br/&gt;
doClose)&quot; and default doClose to true?&lt;/p&gt;

&lt;p&gt;Finally: does MergePolicy really need a close()?  Is this overkill (at&lt;br/&gt;
this point)?&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; Well I think the current MergePolicy API (where the &quot;merge&quot; method&lt;br/&gt;
&amp;gt; calls IndexWriter.merge itself, must cascade itself, etc.) makes it&lt;br/&gt;
&amp;gt; hard to build a generic ConcurrentMergePolicy &quot;wrapper&quot; that you&lt;br/&gt;
&amp;gt; could use to make any MergePolicy concurrent &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/help_16.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;. How would you do&lt;br/&gt;
&amp;gt; it?&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; I really haven&apos;t had time to go heads down on this (the old&lt;br/&gt;
&amp;gt; concurrent merge policy was a derived class rather than a wrapper&lt;br/&gt;
&amp;gt; class). But I was thinking that perhaps ConurrentMergePolicy would&lt;br/&gt;
&amp;gt; actually wrap IndexWriter as well as the serial merge policy, i.e.,&lt;br/&gt;
&amp;gt; implement IndexMerger (my biggest argument for IM at this&lt;br/&gt;
&amp;gt; point). But I haven&apos;t looked deeply at whether this will work but I&lt;br/&gt;
&amp;gt; think it has at least a chance.&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; I should know more about this is a day or two. &lt;/p&gt;

&lt;p&gt;I don&apos;t see how it can work (building the generic concurrency wrapper&lt;br/&gt;
&quot;under&quot; IndexMerger) because the MergePolicy is in &quot;serial control&quot;,&lt;br/&gt;
eg, when it wants to cascade merges.  How will you return that thread&lt;br/&gt;
back to IndexWriter?&lt;/p&gt;

&lt;p&gt;Also it feels like the wrong place for concurrency &amp;#8211; I think&lt;br/&gt;
generally for &quot;macro&quot; concurrency you want it higher up, not lower&lt;br/&gt;
down, in the call stack.&lt;/p&gt;

&lt;p&gt;With concurrency wrapper &quot;on the top&quot; it&apos;s able to easily take a merge&lt;br/&gt;
request as returned by the policy, kick it off in the backrground, and&lt;br/&gt;
immediately return control of original thread back to IndexWriter.&lt;/p&gt;

&lt;p&gt;But if you see a way to make it work &quot;on the bottom&quot;, let&apos;s definitely&lt;br/&gt;
explore it &amp;amp; understand the tradeoffs.&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; I think you can still have state (as instance variables in your&lt;br/&gt;
&amp;gt; &amp;gt; class)? How would this simplification restrict the space of merge&lt;br/&gt;
&amp;gt; &amp;gt; policies?&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; s/state/stack state/. Yeah, you can always unwind your loops and&lt;br/&gt;
&amp;gt; lift your recursions, put all that stack state into instance&lt;br/&gt;
&amp;gt; variables. But, well, yuck. I&apos;d like to make it easy to write simple&lt;br/&gt;
&amp;gt; merge policies and take up the heavy lifting elsewhere. Hopefully&lt;br/&gt;
&amp;gt; there will be more merge policies than index writers.&lt;/p&gt;

&lt;p&gt;Can you give an example of the kind of &quot;state&quot; we&apos;re talking about?&lt;br/&gt;
Is this just academic?&lt;/p&gt;

&lt;p&gt;Since the segments change in an unpredictable way (as seen by&lt;br/&gt;
MergePolicy) eg from addIndexes*, flushing, concurrent merge swapping&lt;br/&gt;
things at random times (thus requiring careful locking), etc, it seems&lt;br/&gt;
like you can&apos;t be keeping much state (stack or instance) that depends&lt;br/&gt;
on what segments are in the index?&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; Oh, no: ConcurrentMergePolicy would still call&lt;br/&gt;
&amp;gt; &amp;gt; IndexWriter.merge(spec), just with a separate thread. And so all&lt;br/&gt;
&amp;gt; &amp;gt; synchronization required is still inside IndexWriter (I think?).&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; That&apos;s my idea.&lt;/p&gt;

&lt;p&gt;Actually I was talking about my idea (to &quot;simplify MergePolicy.merge&lt;br/&gt;
API&quot;).  With the simplification (whereby MergePolicy.merge just&lt;br/&gt;
returns the MergeSpecification instead of driving the merge itself) I&lt;br/&gt;
believe it&apos;s simple to make a concurrency wrapper around any merge&lt;br/&gt;
policy, and, have all necessary locking for SegmentInfos inside&lt;br/&gt;
IndexWriter.&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; In fact, if we stick with the current MergePolicy API, aren&apos;t you&lt;br/&gt;
&amp;gt; &amp;gt; going to have to put some locking into eg the LogDocMergePolicy&lt;br/&gt;
&amp;gt; &amp;gt; when concurrent merges might be happening?&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; Yes and no. If CMP implements IndexMerger, I think we might be okay?&lt;/p&gt;

&lt;p&gt;If CMP implements IndexMerger you must have locking inside any&lt;br/&gt;
MergePolicy that&apos;s calling into CMP?  Whereas with the simplified&lt;br/&gt;
MergePolicy.merge API, no locking is necessary because IndexWriter&lt;br/&gt;
would lock segmentInfos whenever it calls MergePolicy.merge.&lt;/p&gt;

&lt;p&gt;&amp;gt; In the previous iteration, I used derivation so that&lt;br/&gt;
&amp;gt; ConcurrentLogDocMergePolicy derived from the serial version but had&lt;br/&gt;
&amp;gt; the necessary threading. I agree that a wrapper is better solution&lt;br/&gt;
&amp;gt; if it can be made to work.&lt;/p&gt;

&lt;p&gt;I think it (concurrency wrapper around any merge policy) can be made&lt;br/&gt;
to work, if we do simplify the MergePolicy.merge API.  I&apos;m not sure it&lt;br/&gt;
can be made to work if we don&apos;t, but if you have an approach we should&lt;br/&gt;
work through it!&lt;/p&gt;</comment>
                    <comment id="12518453" author="ningli" created="Wed, 8 Aug 2007 15:23:44 +0100"  >&lt;p&gt;On 8/8/07, Michael McCandless (JIRA) &amp;lt;jira@apache.org&amp;gt; wrote:&lt;br/&gt;
&amp;gt; Actually I was talking about my idea (to &quot;simplify MergePolicy.merge&lt;br/&gt;
&amp;gt; API&quot;).  With the simplification (whereby MergePolicy.merge just&lt;br/&gt;
&amp;gt; returns the MergeSpecification instead of driving the merge itself) I&lt;br/&gt;
&amp;gt; believe it&apos;s simple to make a concurrency wrapper around any merge&lt;br/&gt;
&amp;gt; policy, and, have all necessary locking for SegmentInfos inside&lt;br/&gt;
&amp;gt; IndexWriter.&lt;/p&gt;

&lt;p&gt;I agree with Mike. In fact, MergeSelector.select, which is the counterpart&lt;br/&gt;
of MergePolicy.merge in the patch I submitted for concurrent merge,&lt;br/&gt;
simply returns a MergeSpecification. It&apos;s simple and sufficient to have&lt;br/&gt;
all necessary lockings for SegmentInfos in one class, say IndexWriter.&lt;br/&gt;
For example, IndexWriter locks SegmentInfos when MergePolicy(MergeSelector)&lt;br/&gt;
picks a merge spec. Another example, when a merge is finished, say&lt;br/&gt;
IndexWriter.checkin is called which locks SegmentInfos and replaces&lt;br/&gt;
the source segment infos with the target segment info.&lt;/p&gt;


&lt;p&gt;On 8/7/07, Steven Parkes (JIRA) &amp;lt;jira@apache.org&amp;gt; wrote:&lt;br/&gt;
&amp;gt; The synchronization is still tricky, since parts of segmentInfos are&lt;br/&gt;
&amp;gt; getting changed at various times and there are references and/or&lt;br/&gt;
&amp;gt; copies of it other places. And as Ning pointed out to me, we also&lt;br/&gt;
&amp;gt; have to deal with buffered delete terms. I&apos;d say I got about 80% of&lt;br/&gt;
&amp;gt;the way there on the last go around. I&apos;m hoping to get all the way&lt;br/&gt;
&amp;gt; this time.&lt;/p&gt;

&lt;p&gt;It just occurred to me that there is a neat way to handle deletes that&lt;br/&gt;
are flushed during a concurrent merge. For example, MergePolicy&lt;br/&gt;
decides to merge segments B and C, with B&apos;s delete file 0001 and&lt;br/&gt;
C&apos;s 100. When the concurrent merge finishes, B&apos;s delete file becomes&lt;br/&gt;
0011 and C&apos;s 110. We do a simple computation on the delete bit&lt;br/&gt;
vectors and check in the merged segment with delete file 00110.&lt;/p&gt;</comment>
                    <comment id="12518486" author="ningli" created="Wed, 8 Aug 2007 17:02:47 +0100"  >&lt;p&gt;The following comments are about the impact on merge if we add&lt;br/&gt;
&quot;deleteDocument(int doc)&quot; (and deprecate IndexModifier). Since it&lt;br/&gt;
concerns the topic in this issue, I also post it here to get your opinions.&lt;/p&gt;

&lt;p&gt;I&apos;m thinking about the impact of adding &quot;deleteDocument(int doc)&quot; on&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-847&quot; title=&quot;Factor merge policy out of IndexWriter&quot;&gt;&lt;del&gt;LUCENE-847&lt;/del&gt;&lt;/a&gt;, especially on concurrent merge. The semantics of&lt;br/&gt;
&quot;deleteDocument(int doc)&quot; is that the document to delete is specified&lt;br/&gt;
by the document id on the index at the time of the call. When a merge&lt;br/&gt;
is finished and the result is being checked into IndexWriter&apos;s&lt;br/&gt;
SegmentInfos, document ids may change. Therefore, it may be necessary&lt;br/&gt;
to flush buffered delete doc ids (thus buffered docs and delete terms&lt;br/&gt;
as well) before a merge result is checked in.&lt;/p&gt;

&lt;p&gt;The flush is not necessary if there is no buffered delete doc ids. I&lt;br/&gt;
don&apos;t think it should be the reason not to support &quot;deleteDocument(int&lt;br/&gt;
doc)&quot; in IndexWriter. But its impact on concurrent merge is a concern.&lt;/p&gt;</comment>
                    <comment id="12518508" author="mikemccand" created="Wed, 8 Aug 2007 18:09:29 +0100"  >&lt;p&gt;&amp;gt; It just occurred to me that there is a neat way to handle deletes&lt;br/&gt;
&amp;gt; that are flushed during a concurrent merge. For example, MergePolicy&lt;br/&gt;
&amp;gt; decides to merge segments B and C, with B&apos;s delete file 0001 and C&apos;s&lt;br/&gt;
&amp;gt; 100. When the concurrent merge finishes, B&apos;s delete file becomes&lt;br/&gt;
&amp;gt; 0011 and C&apos;s 110. We do a simple computation on the delete bit&lt;br/&gt;
&amp;gt; vectors and check in the merged segment with delete file 00110&lt;/p&gt;

&lt;p&gt;Excellent!  This lets you efficiently merge in the additional deletes&lt;br/&gt;
(if any) that were flushed against each of the merged segments after&lt;br/&gt;
the merge had begun.  Furthermore, I think this is all contained&lt;br/&gt;
within IndexWriter, right?&lt;/p&gt;

&lt;p&gt;Ie when we go to &quot;replace/checkin&quot; the newly merged segment, this&lt;br/&gt;
&quot;merge newly flushed deletes&quot; would execute at that time.  And, I&lt;br/&gt;
think, we would block flushes while this is happening, but&lt;br/&gt;
addDocument/deleteDocument/updateDocument would still be allowed?&lt;/p&gt;

&lt;p&gt;It should in fact be quite fast to run since delete BitVectors is all&lt;br/&gt;
in RAM.&lt;/p&gt;

&lt;p&gt;&amp;gt; I&apos;m thinking about the impact of adding &quot;deleteDocument(int doc)&quot; on&lt;br/&gt;
&amp;gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-847&quot; title=&quot;Factor merge policy out of IndexWriter&quot;&gt;&lt;del&gt;LUCENE-847&lt;/del&gt;&lt;/a&gt;, especially on concurrent merge. The semantics of&lt;br/&gt;
&amp;gt; &quot;deleteDocument(int doc)&quot; is that the document to delete is&lt;br/&gt;
&amp;gt; specified by the document id on the index at the time of the&lt;br/&gt;
&amp;gt; call. When a merge is finished and the result is being checked into&lt;br/&gt;
&amp;gt; IndexWriter&apos;s SegmentInfos, document ids may change. Therefore, it&lt;br/&gt;
&amp;gt; may be necessary to flush buffered delete doc ids (thus buffered&lt;br/&gt;
&amp;gt; docs and delete terms as well) before a merge result is checked in.&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; The flush is not necessary if there is no buffered delete doc ids. I&lt;br/&gt;
&amp;gt; don&apos;t think it should be the reason not to support&lt;br/&gt;
&amp;gt; &quot;deleteDocument(int doc)&quot; in IndexWriter. But its impact on&lt;br/&gt;
&amp;gt; concurrent merge is a concern.&lt;/p&gt;

&lt;p&gt;Couldn&apos;t we also just update the docIDs of pending deletes, and not&lt;br/&gt;
flush?  Ie we know the mapping of old -&amp;gt; new docID caused by the&lt;br/&gt;
merge, so we can run through all deleted docIDs and remap?&lt;/p&gt;</comment>
                    <comment id="12518520" author="ningli" created="Wed, 8 Aug 2007 18:48:34 +0100"  >&lt;p&gt;&amp;gt; Furthermore, I think this is all contained within IndexWriter, right?&lt;br/&gt;
&amp;gt; Ie when we go to &quot;replace/checkin&quot; the newly merged segment, this&lt;br/&gt;
&amp;gt; &quot;merge newly flushed deletes&quot; would execute at that time. And, I&lt;br/&gt;
&amp;gt; think, we would block flushes while this is happening, but&lt;br/&gt;
&amp;gt; addDocument/deleteDocument/updateDocument would still be allowed?&lt;/p&gt;

&lt;p&gt;Yes and yes. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&amp;gt; Couldn&apos;t we also just update the docIDs of pending deletes, and not&lt;br/&gt;
&amp;gt; flush? Ie we know the mapping of old -&amp;gt; new docID caused by the&lt;br/&gt;
&amp;gt; merge, so we can run through all deleted docIDs and remap? &lt;/p&gt;

&lt;p&gt;Hmm, I was worried quite a number of delete docIDs could be buffered,&lt;br/&gt;
but I guess it&apos;s still better than having to do a flush. So yes, this is better!&lt;/p&gt;</comment>
                    <comment id="12519790" author="steven_parkes" created="Tue, 14 Aug 2007 22:49:25 +0100"  >&lt;p&gt;	Are you going to fix all unit tests that call the now-deprecated APIs?&lt;/p&gt;

&lt;p&gt;Yeah. Thanks for the reminder.&lt;/p&gt;

&lt;p&gt;As to the IndexWriter vs. IndexMerger issue, I still think having the interface is useful if not only that it makes my testing much easier. I have a MockIndexMerger that implements only the functions in the interface and therefore I can test merge policies without creating a writer. For me this has been a big win ...&lt;/p&gt;

&lt;p&gt;	Exactly: these settings decide when a segment is flushed, so, why put&lt;br/&gt;
	them into IndexMerger interface?  They shouldn&apos;t have anything to with&lt;br/&gt;
	merging; I think they should be removed.&lt;/p&gt;

&lt;p&gt;	For &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-845&quot; title=&quot;If you &amp;quot;flush by RAM usage&amp;quot; then IndexWriter may over-merge&quot;&gt;&lt;del&gt;LUCENE-845&lt;/del&gt;&lt;/a&gt; I&apos;m working on a replacement for LogDocMergePolicy that&lt;br/&gt;
	does not use maxBufferedDocs.&lt;/p&gt;

&lt;p&gt;I can see that one could write a merge policy that didn&apos;t have any idea of how the initial buffering was done, but I worry about precluding it. Maybe the &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-845&quot; title=&quot;If you &amp;quot;flush by RAM usage&amp;quot; then IndexWriter may over-merge&quot;&gt;&lt;del&gt;LUCENE-845&lt;/del&gt;&lt;/a&gt; patch will show a strong enough pattern to believe no merge policies will need it?&lt;/p&gt;

&lt;p&gt;	I think factoring into a base class is an OK solution, but, it&lt;br/&gt;
	shouldn&apos;t be MergePolicy&apos;s job to remember to call this final &quot;move&lt;br/&gt;
	any segments in the wrong directory over&quot; code.  As long as its in one&lt;br/&gt;
	place and people don&apos;t have to copy/paste code between MergePolicy&lt;br/&gt;
	sources.&lt;/p&gt;

&lt;p&gt;In the case of concurrent merges, I think this gets more complicated. When do you do those directory copies? I think you can&apos;t do them at the return from the merge policy because the merge policy may want to do them, but later.&lt;/p&gt;

&lt;p&gt;I don&apos;t think IndexWriter has enough information to know when the copies need to done. Doubly so if we have concurrent merges?&lt;/p&gt;

&lt;p&gt;I still stand by it should be the merge policy making the choice. You could have the code in IndexWriter too, but then there&apos;d be duplicate code. To put the code only in IndexWriter removes the choice from the merge policy.&lt;/p&gt;

&lt;p&gt;	I think there&lt;br/&gt;
	should in fact be a default optimize() in the base class that does&lt;br/&gt;
	what current IndexWriter now does so that a MergePolicy need not&lt;br/&gt;
	implement optimize at all.&lt;/p&gt;

&lt;p&gt;It&apos;d be nice, but I don&apos;t know how to do it: the merge factor is not generic, so I don&apos;t know how to implement the loop generically.&lt;/p&gt;

&lt;p&gt;Ah ... I see: with your forced merge ... hmmm.&lt;/p&gt;

&lt;p&gt;	No, forced would mean the merge policy must do a merge; whereas,&lt;br/&gt;
	normally, it&apos;s free not to do a merge until it wants to.&lt;/p&gt;

&lt;p&gt;Hmmmm ...&lt;/p&gt;

&lt;p&gt;I think adding a forced merge concept here is new ... If it&apos;s simply to support optimize, I&apos;m not sure I find it too compelling. LogDoc as it stands uses different algorithms for incremental merges and optimize, so there&apos;s not too much of a concept of forced merges vs. optional merges to be factored out. So I guess I&apos;m not seeing a strong compelling case for creating it?&lt;/p&gt;

&lt;p&gt;	Well, it&apos;s sort of awkward if you want to vary that max # segments.&lt;br/&gt;
	Say during the day you optimize down to 15 segments every time you&lt;br/&gt;
	update the index, but then at night you want to optimize down to 5.&lt;br/&gt;
	If we don&apos;t add method to IndexWriter you then must have instance var&lt;br/&gt;
	on your MergePolicy that you set, then you call optimize.  It&apos;s not&lt;br/&gt;
	clean since really it should be a parameter.&lt;/p&gt;

&lt;p&gt;Well, I don&apos;t know if I buy the argument that it should be a parameter. The merge policy has lots of state like docs/seg. I don&apos;t really see why segs/optimize is different.&lt;/p&gt;

&lt;p&gt;My main reason for not wanting put this into IndexWriter is then every merge policy must support it.&lt;/p&gt;

&lt;p&gt;	Wait: there is a barrier, right?  In IndexWriter.replace we don&apos;t do&lt;br/&gt;
	the right thing with non-contiguous merges?&lt;/p&gt;

&lt;p&gt;Yeah, I meant that I&apos;m not aware of any barriers except fixing IndexWriter#replace, in other words, I&apos;m not aware of any other places where non-contiguity would cause a failure.&lt;/p&gt;

&lt;p&gt;	I&apos;m not wed to &quot;maybeMerge()&quot; but I really don&apos;t like &quot;merge&quot; &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  It&apos;s&lt;br/&gt;
	overloaded now.&lt;/p&gt;

&lt;p&gt;	EG IndexMerger interface has a method called &quot;merge&quot; that is named&lt;br/&gt;
	correctly because it will specifically go a do the requested merge.&lt;br/&gt;
	So does IndexWriter.&lt;/p&gt;

&lt;p&gt;	Then, you have other &lt;span class=&quot;error&quot;&gt;&amp;#91;overloaded&amp;#93;&lt;/span&gt; methods in LogDocMergePolicy called&lt;br/&gt;
	&quot;merge&quot; that are named appropriately (they will do a specific merge).&lt;/p&gt;

&lt;p&gt;	How about &quot;checkForMerges()&quot;?&lt;/p&gt;

&lt;p&gt;I don&apos;t find it ambiguous based on class and argument type. It&apos;s all personal, of course.&lt;/p&gt;

&lt;p&gt;I&apos;d definitely prefer maybe over checkFor because that sounds like a predicate.&lt;/p&gt;

&lt;p&gt;	Maybe we could add a &quot;setMergePolicy(MergePolicy policy, boolean&lt;br/&gt;
	doClose)&quot; and default doClose to true?&lt;/p&gt;

&lt;p&gt;That sounds good.&lt;/p&gt;

&lt;p&gt;	Finally: does MergePolicy really need a close()?&lt;/p&gt;

&lt;p&gt;I think so. The concurrent merge policy maintains all sorts of state.&lt;/p&gt;

&lt;p&gt;	I don&apos;t see how it can work (building the generic concurrency wrapper&lt;br/&gt;
	&quot;under&quot; IndexMerger) because the MergePolicy is in &quot;serial control&quot;,&lt;br/&gt;
	eg, when it wants to cascade merges.  How will you return that thread&lt;br/&gt;
	back to IndexWriter?&lt;/p&gt;

&lt;p&gt;So this is how it looks now: the concurrent merge policy is both a merge policy and an index merger. The serial merge policy knows nothing about it other than it does not get IndexWriter as its merge.&lt;/p&gt;

&lt;p&gt;The index writer wants its merge, so it does it merge/maybeMerge call on the concurrent merge policy. The CMP calls merge on the serial policy, but substitutes itself for the merger rather than IndexWriter.&lt;/p&gt;

&lt;p&gt;The serial merge policy goes on its merry way, looking for merges to do (in the current model, this is a loop; more on that in a minute). Each time it has a subset of segments to merge, it calls merger.merge(...).&lt;/p&gt;

&lt;p&gt;At this point, the concurrent merge policy takes over again. It looks at the segments to be merged and other segments being processed by all existing merge threads and determines if there&apos;s a conflict (a request to merge a segment that&apos;s currently in a merge). If there&apos;s no conflict, it starts a merge thread and calls IndexWriter#merge on the thread. The original calling thread returns immediately. (I have a few ideas how to handle conflicts, the simplest of which is to wait for the conflicting merge and the restart the serial merge, e.g., revert to serial).&lt;/p&gt;

&lt;p&gt;This seems to work pretty well, so far. The only difference in API for the serial merges is that the merge operation can&apos;t return the number of documents in the result (since it isn&apos;t known how many docs will be deleted).   &lt;/p&gt;

&lt;p&gt;	With concurrency wrapper &quot;on the top&quot; it&apos;s able to easily take a merge&lt;br/&gt;
	request as returned by the policy, kick it off in the backrground, and&lt;br/&gt;
	immediately return control of original thread back to IndexWriter.&lt;/p&gt;

&lt;p&gt;What I don&apos;t know how to do with this is figure out how to do a bunch of merges. Lets say I have two levels in LogDoc that are merge worthy. If I call LogDoc, it&apos;ll return the lower level. That&apos;s all good. But what about doing the higher level in parallel? If I call LogDoc again, it&apos;s going to return the lower level again because it knows nothing about the current merge going on.&lt;/p&gt;

&lt;p&gt;LogDoc already does things in a loop: it&apos;s pretty much set up to call all possible merges at one time (if they return immediately).&lt;/p&gt;

&lt;p&gt;It would be possible to have it return a vector of segmentInfo subsets, but I don&apos;t see the gain (and it doesn&apos;t work out as well for my putative conflict resolution).&lt;/p&gt;

&lt;p&gt;	have all necessary locking for SegmentInfos inside&lt;br/&gt;
	IndexWriter&lt;/p&gt;

&lt;p&gt;This was a red-herring on my part. All the &quot;segmentInfos locking&quot; has always been in IndexWriter. That&apos;s note exactly sufficient. The fundamental issue is that IndexWriter#merge has to operate without a lock on IndexWriter. At some point, I was thinking that meant it would have to lock SegmentInfos but that&apos;s ludicrous, actually. It&apos;s sufficient for IndexWriter#replace to be synchronized.&lt;/p&gt;

&lt;p&gt;	If CMP implements IndexMerger you must have locking inside any&lt;br/&gt;
	MergePolicy that&apos;s calling into CMP?&lt;/p&gt;

&lt;p&gt;No. CMP does it&apos;s own locking (for purposes of thread management) but the serial merge policies no nothing of this (and they can expect to be called synchronously).&lt;/p&gt;</comment>
                    <comment id="12519793" author="steven_parkes" created="Tue, 14 Aug 2007 22:52:07 +0100"  >&lt;p&gt;	It just occurred to me that there is a neat way to handle deletes that&lt;br/&gt;
	are flushed during a concurrent merge. For example, MergePolicy&lt;br/&gt;
	decides to merge segments B and C, with B&apos;s delete file 0001 and&lt;br/&gt;
	C&apos;s 100. When the concurrent merge finishes, B&apos;s delete file becomes&lt;br/&gt;
	0011 and C&apos;s 110. We do a simple computation on the delete bit&lt;br/&gt;
	vectors and check in the merged segment with delete file 00110.&lt;/p&gt;

&lt;p&gt;Well, that makes my life much easier. Now I don&apos;t have to figure out what to do, just have to make it so ...&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;</comment>
                    <comment id="12520071" author="steven_parkes" created="Wed, 15 Aug 2007 20:32:29 +0100"  >&lt;p&gt;Updated patch:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Don&apos;t call deprecated methods&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;note: currently renamed with &quot;_&quot; prepended to make easy to find; don&apos;t commit&lt;br/&gt;
    those&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;Factor MergePolicyBase&lt;/li&gt;
	&lt;li&gt;comments to remind to delete before commit (though might still have missed some)&lt;/li&gt;
	&lt;li&gt;Make LDMP casts not throw bad cast&lt;/li&gt;
	&lt;li&gt;Get rid of releaseMergePolicy and add doClose parameter on set&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Didn&apos;t factor copy from other dirs: requires compound file choices&lt;/li&gt;
	&lt;li&gt;Didn&apos;t (yet) rename merge -&amp;gt; maybeMerge&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Does this mean optimize -&amp;gt; maybeOptimize, too?&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12520260" author="mikemccand" created="Thu, 16 Aug 2007 15:20:50 +0100"  >&lt;p&gt;One new small item: you&apos;ve added a &quot;public void merge()&quot; to&lt;br/&gt;
IndexWriter so that people can externally kick off a merge request,&lt;br/&gt;
which is good I think.&lt;/p&gt;

&lt;p&gt;But, is it really necessary to flush here?  It would be better to not&lt;br/&gt;
flush so that users then have two separate methods (flush() and&lt;br/&gt;
merge()) to do each function independently.&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; Are you going to fix all unit tests that call the now-deprecated&lt;br/&gt;
&amp;gt; &amp;gt; APIs?&lt;br/&gt;
&amp;gt; &lt;br/&gt;
&amp;gt; Yeah. Thanks for the reminder.&lt;/p&gt;

&lt;p&gt;On thinking about this more ... and on seeing all the diffs ... I no&lt;br/&gt;
longer feel we should be deprecating &quot;get/setUseCompoundFile()&quot; nor&lt;br/&gt;
&quot;get/setMergeFactor()&quot; nor &quot;get/setMaxMergeDocs()&quot; in IndexWriter.&lt;/p&gt;

&lt;p&gt;The vast majoriy of Lucene users will not make their own merge policy&lt;br/&gt;
(just use the default merge policy) and so I don&apos;t think we should be&lt;br/&gt;
complicating their lives with having to now write lines like this when&lt;br/&gt;
they want to change settings:&lt;/p&gt;

&lt;p&gt;   ((LogDocMergePolicy)writer.getMergePolicy()).setUseCompoundFile(useCompoundFile);&lt;/p&gt;

&lt;p&gt;Also, this ties our hands if ever we want to change the default merge&lt;br/&gt;
policy (which, under &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-845&quot; title=&quot;If you &amp;quot;flush by RAM usage&amp;quot; then IndexWriter may over-merge&quot;&gt;&lt;del&gt;LUCENE-845&lt;/del&gt;&lt;/a&gt;, I&apos;d like to do).&lt;/p&gt;

&lt;p&gt;I think instead we should leave the methods, not deprecated, as&lt;br/&gt;
convenience (sugar) methods.  Simple things should be simple; complex&lt;br/&gt;
things should be possible.  Sorry I didn&apos;t think of this before you&lt;br/&gt;
made the new patch Steve &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; I&apos;m not wed to &quot;maybeMerge()&quot; but I really don&apos;t like &quot;merge&quot; &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
&amp;gt; &amp;gt; It&apos;s overloaded now.&lt;br/&gt;
&amp;gt; &amp;gt; &lt;br/&gt;
&amp;gt; &amp;gt; EG IndexMerger interface has a method called &quot;merge&quot; that is named&lt;br/&gt;
&amp;gt; &amp;gt; correctly because it will specifically go a do the requested&lt;br/&gt;
&amp;gt; &amp;gt; merge.  So does IndexWriter.&lt;br/&gt;
&amp;gt; &amp;gt;&lt;br/&gt;
&amp;gt; &amp;gt; Then, you have other &lt;span class=&quot;error&quot;&gt;&amp;#91;overloaded&amp;#93;&lt;/span&gt; methods in LogDocMergePolicy&lt;br/&gt;
&amp;gt; &amp;gt; called &quot;merge&quot; that are named appropriately (they will do a&lt;br/&gt;
&amp;gt; &amp;gt; specific merge).&lt;br/&gt;
&amp;gt; &amp;gt; &lt;br/&gt;
&amp;gt; &amp;gt; How about &quot;checkForMerges()&quot;?&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; I don&apos;t find it ambiguous based on class and argument type. It&apos;s all&lt;br/&gt;
&amp;gt; personal, of course.&lt;br/&gt;
&amp;gt; &lt;br/&gt;
&amp;gt; I&apos;d definitely prefer maybe over checkFor because that sounds like a&lt;br/&gt;
&amp;gt; predicate.&lt;/p&gt;

&lt;p&gt;OK let&apos;s settle on &quot;maybeMerge&quot;?&lt;/p&gt;

&lt;p&gt;&amp;gt;    - Does this mean optimize -&amp;gt; maybeOptimize, too?&lt;/p&gt;

&lt;p&gt;Uh, no: when someone calls optimize that means it really must be done,&lt;br/&gt;
right?  So &quot;optimize&quot; is the right name I think.&lt;/p&gt;

&lt;p&gt;&amp;gt; * Make LDMP casts not throw bad cast &lt;/p&gt;

&lt;p&gt;Can you factor this out, eg add a private method&lt;br/&gt;
&quot;getLogDocMergePolicy(String reason)&quot; that would be the one place that&lt;br/&gt;
does the class casting &amp;amp; throwing an error message from one single&lt;br/&gt;
source line?  Right now the message is copied in multiple places and,&lt;br/&gt;
it&apos;s wrong for mergeFactor (was copied from useCompoundFile).&lt;/p&gt;

&lt;p&gt;&amp;gt; * Get rid of releaseMergePolicy and add doClose parameter on set&lt;/p&gt;

&lt;p&gt;Looks good, thanks.  Can you add javadocs (w/ params) for both of&lt;br/&gt;
these new methods?&lt;/p&gt;

&lt;p&gt;&amp;gt; As to the IndexWriter vs. IndexMerger issue, I still think having&lt;br/&gt;
&amp;gt; the interface is useful if not only that it makes my testing much&lt;br/&gt;
&amp;gt; easier. I have a MockIndexMerger that implements only the functions&lt;br/&gt;
&amp;gt; in the interface and therefore I can test merge policies without&lt;br/&gt;
&amp;gt; creating a writer. For me this has been a big win ...&lt;/p&gt;

&lt;p&gt;Subclassing IndexWriter to make MockIndexMerger would also work for&lt;br/&gt;
testing?  This is what MockRAMDirectory does for example...&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; Exactly: these settings decide when a segment is flushed, so, why&lt;br/&gt;
&amp;gt; &amp;gt; put them into IndexMerger interface? They shouldn&apos;t have anything&lt;br/&gt;
&amp;gt; &amp;gt; to with merging; I think they should be removed.&lt;br/&gt;
&amp;gt; &amp;gt; &lt;br/&gt;
&amp;gt; &amp;gt; For &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-845&quot; title=&quot;If you &amp;quot;flush by RAM usage&amp;quot; then IndexWriter may over-merge&quot;&gt;&lt;del&gt;LUCENE-845&lt;/del&gt;&lt;/a&gt; I&apos;m working on a replacement for LogDocMergePolicy&lt;br/&gt;
&amp;gt; &amp;gt; that does not use maxBufferedDocs.&lt;/p&gt;

&lt;p&gt;&amp;gt; I can see that one could write a merge policy that didn&apos;t have any&lt;br/&gt;
&amp;gt; idea of how the initial buffering was done, but I worry about&lt;br/&gt;
&amp;gt; precluding it. Maybe the &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-845&quot; title=&quot;If you &amp;quot;flush by RAM usage&amp;quot; then IndexWriter may over-merge&quot;&gt;&lt;del&gt;LUCENE-845&lt;/del&gt;&lt;/a&gt; patch will show a strong enough&lt;br/&gt;
&amp;gt; pattern to believe no merge policies will need it?&lt;/p&gt;

&lt;p&gt;We wouldn&apos;t be precluding it (people can still get it from their&lt;br/&gt;
IndexWriter).  This is one of the big reasons that I don&apos;t like making&lt;br/&gt;
an interface out of IndexMerger: here we are having to pick &amp;amp; choose&lt;br/&gt;
which settings from IndexWriter a merge policy is &quot;allowed&quot; to use.  I&lt;br/&gt;
don&apos;t think that&apos;s necessary (we are just making extra work for&lt;br/&gt;
ourselves) and inevitably we won&apos;t get it right...&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; I think factoring into a base class is an OK solution, but, it&lt;br/&gt;
&amp;gt; &amp;gt; shouldn&apos;t be MergePolicy&apos;s job to remember to call this final&lt;br/&gt;
&amp;gt; &amp;gt; &quot;move any segments in the wrong directory over&quot; code. As long as&lt;br/&gt;
&amp;gt; &amp;gt; its in one place and people don&apos;t have to copy/paste code&lt;br/&gt;
&amp;gt; &amp;gt; between MergePolicy sources.&lt;br/&gt;
&amp;gt; &lt;br/&gt;
&amp;gt; In the case of concurrent merges, I think this gets more&lt;br/&gt;
&amp;gt; complicated. When do you do those directory copies? I think you&lt;br/&gt;
&amp;gt; can&apos;t do them at the return from the merge policy because the merge&lt;br/&gt;
&amp;gt; policy may want to do them, but later.&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; I don&apos;t think IndexWriter has enough information to know when the&lt;br/&gt;
&amp;gt; copies need to done. Doubly so if we have concurrent merges? &lt;/p&gt;

&lt;p&gt;Ahh, good point.  Though, this raises the tricky question of index&lt;br/&gt;
consistency ... IndexWriter commits the new segments file right after&lt;br/&gt;
mergePolicy.merge returns ... so for CMP we suddenly have an unusable&lt;br/&gt;
index (as seen by an IndexReader).  EG if things crash any time after&lt;br/&gt;
this point and before the background merging finishes &amp;amp; commits,&lt;br/&gt;
you&apos;re hosed.&lt;/p&gt;

&lt;p&gt;Maybe it&apos;s too ambitious to allow merges of segments from other&lt;br/&gt;
directories to run concurrently?&lt;/p&gt;

&lt;p&gt;I would consider it a hard error in IndexWriter if after calling&lt;br/&gt;
mergePolicy.merge from any of the addIndexes*, there remain segments&lt;br/&gt;
in other directories.  I think we should catch this &amp;amp; throw an&lt;br/&gt;
exception?&lt;/p&gt;

&lt;p&gt;&amp;gt; I still stand by it should be the merge policy making the&lt;br/&gt;
&amp;gt; choice. You could have the code in IndexWriter too, but then there&apos;d&lt;br/&gt;
&amp;gt; be duplicate code. To put the code only in IndexWriter removes the&lt;br/&gt;
&amp;gt; choice from the merge policy.&lt;/p&gt;

&lt;p&gt;I agree that merge policy should be the one making the choice, but the&lt;br/&gt;
execution of it should be a centralized place (IndexWriter).  EG with&lt;br/&gt;
the simplified API, the merge policy would just return, one by one,&lt;br/&gt;
each of the segments that is in a different directory...&lt;/p&gt;

&lt;p&gt;We can&apos;t all be copy/pasting code (like I had to do for &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-845&quot; title=&quot;If you &amp;quot;flush by RAM usage&amp;quot; then IndexWriter may over-merge&quot;&gt;&lt;del&gt;LUCENE-845&lt;/del&gt;&lt;/a&gt;)&lt;br/&gt;
for checking &amp;amp; then moving segments across directories.  I think we&lt;br/&gt;
need single source for this, somehow.&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; I think there should in fact be a default optimize() in the base class&lt;br/&gt;
&amp;gt; &amp;gt; that does what current IndexWriter now does so that a MergePolicy need&lt;br/&gt;
&amp;gt; &amp;gt; not implement optimize at all.&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; It&apos;d be nice, but I don&apos;t know how to do it: the merge factor is not&lt;br/&gt;
&amp;gt; generic, so I don&apos;t know how to implement the loop generically.&lt;/p&gt;

&lt;p&gt;Hmmm, OK.  I think what you did (factoring out that massive&lt;br/&gt;
conditional) is good here.&lt;/p&gt;

&lt;p&gt;&amp;gt; Ah ... I see: with your forced merge ... hmmm.&lt;br/&gt;
&amp;gt; &lt;br/&gt;
&amp;gt; No, forced would mean the merge policy must do a merge; whereas,&lt;br/&gt;
&amp;gt; normally, it&apos;s free not to do a merge until it wants to.&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; I think adding a forced merge concept here is new ... If it&apos;s simply&lt;br/&gt;
&amp;gt; to support optimize, I&apos;m not sure I find it too compelling. LogDoc&lt;br/&gt;
&amp;gt; as it stands uses different algorithms for incremental merges and&lt;br/&gt;
&amp;gt; optimize, so there&apos;s not too much of a concept of forced merges&lt;br/&gt;
&amp;gt; vs. optional merges to be factored out. So I guess I&apos;m not seeing a&lt;br/&gt;
&amp;gt; strong compelling case for creating it?&lt;/p&gt;

&lt;p&gt;OK, I agree, let&apos;s not add &quot;forced&quot;.  How about, instead we only&lt;br/&gt;
require mergePolicy to implement optimize(int maxNumSegments)?  (And&lt;br/&gt;
current IndexWriter.optimize() calls this with parameter &quot;1&quot;).&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; Well, it&apos;s sort of awkward if you want to vary that max #&lt;br/&gt;
&amp;gt; &amp;gt; segments.  Say during the day you optimize down to 15 segments&lt;br/&gt;
&amp;gt; &amp;gt; every time you update the index, but then at night you want to&lt;br/&gt;
&amp;gt; &amp;gt; optimize down to 5.  If we don&apos;t add method to IndexWriter you&lt;br/&gt;
&amp;gt; &amp;gt; then must have instance var on your MergePolicy that you set,&lt;br/&gt;
&amp;gt; &amp;gt; then you call optimize. It&apos;s not clean since really it should be&lt;br/&gt;
&amp;gt; &amp;gt; a parameter.&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; Well, I don&apos;t know if I buy the argument that it should be a&lt;br/&gt;
&amp;gt; parameter. The merge policy has lots of state like docs/seg. I don&apos;t&lt;br/&gt;
&amp;gt; really see why segs/optimize is different.&lt;/p&gt;

&lt;p&gt;I think this would be a useful enough method that it should be &quot;made&lt;br/&gt;
simple&quot; (ie, this is different from the &quot;other state&quot; that a merge&lt;br/&gt;
policy would store).  I opened a separate issue &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-982&quot; title=&quot;Create new method optimize(int maxNumSegments) in IndexWriter&quot;&gt;&lt;del&gt;LUCENE-982&lt;/del&gt;&lt;/a&gt; to track&lt;br/&gt;
this.&lt;/p&gt;

&lt;p&gt;&amp;gt; My main reason for not wanting put this into IndexWriter is then&lt;br/&gt;
&amp;gt; every merge policy must support it.&lt;/p&gt;

&lt;p&gt;This is why I want to address it now, while we are cementing the&lt;br/&gt;
MergePolicy API: I don&apos;t want to preclude it.&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; Wait: there is a barrier, right? In IndexWriter.replace we don&apos;t do&lt;br/&gt;
&amp;gt; &amp;gt; the right thing with non-contiguous merges?&lt;br/&gt;
&amp;gt; &lt;br/&gt;
&amp;gt; Yeah, I meant that I&apos;m not aware of any barriers except fixing&lt;br/&gt;
&amp;gt; IndexWriter#replace, in other words, I&apos;m not aware of any other&lt;br/&gt;
&amp;gt; places where non-contiguity would cause a failure.&lt;/p&gt;

&lt;p&gt;OK, good, that&apos;s my impression too.&lt;/p&gt;

&lt;p&gt;Although ... do you think we need need some way for merge policy to&lt;br/&gt;
state where the new segment should be inserted into SegmentInfos?  For&lt;br/&gt;
the contiguous case it seems clear that we should default to what is&lt;br/&gt;
done now (new segment goes into same spot where old segments were).&lt;br/&gt;
But for the non-contiguous case, how would IndexWriter know where to&lt;br/&gt;
put the newly created segment?&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; Finally: does MergePolicy really need a close()?&lt;br/&gt;
&amp;gt; &lt;br/&gt;
&amp;gt; I think so. The concurrent merge policy maintains all sorts of&lt;br/&gt;
&amp;gt; state.&lt;/p&gt;

&lt;p&gt;OK.  Hmmm, does CMP block on close while it joins to any running merge&lt;br/&gt;
threads?  How can the user close IndexWriter and abort the running&lt;br/&gt;
merges?  I guess CMP would provide a method to abort any running&lt;br/&gt;
merges, and user would first call that before calling&lt;br/&gt;
IndexWriter.close?&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; I don&apos;t see how it can work (building the generic concurrency&lt;br/&gt;
&amp;gt; &amp;gt; wrapper &quot;under&quot; IndexMerger) because the MergePolicy is in &quot;serial&lt;br/&gt;
&amp;gt; &amp;gt; control&quot;, eg, when it wants to cascade merges. How will you return&lt;br/&gt;
&amp;gt; &amp;gt; that thread back to IndexWriter?&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; So this is how it looks now: the concurrent merge policy is both a&lt;br/&gt;
&amp;gt; merge policy and an index merger. The serial merge policy knows&lt;br/&gt;
&amp;gt; nothing about it other than it does not get IndexWriter as its&lt;br/&gt;
&amp;gt; merge.&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; The index writer wants its merge, so it does it merge/maybeMerge&lt;br/&gt;
&amp;gt; call on the concurrent merge policy. The CMP calls merge on the&lt;br/&gt;
&amp;gt; serial policy, but substitutes itself for the merger rather than&lt;br/&gt;
&amp;gt; IndexWriter.&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; The serial merge policy goes on its merry way, looking for merges to&lt;br/&gt;
&amp;gt; do (in the current model, this is a loop; more on that in a&lt;br/&gt;
&amp;gt; minute). Each time it has a subset of segments to merge, it calls&lt;br/&gt;
&amp;gt; merger.merge(...).&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; At this point, the concurrent merge policy takes over again. It&lt;br/&gt;
&amp;gt; looks at the segments to be merged and other segments being&lt;br/&gt;
&amp;gt; processed by all existing merge threads and determines if there&apos;s a&lt;br/&gt;
&amp;gt; conflict (a request to merge a segment that&apos;s currently in a&lt;br/&gt;
&amp;gt; merge). If there&apos;s no conflict, it starts a merge thread and calls&lt;br/&gt;
&amp;gt; IndexWriter#merge on the thread. The original calling thread returns&lt;br/&gt;
&amp;gt; immediately. (I have a few ideas how to handle conflicts, the&lt;br/&gt;
&amp;gt; simplest of which is to wait for the conflicting merge and the&lt;br/&gt;
&amp;gt; restart the serial merge, e.g., revert to serial).&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; This seems to work pretty well, so far. The only difference in API&lt;br/&gt;
&amp;gt; for the serial merges is that the merge operation can&apos;t return the&lt;br/&gt;
&amp;gt; number of documents in the result (since it isn&apos;t known how many&lt;br/&gt;
&amp;gt; docs will be deleted).&lt;/p&gt;

&lt;p&gt;Hmmm.  This looks more complex than the proposed API simplification,&lt;br/&gt;
because you now have CMP on the top and on the bottom.  Also, this&lt;br/&gt;
requires the IndexMerger interface, but with the simplification we&lt;br/&gt;
would not need a separate interface.  Finally, I&apos;m pretty sure you&lt;br/&gt;
have locking issues (more below...), which are required of all merge&lt;br/&gt;
policies, that the simplified API wouldn&apos;t have.&lt;/p&gt;

&lt;p&gt;How we handle conflicts is important but I think independent of this&lt;br/&gt;
API discussion (ie both your CMP and my CMP have this same challenge,&lt;br/&gt;
and I agree we should start simple by just blocking when the selected&lt;br/&gt;
merge conflicts with a previous one that&apos;s still in progress).&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; With concurrency wrapper &quot;on the top&quot; it&apos;s able to easily take a&lt;br/&gt;
&amp;gt; &amp;gt; merge request as returned by the policy, kick it off in the&lt;br/&gt;
&amp;gt; &amp;gt; backrground, and immediately return control of original thread&lt;br/&gt;
&amp;gt; &amp;gt; back to IndexWriter.&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; What I don&apos;t know how to do with this is figure out how to do a&lt;br/&gt;
&amp;gt; bunch of merges. Lets say I have two levels in LogDoc that are merge&lt;br/&gt;
&amp;gt; worthy. If I call LogDoc, it&apos;ll return the lower level. That&apos;s all&lt;br/&gt;
&amp;gt; good. But what about doing the higher level in parallel? If I call&lt;br/&gt;
&amp;gt; LogDoc again, it&apos;s going to return the lower level again because it&lt;br/&gt;
&amp;gt; knows nothing about the current merge going on.&lt;/p&gt;

&lt;p&gt;True, LogDoc as it now stands would never exploit concurrency (it will&lt;br/&gt;
always return the highest level that needs merging).  But, we could&lt;br/&gt;
relax that such that if ever the lowest level has &amp;gt; 2*mergeFactor&lt;br/&gt;
pending segments to merge then we select the 2nd set.  This would&lt;br/&gt;
expose concurrency that would only be used when CMP is in use.  But I&lt;br/&gt;
think we should do this, later, as an enhancement.  Let&apos;s focus on&lt;br/&gt;
simplifying the API now...&lt;/p&gt;

&lt;p&gt;&amp;gt; It would be possible to have it return a vector of segmentInfo&lt;br/&gt;
&amp;gt; subsets, but I don&apos;t see the gain (and it doesn&apos;t work out as well&lt;br/&gt;
&amp;gt; for my putative conflict resolution).&lt;/p&gt;

&lt;p&gt;Yeah that would make the API even more complex, which is the wrong&lt;br/&gt;
direction here &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; have all necessary locking for SegmentInfos inside IndexWriter&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; This was a red-herring on my part. All the &quot;segmentInfos locking&quot;&lt;br/&gt;
&amp;gt; has always been in IndexWriter. That&apos;s note exactly sufficient. The&lt;br/&gt;
&amp;gt; fundamental issue is that IndexWriter#merge has to operate without a&lt;br/&gt;
&amp;gt; lock on IndexWriter. At some point, I was thinking that meant it&lt;br/&gt;
&amp;gt; would have to lock SegmentInfos but that&apos;s ludicrous, actually. It&apos;s&lt;br/&gt;
&amp;gt; sufficient for IndexWriter#replace to be synchronized.&lt;/p&gt;

&lt;p&gt;Right: merging certainly shouldn&apos;t hold lock on IndexWriter nor&lt;br/&gt;
segmentInfos.&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; If CMP implements IndexMerger you must have locking inside any&lt;br/&gt;
&amp;gt; &amp;gt; MergePolicy that&apos;s calling into CMP?&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; No. CMP does it&apos;s own locking (for purposes of thread management)&lt;br/&gt;
&amp;gt; but the serial merge policies no nothing of this (and they can&lt;br/&gt;
&amp;gt; expect to be called synchronously).&lt;/p&gt;

&lt;p&gt;This I don&apos;t get: it seems to me that the serial merge policies must&lt;br/&gt;
do their own locking when they access the SegmentInfos that&apos;s passed&lt;br/&gt;
in?  And that lock must be released, somehow, when they call merge?&lt;br/&gt;
Would merge (inside IndexWriter) somehow release the lock on being&lt;br/&gt;
called?  I don&apos;t see how you&apos;re going to make the locking work, but I&lt;br/&gt;
think it&apos;s required with the current API.&lt;/p&gt;

&lt;p&gt;This is another benefit of the simplified API: MergePolicy.maybeMerge&lt;br/&gt;
would only be called with a lock already acquired (by IndexWriter) on&lt;br/&gt;
the segmentInfos.  Then maybeMerge looks @ the segmentInfos, makes its&lt;br/&gt;
choice, and returns it, and the lock is released.  The lock is not&lt;br/&gt;
held for an extended period of time...&lt;/p&gt;</comment>
                    <comment id="12520293" author="steven_parkes" created="Thu, 16 Aug 2007 17:26:34 +0100"  >&lt;p&gt;	One new small item: you&apos;ve added a &quot;public void merge()&quot; to&lt;br/&gt;
	IndexWriter so that people can externally kick off a merge request,&lt;br/&gt;
	which is good I think.&lt;/p&gt;

&lt;p&gt;	But, is it really necessary to flush here?  It would be better to not&lt;br/&gt;
	flush so that users then have two separate methods (flush() and&lt;br/&gt;
	merge()) to do each function independently.&lt;/p&gt;

&lt;p&gt;That makes sense.&lt;/p&gt;

&lt;p&gt;Note that merge() was added not for users (which I have no strong opinion about) but so that, potentially, CMP can check again for merges when a set of merge threads completes, i.e., cascade.&lt;/p&gt;

&lt;p&gt;	I think instead we should leave the methods, not deprecated, as&lt;br/&gt;
	convenience (sugar) methods.  Simple things should be simple; complex&lt;br/&gt;
	things should be possible.&lt;/p&gt;

&lt;p&gt;I think this argues for a LegacyMergePolicy interface again, then? If we change the default merge policy and someone changes their code to use LogDoc for their own purposes, in both cases the getters/setters should work? So cast to the interface and as long as the merge policy supports this, the getters/setters work (unless the merge policy decides to throw within), otherwise the getters/setters throw? &lt;/p&gt;

&lt;p&gt;	Uh, no: when someone calls optimize that means it really must be done,&lt;br/&gt;
	right?  So &quot;optimize&quot; is the right name I think.&lt;/p&gt;

&lt;p&gt;Yeah, but it might do nothing. Just as merge might do nothing.&lt;/p&gt;

&lt;p&gt;	Can you factor this out, eg add a private method&lt;br/&gt;
	&quot;getLogDocMergePolicy(String reason)&quot;&lt;/p&gt;

&lt;p&gt;Sure.&lt;/p&gt;

&lt;p&gt;	Looks good, thanks.  Can you add javadocs (w/ params) for both of&lt;br/&gt;
	these new methods?&lt;/p&gt;

&lt;p&gt;Sure.&lt;/p&gt;

&lt;p&gt;	Though, this raises the tricky question of index&lt;br/&gt;
	consistency ...&lt;/p&gt;

&lt;p&gt;Definitely. I&apos;m still trying to understand all the subtleties here.&lt;/p&gt;

&lt;p&gt;	IndexWriter commits the new segments file right after&lt;br/&gt;
	mergePolicy.merge returns ... so for CMP we suddenly have an unusable&lt;br/&gt;
	index (as seen by an IndexReader).&lt;/p&gt;

&lt;p&gt;How so? I figured that after mergePolicy.merge returns, in the case of CMP with an ongoing merge, segmentInfos won&apos;t have changed at all. Is that a problem?&lt;/p&gt;

&lt;p&gt;I thought the issue would be on the other end, where the concurrent merge finishes and needs to update segmentInfos.&lt;/p&gt;

&lt;p&gt;	Maybe it&apos;s too ambitious to allow merges of segments from other&lt;br/&gt;
	directories to run concurrently?&lt;/p&gt;

&lt;p&gt;Yeah, that might be the case. At least as a default?&lt;/p&gt;

&lt;p&gt;	I would consider it a hard error in IndexWriter if after calling&lt;br/&gt;
	mergePolicy.merge from any of the addIndexes*, there remain segments&lt;br/&gt;
	in other directories.  I think we should catch this &amp;amp; throw an&lt;br/&gt;
	exception?&lt;/p&gt;

&lt;p&gt;It would be easy enough for CMP to block in this case, rather than returning immediately. Wouldn&apos;t that be better? And I suppose it&apos;s possible to imagine an API on CMP for specifying this behavior?&lt;/p&gt;

&lt;p&gt;	I opened a separate issue &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-982&quot; title=&quot;Create new method optimize(int maxNumSegments) in IndexWriter&quot;&gt;&lt;del&gt;LUCENE-982&lt;/del&gt;&lt;/a&gt; to track this.&lt;/p&gt;

&lt;p&gt;I think this is good. I think it&apos;s an interesting issue but not directly related to the refactor?&lt;/p&gt;

&lt;p&gt;	Although ... do you think we need need some way for merge policy to&lt;br/&gt;
	state where the new segment should be inserted into SegmentInfos?&lt;/p&gt;

&lt;p&gt;Right now I assumed it would replace the left most-segment.&lt;/p&gt;

&lt;p&gt;Since I don&apos;t really know the details of what such a merge policy would like, I don&apos;t really know what it needs.&lt;/p&gt;

&lt;p&gt;If you&apos;ve thought about this more, do you have a suggestion? I suppose we could just add an int. But, then again, I&apos;d do that as a separate function, leaving the original available, so we can do this later, completely compatibly?&lt;/p&gt;

&lt;p&gt;	Hmmm, does CMP block on close while it joins to any running merge&lt;br/&gt;
	threads?&lt;/p&gt;

&lt;p&gt;Yeah, at least in my sandbox.&lt;/p&gt;

&lt;p&gt;	How can the user close IndexWriter and abort the running&lt;br/&gt;
	merges?  I guess CMP would provide a method to abort any running&lt;br/&gt;
	merges, and user would first call that before calling&lt;br/&gt;
	IndexWriter.close?&lt;/p&gt;

&lt;p&gt;I hadn&apos;t really thought about this but I can see that should be made possible. It&apos;s always safe to abandon a merge so it should be available, for fast, safe, and clean shutdown.&lt;/p&gt;

&lt;p&gt;	True, LogDoc as it now stands would never exploit concurrency (it will&lt;br/&gt;
	always return the highest level that needs merging).  But, we could&lt;br/&gt;
	relax that such that if ever the lowest level has &amp;gt; 2*mergeFactor&lt;br/&gt;
	pending segments to merge then we select the 2nd set.&lt;/p&gt;

&lt;p&gt;Okay. But it will always return that? Still doesn&apos;t sound concurrent?&lt;/p&gt;

&lt;p&gt;The thing is, the serial merge policy has no concept of concurrent merges, so if the API is always to select the best merge, until a pervious merge finishes, it will always return that as the best merge.&lt;/p&gt;

&lt;p&gt;Concurrent is going to require, by hook or by crook, that a merge policy be able to generate a set of non-conflicting merges, is it not?&lt;/p&gt;

&lt;p&gt;I think the &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-845&quot; title=&quot;If you &amp;quot;flush by RAM usage&amp;quot; then IndexWriter may over-merge&quot;&gt;&lt;del&gt;LUCENE-845&lt;/del&gt;&lt;/a&gt; merge policy does this now, given that CMP gathers up the merge calls. I&apos;m not sure the current &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-847&quot; title=&quot;Factor merge policy out of IndexWriter&quot;&gt;&lt;del&gt;LUCENE-847&lt;/del&gt;&lt;/a&gt; merge policy does (I&apos;d have to double check) because it sometimes will try to use the result of the current merge in the next merge. The &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-845&quot; title=&quot;If you &amp;quot;flush by RAM usage&amp;quot; then IndexWriter may over-merge&quot;&gt;&lt;del&gt;LUCENE-845&lt;/del&gt;&lt;/a&gt; merge doesn&apos;t try to do this which is a&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/thumbs_down.gif&quot; height=&quot;19&quot; width=&quot;19&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; (inconsequential) change?&lt;/p&gt;

&lt;p&gt;	This is another benefit of the simplified API: MergePolicy.maybeMerge&lt;br/&gt;
	would only be called with a lock already acquired (by IndexWriter) on&lt;br/&gt;
	the segmentInfos.&lt;/p&gt;

&lt;p&gt;Do you really mean a lock on segmentInfos or just the lock on IndexWriter? I&apos;m assuming the latter and I think this is the case for both API models.&lt;/p&gt;

&lt;p&gt;I don&apos;t think it&apos;s feasible to have a lock on segmentInfos separately. Only IndexWriter should change segmentInfos and no code should try to look at segmentInfos w/o being called via an IW synch method.&lt;/p&gt;

&lt;p&gt;This does imply that CMP has to copy any segmentInfos data it plans to use during concurrent merging, since the IW lock is not held during these periods. Then, when the merge is done, segmentInfos is updated in IndexWriter via a synch call to IW#replace.&lt;/p&gt;

&lt;p&gt;This means IW#segmentInfos can change while a merge is in progress and this has to be accounted for. That&apos;s what I&apos;m walking through now.&lt;/p&gt;</comment>
                    <comment id="12520374" author="mikemccand" created="Thu, 16 Aug 2007 22:11:13 +0100"  >&lt;p&gt;&amp;gt; Note that merge() was added not for users (which I have no strong&lt;br/&gt;
&amp;gt; opinion about) but so that, potentially, CMP can check again for&lt;br/&gt;
&amp;gt; merges when a set of merge threads completes, i.e., cascade.&lt;/p&gt;

&lt;p&gt;OK, got it.  In fact, then it seems more important that we NOT flush&lt;br/&gt;
at this point?&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; I think instead we should leave the methods, not deprecated, as&lt;br/&gt;
&amp;gt; &amp;gt; convenience (sugar) methods. Simple things should be simple;&lt;br/&gt;
&amp;gt; &amp;gt; complex things should be possible.&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; I think this argues for a LegacyMergePolicy interface again, then?&lt;br/&gt;
&amp;gt; If we change the default merge policy and someone changes their code&lt;br/&gt;
&amp;gt; to use LogDoc for their own purposes, in both cases the&lt;br/&gt;
&amp;gt; getters/setters should work? So cast to the interface and as long as&lt;br/&gt;
&amp;gt; the merge policy supports this, the getters/setters work (unless the&lt;br/&gt;
&amp;gt; merge policy decides to throw within), otherwise the getters/setters&lt;br/&gt;
&amp;gt; throw?&lt;/p&gt;

&lt;p&gt;I don&apos;t think so: I think if someone changes the merge policy to&lt;br/&gt;
something else, it&apos;s fine to require that they then do settings&lt;br/&gt;
directly through that merge policy.  I don&apos;t think we should bring&lt;br/&gt;
back the LegacyMergePolicy interface.&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; Uh, no: when someone calls optimize that means it really must be&lt;br/&gt;
&amp;gt; &amp;gt; done, right? So &quot;optimize&quot; is the right name I think.&lt;br/&gt;
&amp;gt; &lt;br/&gt;
&amp;gt; Yeah, but it might do nothing. Just as merge might do nothing.&lt;/p&gt;

&lt;p&gt;Well... that&apos;s the exception not the rule.  My vote would be for&lt;br/&gt;
&quot;maybeMerge(...)&quot;  and &quot;optimize(..)&quot;.&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; Though, this raises the tricky question of index consistency ...&lt;br/&gt;
&amp;gt; &lt;br/&gt;
&amp;gt; Definitely. I&apos;m still trying to understand all the subtleties here.&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; &amp;gt; IndexWriter commits the new segments file right after&lt;br/&gt;
&amp;gt; &amp;gt; mergePolicy.merge returns ... so for CMP we suddenly have an&lt;br/&gt;
&amp;gt; &amp;gt; unusable index (as seen by an IndexReader).&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; How so? I figured that after mergePolicy.merge returns, in the case&lt;br/&gt;
&amp;gt; of CMP with an ongoing merge, segmentInfos won&apos;t have changed at&lt;br/&gt;
&amp;gt; all. Is that a problem?&lt;/p&gt;

&lt;p&gt;This is inside addIndexes that we&apos;re talking about.  It will have&lt;br/&gt;
changed because the added indexes were stuck into the segmentInfos.&lt;br/&gt;
If you commit that segmentInfos, which now references segments in&lt;br/&gt;
other directories, the index is inconsistent, until the merge policy&lt;br/&gt;
finishes its work (including copying over segments from other dirs).&lt;br/&gt;
In fact this used to be an issue but was fixed in &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-702&quot; title=&quot;Disk full during addIndexes(Directory[]) can corrupt index&quot;&gt;&lt;del&gt;LUCENE-702&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; Maybe it&apos;s too ambitious to allow merges of segments from other&lt;br/&gt;
&amp;gt; &amp;gt; directories to run concurrently?&lt;br/&gt;
&amp;gt; &lt;br/&gt;
&amp;gt; Yeah, that might be the case. At least as a default?&lt;/p&gt;

&lt;p&gt;I think it&apos;s worse: I think we shouldn&apos;t allow any mergePolicy to&lt;br/&gt;
leave the index inconsistent (failing to copy over segments from other&lt;br/&gt;
directories).  I think it&apos;s a bug if the mergePolicy does that and we&lt;br/&gt;
should check &amp;amp; raise an exception, and not commit the new segments&lt;br/&gt;
file.   IndexWriter should in general protect itself from a mergePolicy&lt;br/&gt;
that makes the index inconsistent (and, refuse to commit the resulting&lt;br/&gt;
segments file).&lt;/p&gt;

&lt;p&gt;With the proposed &quot;stateless API&quot; we would keep calling the&lt;br/&gt;
mergePolicy, after each merge, until it returned null, and then do the&lt;br/&gt;
check that index is consistent.&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; I would consider it a hard error in IndexWriter if after calling&lt;br/&gt;
&amp;gt; &amp;gt; mergePolicy.merge from any of the addIndexes*, there remain&lt;br/&gt;
&amp;gt; &amp;gt; segments in other directories. I think we should catch this &amp;amp;&lt;br/&gt;
&amp;gt; &amp;gt; throw an exception?&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; It would be easy enough for CMP to block in this case, rather than&lt;br/&gt;
&amp;gt; returning immediately. Wouldn&apos;t that be better? And I suppose it&apos;s&lt;br/&gt;
&amp;gt; possible to imagine an API on CMP for specifying this behavior?&lt;/p&gt;

&lt;p&gt;I think CMP should indeed block in this case.  I wouldn&apos;t add an API&lt;br/&gt;
to change it.  It&apos;s too dangerous to allow an index to become&lt;br/&gt;
inconsistent.&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; I opened a separate issue &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-982&quot; title=&quot;Create new method optimize(int maxNumSegments) in IndexWriter&quot;&gt;&lt;del&gt;LUCENE-982&lt;/del&gt;&lt;/a&gt; to track this.&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; I think this is good. I think it&apos;s an interesting issue but not&lt;br/&gt;
&amp;gt; directly related to the refactor?&lt;/p&gt;

&lt;p&gt;I think it is related: we should not preclude it in this refactoring.&lt;br/&gt;
I think we should fix MergePolicy.optimize to take &quot;int&lt;br/&gt;
maxNumSegments&quot;?&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; Although ... do you think we need need some way for merge policy&lt;br/&gt;
&amp;gt; &amp;gt; to state where the new segment should be inserted into&lt;br/&gt;
&amp;gt; &amp;gt; SegmentInfos?&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; Right now I assumed it would replace the left most-segment.&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; Since I don&apos;t really know the details of what such a merge policy&lt;br/&gt;
&amp;gt; would like, I don&apos;t really know what it needs.&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; If you&apos;ve thought about this more, do you have a suggestion? I&lt;br/&gt;
&amp;gt; suppose we could just add an int. But, then again, I&apos;d do that as a&lt;br/&gt;
&amp;gt; separate function, leaving the original available, so we can do this&lt;br/&gt;
&amp;gt; later, completely compatibly?&lt;/p&gt;

&lt;p&gt;I don&apos;t have a suggestion &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  And I agree, this is safely postponed while&lt;br/&gt;
keeping future backwards compatibility, so, punt!&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; How can the user close IndexWriter and abort the running merges?  I&lt;br/&gt;
&amp;gt; &amp;gt; guess CMP would provide a method to abort any running merges, and&lt;br/&gt;
&amp;gt; &amp;gt; user would first call that before calling IndexWriter.close?&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; I hadn&apos;t really thought about this but I can see that should be made&lt;br/&gt;
&amp;gt; possible. It&apos;s always safe to abandon a merge so it should be&lt;br/&gt;
&amp;gt; available, for fast, safe, and clean shutdown.&lt;/p&gt;

&lt;p&gt;OK.  Seems like a CMP specific issue (doesn&apos;t impact this discussion).&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; True, LogDoc as it now stands would never exploit concurrency (it&lt;br/&gt;
&amp;gt; &amp;gt; will always return the highest level that needs merging). But, we&lt;br/&gt;
&amp;gt; &amp;gt; could relax that such that if ever the lowest level has &amp;gt;&lt;br/&gt;
&amp;gt; &amp;gt; 2*mergeFactor pending segments to merge then we select the 2nd&lt;br/&gt;
&amp;gt; &amp;gt; set.&lt;br/&gt;
&amp;gt; &lt;br/&gt;
&amp;gt; Okay. But it will always return that? Still doesn&apos;t sound&lt;br/&gt;
&amp;gt; concurrent?&lt;/p&gt;

&lt;p&gt;No, after another N (= mergeFactor) flushes, it would return a new&lt;br/&gt;
suggested merge.  I think this gives CMP concurrency to work with.&lt;br/&gt;
Also I think other merge policies (eg the rough suggestion in&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-854&quot; title=&quot;Create merge policy that doesn&amp;#39;t periodically inadvertently optimize&quot;&gt;&lt;del&gt;LUCENE-854&lt;/del&gt;&lt;/a&gt;) could provide substantial concurrency.&lt;/p&gt;

&lt;p&gt;&amp;gt; The thing is, the serial merge policy has no concept of concurrent&lt;br/&gt;
&amp;gt; merges, so if the API is always to select the best merge, until a&lt;br/&gt;
&amp;gt; pervious merge finishes, it will always return that as the best&lt;br/&gt;
&amp;gt; merge.&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; Concurrent is going to require, by hook or by crook, that a merge&lt;br/&gt;
&amp;gt; policy be able to generate a set of non-conflicting merges, is it&lt;br/&gt;
&amp;gt; not?&lt;/p&gt;

&lt;p&gt;Correct, if we want more than 1 merge running at once then&lt;br/&gt;
mergePolicy must provide non-conflicting merges.&lt;/p&gt;

&lt;p&gt;But, providing just a single concurrent merge already gains us&lt;br/&gt;
concurrency of merging with adding of docs.  Just that is a great step&lt;br/&gt;
forward, and, it&apos;s not clear we can expect performance gains by doing&lt;br/&gt;
2 merges simultaneously with adding docs.  Have you tested this to&lt;br/&gt;
see?&lt;/p&gt;

&lt;p&gt;If we think there are still gains there, we can use the idea above, or&lt;br/&gt;
apps can use other merge policies (like &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-854&quot; title=&quot;Create merge policy that doesn&amp;#39;t periodically inadvertently optimize&quot;&gt;&lt;del&gt;LUCENE-854&lt;/del&gt;&lt;/a&gt;) that don&apos;t always&lt;br/&gt;
choose non-concurrent (conflicting) merges.&lt;/p&gt;

&lt;p&gt;&amp;gt; I think the &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-845&quot; title=&quot;If you &amp;quot;flush by RAM usage&amp;quot; then IndexWriter may over-merge&quot;&gt;&lt;del&gt;LUCENE-845&lt;/del&gt;&lt;/a&gt; merge policy does this now, given that CMP&lt;br/&gt;
&amp;gt; gathers up the merge calls. I&apos;m not sure the current &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-847&quot; title=&quot;Factor merge policy out of IndexWriter&quot;&gt;&lt;del&gt;LUCENE-847&lt;/del&gt;&lt;/a&gt;&lt;br/&gt;
&amp;gt; merge policy does (I&apos;d have to double check) because it sometimes&lt;br/&gt;
&amp;gt; will try to use the result of the current merge in the next&lt;br/&gt;
&amp;gt; merge. The &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-845&quot; title=&quot;If you &amp;quot;flush by RAM usage&amp;quot; then IndexWriter may over-merge&quot;&gt;&lt;del&gt;LUCENE-845&lt;/del&gt;&lt;/a&gt; merge doesn&apos;t try to do this which is a&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/thumbs_down.gif&quot; height=&quot;19&quot; width=&quot;19&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
&amp;gt; (inconsequential) change?&lt;/p&gt;

&lt;p&gt;Right, the &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-845&quot; title=&quot;If you &amp;quot;flush by RAM usage&amp;quot; then IndexWriter may over-merge&quot;&gt;&lt;del&gt;LUCENE-845&lt;/del&gt;&lt;/a&gt; merge policy doesn&apos;t look @ the return result of&lt;br/&gt;
&quot;merge&quot;.  It just looks at the newly created SegmentInfos.&lt;/p&gt;

&lt;p&gt;Hmmmm, in fact, I think your CMP wrapper would not work with the merge&lt;br/&gt;
policy in &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-845&quot; title=&quot;If you &amp;quot;flush by RAM usage&amp;quot; then IndexWriter may over-merge&quot;&gt;&lt;del&gt;LUCENE-845&lt;/del&gt;&lt;/a&gt;, right?  Ie, won&apos;t it will just recurse forever?&lt;br/&gt;
So actually I don&apos;t see how your CMP (using the current API) can in&lt;br/&gt;
general safely &quot;wrap&quot; around a merge policy w/o breaking things?&lt;/p&gt;

&lt;p&gt;Whereas w/ stateless API, where merge policy just returns what should&lt;br/&gt;
be merged rather than executing it itself and cascading, would work&lt;br/&gt;
fine.&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; This is another benefit of the simplified API:&lt;br/&gt;
&amp;gt; &amp;gt; MergePolicy.maybeMerge would only be called with a lock already&lt;br/&gt;
&amp;gt; &amp;gt; acquired (by IndexWriter) on the segmentInfos.&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; Do you really mean a lock on segmentInfos or just the lock on&lt;br/&gt;
&amp;gt; IndexWriter? I&apos;m assuming the latter and I think this is the case&lt;br/&gt;
&amp;gt; for both API models.&lt;/p&gt;

&lt;p&gt;But, if you lock on IndexWriter, what about apps that use multiple&lt;br/&gt;
threads to add documents and but don&apos;t use CMP?  When one thread gets&lt;br/&gt;
tied up merging, you&apos;ll then block on the other synchronized methods?&lt;br/&gt;
And you also can&apos;t flush from other threads either?  I think flushing&lt;br/&gt;
a new segment should be allowed to run concurrently with the merge?&lt;/p&gt;

&lt;p&gt;Whereas if you lock only segmentInfos, and use the proposed stateless&lt;br/&gt;
API, I think the other threads would not be blocked?  I guess I don&apos;t&lt;br/&gt;
see the reason to synchronize on IndexWriter instead of segmentInfos.&lt;/p&gt;

&lt;p&gt;Net/net I&apos;m still thinking we should simplify this API to be&lt;br/&gt;
stateless.  I think there are a number of benefits:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;We would no longer need to add a new IndexMerger interface that&lt;br/&gt;
    adds unecessary complexity to Lucnee (and, make the awkward&lt;br/&gt;
    decisions up front on which IndexWriter fields are allowed to be&lt;br/&gt;
    visible through the interface).&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Keep CMP simpler (only top of stack (where I think &quot;macro&quot;&lt;br/&gt;
    concurrency should live), not top and bottom).&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Work correctly as wrapper around other merge policies (ie not hit&lt;br/&gt;
    infinite recursion because mergePolicy had naturally assumed that&lt;br/&gt;
    &quot;merge&quot; would have changed the segmentInfos)&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Allows locking on segmentInfos (not IndexWriter), and allows&lt;br/&gt;
    concurrency on multiple threads adding docs even without using&lt;br/&gt;
    CMP.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12520408" author="steven_parkes" created="Fri, 17 Aug 2007 00:20:38 +0100"  >&lt;p&gt;	I don&apos;t think so: I think if someone changes the merge policy to&lt;br/&gt;
	something else, it&apos;s fine to require that they then do settings&lt;br/&gt;
	directly through that merge policy.&lt;/p&gt;

&lt;p&gt;You&apos;re going to want to change the default merge policy, right?  So you&apos;re going to change the hard cast in IW to that policy? So it&apos;ll fail for anyone that wants to just getMergePolicy back to the old policy?&lt;/p&gt;

&lt;p&gt;If that&apos;s the case, I&apos;m going to keep those tests the way they are because when you do change the policy, I&apos;m assuming you&apos;ll keep many of them, just add the manual setMergePolicy(), and they&apos;ll need to have those casts put back in?&lt;/p&gt;

&lt;p&gt;Maybe we just put it in MergePolicy interface and let them throw (e.g., via MergePolicyBase) if called on an unsupported merge policy? That&apos;s moving from compile time checking to run time checking, but ... &lt;/p&gt;

&lt;p&gt;	This is inside addIndexes that we&apos;re talking about.&lt;/p&gt;

&lt;p&gt;Ah. Right.&lt;/p&gt;

&lt;p&gt;	I think we shouldn&apos;t allow any mergePolicy to&lt;br/&gt;
	leave the index inconsistent (failing to copy over segments from other&lt;br/&gt;
	directories).&lt;/p&gt;

&lt;p&gt;That makes sense to me. CMP could enforce this, even in the case of concurrent merges.&lt;/p&gt;

&lt;p&gt;	No, after another N (= mergeFactor) flushes, it would return a new&lt;br/&gt;
	suggested merge.&lt;/p&gt;

&lt;p&gt;Okay. I think I&apos;m following you here.&lt;/p&gt;

&lt;p&gt;Here&apos;s what I understand: in your model, (1) each call to merge will only ever generate one merge thread (regardless of how many levels might be full) and (2) you can get concurrency out of this as long as you consider a level &quot;merge worthy&quot; as different from &quot;full&quot;, i.e., blocking).&lt;/p&gt;

&lt;p&gt;You did say  &lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; But, we&lt;br/&gt;
&amp;gt; &amp;gt; could relax that such that if ever the lowest level has &amp;gt;&lt;br/&gt;
&amp;gt; &amp;gt; 2*mergeFactor pending segments to merge then we select the 2nd&lt;br/&gt;
&amp;gt; &amp;gt; set.&lt;/p&gt;

&lt;p&gt;And I think you&apos;d want to modify that to select the lowest sufficiently over subscribed level, not just the lowest level if it&apos;s oversubscribed?&lt;/p&gt;

&lt;p&gt;Perhaps this is sufficient, but not necessary? I see it as simpler just to have the merge policy (abstractly) generate a set of non-conflicting merges and let someone else worry about scheduling them.&lt;/p&gt;

&lt;p&gt;	But, providing just a single concurrent merge already gains us&lt;br/&gt;
	concurrency of merging with adding of docs.&lt;/p&gt;

&lt;p&gt;I&apos;m worried about when you start the leftmost merge, that, say, is going to take a day. With a steady influx of docs, it&apos;s not going to be long before you need another merge and if you have only one thread, you&apos;re going to block for the rest of the day. You&apos;ve bought a little concurrency, but it&apos;s the almost day-long block I really want to avoid.&lt;/p&gt;

&lt;p&gt;With a log-like policy, I think it&apos;s feasible to have logN threads. You might not want them all doing disk i/o at the same time: you&apos;d want to prioritize threads on the small merges and/or suspend large merge threads.  The speed with which the larger merge threads can vary when other merges are taking place, you just have to not stop them and start over. &lt;/p&gt;

&lt;p&gt;	Right, the &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-845&quot; title=&quot;If you &amp;quot;flush by RAM usage&amp;quot; then IndexWriter may over-merge&quot;&gt;&lt;del&gt;LUCENE-845&lt;/del&gt;&lt;/a&gt; merge policy doesn&apos;t look @ the return result of&lt;br/&gt;
	&quot;merge&quot;.  It just looks at the newly created SegmentInfos.&lt;/p&gt;

&lt;p&gt;Yeah. My thinking was this would be tweaked. If merger.merge returns a valid number of docs, it could recurse as it does. If merger.merge returned -1 (which CMP does), it would not recurse but simply continue the loop.&lt;/p&gt;

&lt;p&gt;	Hmmmm, in fact, I think your CMP wrapper would not work with the merge&lt;br/&gt;
	policy in &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-845&quot; title=&quot;If you &amp;quot;flush by RAM usage&amp;quot; then IndexWriter may over-merge&quot;&gt;&lt;del&gt;LUCENE-845&lt;/del&gt;&lt;/a&gt;, right?  Ie, won&apos;t it will just recurse forever?&lt;br/&gt;
	So actually I don&apos;t see how your CMP (using the current API) can in&lt;br/&gt;
	general safely &quot;wrap&quot; around a merge policy w/o breaking things?&lt;/p&gt;

&lt;p&gt;I think it&apos;s safe, just not concurrent. The recursion would generate the same set of segments to merge and CMP would make the second call block (abstractly, anyway: it actually throws an exception that unwinds the stack and causes the call to start again from the top when the conflicting merge finishes).&lt;/p&gt;

&lt;p&gt;	But, if you lock on IndexWriter, what about apps that use multiple&lt;br/&gt;
	threads to add documents and but don&apos;t use CMP?  When one thread gets&lt;br/&gt;
	tied up merging, you&apos;ll then block on the other synchronized methods?&lt;br/&gt;
	And you also can&apos;t flush from other threads either?  I think flushing&lt;br/&gt;
	a new segment should be allowed to run concurrently with the merge?&lt;/p&gt;

&lt;p&gt;I&apos;m not sure I&apos;m following this. That&apos;s what happens now, right? Are you trying to get more concurrency then there is now w/o using CMP? I certainly haven&apos;t been trying to do that.&lt;/p&gt;

&lt;p&gt;	I guess I don&apos;t&lt;br/&gt;
	see the reason to synchronize on IndexWriter instead of segmentInfos.&lt;/p&gt;

&lt;p&gt;I looked at trying to make IW work when a synchronization of IW didn&apos;t imply a synchronization of segmentInfos. It&apos;s a very, very heavily used little data structure. I found it very hard to convince myself I could catch all the places locks would be required. And at the same time, I seemed to be able to do everything I needed with IW locking.&lt;/p&gt;

&lt;p&gt;That said, the code&apos;s not done, so ....&lt;/p&gt;

&lt;p&gt;	Net/net I&apos;m still thinking we should simplify this API to be&lt;br/&gt;
	stateless.  I think there are a number of benefits:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;We would no longer need to add a new IndexMerger interface that&lt;br/&gt;
	    adds unecessary complexity to Lucnee (and, make the awkward&lt;br/&gt;
	    decisions up front on which IndexWriter fields are allowed to be&lt;br/&gt;
	    visible through the interface).&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Keep CMP simpler (only top of stack (where I think &quot;macro&quot;&lt;br/&gt;
	    concurrency should live), not top and bottom).&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Work correctly as wrapper around other merge policies (ie not hit&lt;br/&gt;
	    infinite recursion because mergePolicy had naturally assumed that&lt;br/&gt;
	    &quot;merge&quot; would have changed the segmentInfos)&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Allows locking on segmentInfos (not IndexWriter), and allows&lt;br/&gt;
 	   concurrency on multiple threads adding docs even without using&lt;br/&gt;
 	   CMP.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Hmmm ... I guess our approaches are pretty different. If you want to take a stab at this ...&lt;/p&gt;</comment>
                    <comment id="12520874" author="mikemccand" created="Sat, 18 Aug 2007 19:01:10 +0100"  >&lt;p&gt;&amp;gt; &amp;gt; I don&apos;t think so: I think if someone changes the merge policy to&lt;br/&gt;
&amp;gt; &amp;gt; something else, it&apos;s fine to require that they then do settings&lt;br/&gt;
&amp;gt; &amp;gt; directly through that merge policy.&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; You&apos;re going to want to change the default merge policy, right?  So&lt;br/&gt;
&amp;gt; you&apos;re going to change the hard cast in IW to that policy? So it&apos;ll&lt;br/&gt;
&amp;gt; fail for anyone that wants to just getMergePolicy back to the old&lt;br/&gt;
&amp;gt; policy?&lt;/p&gt;

&lt;p&gt;I don&apos;t really follow... my feeling is we should not deprecate&lt;br/&gt;
setUseCompoundFile, setMergeFactor, setMaxMergeDocs.&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; I think we shouldn&apos;t allow any mergePolicy to leave the index&lt;br/&gt;
&amp;gt; &amp;gt; inconsistent (failing to copy over segments from other&lt;br/&gt;
&amp;gt; &amp;gt; directories).&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; That makes sense to me. CMP could enforce this, even in the case of&lt;br/&gt;
&amp;gt; concurrent merges.&lt;/p&gt;

&lt;p&gt;I think IndexWriter should enforce it?  Ie no merge policy should be&lt;br/&gt;
allowed to leave segments in other dirs (= at inconsistent index) at&lt;br/&gt;
point of commit.&lt;/p&gt;

&lt;p&gt;&amp;gt; Perhaps this is sufficient, but not necessary? I see it as simpler&lt;br/&gt;
&amp;gt; just to have the merge policy (abstractly) generate a set of&lt;br/&gt;
&amp;gt; non-conflicting merges and let someone else worry about scheduling&lt;br/&gt;
&amp;gt; them.&lt;/p&gt;

&lt;p&gt;I like that idea &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  It fits well w/ the stateless API.  Ie, merge&lt;br/&gt;
policy returns all possible merges and &quot;someone above&quot; takes care of&lt;br/&gt;
scheduling them.&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; But, providing just a single concurrent merge already gains us&lt;br/&gt;
&amp;gt; &amp;gt; concurrency of merging with adding of docs.&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; I&apos;m worried about when you start the leftmost merge, that, say, is&lt;br/&gt;
&amp;gt; going to take a day. With a steady influx of docs, it&apos;s not going to&lt;br/&gt;
&amp;gt; be long before you need another merge and if you have only one&lt;br/&gt;
&amp;gt; thread, you&apos;re going to block for the rest of the day. You&apos;ve bought&lt;br/&gt;
&amp;gt; a little concurrency, but it&apos;s the almost day-long block I really&lt;br/&gt;
&amp;gt; want to avoid.&lt;/p&gt;

&lt;p&gt;Ahh ... very good point.  I agree.&lt;/p&gt;

&lt;p&gt;&amp;gt; With a log-like policy, I think it&apos;s feasible to have logN&lt;br/&gt;
&amp;gt; threads. You might not want them all doing disk i/o at the same&lt;br/&gt;
&amp;gt; time: you&apos;d want to prioritize threads on the small merges and/or&lt;br/&gt;
&amp;gt; suspend large merge threads.  The speed with which the larger merge&lt;br/&gt;
&amp;gt; threads can vary when other merges are taking place, you just have&lt;br/&gt;
&amp;gt; to not stop them and start over.&lt;/p&gt;

&lt;p&gt;Agreed: CMP should do this.&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; Right, the &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-845&quot; title=&quot;If you &amp;quot;flush by RAM usage&amp;quot; then IndexWriter may over-merge&quot;&gt;&lt;del&gt;LUCENE-845&lt;/del&gt;&lt;/a&gt; merge policy doesn&apos;t look @ the return&lt;br/&gt;
&amp;gt; &amp;gt; result of &quot;merge&quot;.  It just looks at the newly created&lt;br/&gt;
&amp;gt; &amp;gt; SegmentInfos.&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; Yeah. My thinking was this would be tweaked. If merger.merge returns&lt;br/&gt;
&amp;gt; a valid number of docs, it could recurse as it does. If merger.merge&lt;br/&gt;
&amp;gt; returned -1 (which CMP does), it would not recurse but simply&lt;br/&gt;
&amp;gt; continue the loop.&lt;/p&gt;

&lt;p&gt;Hmm.  This means each merge policy must know whether it&apos;s talking to&lt;br/&gt;
CMP or IndexWriter underneith?  With the stateless approach this&lt;br/&gt;
wouldn&apos;t happen.&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; Hmmmm, in fact, I think your CMP wrapper would not work with the&lt;br/&gt;
&amp;gt; &amp;gt; merge policy in &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-845&quot; title=&quot;If you &amp;quot;flush by RAM usage&amp;quot; then IndexWriter may over-merge&quot;&gt;&lt;del&gt;LUCENE-845&lt;/del&gt;&lt;/a&gt;, right?  Ie, won&apos;t it will just recurse&lt;br/&gt;
&amp;gt; &amp;gt; forever?  So actually I don&apos;t see how your CMP (using the current&lt;br/&gt;
&amp;gt; &amp;gt; API) can in general safely &quot;wrap&quot; around a merge policy w/o&lt;br/&gt;
&amp;gt; &amp;gt; breaking things?&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; I think it&apos;s safe, just not concurrent. The recursion would generate&lt;br/&gt;
&amp;gt; the same set of segments to merge and CMP would make the second call&lt;br/&gt;
&amp;gt; block (abstractly, anyway: it actually throws an exception that&lt;br/&gt;
&amp;gt; unwinds the stack and causes the call to start again from the top&lt;br/&gt;
&amp;gt; when the conflicting merge finishes).&lt;/p&gt;

&lt;p&gt;Oh I see...  that&apos;s kind of sneaky (planning on using exceptions to&lt;br/&gt;
abort a merge requested by the policy).  I think the stateless&lt;br/&gt;
approach would be cleaner here.&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; But, if you lock on IndexWriter, what about apps that use multiple&lt;br/&gt;
&amp;gt; &amp;gt; threads to add documents and but don&apos;t use CMP?  When one thread&lt;br/&gt;
&amp;gt; &amp;gt; gets tied up merging, you&apos;ll then block on the other synchronized&lt;br/&gt;
&amp;gt; &amp;gt; methods?  And you also can&apos;t flush from other threads either?  I&lt;br/&gt;
&amp;gt; &amp;gt; think flushing a new segment should be allowed to run concurrently&lt;br/&gt;
&amp;gt; &amp;gt; with the merge?&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; I&apos;m not sure I&apos;m following this. That&apos;s what happens now, right? Are&lt;br/&gt;
&amp;gt; you trying to get more concurrency then there is now w/o using CMP?&lt;br/&gt;
&amp;gt; I certainly haven&apos;t been trying to do that.&lt;/p&gt;

&lt;p&gt;True, this is something new.  But since you&apos;re already doing the work&lt;br/&gt;
to allow a merge to run in the BG without blocking adding of docs,&lt;br/&gt;
flushing, etc, wouldn&apos;t this come nearly for free?  Actually I think&lt;br/&gt;
all that&apos;s necessary, regardless of sync&apos;ing on IndexWriter or&lt;br/&gt;
SegmentInfos is to move the &quot;if (triggerMerge)&quot; out of the&lt;br/&gt;
synchronized method/block.&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; I guess I don&apos;t see the reason to synchronize on IndexWriter&lt;br/&gt;
&amp;gt; &amp;gt; instead of segmentInfos.&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; I looked at trying to make IW work when a synchronization of IW&lt;br/&gt;
&amp;gt; didn&apos;t imply a synchronization of segmentInfos. It&apos;s a very, very&lt;br/&gt;
&amp;gt; heavily used little data structure. I found it very hard to convince&lt;br/&gt;
&amp;gt; myself I could catch all the places locks would be required. And at&lt;br/&gt;
&amp;gt; the same time, I seemed to be able to do everything I needed with IW&lt;br/&gt;
&amp;gt; locking.&lt;/p&gt;

&lt;p&gt;Well, eg flush() now synchronizes on IndexWriter: we don&apos;t want 2&lt;br/&gt;
threads doing this at once.  But, the touching of segmentInfos inside&lt;br/&gt;
flush (to add the new SegmentInfo) is a tiny fleeting event (like&lt;br/&gt;
replace) and so you would want segmentInfos to be free to change while&lt;br/&gt;
the flushing was running (eg by a BG merge that has finished).&lt;/p&gt;

&lt;p&gt;&amp;gt; Hmmm ... I guess our approaches are pretty different. If you want to&lt;br/&gt;
&amp;gt; take a stab at this ...&lt;/p&gt;

&lt;p&gt;OK I will try to take a rough stab a the stateless approach....&lt;/p&gt;</comment>
                    <comment id="12520881" author="steven_parkes" created="Sat, 18 Aug 2007 19:29:29 +0100"  >&lt;p&gt;	my feeling is we should not deprecate&lt;br/&gt;
	setUseCompoundFile, setMergeFactor, setMaxMergeDocs&lt;/p&gt;

&lt;p&gt;I understood that you didn&apos;t want to deprecate them in IndexWriter. I wasn&apos;t sure that you meant that they should be added to the MergePolicy interface? If you do, everything makes sense. Otherwise, it sounds like there&apos;s still a cast in there and I&apos;m not sure about that.&lt;/p&gt;

&lt;p&gt;	I think IndexWriter should enforce it?  Ie no merge policy should be&lt;br/&gt;
	allowed to leave segments in other dirs (= at inconsistent index) at&lt;br/&gt;
	point of commit.&lt;/p&gt;

&lt;p&gt;I think it&apos;s just about code location: since a merge policy might want to factor into it&apos;s algorithm the directories used, it needs the info and it will presumably sometimes do it. Presumably you could provide code in MergePolicyBase so the merges could decide when but wouldn&apos;t have to write the copy loop. If you put the code in IndexWriter too, it sounds duplicated, again presuming sometimes a policy might want to do it itself. &lt;/p&gt;

&lt;p&gt;	I like that idea &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  It fits well w/ the stateless API.  Ie, merge&lt;br/&gt;
	policy returns all possible merges and &quot;someone above&quot; takes care of&lt;br/&gt;
	scheduling them.&lt;/p&gt;

&lt;p&gt;So it returns a vector of specs?&lt;/p&gt;

&lt;p&gt;That&apos;s essentially what the CMP as an above/below wrapper does. I can see that above/below is strange enough to be less clever (I wasn&apos;t trying to be so much clever as backwards compatible) and more insane.&lt;/p&gt;

&lt;p&gt;Sane is good.&lt;/p&gt;

&lt;p&gt;	Hmm.  This means each merge policy must know whether it&apos;s talking to&lt;br/&gt;
	CMP or IndexWriter underneith?  With the stateless approach this&lt;br/&gt;
	wouldn&apos;t happen.&lt;/p&gt;

&lt;p&gt;Well, I wouldn&apos;t so much say it has to know. All it cares is what merge returns. Doesn&apos;t have to know who returned it or why.&lt;/p&gt;

&lt;p&gt;The only real difference between this and the &quot;generate a vector of merges&quot; is that in the merge policy can take advantage immediately of merge results in the serial case where if you&apos;re generating a vector of merges, it can&apos;t know.&lt;/p&gt;

&lt;p&gt;Of course, I guess in that case, if IndexWriter gets a vector of merges, it can always take the lowest and ignore the rest, calling the merge policy again incase it wants to request a different set. Then you only have the excess computation for merges you never really considered.&lt;/p&gt;

&lt;p&gt;	Oh I see...  that&apos;s kind of sneaky (planning on using exceptions to&lt;br/&gt;
	abort a merge requested by the policy).&lt;/p&gt;

&lt;p&gt;There&apos;s always going to be the chance of an exception to a merge. I&apos;m pretty sure of that. But you&apos;re right, if the merge policy isn&apos;t in the control path, it would never see them. They&apos;ll be there, but it&apos;s out of the path.&lt;/p&gt;

&lt;p&gt;	But since you&apos;re already doing the work&lt;br/&gt;
	to allow a merge to run in the BG without blocking adding of docs,&lt;br/&gt;
	flushing, etc, wouldn&apos;t this come nearly for free?&lt;/p&gt;

&lt;p&gt;I haven&apos;t looked at this.&lt;/p&gt;

&lt;p&gt;	Well, eg flush() now synchronizes on IndexWriter&lt;/p&gt;

&lt;p&gt;Yeah, and making it not is less than straightforward. I&apos;ve looked at his code a fair amount, experimented with different ideas, but hadn&apos;t gotten all the way to a working model.&lt;/p&gt;

&lt;p&gt;You can look at locking segmentInfos but there are many places that segmentInfos is iterated over that would require locks if the lock on IW wasn&apos;t sufficient to guarantee that the iteration was safe.&lt;/p&gt;

&lt;p&gt;I did look at that early on, so maybe my understanding was still too lacking and it&apos;s more feasible than I was thinking ...&lt;/p&gt;</comment>
                    <comment id="12522575" author="mikemccand" created="Fri, 24 Aug 2007 17:38:21 +0100"  >&lt;p&gt;OK I started from the original patch and made the changes described&lt;br/&gt;
below.&lt;/p&gt;

&lt;p&gt;This is still a work in progress, but I think I think the new&lt;br/&gt;
stateless approach works very well.&lt;/p&gt;

&lt;p&gt;All unit tests pass (one assert had to be changed in&lt;br/&gt;
TestAddIndexesNoOptimize).&lt;/p&gt;

&lt;p&gt;I created a ConcurrentMergePolicyWrapper along with this (I&apos;ll post&lt;br/&gt;
patch to &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-870&quot; title=&quot;add concurrent merge policy&quot;&gt;&lt;del&gt;LUCENE-870&lt;/del&gt;&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;I&apos;ve also included the two merge policies from &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-845&quot; title=&quot;If you &amp;quot;flush by RAM usage&amp;quot; then IndexWriter may over-merge&quot;&gt;&lt;del&gt;LUCENE-845&lt;/del&gt;&lt;/a&gt; (still&lt;br/&gt;
defaulting to LogDocMergePolicy).&lt;/p&gt;

&lt;p&gt;Here are the changes:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Renamed merge -&amp;gt; maybeMerge&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Changed the API to be &quot;stateless&quot; meaning the merge policy is no&lt;br/&gt;
    longer responsible for running the merges itself.  Instead, it&lt;br/&gt;
    quickly returns the specification, which describes which merges&lt;br/&gt;
    are needed, back to the writer and the writer then runs them.  I&lt;br/&gt;
    also changed MergeSpecification to contain a list of OneMerge&lt;br/&gt;
    instances.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Removed IndexMerger interface (just use IndexWriter instead)&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Put isOptimized() logic into LogMergePolicy: on thinking about&lt;br/&gt;
    this more (and seeing response to a thread on java-dev), I now&lt;br/&gt;
    agree with Steve that this logically belongs in LogMergePolicy&lt;br/&gt;
    because each MergePolicy is free to define just what it considers&lt;br/&gt;
    &quot;optimized&quot; to mean.  Then I removed the MergePolicyBase.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Un-deprecated 
{get/set}
{UseCompoundFile,MergeFactor,MaxMergeDocs}
&lt;p&gt;.&lt;br/&gt;
    But I did leave the static constants deprecated.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;IndexWriter keeps track of which segments are involved in running&lt;br/&gt;
    merges and throws a MergeException if it&apos;s asked to initiate a&lt;br/&gt;
    merge that involves a segment that&apos;s already being merged.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Fixed LogMergePolicy to return all possible merges (exposes&lt;br/&gt;
    concurrency).&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Implemented the &quot;merge deletes when commiting the merge&quot; algorithm&lt;br/&gt;
    that Ning suggested (this is in commitMerge).&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Assert that the merge request is in fact contiguous (at start &amp;amp;&lt;br/&gt;
    finish of merge) &amp;amp; throw MergeException if not.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Fixed a number of sneaky concurrency issues so that CMPW would&lt;br/&gt;
    work.  Broke &quot;merge&quot; into mergeInit, mergeMiddle and mergeFinish.&lt;br/&gt;
    The first &amp;amp; last are carefully sychronized.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;I put copyDirFiles in IW and call this in addIndexesNoOptimize&lt;br/&gt;
    before committing new segments file: we can&apos;t let mergePolicy&lt;br/&gt;
    leave the index inconsistent.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;I reverted the changes to addIndexes(IndexReader[]): I think the&lt;br/&gt;
    change here wasn&apos;t valid: you can&apos;t assume that you can re-create&lt;br/&gt;
    any IndexReader instance by loading from its directory; I put the&lt;br/&gt;
    original back for this method.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;the changes to addIndexes I&apos;m not sure are good.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Fixed LogMergePolicy to return more than 1 merge&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Made CMPW&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Renamed replace -&amp;gt; commitMerge; made it private.&lt;/li&gt;
&lt;/ul&gt;

</comment>
                    <comment id="12523104" author="mikemccand" created="Mon, 27 Aug 2007 22:05:35 +0100"  >&lt;p&gt;OK new patch:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Added the missing MergePolicy.java from last time that Ning caught&lt;br/&gt;
    (thanks!)&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Fixed some javadocs&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Relaxed synchronization of merging so that merges can run&lt;br/&gt;
    concurrently with flushing if you are using multiple thread to do&lt;br/&gt;
    indexing.  This gains concurrency of merging even if you are not&lt;br/&gt;
    using CMPW.  But I left flushing as synchronized; I think we can&lt;br/&gt;
    relax this at some point in the future.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Fixed some concurrency issues&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Added &quot;minMergeDocs&quot; to LogDocMergePolicy and &quot;minMergeMB&quot; to&lt;br/&gt;
    LogByteSizeMergePolicy; set their defaults as described in&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-845&quot; title=&quot;If you &amp;quot;flush by RAM usage&amp;quot; then IndexWriter may over-merge&quot;&gt;&lt;del&gt;LUCENE-845&lt;/del&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Still a few small things to do.  I think it&apos;s getting close.&lt;/p&gt;</comment>
                    <comment id="12523621" author="ningli" created="Wed, 29 Aug 2007 17:22:04 +0100"  >&lt;p&gt;I include comments for both &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-847&quot; title=&quot;Factor merge policy out of IndexWriter&quot;&gt;&lt;del&gt;LUCENE-847&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-870&quot; title=&quot;add concurrent merge policy&quot;&gt;&lt;del&gt;LUCENE-870&lt;/del&gt;&lt;/a&gt; here since they are closely related.&lt;/p&gt;

&lt;p&gt;I like the stateless approach used for refactoring merge policy. But modeling concurrent merge (ConcurrentMergePolicyWrapper) as a MergePolicy seems to be inconsistent with the MergePolicy interface:&lt;br/&gt;
  1 As you pointed out, &quot;the merge policy is no longer responsible for running the merges itself&quot;. MergePolicy.maybeMerge simply returns a merge specification. But ConcurrentMergePolicyWrapper.maybeMerge actually starts concurrent merge threads thus doing the merges.&lt;br/&gt;
  2 Related to 1, cascading is done in IndexWriter in non-concurrent case. But in concurrent case, cascading is also done in merge threads which are started by ConcurrentMergePolicyWrapper.maybeMerge.&lt;/p&gt;

&lt;p&gt;MergePolicy.maybeMerge should continue to simply return a merge specification. (BTW, should we rename this maybeMerge to, say, findCandidateMerges?) Can we carve the merge process out of IndexWriter into a Merger? IndexWriter still provides the building blocks - merge(OneMerge), mergeInit(OneMerge), etc. Merger uses these building blocks. A ConcurrentMerger extends Merger but starts concurrent merge threads as ConcurrentMergePolicyWrapper does.&lt;/p&gt;


&lt;p&gt;Other comments:&lt;br/&gt;
1 UpdateDocument&apos;s and deleteDocument&apos;s bufferDeleteTerm are synchronized on different variables in this patch. However, the semantics of updateDocument changed since &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-843&quot; title=&quot;improve how IndexWriter uses RAM to buffer added documents&quot;&gt;&lt;del&gt;LUCENE-843&lt;/del&gt;&lt;/a&gt;. Before &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-843&quot; title=&quot;improve how IndexWriter uses RAM to buffer added documents&quot;&gt;&lt;del&gt;LUCENE-843&lt;/del&gt;&lt;/a&gt;, updateDocument, which is a delete and an insert, guaranteed the delete and the insert are committed together (thus an update). Now it&apos;s possible that they are committed in different transactions. If we consider DocumentsWriter as the RAM staging area for IndexWriter, then deletes are also buffered in RAM staging area and we can restore our previous semantics, right?&lt;/p&gt;

&lt;p&gt;2 OneMerge.segments seems to rely on its segment infos&apos; reference to segment infos of IndexWriter.segmentInfos. The use in commitMerge, which calls ensureContiguousMerge, is an example. However, segmentInfos can be a cloned copy because of exceptions, thus the reference broken.&lt;/p&gt;

&lt;p&gt;3 Calling optimize of an IndexWriter with the current ConcurrentMergePolicyWrapper may cause deadlock: the one merge spec returned by MergePolicy.optimize may be in conflict with a concurrent merge (the same merge spec will be returned without changes to segmentInfos), but a concurrent merge cannot finish because optimize is holding the lock.&lt;/p&gt;

&lt;p&gt;4 Finally, a couple of minor things:&lt;br/&gt;
  1 LogMergePolicy.useCompoundFile(SegmentInfos infos, SegmentInfo info) and useCompoundDocStore(SegmentInfos infos): why the parameters?&lt;br/&gt;
  2 Do we need doMergeClose in IndexWriter? Can we simply close a MergePolicy if not null?&lt;/p&gt;</comment>
                    <comment id="12523798" author="mikemccand" created="Thu, 30 Aug 2007 10:09:44 +0100"  >&lt;p&gt;Thanks for the detailed review Ning!&lt;/p&gt;

&lt;p&gt;&amp;gt; 1 As you pointed out, &quot;the merge policy is no longer responsible for&lt;br/&gt;
&amp;gt; running the merges itself&quot;. MergePolicy.maybeMerge simply returns a&lt;br/&gt;
&amp;gt; merge specification. But ConcurrentMergePolicyWrapper.maybeMerge&lt;br/&gt;
&amp;gt; actually starts concurrent merge threads thus doing the merges.&lt;/p&gt;

&lt;p&gt;True, but I was thinking CMPW could be an exception to this rule.  I&lt;br/&gt;
guess I would change the rule to &quot;simple merge policies don&apos;t have to&lt;br/&gt;
run their own merges&quot;?&lt;/p&gt;

&lt;p&gt;However I do agree, CMPW is clearly a different beast from a typical&lt;br/&gt;
merge policy because it entails scheduling, not selection, of merges.&lt;/p&gt;

&lt;p&gt;&amp;gt; 2 Related to 1, cascading is done in IndexWriter in non-concurrent&lt;br/&gt;
&amp;gt; case. But in concurrent case, cascading is also done in merge&lt;br/&gt;
&amp;gt; threads which are started by&lt;br/&gt;
&amp;gt; ConcurrentMergePolicyWrapper.maybeMerge.&lt;/p&gt;

&lt;p&gt;Good point...  I think I could refactor this so that cascading logic&lt;br/&gt;
lives entirely in one place IndexWriter.&lt;/p&gt;

&lt;p&gt;&amp;gt; MergePolicy.maybeMerge should continue to simply return a merge&lt;br/&gt;
&amp;gt; specification. (BTW, should we rename this maybeMerge to, say,&lt;br/&gt;
&amp;gt; findCandidateMerges?)&lt;/p&gt;

&lt;p&gt;Good!  I like findCandidateMerges better; I&apos;ll change it.&lt;/p&gt;

&lt;p&gt;&amp;gt; Can we carve the merge process out of IndexWriter into a Merger?&lt;br/&gt;
&amp;gt; IndexWriter still provides the building blocks - merge(OneMerge),&lt;br/&gt;
&amp;gt; mergeInit(OneMerge), etc. Merger uses these building blocks. A&lt;br/&gt;
&amp;gt; ConcurrentMerger extends Merger but starts concurrent merge threads&lt;br/&gt;
&amp;gt; as ConcurrentMergePolicyWrapper does.&lt;/p&gt;

&lt;p&gt;How would this be used?  Ie, how would one make an IndexWriter that&lt;br/&gt;
uses the ConcurrentMerger?  Would we add expert methods&lt;br/&gt;
IndexWriter.set/getIndexMerger(...)?  (And presumably the mergePolicy&lt;br/&gt;
is now owned by IndexMerger so it would have the&lt;br/&gt;
set/getMergePolicy(...)?)&lt;/p&gt;

&lt;p&gt;Also, how would you separate what remains in IW vs what would be in&lt;br/&gt;
IndexMerger?&lt;/p&gt;

&lt;p&gt;I like this approach in principle; I&apos;m just trying to hash out the&lt;br/&gt;
details...&lt;/p&gt;

&lt;p&gt;&amp;gt; 1 UpdateDocument&apos;s and deleteDocument&apos;s bufferDeleteTerm are&lt;br/&gt;
&amp;gt; synchronized on different variables in this patch.&lt;/p&gt;

&lt;p&gt;Woops, good catch!  I&apos;ll fix.&lt;/p&gt;

&lt;p&gt;&amp;gt; However, the semantics of updateDocument changed since&lt;br/&gt;
&amp;gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-843&quot; title=&quot;improve how IndexWriter uses RAM to buffer added documents&quot;&gt;&lt;del&gt;LUCENE-843&lt;/del&gt;&lt;/a&gt;. Before &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-843&quot; title=&quot;improve how IndexWriter uses RAM to buffer added documents&quot;&gt;&lt;del&gt;LUCENE-843&lt;/del&gt;&lt;/a&gt;, updateDocument, which is a delete and&lt;br/&gt;
&amp;gt; an insert, guaranteed the delete and the insert are committed&lt;br/&gt;
&amp;gt; together (thus an update). Now it&apos;s possible that they are committed&lt;br/&gt;
&amp;gt; in different transactions. If we consider DocumentsWriter as the RAM&lt;br/&gt;
&amp;gt; staging area for IndexWriter, then deletes are also buffered in RAM&lt;br/&gt;
&amp;gt; staging area and we can restore our previous semantics, right?&lt;/p&gt;

&lt;p&gt;Hmm ... you&apos;re right.  This is a separate issue from merge policy,&lt;br/&gt;
right?  Are you proposing buffering deletes in DocumentsWriter&lt;br/&gt;
instead?&lt;/p&gt;

&lt;p&gt;&amp;gt; 2 OneMerge.segments seems to rely on its segment infos&apos; reference to&lt;br/&gt;
&amp;gt; segment infos of IndexWriter.segmentInfos. The use in commitMerge,&lt;br/&gt;
&amp;gt; which calls ensureContiguousMerge, is an example. However,&lt;br/&gt;
&amp;gt; segmentInfos can be a cloned copy because of exceptions, thus the&lt;br/&gt;
&amp;gt; reference broken.&lt;/p&gt;

&lt;p&gt;Good catch!  How to fix?  One thing we could do is always use&lt;br/&gt;
SegmentInfo.reset(...) and never swap in clones at the SegmentInfo&lt;br/&gt;
level.  This way using the default &apos;equals&apos; (same instance) would&lt;br/&gt;
work.  Or we could establish identity (equals) of a SegmentInfo as&lt;br/&gt;
checking if the directory plus segment name are equal?  I think I&apos;d&lt;br/&gt;
lean to the 2nd option....&lt;/p&gt;

&lt;p&gt;&amp;gt; 3 Calling optimize of an IndexWriter with the current&lt;br/&gt;
&amp;gt; ConcurrentMergePolicyWrapper may cause deadlock: the one merge spec&lt;br/&gt;
&amp;gt; returned by MergePolicy.optimize may be in conflict with a&lt;br/&gt;
&amp;gt; concurrent merge (the same merge spec will be returned without&lt;br/&gt;
&amp;gt; changes to segmentInfos), but a concurrent merge cannot finish&lt;br/&gt;
&amp;gt; because optimize is holding the lock.&lt;/p&gt;

&lt;p&gt;Hmmm yes.  In fact I think we can remove synchronized from optimize&lt;br/&gt;
altogether since within it we are synchronizing(this) at the right&lt;br/&gt;
places?  If more than one thread calls optimize at once, externally,&lt;br/&gt;
it is actually OK: they will each pick a merge that&apos;s viable&lt;br/&gt;
(concurrently) and will run the merge, else return once there is no&lt;br/&gt;
more concurrency left.  I&apos;ll add a unit test that confirms this.&lt;/p&gt;

&lt;p&gt;&amp;gt; 4 Finally, a couple of minor things:&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt;   1 LogMergePolicy.useCompoundFile(SegmentInfos infos, SegmentInfo&lt;br/&gt;
&amp;gt;     info) and useCompoundDocStore(SegmentInfos infos): why the&lt;br/&gt;
&amp;gt;     parameters?&lt;/p&gt;

&lt;p&gt;Well, useCompoundFile(...) is given a single newly flushed segment and&lt;br/&gt;
should decide whether it should be CFS.  Whereas&lt;br/&gt;
useCompoundDocStore(...) is called when doc stores are flushed.  When&lt;br/&gt;
autoCommit=false, segments can share a single set of doc stores, so&lt;br/&gt;
there&apos;s no single SegmentInfo to pass down.&lt;/p&gt;

&lt;p&gt;&amp;gt; 2 Do we need doMergeClose in IndexWriter? Can we simply close a&lt;br/&gt;
&amp;gt;   MergePolicy if not null?&lt;/p&gt;

&lt;p&gt;Good point.  I think this is reasonable &amp;#8211; I&apos;ll fix.&lt;/p&gt;</comment>
                    <comment id="12523957" author="ningli" created="Thu, 30 Aug 2007 23:33:30 +0100"  >&lt;p&gt;&amp;gt; True, but I was thinking CMPW could be an exception to this rule.  I&lt;br/&gt;
&amp;gt; guess I would change the rule to &quot;simple merge policies don&apos;t have to&lt;br/&gt;
&amp;gt; run their own merges&quot;?&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; Let&apos;s see if we have to make that exception.&lt;/p&gt;

&lt;p&gt;&amp;gt; Good point...  I think I could refactor this so that cascading logic&lt;br/&gt;
&amp;gt; lives entirely in one place IndexWriter.&lt;/p&gt;

&lt;p&gt;Another problem of the current cascading in CMPW.MergeThread is, if multiple candidate merges are found, all of them are added to IndexWriter.mergingSegments. But all but the first should be removed because only the first merge is carried out (thus removed from mergeSegments after the merge is done).&lt;/p&gt;

&lt;p&gt;How do you make cascading live entirely in IndexWriter? Just removing cascading from CMPW.MergeThread has one drawback. For example, segment sizes of an index are: 40, 20, 10, buffer size is 10 and merge factor is 2. A buffer full flush of 10 will trigger merge of 10 &amp;amp; 10, then cascade to 20 &amp;amp; 20, then cascade to 40 &amp;amp; 40. CMPW without cascading will stop after 10 &amp;amp; 10 since IndexWriter.maybeMerge has already returned. Then we have to wait for the next flush to merge 20 &amp;amp; 20.&lt;/p&gt;

&lt;p&gt;&amp;gt; How would this be used?  Ie, how would one make an IndexWriter that&lt;br/&gt;
&amp;gt; uses the ConcurrentMerger?  Would we add expert methods&lt;br/&gt;
&amp;gt; IndexWriter.set/getIndexMerger(...)?  (And presumably the mergePolicy&lt;br/&gt;
&amp;gt; is now owned by IndexMerger so it would have the&lt;br/&gt;
&amp;gt; set/getMergePolicy(...)?)&lt;br/&gt;
&amp;gt; &lt;br/&gt;
&amp;gt; Also, how would you separate what remains in IW vs what would be in&lt;br/&gt;
&amp;gt; IndexMerger?&lt;/p&gt;

&lt;p&gt;Maybe Merger does and only does merge (so IndexWriter still owns MergePolicy)? Say, base class Merger.merge simply calls IndexWriter.merge. ConcurrentMerger.merge creates a merge thread if possible. Otherwise it calls super.merge, which does non-concurrent merge. IndexWriter simply calls its merger&apos;s merge instead of its own merge. Everything else remains in IndexWriter.&lt;/p&gt;


&lt;p&gt;1&lt;br/&gt;
&amp;gt; Hmm ... you&apos;re right.  This is a separate issue from merge policy,&lt;br/&gt;
&amp;gt; right?  Are you proposing buffering deletes in DocumentsWriter&lt;br/&gt;
&amp;gt; instead?&lt;/p&gt;

&lt;p&gt;Yes, this is a separate issue. And yes if we consider DocumentsWriter as staging area.&lt;/p&gt;

&lt;p&gt;2&lt;br/&gt;
&amp;gt; Good catch!  How to fix?  One thing we could do is always use&lt;br/&gt;
&amp;gt; SegmentInfo.reset(...) and never swap in clones at the SegmentInfo&lt;br/&gt;
&amp;gt; level.  This way using the default &apos;equals&apos; (same instance) would&lt;br/&gt;
&amp;gt; work.  Or we could establish identity (equals) of a SegmentInfo as&lt;br/&gt;
&amp;gt; checking if the directory plus segment name are equal?  I think I&apos;d&lt;br/&gt;
&amp;gt; lean to the 2nd option....&lt;/p&gt;

&lt;p&gt;I think the 2nd option is better.&lt;/p&gt;

&lt;p&gt;3&lt;br/&gt;
&amp;gt; Hmmm yes.  In fact I think we can remove synchronized from optimize&lt;br/&gt;
&amp;gt; altogether since within it we are synchronizing(this) at the right&lt;br/&gt;
&amp;gt; places?  If more than one thread calls optimize at once, externally,&lt;br/&gt;
&amp;gt; it is actually OK: they will each pick a merge that&apos;s viable&lt;br/&gt;
&amp;gt; (concurrently) and will run the merge, else return once there is no&lt;br/&gt;
&amp;gt; more concurrency left.  I&apos;ll add a unit test that confirms this.&lt;/p&gt;

&lt;p&gt;That seems to be the case. The fact that &quot;the same merge spec will be returned without changes to segmentInfos&quot; reminds me: MergePolicy.findCandidateMerges finds merges which may not be eligible; but CMPW checks for eligibility when looking for candidate merges. Maybe we should unify the behaviour? BTW, MergePolicy.optimize (a rename?) doesn&apos;t check for eligibility either.&lt;/p&gt;

&lt;p&gt;4&lt;br/&gt;
&amp;gt; Well, useCompoundFile(...) is given a single newly flushed segment and&lt;br/&gt;
&amp;gt; should decide whether it should be CFS.  Whereas&lt;br/&gt;
&amp;gt; useCompoundDocStore(...) is called when doc stores are flushed.  When&lt;br/&gt;
&amp;gt; autoCommit=false, segments can share a single set of doc stores, so&lt;br/&gt;
&amp;gt; there&apos;s no single SegmentInfo to pass down.&lt;/p&gt;

&lt;p&gt;The reason I asked is because none of them are used right now. So they might be used in the future?&lt;/p&gt;</comment>
                    <comment id="12524039" author="mikemccand" created="Fri, 31 Aug 2007 09:31:22 +0100"  >
&lt;p&gt;&amp;gt; &amp;gt; Good point...  I think I could refactor this so that cascading logic&lt;br/&gt;
&amp;gt; &amp;gt; lives entirely in one place IndexWriter.&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; Another problem of the current cascading in CMPW.MergeThread is, if&lt;br/&gt;
&amp;gt; multiple candidate merges are found, all of them are added to&lt;br/&gt;
&amp;gt; IndexWriter.mergingSegments. But all but the first should be removed&lt;br/&gt;
&amp;gt; because only the first merge is carried out (thus removed from&lt;br/&gt;
&amp;gt; mergeSegments after the merge is done).&lt;/p&gt;

&lt;p&gt;You&apos;re right &amp;#8211; I&apos;m only doing the first non-conflicting merge in&lt;br/&gt;
CMPW (but then not releasing the rest of them).  I think this would be&lt;br/&gt;
fixed by having cascading logic only in IndexWriter.&lt;/p&gt;

&lt;p&gt;&amp;gt; How do you make cascading live entirely in IndexWriter? Just&lt;br/&gt;
&amp;gt; removing cascading from CMPW.MergeThread has one drawback.  For&lt;br/&gt;
&amp;gt; example, segment sizes of an index are: 40, 20, 10, buffer size is&lt;br/&gt;
&amp;gt; 10 and merge factor is 2. A buffer full flush of 10 will trigger&lt;br/&gt;
&amp;gt; merge of 10 &amp;amp; 10, then cascade to 20 &amp;amp; 20, then cascade to 40 &amp;amp;&lt;br/&gt;
&amp;gt; 40. CMPW without cascading will stop after 10 &amp;amp; 10 since&lt;br/&gt;
&amp;gt; IndexWriter.maybeMerge has already returned. Then we have to wait&lt;br/&gt;
&amp;gt; for the next flush to merge 20 &amp;amp; 20.&lt;/p&gt;

&lt;p&gt;Oh, I would remove from CMPW and add then add it into IndexWriter (so&lt;br/&gt;
the scenario above would cascade normally).  Meaning, IndexWriter,&lt;br/&gt;
upon completing a merge, would always consult the policy for whether&lt;br/&gt;
the completed merge has now enabled any new merges.&lt;/p&gt;

&lt;p&gt;This is somewhat messy though (with CMPW as a MergePolicy) because&lt;br/&gt;
then findCandidateMerges would need to know if it was being called&lt;br/&gt;
(due to cascading) under one of its own threads and if so act&lt;br/&gt;
differently.  Another good reason to make it a separate Merger&lt;br/&gt;
subclass.&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; How would this be used?  Ie, how would one make an IndexWriter&lt;br/&gt;
&amp;gt; &amp;gt; that uses the ConcurrentMerger?  Would we add expert methods&lt;br/&gt;
&amp;gt; &amp;gt; IndexWriter.set/getIndexMerger(...)?  (And presumably the&lt;br/&gt;
&amp;gt; &amp;gt; mergePolicy is now owned by IndexMerger so it would have the&lt;br/&gt;
&amp;gt; &amp;gt; set/getMergePolicy(...)?)&lt;br/&gt;
&amp;gt; &amp;gt; &lt;br/&gt;
&amp;gt; &amp;gt; Also, how would you separate what remains in IW vs what would be&lt;br/&gt;
&amp;gt; &amp;gt; in IndexMerger?&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; Maybe Merger does and only does merge (so IndexWriter still owns&lt;br/&gt;
&amp;gt; MergePolicy)? Say, base class Merger.merge simply calls&lt;br/&gt;
&amp;gt; IndexWriter.merge. ConcurrentMerger.merge creates a merge thread if&lt;br/&gt;
&amp;gt; possible. Otherwise it calls super.merge, which does non-concurrent&lt;br/&gt;
&amp;gt; merge. IndexWriter simply calls its merger&apos;s merge instead of its&lt;br/&gt;
&amp;gt; own merge. Everything else remains in IndexWriter.&lt;/p&gt;

&lt;p&gt;OK I will test out this approach.&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; Hmm ... you&apos;re right.  This is a separate issue from merge policy,&lt;br/&gt;
&amp;gt; &amp;gt; right?  Are you proposing buffering deletes in DocumentsWriter&lt;br/&gt;
&amp;gt; &amp;gt; instead?&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; Yes, this is a separate issue. And yes if we consider&lt;br/&gt;
&amp;gt;  DocumentsWriter as staging area.&lt;/p&gt;

&lt;p&gt;I will open new issue.&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; Good catch!  How to fix?  One thing we could do is always use&lt;br/&gt;
&amp;gt; &amp;gt; SegmentInfo.reset(...) and never swap in clones at the SegmentInfo&lt;br/&gt;
&amp;gt; &amp;gt; level.  This way using the default &apos;equals&apos; (same instance) would&lt;br/&gt;
&amp;gt; &amp;gt; work.  Or we could establish identity (equals) of a SegmentInfo as&lt;br/&gt;
&amp;gt; &amp;gt; checking if the directory plus segment name are equal?  I think&lt;br/&gt;
&amp;gt; &amp;gt; I&apos;d lean to the 2nd option....&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; I think the 2nd option is better.&lt;/p&gt;

&lt;p&gt;I&apos;ll take this approach.&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; Hmmm yes.  In fact I think we can remove synchronized from&lt;br/&gt;
&amp;gt; &amp;gt; optimize altogether since within it we are synchronizing(this) at&lt;br/&gt;
&amp;gt; &amp;gt; the right places?  If more than one thread calls optimize at once,&lt;br/&gt;
&amp;gt; &amp;gt; externally, it is actually OK: they will each pick a merge that&apos;s&lt;br/&gt;
&amp;gt; &amp;gt; viable (concurrently) and will run the merge, else return once&lt;br/&gt;
&amp;gt; &amp;gt; there is no more concurrency left.  I&apos;ll add a unit test that&lt;br/&gt;
&amp;gt; &amp;gt; confirms this.&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; That seems to be the case.&lt;/p&gt;

&lt;p&gt;I&apos;ll add unit test to confirm.&lt;/p&gt;

&lt;p&gt;&amp;gt; The fact that &quot;the same merge spec will be returned without changes&lt;br/&gt;
&amp;gt; to segmentInfos&quot; reminds me: MergePolicy.findCandidateMerges finds&lt;br/&gt;
&amp;gt; merges which may not be eligible; but CMPW checks for eligibility&lt;br/&gt;
&amp;gt; when looking for candidate merges. Maybe we should unify the&lt;br/&gt;
&amp;gt; behaviour?&lt;/p&gt;

&lt;p&gt;Not quite following you here... not being eligible because the merge&lt;br/&gt;
is in-progress in a thread is something I think any given MergePolicy&lt;br/&gt;
should not have to track?  Once I factor out CMPW as its own Merger&lt;br/&gt;
subclass I think the eligibility check happens only in IndexWriter?&lt;/p&gt;

&lt;p&gt;&amp;gt; BTW, MergePolicy.optimize (a rename?) doesn&apos;t check for eligibility&lt;br/&gt;
&amp;gt; either.&lt;/p&gt;

&lt;p&gt;Rename to/from what?  (It is currently called MergePolicy.optimize).&lt;br/&gt;
IndexWriter steps through the merges and only runs the ones that do&lt;br/&gt;
not conflict (are eligible)?&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; Well, useCompoundFile(...) is given a single newly flushed segment&lt;br/&gt;
&amp;gt; &amp;gt; and should decide whether it should be CFS.  Whereas&lt;br/&gt;
&amp;gt; &amp;gt; useCompoundDocStore(...) is called when doc stores are flushed.&lt;br/&gt;
&amp;gt; &amp;gt; When autoCommit=false, segments can share a single set of doc&lt;br/&gt;
&amp;gt; &amp;gt; stores, so there&apos;s no single SegmentInfo to pass down.&lt;br/&gt;
&amp;gt; &lt;br/&gt;
&amp;gt; The reason I asked is because none of them are used right now. So&lt;br/&gt;
&amp;gt; they might be used in the future?&lt;/p&gt;

&lt;p&gt;Both of these methods are now called by IndexWriter (in the patch),&lt;br/&gt;
upon flushing a new segment.&lt;/p&gt;</comment>
                    <comment id="12524084" author="ningli" created="Fri, 31 Aug 2007 14:39:44 +0100"  >&lt;p&gt;&amp;gt; Not quite following you here... not being eligible because the merge&lt;br/&gt;
&amp;gt; is in-progress in a thread is something I think any given MergePolicy&lt;br/&gt;
&amp;gt; should not have to track?  Once I factor out CMPW as its own Merger&lt;br/&gt;
&amp;gt; subclass I think the eligibility check happens only in IndexWriter?&lt;/p&gt;

&lt;p&gt;I was referring to the current patch: LogMergePolicy does not check for eligibility, but CMPW, a subclass of MergePolicy, checks for eligibility. Yes, the eligibility check only happens in IndexWriter after we do Merger class.&lt;/p&gt;

&lt;p&gt;&amp;gt; Rename to/from what?  (It is currently called MergePolicy.optimize).&lt;br/&gt;
&amp;gt; IndexWriter steps through the merges and only runs the ones that do&lt;br/&gt;
&amp;gt; not conflict (are eligible)?&lt;/p&gt;

&lt;p&gt;Maybe rename to MergePolicy.findMergesToOptimize?&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; The reason I asked is because none of them are used right now. So&lt;br/&gt;
&amp;gt; &amp;gt; they might be used in the future?&lt;br/&gt;
&amp;gt; &lt;br/&gt;
&amp;gt; Both of these methods are now called by IndexWriter (in the patch),&lt;br/&gt;
&amp;gt; upon flushing a new segment.&lt;/p&gt;

&lt;p&gt;I was referring to the parameters. The parameters are not used.&lt;/p&gt;</comment>
                    <comment id="12524138" author="mikemccand" created="Fri, 31 Aug 2007 18:01:51 +0100"  >
&lt;p&gt;&amp;gt; &amp;gt; Not quite following you here... not being eligible because the&lt;br/&gt;
&amp;gt; &amp;gt; merge is in-progress in a thread is something I think any given&lt;br/&gt;
&amp;gt; &amp;gt; MergePolicy should not have to track?  Once I factor out CMPW as&lt;br/&gt;
&amp;gt; &amp;gt; its own Merger subclass I think the eligibility check happens only&lt;br/&gt;
&amp;gt; &amp;gt; in IndexWriter?&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; I was referring to the current patch: LogMergePolicy does not check&lt;br/&gt;
&amp;gt; for eligibility, but CMPW, a subclass of MergePolicy, checks for&lt;br/&gt;
&amp;gt; eligibility. Yes, the eligibility check only happens in IndexWriter&lt;br/&gt;
&amp;gt; after we do Merger class.&lt;/p&gt;

&lt;p&gt;OK, let&apos;s leave eligibility check in IW.&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; Rename to/from what?  (It is currently called&lt;br/&gt;
&amp;gt; &amp;gt; MergePolicy.optimize).  IndexWriter steps through the merges and&lt;br/&gt;
&amp;gt; &amp;gt; only runs the ones that do not conflict (are eligible)?&lt;br/&gt;
&amp;gt; &lt;br/&gt;
&amp;gt; Maybe rename to MergePolicy.findMergesToOptimize?&lt;/p&gt;

&lt;p&gt;OK, that&apos;s good.&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; &amp;gt; The reason I asked is because none of them are used right&lt;br/&gt;
&amp;gt; &amp;gt; &amp;gt; now. So they might be used in the future?&lt;br/&gt;
&amp;gt; &amp;gt; &lt;br/&gt;
&amp;gt; &amp;gt; Both of these methods are now called by IndexWriter (in the&lt;br/&gt;
&amp;gt; &amp;gt; patch), upon flushing a new segment.&lt;br/&gt;
&amp;gt; &lt;br/&gt;
&amp;gt; I was referring to the parameters. The parameters are not used.&lt;/p&gt;

&lt;p&gt;Ahh, got it.  Yes the thinking is merge policies in the future may&lt;br/&gt;
want to look @ segmentinfos to decide.&lt;/p&gt;</comment>
                    <comment id="12525783" author="mikemccand" created="Fri, 7 Sep 2007 18:17:01 +0100"  >
&lt;p&gt;Attached new patch (take5) incorporating Ning&apos;s feedback.&lt;/p&gt;

&lt;p&gt;This patch includes &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-845&quot; title=&quot;If you &amp;quot;flush by RAM usage&amp;quot; then IndexWriter may over-merge&quot;&gt;&lt;del&gt;LUCENE-845&lt;/del&gt;&lt;/a&gt; (a new merge default merge policy plus&lt;br/&gt;
a &quot;merge by size in bytes of segment&quot; merge policy), &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-847&quot; title=&quot;Factor merge policy out of IndexWriter&quot;&gt;&lt;del&gt;LUCENE-847&lt;/del&gt;&lt;/a&gt;&lt;br/&gt;
(factor merge policy/scheduling out of IndexWriter) and &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-870&quot; title=&quot;add concurrent merge policy&quot;&gt;&lt;del&gt;LUCENE-870&lt;/del&gt;&lt;/a&gt;&lt;br/&gt;
(ConcurrentMergeScheduler).&lt;/p&gt;

&lt;p&gt;The one thing remaining after these are done, that I&apos;ll open a&lt;br/&gt;
separate issue for and commit separately, is to switch IndexWriter to&lt;br/&gt;
flush by RAM usage by default (instead of by docCount == 10) as well&lt;br/&gt;
as merge by size-in-bytes by default.&lt;/p&gt;

&lt;p&gt;I broke out a separate MergeScheduler interface.  SerialMergeScheduler&lt;br/&gt;
is the default (matches how merges are executed today: sequentially,&lt;br/&gt;
using the calling thread).  ConcurrentMergeScheduler runs the merges&lt;br/&gt;
as separate threads (up to a max number at which point the extras are&lt;br/&gt;
done sequentially).&lt;/p&gt;

&lt;p&gt;Other changes:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Allow multiple threads to call optimize().  I added a unit test&lt;br/&gt;
    for this.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Tightnened calls to deleter.refresh(), which remove partially&lt;br/&gt;
    created files on an exception, to remove only those files that the&lt;br/&gt;
    given piece of code would create.  This is very important because&lt;br/&gt;
    otherwise refresh() could remove the files being created by a&lt;br/&gt;
    background merge.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Added some unit tests&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12525797" author="cutting" created="Fri, 7 Sep 2007 19:19:36 +0100"  >&lt;p&gt;Is there any reason not to make ConcurrentMergeScheduler the default too after this is committed?&lt;/p&gt;</comment>
                    <comment id="12525802" author="mikemccand" created="Fri, 7 Sep 2007 19:47:07 +0100"  >&lt;p&gt;&amp;gt; Is there any reason not to make ConcurrentMergeScheduler the default too after this is committed?&lt;/p&gt;

&lt;p&gt;Good question.  The only downsides I can think of are:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;It&apos;s all fresh code so until we let it &quot;age&quot; some, it&apos;s a higher&lt;br/&gt;
    risk that something broke.  That said there is decent unit test&lt;br/&gt;
    coverage for it and these unit tests did find some sneaky issues&lt;br/&gt;
    (which I fixed!).&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;It only actually helps on machines that have some concurrency.&lt;br/&gt;
    But in this case we are largely talking about IO concurrent w/ CPU&lt;br/&gt;
    which nearly all machines have I think.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I think the benefits are sizable:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Good performance gains (25% speedup of net indexing time for all&lt;br/&gt;
    of Wikipedia content &amp;#8211; details in &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-870&quot; title=&quot;add concurrent merge policy&quot;&gt;&lt;del&gt;LUCENE-870&lt;/del&gt;&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Trivial way to leverage concurrency (ie you don&apos;t need to manage&lt;br/&gt;
    your own threads).&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;No more unexpected long pauses on certain addDocument calls.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;So I think it would make sense to make it the default.  I&apos;ll include&lt;br/&gt;
that in the new issue for changing defaults in IndexWriter.&lt;/p&gt;</comment>
                    <comment id="12525903" author="mikemccand" created="Sat, 8 Sep 2007 11:11:24 +0100"  >&lt;p&gt;OK, as a better test of ConcurrentMergeScheduler, and towards making it&lt;br/&gt;
the default merge scheduler, I tried making it the default in&lt;br/&gt;
IndexWriter and then ran all unit tests, and uncovered problems with&lt;br/&gt;
the current patch (notably how optimize works!).  So I&apos;m working on an&lt;br/&gt;
new patch now....&lt;/p&gt;
</comment>
                    <comment id="12526029" author="ningli" created="Sun, 9 Sep 2007 22:28:23 +0100"  >&lt;p&gt;Comments on optimize():&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;In the while loop of optimize(), LogMergePolicy.findMergesForOptimize returns a merge spec with one merge. If ConcurrentMergeScheduler is used, the one merge will be started in MergeScheduler.merge() and findMergesForOptimize will be called again. Before the one merge finishes, findMergesForOptimize will return the same spec but the one merge is already started. So only one concurrent merge is possible and the main thread will spin on calling findMergesForOptimize and attempting to merge.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;One possible solution is to make LogMergePolicy.findMergesForOptimize return multiple merge candidates. It allows higher level of concurrency. It also alleviates a bit the problem of main thread spinning. To solve this problem, maybe we can check if a merge is actually started, then sleep briefly if not (which means all merges candidates are in conflict)?&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;A comment on concurrent merge threads:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;One difference between the current approach on concurrent merge and the patch I posted a while back is that, in the current approach, a MergeThread object is created and started for every concurrent merge. In my old patch, maxThreadCount of threads are created and started at the beginning and are used throughout. Both have pros and cons.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12526302" author="mikemccand" created="Tue, 11 Sep 2007 00:20:03 +0100"  >&lt;p&gt;OK, another rev of the patch (take6).  I think it&apos;s close!&lt;/p&gt;

&lt;p&gt;This patch passes all unit tests with SerialMergeScheduler (left as&lt;br/&gt;
the default for now) and also passes all unit tests once you switch&lt;br/&gt;
the default to ConcurrentMergeScheduler instead.&lt;/p&gt;

&lt;p&gt;I made one simplification to the approach: IndexWriter now keeps track&lt;br/&gt;
of &quot;pendingMerges&quot; (merges that mergePolicy has declared are necessary&lt;br/&gt;
but have not yet been started), and &quot;runningMerges&quot; (merges currently&lt;br/&gt;
in flight).  Then MergeScheduler just asks IndexWriter for the next&lt;br/&gt;
pending merge when it&apos;s ready to run it.  This also cleaned up how&lt;br/&gt;
cascading works.&lt;/p&gt;

&lt;p&gt;Other changes:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Optimize: optimize is now fully concurrent (it can run multiple&lt;br/&gt;
    merges at once, new segments can be flushed during an optimize,&lt;br/&gt;
    etc).  Optimize will optimize only those segments present when it&lt;br/&gt;
    started (newly flushed segments may remain separate).&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;New API: optimize(boolean doWait) allows you to not wait for&lt;br/&gt;
    optimize to complete (it runs in background).  This only works&lt;br/&gt;
    when MergeScheduler uses threads.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;New API: close(boolean doWait) allows you to not wait for running&lt;br/&gt;
    merges if you want to &quot;close in a hurry&quot;.  Also only works when&lt;br/&gt;
    MergeScheduler uses threads.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;I fixed LogMergePolicy to expose merge concurrency during optimize&lt;br/&gt;
    by first calling the &quot;normal&quot; merge policy to see if it requires&lt;br/&gt;
    merges and returning those merges if so, and then falling back to&lt;br/&gt;
    the normal &quot;merge the tail &amp;lt;= mergeFactor segments until there is&lt;br/&gt;
    only 1 left&quot;.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Because IndexModifier synchronizes on directory, it can&apos;t use&lt;br/&gt;
    ConcurrentMergeScheduler since this quickly leads to deadlock at&lt;br/&gt;
    least during IndexWriter.close.  So I set it back to&lt;br/&gt;
    SerialMergeScheduler (it is deprecated anyway).&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Added private IndexWriter.message(...) that prints message to the&lt;br/&gt;
    infoStream prefixed by the thread name and changed all&lt;br/&gt;
    infoStream.print*&apos;s to message(...).  Also added more messages in&lt;br/&gt;
    the exceptional cases to aid future diagnostics.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Added more unit tests&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12526305" author="mikemccand" created="Tue, 11 Sep 2007 00:28:26 +0100"  >
&lt;p&gt;&amp;gt; In the while loop of optimize(), LogMergePolicy.findMergesForOptimize&lt;br/&gt;
&amp;gt; returns a merge spec with one merge. If ConcurrentMergeScheduler is&lt;br/&gt;
&amp;gt; used, the one merge will be started in MergeScheduler.merge() and&lt;br/&gt;
&amp;gt; findMergesForOptimize will be called again. Before the one merge&lt;br/&gt;
&amp;gt; finishes, findMergesForOptimize will return the same spec but the&lt;br/&gt;
&amp;gt; one merge is already started. So only one concurrent merge is&lt;br/&gt;
&amp;gt; possible and the main thread will spin on calling&lt;br/&gt;
&amp;gt; findMergesForOptimize and attempting to merge.&lt;/p&gt;

&lt;p&gt;Yes.  The new patch has cleaned this up nicely, I think.&lt;/p&gt;

&lt;p&gt;&amp;gt; One possible solution is to make LogMergePolicy.findMergesForOptimize&lt;br/&gt;
&amp;gt; return multiple merge candidates. It allows higher level of&lt;br/&gt;
&amp;gt; concurrency.&lt;/p&gt;

&lt;p&gt;Good idea!  I took exactly this approach in patch I just attached.  I&lt;br/&gt;
made a simple change: LogMergePolicy.findMergesForOptimize first&lt;br/&gt;
checks if &quot;normal merging&quot; would want to do merges and returns them if&lt;br/&gt;
so.  Since &quot;normal merging&quot; exposes concurrent merges, this gains us&lt;br/&gt;
concurrency for optimize in cases where the index has too many&lt;br/&gt;
segments.  I wasn&apos;t sure how otherwise to expose concurrency...&lt;/p&gt;

&lt;p&gt;&amp;gt; It also alleviates a bit the problem of main thread spinning. To&lt;br/&gt;
&amp;gt; solve this problem, maybe we can check if a merge is actually&lt;br/&gt;
&amp;gt; started, then sleep briefly if not (which means all merges&lt;br/&gt;
&amp;gt; candidates are in conflict)?&lt;/p&gt;

&lt;p&gt;This is much cleaner in new patch: there is no more spinning.  In new&lt;br/&gt;
patch if multiple threads are merging (either spawned by&lt;br/&gt;
ConcurrentMergeaScheduler or provided by the application or both) then&lt;br/&gt;
they all pull from a shared queue of &quot;merges needing to run&quot; and then&lt;br/&gt;
return when that queue is empty.  So no more spinning.&lt;/p&gt;

&lt;p&gt;&amp;gt; One difference between the current approach on concurrent merge and&lt;br/&gt;
&amp;gt; the patch I posted a while back is that, in the current approach, a&lt;br/&gt;
&amp;gt; MergeThread object is created and started for every concurrent&lt;br/&gt;
&amp;gt; merge. In my old patch, maxThreadCount of threads are created and&lt;br/&gt;
&amp;gt; started at the beginning and are used throughout. Both have pros and&lt;br/&gt;
&amp;gt; cons.&lt;/p&gt;

&lt;p&gt;Yeah I thought I would keep it simple (launch thread when needed then&lt;br/&gt;
let it finish when it&apos;s done) rather than use a pool.  This way&lt;br/&gt;
threads are only created (and are only alive) while concurrency is&lt;br/&gt;
actually needed (ie &amp;gt; N merges necessary at once).  But yes there are&lt;br/&gt;
pros/cons either way.&lt;/p&gt;</comment>
                    <comment id="12526628" author="ningli" created="Tue, 11 Sep 2007 23:59:52 +0100"  >&lt;p&gt;&amp;gt; OK, another rev of the patch (take6).  I think it&apos;s close!&lt;/p&gt;

&lt;p&gt;Yes, it&apos;s close! &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&amp;gt; I made one simplification to the approach: IndexWriter now keeps track&lt;br/&gt;
&amp;gt; of &quot;pendingMerges&quot; (merges that mergePolicy has declared are necessary&lt;br/&gt;
&amp;gt; but have not yet been started), and &quot;runningMerges&quot; (merges currently&lt;br/&gt;
&amp;gt; in flight).  Then MergeScheduler just asks IndexWriter for the next&lt;br/&gt;
&amp;gt; pending merge when it&apos;s ready to run it.  This also cleaned up how&lt;br/&gt;
&amp;gt; cascading works.&lt;/p&gt;

&lt;p&gt;I like this simplification.&lt;/p&gt;

&lt;p&gt;&amp;gt;   * Optimize: optimize is now fully concurrent (it can run multiple&lt;br/&gt;
&amp;gt;     merges at once, new segments can be flushed during an optimize,&lt;br/&gt;
&amp;gt;     etc).  Optimize will optimize only those segments present when it&lt;br/&gt;
&amp;gt;     started (newly flushed segments may remain separate).&lt;/p&gt;

&lt;p&gt;This semantics does add a bit complexity - segmentsToOptimize, OneMerge.optimize.&lt;/p&gt;

&lt;p&gt;&amp;gt; Good idea!  I took exactly this approach in patch I just attached.  I&lt;br/&gt;
&amp;gt; made a simple change: LogMergePolicy.findMergesForOptimize first&lt;br/&gt;
&amp;gt; checks if &quot;normal merging&quot; would want to do merges and returns them if&lt;br/&gt;
&amp;gt; so.  Since &quot;normal merging&quot; exposes concurrent merges, this gains us&lt;br/&gt;
&amp;gt; concurrency for optimize in cases where the index has too many&lt;br/&gt;
&amp;gt; segments.  I wasn&apos;t sure how otherwise to expose concurrency...&lt;/p&gt;

&lt;p&gt;Another option is to schedule merges for the newest N segments and the next newest N segments and the next next... N is the merge factor.&lt;/p&gt;


&lt;p&gt;A couple of other things:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;It seems you intended sync() to be part of the MergeScheduler interface?&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;IndexWriter.close(&lt;span class=&quot;error&quot;&gt;&amp;#91;true&amp;#93;&lt;/span&gt;), abort(): The behaviour should be the same whether the calling thread is the one that actually gets to do the closing. Right now, only the thread that actually does the closing waits for the closing. The others do not wait for the closing.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12526712" author="mikemccand" created="Wed, 12 Sep 2007 09:56:16 +0100"  >&lt;p&gt;&amp;gt; &amp;gt; Good idea! I took exactly this approach in patch I just attached. I&lt;br/&gt;
&amp;gt; &amp;gt; made a simple change: LogMergePolicy.findMergesForOptimize first&lt;br/&gt;
&amp;gt; &amp;gt; checks if &quot;normal merging&quot; would want to do merges and returns them if&lt;br/&gt;
&amp;gt; &amp;gt; so. Since &quot;normal merging&quot; exposes concurrent merges, this gains us&lt;br/&gt;
&amp;gt; &amp;gt; concurrency for optimize in cases where the index has too many&lt;br/&gt;
&amp;gt; &amp;gt; segments. I wasn&apos;t sure how otherwise to expose concurrency...&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; Another option is to schedule merges for the newest N segments and&lt;br/&gt;
&amp;gt; the next newest N segments and the next next... N is the merge&lt;br/&gt;
&amp;gt; factor.&lt;/p&gt;

&lt;p&gt;OK, that is simpler.  I&apos;ll take that approach (and not call the&lt;br/&gt;
&quot;normal&quot; merge policy first).&lt;/p&gt;

&lt;p&gt;&amp;gt; A couple of other things:&lt;br/&gt;
&amp;gt; &lt;br/&gt;
&amp;gt;   - It seems you intended sync() to be part of the MergeScheduler&lt;br/&gt;
&amp;gt;     interface?&lt;/p&gt;

&lt;p&gt;I had started down this route but then backed away from it: I think&lt;br/&gt;
IndexWriter should handle this rather than making every MergeScheduler&lt;br/&gt;
have duplicated code for doing so.  Oh I see, I had left empty sync()&lt;br/&gt;
in SerialMergeScheduler; I&apos;ll remove that.&lt;/p&gt;

&lt;p&gt;&amp;gt;  - IndexWriter.close(&lt;span class=&quot;error&quot;&gt;&amp;#91;true&amp;#93;&lt;/span&gt;), abort(): The behaviour should be the&lt;br/&gt;
&amp;gt;    same whether the calling thread is the one that actually gets to do&lt;br/&gt;
&amp;gt;    the closing. Right now, only the thread that actually does the&lt;br/&gt;
&amp;gt;    closing waits for the closing. The others do not wait for the&lt;br/&gt;
&amp;gt;    closing.&lt;/p&gt;

&lt;p&gt;Ahh good point.  OK, I&apos;ll have other threads wait() until the&lt;br/&gt;
close/abort is complete.&lt;/p&gt;</comment>
                    <comment id="12526864" author="mikemccand" created="Wed, 12 Sep 2007 18:42:33 +0100"  >&lt;p&gt;New patch (take 7).&lt;/p&gt;

&lt;p&gt;I folded in Ning&apos;s comments (above) and Yonik&apos;s comments from&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-845&quot; title=&quot;If you &amp;quot;flush by RAM usage&amp;quot; then IndexWriter may over-merge&quot;&gt;&lt;del&gt;LUCENE-845&lt;/del&gt;&lt;/a&gt;, added javadocs &amp;amp; fixed Javadoc warnings and fixed two&lt;br/&gt;
other small issues.  All tests pass on Linux, OS X, win32, with either&lt;br/&gt;
SerialMergeScheduler or ConcurrentMergeScheduler as the default.&lt;/p&gt;

&lt;p&gt;I plan to commit in a few days time...&lt;/p&gt;</comment>
                    <comment id="12527224" author="ningli" created="Thu, 13 Sep 2007 20:11:06 +0100"  >&lt;p&gt;Access of mergeThreads in ConcurrentMergeScheduler.merge() should be synchronized.&lt;/p&gt;</comment>
                    <comment id="12527227" author="mikemccand" created="Thu, 13 Sep 2007 20:14:50 +0100"  >&lt;p&gt;Ahh, good catch.  Will fix!&lt;/p&gt;</comment>
                    <comment id="12527239" author="ningli" created="Thu, 13 Sep 2007 21:22:06 +0100"  >&lt;p&gt;Hmm, it&apos;s actually possible to have concurrent merges with SerialMergeScheduler.&lt;/p&gt;

&lt;p&gt;Making SerialMergeScheduler.merge synchronize on SerialMergeScheduler will serialize all merges. A merge can still be concurrent with a ram flush.&lt;/p&gt;

&lt;p&gt;Making SerialMergeScheduler.merge synchronize on IndexWriter will serialize all merges and ram flushes.&lt;/p&gt;</comment>
                    <comment id="12527258" author="mikemccand" created="Thu, 13 Sep 2007 22:02:30 +0100"  >&lt;p&gt;&amp;gt; Hmm, it&apos;s actually possible to have concurrent merges with&lt;br/&gt;
&amp;gt; SerialMergeScheduler.&lt;/p&gt;

&lt;p&gt;This was actually intentional: I thought it fine if the application is&lt;br/&gt;
sending multiple threads into IndexWriter to allow merges to run&lt;br/&gt;
concurrently.  Because, the application can always back down to a&lt;br/&gt;
single thread to get everything serialized if that&apos;s really required?&lt;/p&gt;</comment>
                    <comment id="12527286" author="ningli" created="Thu, 13 Sep 2007 22:49:45 +0100"  >&lt;p&gt;&amp;gt; This was actually intentional: I thought it fine if the application is&lt;br/&gt;
&amp;gt; sending multiple threads into IndexWriter to allow merges to run&lt;br/&gt;
&amp;gt; concurrently.  Because, the application can always back down to a&lt;br/&gt;
&amp;gt; single thread to get everything serialized if that&apos;s really required?&lt;/p&gt;

&lt;p&gt;Today, applications use multiple threads on IndexWriter to get some concurrency on document parsing. With this patch, applications that want concurrent merges would simply use ConcurrentMergeScheduler, no?&lt;/p&gt;

&lt;p&gt;Or a rename since it doesn&apos;t really serialize merges?&lt;/p&gt;</comment>
                    <comment id="12527289" author="markrmiller@gmail.com" created="Thu, 13 Sep 2007 22:59:55 +0100"  >&lt;p&gt;I have to triple check, but on first glance, my apps performance halfed using the ConcurrentMergeScheduler on a recent core duo with 2 GB RAM (As compared to the SerialMergeSceduler). Seems unexpected?&lt;/p&gt;</comment>
                    <comment id="12527295" author="mikemccand" created="Thu, 13 Sep 2007 23:06:38 +0100"  >
&lt;p&gt;&amp;gt; Today, applications use multiple threads on IndexWriter to get some&lt;br/&gt;
&amp;gt; concurrency on document parsing. With this patch, applications that&lt;br/&gt;
&amp;gt; want concurrent merges would simply use ConcurrentMergeScheduler,&lt;br/&gt;
&amp;gt; no?&lt;/p&gt;

&lt;p&gt;True.  OK I will make SerialMergeScheduler.merge serialized.  This way&lt;br/&gt;
only one merge can happen at a time even when the application is using&lt;br/&gt;
multiple threads.&lt;/p&gt;</comment>
                    <comment id="12527297" author="mikemccand" created="Thu, 13 Sep 2007 23:07:31 +0100"  >&lt;p&gt;&amp;gt; I have to triple check, but on first glance, my apps performance&lt;br/&gt;
&amp;gt; halfed using the ConcurrentMergeScheduler on a recent core duo with&lt;br/&gt;
&amp;gt; 2 GB RAM (As compared to the SerialMergeSceduler). Seems unexpected?&lt;/p&gt;

&lt;p&gt;Whoa, that&apos;s certainly unexpected!  I&apos;ll go re-run my perf test.&lt;/p&gt;</comment>
                    <comment id="12527300" author="markrmiller@gmail.com" created="Thu, 13 Sep 2007 23:42:15 +0100"  >&lt;p&gt;Looks like some anomalous tests. Last night I checked twice, but today results are: 58 to 48 in favor of Concurrent. I am going to assume my first results where invalid. Sorry for the noise and thanks for the great patch. Has passed quite a few stress tests I run on my app without any problems so far. Do both merge policies allow for a closer to constant add time or is it just the Concurrent policy?&lt;/p&gt;</comment>
                    <comment id="12527304" author="mikemccand" created="Thu, 13 Sep 2007 23:50:44 +0100"  >&lt;p&gt;&amp;gt; Looks like some anomalous tests. Last night I checked twice, but&lt;br/&gt;
&amp;gt; today results are: 58 to 48 in favor of Concurrent. I am going to&lt;br/&gt;
&amp;gt; assume my first results where invalid. Sorry for the noise and&lt;br/&gt;
&amp;gt; thanks for the great patch.&lt;/p&gt;

&lt;p&gt;OK, phew!&lt;/p&gt;

&lt;p&gt;&amp;gt; Has passed quite a few stress tests I run on my app without any&lt;br/&gt;
&amp;gt; problems so far.&lt;/p&gt;

&lt;p&gt;I&apos;m glad to hear that &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  Thanks for being such an early adopter!&lt;/p&gt;

&lt;p&gt;&amp;gt; Do both merge policies allow for a closer to constant add time or is&lt;br/&gt;
&amp;gt; it just the Concurrent policy?&lt;/p&gt;

&lt;p&gt;Not sure I understand the question &amp;#8211; you mean addDocument?  Yes it&apos;s&lt;br/&gt;
only ConcurrentMergeScheduler that should keep addDocument calls&lt;br/&gt;
constant time, because SerialMergeScheduler will hijack the addDocument&lt;br/&gt;
thread to do its merges.&lt;/p&gt;</comment>
                    <comment id="12527557" author="mikemccand" created="Fri, 14 Sep 2007 17:19:53 +0100"  >&lt;p&gt;Attached take8, incorporating Ning&apos;s feedback plus some small&lt;br/&gt;
refactoring and fixing one case where optimize() would do an&lt;br/&gt;
unecessary merge.&lt;/p&gt;</comment>
                </comments>
                <issuelinks>
                        <issuelinktype id="10032">
                <name>Blocker</name>
                                <outwardlinks description="blocks">
                            <issuelink>
            <issuekey id="12365610">LUCENE-845</issuekey>
        </issuelink>
                    </outwardlinks>
                                            </issuelinktype>
                        <issuelinktype id="10001">
                <name>dependent</name>
                                                <inwardlinks description="is depended upon by">
                            <issuelink>
            <issuekey id="12368221">LUCENE-870</issuekey>
        </issuelink>
                    </inwardlinks>
                            </issuelinktype>
                    </issuelinks>
                <attachments>
                    <attachment id="12354478" name="concurrentMerge.patch" size="106230" author="ningli" created="Thu, 29 Mar 2007 04:21:07 +0100" />
                    <attachment id="12363880" name="LUCENE-847.patch.txt" size="153632" author="steven_parkes" created="Wed, 15 Aug 2007 20:32:29 +0100" />
                    <attachment id="12363276" name="LUCENE-847.patch.txt" size="113349" author="steven_parkes" created="Mon, 6 Aug 2007 21:11:27 +0100" />
                    <attachment id="12364527" name="LUCENE-847.take3.patch" size="76982" author="mikemccand" created="Fri, 24 Aug 2007 17:38:20 +0100" />
                    <attachment id="12364638" name="LUCENE-847.take4.patch" size="90776" author="mikemccand" created="Mon, 27 Aug 2007 22:05:35 +0100" />
                    <attachment id="12365364" name="LUCENE-847.take5.patch" size="148834" author="mikemccand" created="Fri, 7 Sep 2007 18:17:01 +0100" />
                    <attachment id="12365513" name="LUCENE-847.take6.patch" size="167913" author="mikemccand" created="Tue, 11 Sep 2007 00:20:03 +0100" />
                    <attachment id="12365650" name="LUCENE-847.take7.patch" size="175740" author="mikemccand" created="Wed, 12 Sep 2007 18:42:33 +0100" />
                    <attachment id="12365879" name="LUCENE-847.take8.patch" size="177358" author="mikemccand" created="Fri, 14 Sep 2007 17:19:53 +0100" />
                    <attachment id="12354112" name="LUCENE-847.txt" size="119626" author="steven_parkes" created="Fri, 23 Mar 2007 19:24:21 +0000" />
                </attachments>
            <subtasks>
        </subtasks>
                <customfields>
                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                <customfieldname>Attachment count</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>10.0</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                <customfieldname>Date of First Response</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>Fri, 23 Mar 2007 20:25:51 +0000</customfieldvalue>

                </customfieldvalues>
            </customfield>
                                                                                                        <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Global Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>12894</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                <customfieldname>Lucene Fields</customfieldname>
                <customfieldvalues>
                        <customfieldvalue key="10121"><![CDATA[New]]></customfieldvalue>
    
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>26882</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                <customfieldname>Time in Status</customfieldname>
                <customfieldvalues>
                    
                </customfieldvalues>
            </customfield>
                            </customfields>
    </item>
</channel>
</rss>