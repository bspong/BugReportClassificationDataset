<!-- 
RSS generated by JIRA (5.2.8#851-sha1:3262fdc28b4bc8b23784e13eadc26a22399f5d88) at Tue Jul 16 13:30:48 UTC 2013

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/LUCENE-888/LUCENE-888.xml?field=key&field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>5.2.8</version>
        <build-number>851</build-number>
        <build-date>26-02-2013</build-date>
    </build-info>

<item>
            <title>[LUCENE-888] Improve indexing performance by increasing internal buffer sizes</title>
                <link>https://issues.apache.org/jira/browse/LUCENE-888</link>
                <project id="12310110" key="LUCENE">Lucene - Core</project>
                        <description>&lt;p&gt;In working on &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-843&quot; title=&quot;improve how IndexWriter uses RAM to buffer added documents&quot;&gt;&lt;del&gt;LUCENE-843&lt;/del&gt;&lt;/a&gt;, I noticed that two buffer sizes have a&lt;br/&gt;
substantial impact on overall indexing performance.&lt;/p&gt;

&lt;p&gt;First is BufferedIndexOutput.BUFFER_SIZE (also used by&lt;br/&gt;
BufferedIndexInput).  Second is CompoundFileWriter&apos;s buffer used to&lt;br/&gt;
actually build the compound file.  Both are now 1 KB (1024 bytes).&lt;/p&gt;

&lt;p&gt;I ran the same indexing test I&apos;m using for &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-843&quot; title=&quot;improve how IndexWriter uses RAM to buffer added documents&quot;&gt;&lt;del&gt;LUCENE-843&lt;/del&gt;&lt;/a&gt;.  I&apos;m indexing&lt;br/&gt;
~5,500 byte plain text docs derived from the Europarl corpus&lt;br/&gt;
(English).  I index 200,000 docs with compound file enabled and term&lt;br/&gt;
vector positions &amp;amp; offsets stored plus stored fields.  I flush&lt;br/&gt;
documents at 16 MB RAM usage, and I set maxBufferedDocs carefully to&lt;br/&gt;
not hit &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-845&quot; title=&quot;If you &amp;quot;flush by RAM usage&amp;quot; then IndexWriter may over-merge&quot;&gt;&lt;del&gt;LUCENE-845&lt;/del&gt;&lt;/a&gt;.  The resulting index is 1.7 GB.  The index is not&lt;br/&gt;
optimized in the end and I left mergeFactor @ 10.&lt;/p&gt;

&lt;p&gt;I ran the tests on a quad-core OS X 10 machine with 4-drive RAID 0 IO&lt;br/&gt;
system.&lt;/p&gt;

&lt;p&gt;At 1 KB (current Lucene trunk) it takes 622 sec to build the index; if&lt;br/&gt;
I increase both buffers to 8 KB it takes 554 sec to build the index,&lt;br/&gt;
which is an 11% overall gain!&lt;/p&gt;

&lt;p&gt;I will run more tests to see if there is a natural knee in the curve&lt;br/&gt;
(buffer size above which we don&apos;t really gain much more performance).&lt;/p&gt;

&lt;p&gt;I&apos;m guessing we should leave BufferedIndexInput&apos;s default BUFFER_SIZE&lt;br/&gt;
at 1024, at least for now.  During searching there can be quite a few&lt;br/&gt;
of this class instantiated, and likely a larger buffer size for the&lt;br/&gt;
freq/prox streams could actually hurt search performance for those&lt;br/&gt;
searches that use skipping.&lt;/p&gt;

&lt;p&gt;The CompoundFileWriter buffer is created only briefly, so I think we&lt;br/&gt;
can use a fairly large (32 KB?) buffer there.  And there should not be&lt;br/&gt;
too many BufferedIndexOutputs alive at once so I think a large-ish&lt;br/&gt;
buffer (16 KB?) should be OK.&lt;/p&gt;</description>
                <environment></environment>
            <key id="12370045">LUCENE-888</key>
            <summary>Improve indexing performance by increasing internal buffer sizes</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                    <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png">Closed</status>
                    <resolution id="1">Fixed</resolution>
                                <assignee username="mikemccand">Michael McCandless</assignee>
                                <reporter username="mikemccand">Michael McCandless</reporter>
                        <labels>
                    </labels>
                <created>Wed, 23 May 2007 14:23:00 +0100</created>
                <updated>Thu, 2 May 2013 03:29:06 +0100</updated>
                    <resolved>Tue, 29 May 2007 16:15:41 +0100</resolved>
                            <version>2.1</version>
                                <fixVersion>2.2</fixVersion>
                                <component>core/index</component>
                        <due></due>
                    <votes>2</votes>
                        <watches>0</watches>
                                                    <comments>
                    <comment id="12498652" author="michaelbusch" created="Thu, 24 May 2007 15:20:48 +0100"  >&lt;p&gt;&amp;gt; At 1 KB (current Lucene trunk) it takes 622 sec to build the index; if&lt;br/&gt;
&amp;gt; I increase both buffers to 8 KB it takes 554 sec to build the index,&lt;br/&gt;
&amp;gt; which is an 11% overall gain!&lt;/p&gt;

&lt;p&gt;Cool!&lt;/p&gt;

&lt;p&gt;&amp;gt; I&apos;m guessing we should leave BufferedIndexInput&apos;s default BUFFER_SIZE&lt;br/&gt;
&amp;gt; at 1024, at least for now.  During searching there can be quite a few&lt;br/&gt;
&amp;gt; of this class instantiated, and likely a larger buffer size for the&lt;br/&gt;
&amp;gt; freq/prox streams could actually hurt search performance for those&lt;br/&gt;
&amp;gt; searches that use skipping.&lt;/p&gt;

&lt;p&gt;I submitted a patch for &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-430&quot; title=&quot;Reducing buffer sizes for TermDocs.&quot;&gt;&lt;del&gt;LUCENE-430&lt;/del&gt;&lt;/a&gt; which avoids copying the buffer when&lt;br/&gt;
a BufferedIndexInput is cloned. With this patch we could also add a &lt;br/&gt;
method setBufferSize(int) to BufferedIndexInput. This method has to&lt;br/&gt;
be called then right after the input has been created or cloned and&lt;br/&gt;
before the first read is performed (the first read operation allocates&lt;br/&gt;
the buffer). If called later it wouldn&apos;t have any effect. This would&lt;br/&gt;
allow us to adjust the buffer size dynamically, e. g. use large buffers&lt;br/&gt;
for segment merges and stored fields, but smaller ones for freq/prox &lt;br/&gt;
streams, maybe dependent on the document frequency. &lt;br/&gt;
What do you think?&lt;/p&gt;

&lt;p&gt;&amp;gt; The CompoundFileWriter buffer is created only briefly, so I think we&lt;br/&gt;
&amp;gt; can use a fairly large (32 KB?) buffer there.  And there should not be&lt;br/&gt;
&amp;gt; too many BufferedIndexOutputs alive at once so I think a large-ish&lt;br/&gt;
&amp;gt; buffer (16 KB?) should be OK.&lt;/p&gt;

&lt;p&gt;I&apos;m wondering how much performance benefits if you increase the buffer &lt;br/&gt;
size beyond the file system&apos;s page size? Does it make a big difference&lt;br/&gt;
if you use 8 KB, 16 KB or 32 KB? If the answer is yes, then I think&lt;br/&gt;
the numbers you propose are good.&lt;/p&gt;</comment>
                    <comment id="12498696" author="mikemccand" created="Thu, 24 May 2007 17:08:24 +0100"  >&lt;p&gt;&amp;gt; &amp;gt; I&apos;m guessing we should leave BufferedIndexInput&apos;s default BUFFER_SIZE&lt;br/&gt;
&amp;gt; &amp;gt; at 1024, at least for now.  During searching there can be quite a few&lt;br/&gt;
&amp;gt; &amp;gt; of this class instantiated, and likely a larger buffer size for the&lt;br/&gt;
&amp;gt; &amp;gt; freq/prox streams could actually hurt search performance for those&lt;br/&gt;
&amp;gt; &amp;gt; searches that use skipping.&lt;br/&gt;
&amp;gt; &lt;br/&gt;
&amp;gt; I submitted a patch for &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-430&quot; title=&quot;Reducing buffer sizes for TermDocs.&quot;&gt;&lt;del&gt;LUCENE-430&lt;/del&gt;&lt;/a&gt; which avoids copying the buffer when&lt;br/&gt;
&amp;gt; a BufferedIndexInput is cloned. With this patch we could also add a &lt;br/&gt;
&amp;gt; method setBufferSize(int) to BufferedIndexInput. This method has to&lt;br/&gt;
&amp;gt; be called then right after the input has been created or cloned and&lt;br/&gt;
&amp;gt; before the first read is performed (the first read operation allocates&lt;br/&gt;
&amp;gt; the buffer). If called later it wouldn&apos;t have any effect. This would&lt;br/&gt;
&amp;gt; allow us to adjust the buffer size dynamically, e. g. use large buffers&lt;br/&gt;
&amp;gt; for segment merges and stored fields, but smaller ones for freq/prox &lt;br/&gt;
&amp;gt; streams, maybe dependent on the document frequency. &lt;br/&gt;
&amp;gt; What do you think?&lt;/p&gt;

&lt;p&gt;I like that idea!&lt;/p&gt;

&lt;p&gt;I am actually seeing that increased buffer sizes for&lt;br/&gt;
BufferedIndexInput help performance of indexing as well (up to ~5%&lt;br/&gt;
just changing this buffer), so I think we do want to increase this but&lt;br/&gt;
only for merging.&lt;/p&gt;

&lt;p&gt;I wonder if we should just add a ctor to BufferedIndexInput that takes&lt;br/&gt;
the bufferSize?  This would avoid the surprising API caveat you&lt;br/&gt;
describe above.  The problem is, then all classes (SegmentTermDocs,&lt;br/&gt;
SegmentTermPositions, FieldsReader, etc.) that open an IndexInput&lt;br/&gt;
would also have to have ctors to change buffer sizes.  Even if we do&lt;br/&gt;
setBufferSize instead of new ctor we have some cases (eg at least&lt;br/&gt;
SegmentTermEnum) where bytes are read during construction so it&apos;s too&lt;br/&gt;
late for caller to then change buffer size.  Hmmm.  Not clear how to&lt;br/&gt;
do this cleanly...&lt;/p&gt;

&lt;p&gt;Maybe we do the setBufferSize approach, but, if the buffer already&lt;br/&gt;
exists, rather than throwing an exception we check if the new size is&lt;br/&gt;
greater than the old size and if so we grow the buffer?  I can code this&lt;br/&gt;
up.&lt;/p&gt;

&lt;p&gt;&amp;gt; &amp;gt; The CompoundFileWriter buffer is created only briefly, so I think we&lt;br/&gt;
&amp;gt; &amp;gt; can use a fairly large (32 KB?) buffer there.  And there should not be&lt;br/&gt;
&amp;gt; &amp;gt; too many BufferedIndexOutputs alive at once so I think a large-ish&lt;br/&gt;
&amp;gt; &amp;gt; buffer (16 KB?) should be OK.&lt;br/&gt;
&amp;gt; &lt;br/&gt;
&amp;gt; I&apos;m wondering how much performance benefits if you increase the buffer &lt;br/&gt;
&amp;gt; size beyond the file system&apos;s page size? Does it make a big difference&lt;br/&gt;
&amp;gt; if you use 8 KB, 16 KB or 32 KB? If the answer is yes, then I think&lt;br/&gt;
&amp;gt; the numbers you propose are good.&lt;/p&gt;

&lt;p&gt;I&apos;m testing now different sizes of each of these three buffers&lt;br/&gt;
... will post the results.&lt;/p&gt;</comment>
                    <comment id="12498714" author="michaelbusch" created="Thu, 24 May 2007 17:56:24 +0100"  >&lt;p&gt;&amp;gt; I wonder if we should just add a ctor to BufferedIndexInput that takes&lt;br/&gt;
&amp;gt; the bufferSize? This would avoid the surprising API caveat you&lt;br/&gt;
&amp;gt; describe above. The problem is, then all classes (SegmentTermDocs,&lt;br/&gt;
&amp;gt; SegmentTermPositions, FieldsReader, etc.) that open an IndexInput&lt;br/&gt;
&amp;gt; would also have to have ctors to change buffer sizes. Even if we do&lt;br/&gt;
&amp;gt; setBufferSize instead of new ctor we have some cases (eg at least&lt;br/&gt;
&amp;gt; SegmentTermEnum) where bytes are read during construction so it&apos;s too&lt;br/&gt;
&amp;gt; late for caller to then change buffer size. Hmmm. Not clear how to&lt;br/&gt;
&amp;gt; do this cleanly...&lt;/p&gt;

&lt;p&gt;Yeah I was thinking about the ctor approach as well. Actually &lt;br/&gt;
BufferedIndexInput does not have a public ctor so far, it&apos;s created by &lt;br/&gt;
using Directory.openInput(String fileName). And to add a new ctor would &lt;br/&gt;
mean an API change, so subclasses wouldn&apos;t compile anymore without &lt;br/&gt;
changes. &lt;br/&gt;
What me might want to do instead is to add a new new method&lt;br/&gt;
openInput(String fileName, int bufferSize) to Directory which calls&lt;br/&gt;
the existing openInput(String fileName) by default, so subclasses of&lt;br/&gt;
Directory would ignore the bufferSize parameter by default. Then we&lt;br/&gt;
can change FSDirectory to overwrite openInput(String, int):&lt;/p&gt;

&lt;p&gt;  public IndexInput openInput(String name, int bufferSize) &lt;br/&gt;
		throws IOException &lt;/p&gt;
{
    FSIndexInput input = new FSIndexInput(new File(directory, name));
	input.setBufferSize(bufferSize);
	return input;
  }

&lt;p&gt;This should solve the problems you mentioned like in SegmentTermEnum &lt;br/&gt;
and we don&apos;t have to support setBufferSize() after a read has been&lt;br/&gt;
performed. It has also the advantage that we safe an instanceof and&lt;br/&gt;
cast from IndexInput to BufferedIndexInput before setBufferSize()&lt;br/&gt;
can be called.&lt;/p&gt;

&lt;p&gt;After a clone however, we would still have to cast to &lt;br/&gt;
BufferedIndexInput before setBufferSize() can be called.&lt;/p&gt;</comment>
                    <comment id="12498739" author="mikemccand" created="Thu, 24 May 2007 18:55:13 +0100"  >&lt;p&gt;&amp;gt; &amp;gt; I wonder if we should just add a ctor to BufferedIndexInput that takes&lt;br/&gt;
&amp;gt; &amp;gt; the bufferSize? This would avoid the surprising API caveat you&lt;br/&gt;
&amp;gt; &amp;gt; describe above. The problem is, then all classes (SegmentTermDocs,&lt;br/&gt;
&amp;gt; &amp;gt; SegmentTermPositions, FieldsReader, etc.) that open an IndexInput&lt;br/&gt;
&amp;gt; &amp;gt; would also have to have ctors to change buffer sizes. Even if we do&lt;br/&gt;
&amp;gt; &amp;gt; setBufferSize instead of new ctor we have some cases (eg at least&lt;br/&gt;
&amp;gt; &amp;gt; SegmentTermEnum) where bytes are read during construction so it&apos;s too&lt;br/&gt;
&amp;gt; &amp;gt; late for caller to then change buffer size. Hmmm. Not clear how to&lt;br/&gt;
&amp;gt; &amp;gt; do this cleanly...&lt;br/&gt;
&amp;gt; &lt;br/&gt;
&amp;gt; Yeah I was thinking about the ctor approach as well. Actually &lt;br/&gt;
&amp;gt; BufferedIndexInput does not have a public ctor so far, it&apos;s created by &lt;br/&gt;
&amp;gt; using Directory.openInput(String fileName). And to add a new ctor would &lt;br/&gt;
&amp;gt; mean an API change, so subclasses wouldn&apos;t compile anymore without &lt;br/&gt;
&amp;gt; changes. &lt;/p&gt;

&lt;p&gt;Actually, it does have a default public constructor right?  Ie if we add&lt;/p&gt;

&lt;p&gt;  public BufferedIndexInput()&lt;br/&gt;
  public BufferedIndexInput(int bufferSize)&lt;/p&gt;

&lt;p&gt;then I think we don&apos;t break API backwards compatibility?&lt;/p&gt;

&lt;p&gt;&amp;gt; After a clone however, we would still have to cast to&lt;br/&gt;
&amp;gt; BufferedIndexInput before setBufferSize() can be called.&lt;/p&gt;

&lt;p&gt;I plan to add &quot;private int bufferSize&quot; to BufferedIndexInput,&lt;br/&gt;
defaulting to BUFFER_SIZE.  I think then it would just work w/ your&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-430&quot; title=&quot;Reducing buffer sizes for TermDocs.&quot;&gt;&lt;del&gt;LUCENE-430&lt;/del&gt;&lt;/a&gt; patch because your patch sets the clone&apos;s buffer to null&lt;br/&gt;
and then when the clone allocates its buffer it will be length&lt;br/&gt;
bufferSize.  I think?&lt;/p&gt;</comment>
                    <comment id="12498757" author="michaelbusch" created="Thu, 24 May 2007 19:19:32 +0100"  >&lt;p&gt;&amp;gt; Actually, it does have a default public constructor right? Ie if we add&lt;/p&gt;

&lt;p&gt;&amp;gt;  public BufferedIndexInput()&lt;br/&gt;
&amp;gt;  public BufferedIndexInput(int bufferSize)&lt;/p&gt;

&lt;p&gt;&amp;gt; then I think we don&apos;t break API backwards compatibility?&lt;/p&gt;

&lt;p&gt;Oups! Of course, you are right. What was I thinking...&lt;/p&gt;

&lt;p&gt;&amp;gt; I plan to add &quot;private int bufferSize&quot; to BufferedIndexInput,&lt;br/&gt;
&amp;gt; defaulting to BUFFER_SIZE. I think then it would just work w/ your&lt;br/&gt;
&amp;gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-430&quot; title=&quot;Reducing buffer sizes for TermDocs.&quot;&gt;&lt;del&gt;LUCENE-430&lt;/del&gt;&lt;/a&gt; patch because your patch sets the clone&apos;s buffer to null&lt;br/&gt;
&amp;gt; and then when the clone allocates its buffer it will be length&lt;br/&gt;
&amp;gt; bufferSize. I think?&lt;/p&gt;

&lt;p&gt;True. But it would be nice if it was possible to change the buffer size&lt;br/&gt;
after a clone. For example in SegmentTermDocs we could then adjust the&lt;br/&gt;
buffer size of the cloned freqStream according to the document frequency.&lt;br/&gt;
And in my multi-level skipping patch (&lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-866&quot; title=&quot;Multi-level skipping on posting lists&quot;&gt;&lt;del&gt;LUCENE-866&lt;/del&gt;&lt;/a&gt;) I could also benefit&lt;br/&gt;
from this functionality.&lt;/p&gt;

&lt;p&gt;Hmm, in SegmentTermDocs the freq stream is cloned in the ctor. If the&lt;br/&gt;
same instance of SegmentTermDocs is used for different terms, then &lt;br/&gt;
the same clone is used. So actually it would be nice it was possible to &lt;br/&gt;
change the buffer size after read has performed.&lt;/p&gt;

&lt;p&gt;&amp;gt; Maybe we do the setBufferSize approach, but, if the buffer already&lt;br/&gt;
&amp;gt; exists, rather than throwing an exception we check if the new size is&lt;br/&gt;
&amp;gt; greater than the old size and if so we grow the buffer? I can code this&lt;br/&gt;
&amp;gt; up. &lt;/p&gt;

&lt;p&gt;So yes, I think we should implement it this way.&lt;/p&gt;</comment>
                    <comment id="12498776" author="mikemccand" created="Thu, 24 May 2007 19:55:26 +0100"  >&lt;p&gt;&amp;gt; &amp;gt; I plan to add &quot;private int bufferSize&quot; to BufferedIndexInput,&lt;br/&gt;
&amp;gt; &amp;gt; defaulting to BUFFER_SIZE. I think then it would just work w/ your&lt;br/&gt;
&amp;gt; &amp;gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-430&quot; title=&quot;Reducing buffer sizes for TermDocs.&quot;&gt;&lt;del&gt;LUCENE-430&lt;/del&gt;&lt;/a&gt; patch because your patch sets the clone&apos;s buffer to null&lt;br/&gt;
&amp;gt; &amp;gt; and then when the clone allocates its buffer it will be length&lt;br/&gt;
&amp;gt; &amp;gt; bufferSize. I think?&lt;br/&gt;
&amp;gt; &lt;br/&gt;
&amp;gt; True. But it would be nice if it was possible to change the buffer size&lt;br/&gt;
&amp;gt; after a clone. For example in SegmentTermDocs we could then adjust the&lt;br/&gt;
&amp;gt; buffer size of the cloned freqStream according to the document frequency.&lt;br/&gt;
&amp;gt; And in my multi-level skipping patch (&lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-866&quot; title=&quot;Multi-level skipping on posting lists&quot;&gt;&lt;del&gt;LUCENE-866&lt;/del&gt;&lt;/a&gt;) I could also benefit&lt;br/&gt;
&amp;gt; from this functionality.&lt;/p&gt;

&lt;p&gt;OK, I agree: let&apos;s add a BufferedIndexInput.setBufferSize() and also&lt;br/&gt;
openInput(path, bufferSize) to Directory base class &amp;amp; to FSDirectory.&lt;/p&gt;

&lt;p&gt;&amp;gt; Hmm, in SegmentTermDocs the freq stream is cloned in the ctor. If the&lt;br/&gt;
&amp;gt; same instance of SegmentTermDocs is used for different terms, then &lt;br/&gt;
&amp;gt; the same clone is used. So actually it would be nice it was possible to &lt;br/&gt;
&amp;gt; change the buffer size after read has performed.&lt;br/&gt;
&amp;gt; &lt;br/&gt;
&amp;gt; &amp;gt; Maybe we do the setBufferSize approach, but, if the buffer already&lt;br/&gt;
&amp;gt; &amp;gt; exists, rather than throwing an exception we check if the new size is&lt;br/&gt;
&amp;gt; &amp;gt; greater than the old size and if so we grow the buffer? I can code this&lt;br/&gt;
&amp;gt; &amp;gt; up. &lt;br/&gt;
&amp;gt; &lt;br/&gt;
&amp;gt; So yes, I think we should implement it this way.&lt;/p&gt;

&lt;p&gt;OK I will do this.  Actually, I think we should also allow making the&lt;br/&gt;
buffer smaller this way.  Meaning, I will preserve buffer contents&lt;br/&gt;
(starting from bufferPosition) as much as is allowed by the smaller&lt;br/&gt;
buffer.  This way there is no restriction on using this method&lt;br/&gt;
vs. having read bytes already (&quot;principle of least surprise&quot;).&lt;/p&gt;</comment>
                    <comment id="12498780" author="michaelbusch" created="Thu, 24 May 2007 20:06:56 +0100"  >&lt;p&gt;&amp;gt; OK I will do this. Actually, I think we should also allow making the&lt;br/&gt;
&amp;gt; buffer smaller this way. Meaning, I will preserve buffer contents&lt;br/&gt;
&amp;gt; (starting from bufferPosition) as much as is allowed by the smaller&lt;br/&gt;
&amp;gt; buffer. This way there is no restriction on using this method&lt;br/&gt;
&amp;gt; vs. having read bytes already (&quot;principle of least surprise&quot;). &lt;/p&gt;

&lt;p&gt;Yep sounds good. I can code this and commit it with &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-430&quot; title=&quot;Reducing buffer sizes for TermDocs.&quot;&gt;&lt;del&gt;LUCENE-430&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
If you want to do it, then I should commit the existing 430 patch&lt;br/&gt;
soon, so that there are no conflicts in our patches?&lt;/p&gt;</comment>
                    <comment id="12498784" author="mikemccand" created="Thu, 24 May 2007 20:21:46 +0100"  >&lt;p&gt;&amp;gt; &amp;gt; OK I will do this. Actually, I think we should also allow making the&lt;br/&gt;
&amp;gt; &amp;gt; buffer smaller this way. Meaning, I will preserve buffer contents&lt;br/&gt;
&amp;gt; &amp;gt; (starting from bufferPosition) as much as is allowed by the smaller&lt;br/&gt;
&amp;gt; &amp;gt; buffer. This way there is no restriction on using this method&lt;br/&gt;
&amp;gt; &amp;gt; vs. having read bytes already (&quot;principle of least surprise&quot;).&lt;br/&gt;
&amp;gt; &lt;br/&gt;
&amp;gt; Yep sounds good. I can code this and commit it with &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-430&quot; title=&quot;Reducing buffer sizes for TermDocs.&quot;&gt;&lt;del&gt;LUCENE-430&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
&amp;gt; If you want to do it, then I should commit the existing 430 patch&lt;br/&gt;
&amp;gt; soon, so that there are no conflicts in our patches?&lt;/p&gt;

&lt;p&gt;I&apos;m actually coding it up now.  Why don&apos;t you commit &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-430&quot; title=&quot;Reducing buffer sizes for TermDocs.&quot;&gt;&lt;del&gt;LUCENE-430&lt;/del&gt;&lt;/a&gt;&lt;br/&gt;
soonish and then I&apos;ll update &amp;amp; merge?&lt;/p&gt;</comment>
                    <comment id="12498787" author="creamyg" created="Thu, 24 May 2007 20:31:29 +0100"  >&lt;p&gt;I would like to know why these gains are appearing, and how specific they are to a particular system.  How can the optimum buffer size be deduced?  Is it a factor of hard disk sector size?  Memory page size?  Lucene write behavior pattern? Level X Cache size?&lt;/p&gt;</comment>
                    <comment id="12498793" author="michaelbusch" created="Thu, 24 May 2007 20:44:48 +0100"  >&lt;p&gt;&amp;gt; I&apos;m actually coding it up now. Why don&apos;t you commit &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-430&quot; title=&quot;Reducing buffer sizes for TermDocs.&quot;&gt;&lt;del&gt;LUCENE-430&lt;/del&gt;&lt;/a&gt;&lt;br/&gt;
&amp;gt; soonish and then I&apos;ll update &amp;amp; merge?&lt;/p&gt;

&lt;p&gt;Done.&lt;/p&gt;</comment>
                    <comment id="12499018" author="mikemccand" created="Fri, 25 May 2007 11:09:42 +0100"  >&lt;p&gt;OK I ran two sets of tests.  First is only on Mac OS X to see how&lt;br/&gt;
performance changes with buffer sizes.  Second was also on Debian&lt;br/&gt;
Linux &amp;amp; Windows XP Pro.&lt;/p&gt;

&lt;p&gt;The performance gains are 10-18% faster overall.&lt;/p&gt;


&lt;p&gt;FIRST TEST&lt;/p&gt;

&lt;p&gt;I increased buffer sizes, separately, for each of BufferedIndexInput,&lt;br/&gt;
BufferedIndexOutput and CompoundFileWriter.  Each test is run once on&lt;br/&gt;
Mac OS X:&lt;/p&gt;

&lt;p&gt;  BufferedIndexInput&lt;/p&gt;

&lt;p&gt;      1 K   622 sec (current trunk)&lt;br/&gt;
      4 K   607 sec&lt;br/&gt;
      8 K   606 sec&lt;br/&gt;
     16 K   598 sec&lt;br/&gt;
     32 K   606 sec&lt;br/&gt;
     64 K   589 sec&lt;br/&gt;
    128 K   601 sec&lt;/p&gt;

&lt;p&gt;  CompoundFileWriter&lt;/p&gt;

&lt;p&gt;      1 K   622 sec (current trunk)&lt;br/&gt;
      4 K   599 sec&lt;br/&gt;
      8 K   591 sec&lt;br/&gt;
     16 K   578 sec&lt;br/&gt;
     32 K   583 sec&lt;br/&gt;
     64 K   580 sec&lt;/p&gt;

&lt;p&gt;  BufferedIndexOutput&lt;/p&gt;

&lt;p&gt;      1 K   622 sec (current trunk)&lt;br/&gt;
      4 K   588 sec&lt;br/&gt;
      8 K   576 sec&lt;br/&gt;
     16 K   551 sec&lt;br/&gt;
     32 K   566 sec&lt;br/&gt;
     64 K   555 sec&lt;br/&gt;
    128 K   543 sec&lt;br/&gt;
    256 K   534 sec&lt;br/&gt;
    512 K   564 sec&lt;/p&gt;

&lt;p&gt;Comments:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;The results are fairly noisy, but, performance does generally get&lt;br/&gt;
    better w/ larger buffers.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;BufferedIndexOutput seems specifically to like very large output&lt;br/&gt;
    buffers; the other two seem to have less but still significant&lt;br/&gt;
    effect.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Given this I picked 16 K buffer for BufferedIndexOutput, 16 K buffer&lt;br/&gt;
for CompoundFileWriter and 4 K buffer for BufferedIndexInput. I think&lt;br/&gt;
we would get faster performance for a larger buffer for&lt;br/&gt;
BufferedIndexInput, but, even when merging there are quite a few of&lt;br/&gt;
these created (mergeFactor * N where N = number of separate index&lt;br/&gt;
files).&lt;/p&gt;

&lt;p&gt;Then, I re-tested the baseline (trunk) &amp;amp; these buffer sizes across&lt;br/&gt;
platforms (below):&lt;/p&gt;



&lt;p&gt;SECOND TEST&lt;/p&gt;

&lt;p&gt;Baseline (trunk) = 1 K buffers for all 3.  New = 16 K for&lt;br/&gt;
BufferedIndexOutput, 16 K for CompoundFileWriter and 4 K for&lt;br/&gt;
BufferedIndexInput.&lt;/p&gt;

&lt;p&gt;I ran each test 4 times &amp;amp; took the best time:&lt;/p&gt;

&lt;p&gt;Quad core Mac OS X on 4-drive RAID 0&lt;br/&gt;
  baseline  622 sec&lt;br/&gt;
  new       527 sec&lt;br/&gt;
  -&amp;gt; 15% faster&lt;/p&gt;

&lt;p&gt;Dual core Debian Linux (2.6.18 kernel) on 6 drive RAID 5&lt;br/&gt;
  baseline  708 sec&lt;br/&gt;
  new       635 sec&lt;br/&gt;
  -&amp;gt; 10% faster&lt;/p&gt;

&lt;p&gt;Windows XP Pro laptop, single drive&lt;br/&gt;
  baseline  1604 sec&lt;br/&gt;
  new       1308 sec&lt;br/&gt;
  -&amp;gt; 18% faster&lt;/p&gt;

&lt;p&gt;Net/net it&apos;s between 10-18% performance gain overall.  It is&lt;br/&gt;
interesting that the system with the &quot;weakest&quot; IO system (one drive on&lt;br/&gt;
Windows XP vs RAID 0/5 on the others) has the best gains.&lt;/p&gt;</comment>
                    <comment id="12499020" author="mikemccand" created="Fri, 25 May 2007 11:14:13 +0100"  >
&lt;p&gt;&amp;gt; I would like to know why these gains are appearing, and how specific&lt;br/&gt;
&amp;gt; they are to a particular system. How can the optimum buffer size be&lt;br/&gt;
&amp;gt; deduced? Is it a factor of hard disk sector size? Memory page size?&lt;br/&gt;
&amp;gt; Lucene write behavior pattern? Level X Cache size?&lt;/p&gt;

&lt;p&gt;It looks like the gains are cross platform (at least between OS X,&lt;br/&gt;
Linux, Windows XP) and cross-IO architecture.&lt;/p&gt;

&lt;p&gt;I&apos;m not sure how this depends/correlates to the various cache/page&lt;br/&gt;
sizes through the layers of OS -&amp;gt; disk heads.&lt;/p&gt;

&lt;p&gt;It must be that doing an IO request has a fairly high overhead and so&lt;br/&gt;
the more bytes you can read/write at once the faster it is, since you&lt;br/&gt;
amortize that overhead.&lt;/p&gt;

&lt;p&gt;For merging in particular, with mergeFactor=10, I can see that a&lt;br/&gt;
larger buffer size on the input streams should help reduce insane&lt;br/&gt;
seeks back &amp;amp; forth between the 10 files (and the 1 output file).&lt;br/&gt;
Maybe larger reads on the input streams also cause OS&apos;s IO scheduler&lt;br/&gt;
to do larger read-ahead in anticipation?&lt;/p&gt;

&lt;p&gt;And some good news: these gains seem to be additive to the gains in&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-843&quot; title=&quot;improve how IndexWriter uses RAM to buffer added documents&quot;&gt;&lt;del&gt;LUCENE-843&lt;/del&gt;&lt;/a&gt;, at least with my initial testing.&lt;/p&gt;</comment>
                    <comment id="12499044" author="jch" created="Fri, 25 May 2007 12:24:51 +0100"  >&lt;p&gt;&amp;gt; Net/net it&apos;s between 10-18% performance gain overall. It is&lt;br/&gt;
&amp;gt; interesting that the system with the &quot;weakest&quot; IO system (one drive on&lt;br/&gt;
&amp;gt; Windows XP vs RAID 0/5 on the others) has the best gains.&lt;/p&gt;

&lt;p&gt;Actually, it&apos;s not that surprising.  Linux and BSD (MacOS) kernels work hard to do good I/O without the user having to do that much to take it into account.   The improvement you&apos;re seeing in those systems is as much to do with the fact that you&apos;re dealing with complete file system block sizes (4x4k) and complete VM page sizes (4x4k).   You&apos;d probably see similar gains just going from 1k to 4k though: even &quot;cp&quot; benefits from using a 4k block size rather than 1k.  I&apos;d guess that a 4k or 8k buffer would be best on Linux/MacOS and that you wouldn&apos;t see much difference going to 16k.  In fact, in the MacOS tests the big jump seems to be from 1k to 4k with smaller improvements thereafer.&lt;/p&gt;

&lt;p&gt;I&apos;m not that surprised by the WinXP changes: the I/O subsystem on a laptop is usually dire and anything that will cut down on the I/O is going to be a big help.  I would expect that the difference would be more dramatic with a FAT32 file system than it would be with NTFS though.&lt;/p&gt;</comment>
                    <comment id="12499065" author="mikemccand" created="Fri, 25 May 2007 13:07:19 +0100"  >&lt;p&gt;Attached the patch based on above discussion.&lt;/p&gt;</comment>
                    <comment id="12499182" author="michaelbusch" created="Fri, 25 May 2007 18:41:49 +0100"  >&lt;p&gt;Mike,&lt;/p&gt;

&lt;p&gt;I tested and reviewed your patch. It looks good and all tests pass! Two comments:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Should we increase the buffer size for CompoundFileReader to 4KB not only for the merge mode but also for the normal read mode?&lt;/li&gt;
	&lt;li&gt;In BufferedIndexInput.setBufferSize() a new buffer should only be allocated if the new size is different from the previous buffer size.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12499199" author="mikemccand" created="Fri, 25 May 2007 19:40:38 +0100"  >&lt;p&gt;&amp;gt; I tested and reviewed your patch. It looks good and all tests pass!&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;

&lt;p&gt;&amp;gt; - Should we increase the buffer size for CompoundFileReader to 4KB&lt;br/&gt;
&amp;gt; not only for the merge mode but also for the normal read mode?&lt;/p&gt;

&lt;p&gt;I&apos;m a little nervous about that: I don&apos;t know the impact it will have&lt;br/&gt;
on searching, especially queries that heavily use skipping?&lt;/p&gt;

&lt;p&gt;Hmmm, actually, a CSIndexInput potentially goes through 2 buffers when&lt;br/&gt;
it does a read &amp;#8211; its own (since each CSIndexInput subclasses from&lt;br/&gt;
BufferedIndexInput) and then the main stream of the&lt;br/&gt;
CompoundFileReader.  It seems like we shouldn&apos;t do this?  We should&lt;br/&gt;
not do a double copy.&lt;/p&gt;

&lt;p&gt;It almost seems like the double copy would not occur becaase&lt;br/&gt;
readBytes() has logic to read directly from the underlying stream if&lt;br/&gt;
the sizes is &amp;gt;= bufferSize.  However, I see at least one case during&lt;br/&gt;
merging where this logic doesn&apos;t kick in (and we do a double buffer&lt;br/&gt;
copy) because the buffers become &quot;skewed&quot;.  I will open a separate&lt;br/&gt;
issue for this; I think we should fix it and gain some more&lt;br/&gt;
performance.&lt;/p&gt;

&lt;p&gt;&amp;gt; In BufferedIndexInput.setBufferSize() a new buffer should only be&lt;br/&gt;
&amp;gt; allocated if the new size is different from the previous buffer&lt;br/&gt;
&amp;gt; size.&lt;/p&gt;

&lt;p&gt;Ahh, good.  Will do.&lt;/p&gt;</comment>
                    <comment id="12499206" author="michaelbusch" created="Fri, 25 May 2007 20:15:58 +0100"  >&lt;p&gt;&amp;gt; I&apos;m a little nervous about that: I don&apos;t know the impact it will have&lt;br/&gt;
&amp;gt; on searching, especially queries that heavily use skipping?&lt;/p&gt;

&lt;p&gt;Doesn&apos;t the OS always read at least a whole block from the disk (usually&lt;br/&gt;
4 KB)? If the answer is yes, then we don&apos;t safe IO by limiting the buffer&lt;br/&gt;
size to 1 KB, right? Of course it makes sense to limit the size for&lt;br/&gt;
streams that we clone often (like the freq stream) to safe memory and&lt;br/&gt;
array copies. But we never clone the base stream in the cfs reader.&lt;/p&gt;

&lt;p&gt;&amp;gt; Hmmm, actually, a CSIndexInput potentially goes through 2 buffers when&lt;br/&gt;
&amp;gt; it does a read &amp;#8211; its own (since each CSIndexInput subclasses from&lt;br/&gt;
&amp;gt; BufferedIndexInput) and then the main stream of the&lt;br/&gt;
&amp;gt; CompoundFileReader. It seems like we shouldn&apos;t do this? We should&lt;br/&gt;
&amp;gt; not do a double copy.&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; It almost seems like the double copy would not occur becaase&lt;br/&gt;
&amp;gt; readBytes() has logic to read directly from the underlying stream if&lt;br/&gt;
&amp;gt; the sizes is &amp;gt;= bufferSize. However, I see at least one case during&lt;br/&gt;
&amp;gt; merging where this logic doesn&apos;t kick in (and we do a double buffer&lt;br/&gt;
&amp;gt; copy) because the buffers become &quot;skewed&quot;. I will open a separate&lt;br/&gt;
&amp;gt; issue for this; I think we should fix it and gain some more&lt;br/&gt;
&amp;gt; performance.&lt;/p&gt;

&lt;p&gt;Good catch! Reminds me a bit of &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-431&quot; title=&quot;RAMInputStream and RAMOutputStream without further buffering&quot;&gt;&lt;del&gt;LUCENE-431&lt;/del&gt;&lt;/a&gt; where we also did double&lt;br/&gt;
buffering for the RAMInputStream and RAMOutputStream. Yes, I think&lt;br/&gt;
we should fix this.&lt;/p&gt;</comment>
                    <comment id="12499209" author="mikemccand" created="Fri, 25 May 2007 20:35:22 +0100"  >&lt;p&gt;&amp;gt; &amp;gt; I&apos;m a little nervous about that: I don&apos;t know the impact it will have&lt;br/&gt;
&amp;gt; &amp;gt; on searching, especially queries that heavily use skipping?&lt;br/&gt;
&amp;gt; &lt;br/&gt;
&amp;gt; Doesn&apos;t the OS always read at least a whole block from the disk&lt;br/&gt;
&amp;gt; (usually 4 KB)? If the answer is yes, then we don&apos;t safe IO by&lt;br/&gt;
&amp;gt; limiting the buffer size to 1 KB, right? Of course it makes sense to&lt;br/&gt;
&amp;gt; limit the size for streams that we clone often (like the freq&lt;br/&gt;
&amp;gt; stream) to safe memory and array copies. But we never clone the base&lt;br/&gt;
&amp;gt; stream in the cfs reader.&lt;/p&gt;

&lt;p&gt;Yes, I think you&apos;re right.  But we should test search&lt;br/&gt;
performance on a large index &amp;amp; &quot;typical&quot; queries to be sure?  I will&lt;br/&gt;
open a new issue to track this...&lt;/p&gt;</comment>
                    <comment id="12499212" author="cutting" created="Fri, 25 May 2007 20:54:30 +0100"  >&lt;p&gt;&amp;gt; then we don&apos;t save IO by limiting the buffer size to 1 KB&lt;/p&gt;

&lt;p&gt;I&apos;m confused by this.  My assumption is that, when you make a request to read 1k from a disk file, that the OS reads substantially more than 1k from the disk and places it in the buffer cache.  (The cost of randomly reading 1k is nearly the same as randomly reading 100k--both are dominated by seek.) So, if you make another request to read 1k shortly thereafter you&apos;ll get it from the buffer cache and the incremental cost will be that of making a system call.&lt;/p&gt;

&lt;p&gt;In general, one should thus rely on the buffer cache and read-ahead, and make input buffers only big enough so that system call overhead is insignificant.  An alternate strategy is to not trust the buffer cache and read-ahead, but rather to make your buffers large enough so that transfer time dominates seeks.  This can require 1MB or larger buffers, so isn&apos;t always practical.&lt;/p&gt;

&lt;p&gt;So, back to your statement, a 1k buffer doesn&apos;t save physical i/o, but nor should it incur extra physical i/o.  It does incur extra system calls, but uses less memory, which is a tradeoff.  Is that what you meant?&lt;/p&gt;</comment>
                    <comment id="12499214" author="rengels@ix.netcom.com" created="Fri, 25 May 2007 21:09:53 +0100"  >&lt;p&gt;I think the important consideration is how expensive is the system call. Since the system call requires JNI, it MIGHT be expensive.&lt;/p&gt;

&lt;p&gt;Another important consideration is buffer utilization. It is my understanding that the OS will perform read-ahead normally only in sequential access only, outside of the additional bytes read to optimize the physical read. If Lucene performs indexed reads but the data is actually being accessed sequential, Lucene managing its own buffers can far more effective.&lt;/p&gt;

&lt;p&gt;Along these lines, if the server is heavily used for a variety of applications Lucene can manage its own buffers more efficiently - similar to how a database almost always (every commercial one I know) has its own buffer cache and does not rely on the OS. In a GC environment though it may be even more imporant if the buffers were managed/reused from a pool as you avoid the GC overhead.&lt;/p&gt;

&lt;p&gt;Just my thoughts.&lt;/p&gt;

</comment>
                    <comment id="12499221" author="michaelbusch" created="Fri, 25 May 2007 21:35:43 +0100"  >&lt;p&gt;&amp;gt; So, back to your statement, a 1k buffer doesn&apos;t save &lt;br/&gt;
&amp;gt; physical i/o, but nor should it incur extra physical i/o.  &lt;/p&gt;

&lt;p&gt;Yes, I agree.&lt;/p&gt;

&lt;p&gt;&amp;gt; It does incur extra system calls, but uses less memory, &lt;br/&gt;
&amp;gt; which is a tradeoff.&lt;/p&gt;

&lt;p&gt;A coworker told me that he ran some experiments with buffer &lt;br/&gt;
sizes in a different application, and he found out that &lt;br/&gt;
increasing the buffer size beyond the disks block size&lt;br/&gt;
further speed up things. In these tests he read a whole&lt;br/&gt;
file sequentially, which means that the speedup came from&lt;br/&gt;
saving system calls, right? &lt;/p&gt;

&lt;p&gt;So yes, it is a tradeoff between memory usage and amount &lt;br/&gt;
of system calls. That&apos;s the reason for my suggestion to&lt;br/&gt;
only increase the buffer size for input streams that we&lt;br/&gt;
don&apos;t clone, like the base stream in the compound reader.&lt;/p&gt;

&lt;p&gt;But I&apos;m just sort of guessing here, I think we should run&lt;br/&gt;
some performance experiments. Mike already opened &lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-893&quot; title=&quot;Increase buffer sizes used during searching&quot;&gt;&lt;del&gt;LUCENE-893&lt;/del&gt;&lt;/a&gt; for that.&lt;/p&gt;</comment>
                    <comment id="12499223" author="michaelbusch" created="Fri, 25 May 2007 21:43:14 +0100"  >&lt;p&gt;Mike,&lt;/p&gt;

&lt;p&gt;another thing I just noticed is your new testcase doesn&apos;t remove &lt;br/&gt;
the directory &quot;testSetBufferSize&quot; at the end.&lt;/p&gt;</comment>
                    <comment id="12499224" author="eksdev" created="Fri, 25 May 2007 21:47:38 +0100"  >&lt;p&gt;we did some time ago a few tests and simply concluded, it boils down to what Doug said, &quot;It does incur extra system calls, but uses less memory, which is a tradeoff.&quot;&lt;/p&gt;

&lt;p&gt;in &lt;b&gt;our&lt;/b&gt; setup 4k was kind of magic number , ca 5-8% faster. I guess it is actually a compromise between time spent in extra os calls  vs probability of reading more than you will really use (waste time on it). Why 4k number happens often to be good compromise is probably the difference in speed of buffer copy for 4k vs 1k being negligible  compared to time spent on system calls. &lt;/p&gt;

&lt;p&gt;The only conclusion we came up to is that you have to measure it and find good compromise. Our case is a bit atypical, short documents (1G index, 60Mio docs) and queries with a lot of terms (80-200), Win 2003 Server, single disk. &lt;/p&gt;

&lt;p&gt;And I do not remember was it before or after we started using MMAP, so no idea really if this affects MMAP setup, guess not.&lt;/p&gt;
</comment>
                    <comment id="12499225" author="mikemccand" created="Fri, 25 May 2007 21:54:02 +0100"  >&lt;p&gt;&amp;gt; another thing I just noticed is your new testcase doesn&apos;t remove the&lt;br/&gt;
&amp;gt; directory &quot;testSetBufferSize&quot; at the end.&lt;/p&gt;

&lt;p&gt;Woops, I will fix.  I will also fix it to appear under the tempDir.&lt;/p&gt;</comment>
                    <comment id="12499226" author="mikemccand" created="Fri, 25 May 2007 22:00:11 +0100"  >
&lt;p&gt;&amp;gt; we did some time ago a few tests and simply concluded, it boils down to what Doug said, &quot;It does incur extra system calls, but uses less memory, which is a tradeoff.&quot;&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; in &lt;b&gt;our&lt;/b&gt; setup 4k was kind of magic number , ca 5-8% faster. I guess it is actually a compromise between time spent in extra os calls vs probability of reading more than you will really use (waste time on it). Why 4k number happens often to be good compromise is probably the difference in speed of buffer copy for 4k vs 1k being negligible compared to time spent on system calls.&lt;br/&gt;
&amp;gt; &lt;br/&gt;
&amp;gt; The only conclusion we came up to is that you have to measure it and find good compromise. Our case is a bit atypical, short documents (1G index, 60Mio docs) and queries with a lot of terms (80-200), Win 2003 Server, single disk.&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; And I do not remember was it before or after we started using MMAP, so no idea really if this affects MMAP setup, guess not. &lt;/p&gt;

&lt;p&gt;Interesting!  Do you remember if your 5-8% gain was for searching or&lt;br/&gt;
indexing?  This issue is focusing on buffer size impact on indexing&lt;br/&gt;
performance and &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-893&quot; title=&quot;Increase buffer sizes used during searching&quot;&gt;&lt;del&gt;LUCENE-893&lt;/del&gt;&lt;/a&gt; is focusing on search performance.&lt;/p&gt;</comment>
                    <comment id="12499231" author="mikemccand" created="Fri, 25 May 2007 22:09:40 +0100"  >&lt;p&gt;New patch with these changes:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;The unit test now creates its test index under &quot;tempDir&quot; &amp;amp; removes it when done&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Don&apos;t allocate a new buffer in setBufferSize if the newSize == the current size&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12499238" author="michaelbusch" created="Fri, 25 May 2007 22:59:25 +0100"  >&lt;p&gt;Take2 looks good. +1 for committing.&lt;/p&gt;</comment>
                    <comment id="12499280" author="creamyg" created="Sat, 26 May 2007 04:11:57 +0100"  >&lt;p&gt;I have some auxiliary data points to report after experimenting with buffer&lt;br/&gt;
size in KS today on three different systems: OS X 10.4.9, FreeBSD 5.3, and an&lt;br/&gt;
old RedHat 9 box.  &lt;/p&gt;

&lt;p&gt;The FS i/o classes in KinoSearch use a FILE* and&lt;br/&gt;
fopen/fwrite/fread/fseek/ftell, rather than file descriptors and the POSIX&lt;br/&gt;
family of functions.  Theoretically, this is wasteful because FILE* stream i/o&lt;br/&gt;
is buffered, so there&apos;s double buffering happening.  I&apos;ve meant to change that&lt;br/&gt;
for some time.  However, when I&apos;ve used setvbuf(self-&amp;gt;fhandle, NULL, _IONBF)&lt;br/&gt;
to eliminate the buffer for the underlying FILE* object, performance tanks &amp;#8211;&lt;br/&gt;
indexing time doubles.  I still don&apos;t understand exactly why, but I know a&lt;br/&gt;
little more now.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Swapping out the FILE* for a descriptor and switching all the I/O calls to&lt;br/&gt;
    POSIX variants has no measurable impact on any of these systems.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Changing the KS buffer size from 1024 to 4096 has no measurable impact on&lt;br/&gt;
    any of these systems.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Using setvbuf to eliminate the buffering at output turns out to have no&lt;br/&gt;
    impact on indexing performance.  It&apos;s only killing off the read mode FILE*&lt;br/&gt;
    buffer that causes the problem.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;So, it seems that the only change I can make moves the numbers in the wrong&lt;br/&gt;
direction.  &lt;/p&gt;

&lt;p&gt;The results are somewhat puzzling because I would ordinarily have blamed&lt;br/&gt;
sub-optimal flush/refill scheduling in my app for the degraded performance&lt;br/&gt;
with setvbuf() on read mode.  However, the POSIX i/o calls are unbuffered, so&lt;br/&gt;
that&apos;s not it.  My best guess is that disabling buffering for read mode&lt;br/&gt;
disables an fseek/ftell optimization.  &lt;/p&gt;</comment>
                    <comment id="12499299" author="mikemccand" created="Sat, 26 May 2007 11:25:34 +0100"  >&lt;p&gt;Marvin, it&apos;s odd that you see no gains when coming straight from C.&lt;br/&gt;
Hmmm.&lt;/p&gt;

&lt;p&gt;I wonder if IO calls from Java somehow have a sizable overhead that&lt;br/&gt;
the corresponding C calls do not.  I didn&apos;t think JNI was that&lt;br/&gt;
expensive?  Though, it looks like reading into byte[] does entail&lt;br/&gt;
extra byte copying.  We could explore using ByteBuffers from&lt;br/&gt;
java.nio.* ... ahh, this has been somewhat explored already, at least&lt;br/&gt;
in &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-414&quot; title=&quot;Java NIO patch against Lucene 1.9&quot;&gt;&lt;del&gt;LUCENE-414&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-893&quot; title=&quot;Increase buffer sizes used during searching&quot;&gt;&lt;del&gt;LUCENE-893&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Also, how much &quot;merging&quot; is actually done in your test / KS?  How many&lt;br/&gt;
segments are merged at once?  The fact that KS doesn&apos;t re-merge the&lt;br/&gt;
stored fields &amp;amp; term vectors (within one session) is probably also a&lt;br/&gt;
big difference here.&lt;/p&gt;</comment>
                    <comment id="12499307" author="creamyg" created="Sat, 26 May 2007 12:26:10 +0100"  >&lt;p&gt;&amp;gt; Also, how much &quot;merging&quot; is actually done in your test / KS?  How many&lt;br/&gt;
&amp;gt; segments are merged at once?  The fact that KS doesn&apos;t re-merge the stored&lt;br/&gt;
&amp;gt; fields &amp;amp; term vectors (within one session) is probably also a big difference&lt;br/&gt;
&amp;gt; here.&lt;/p&gt;

&lt;p&gt;In the previous test, I was indexing 1000 Reuters articles all in one session.&lt;br/&gt;
The postings were never flushed to disk prior to the final write, as the&lt;br/&gt;
external sorter never exceeded its memory threshold.&lt;/p&gt;

&lt;p&gt;I reran the test on the FreeBSD box, changing it so that the index was built&lt;br/&gt;
up in 10-doc increments.  There was still no measurable change for changing&lt;br/&gt;
either the KS buffer size or POSIX/stream style IO.  However, using setvbuf on&lt;br/&gt;
the read mode FILE* stream i/o was utterly disastrous.  After several minutes&lt;br/&gt;
(compare with 3.8 seconds) I cut it off.  Subsequent testing with a 500-doc&lt;br/&gt;
increment verified that the test actually was working (10.3 secs).&lt;/p&gt;</comment>
                    <comment id="12499548" author="mikemccand" created="Mon, 28 May 2007 13:03:18 +0100"  >
&lt;p&gt;I re-ran the &quot;second test&quot; above, but this time with compound file&lt;br/&gt;
turned off.&lt;/p&gt;

&lt;p&gt;Baseline (trunk) = 1 K buffers for all 3. New = 16 K for&lt;br/&gt;
BufferedIndexOutput, 16 K for CompoundFileWriter and 4 K for&lt;br/&gt;
BufferedIndexInput.  I ran each test 4 times &amp;amp; took the best time.&lt;/p&gt;

&lt;p&gt;Quad core Mac OS X on 4-drive RAID 0&lt;br/&gt;
  baseline 553 sec&lt;br/&gt;
  new 499 sec&lt;br/&gt;
  -&amp;gt; 10% faster&lt;/p&gt;

&lt;p&gt;Dual core Debian Linux (2.6.18 kernel) on 6 drive RAID 5&lt;br/&gt;
  baseline 590 sec&lt;br/&gt;
  new 548 sec&lt;br/&gt;
  -&amp;gt; 7% faster&lt;/p&gt;

&lt;p&gt;Windows XP Pro laptop, single drive&lt;br/&gt;
  baseline 1078 sec&lt;br/&gt;
  new 918 sec&lt;br/&gt;
  -&amp;gt; 15% faster &lt;/p&gt;

&lt;p&gt;Quick observations:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Still a healthy 7-15% overall gain even without compound file by&lt;br/&gt;
    increasing the buffer sizes.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;The overall performance gain on the trunk just by turning off&lt;br/&gt;
    compound file ranges from 7-33% (33% gain = the Windows XP&lt;br/&gt;
    Laptop).&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;OK I plan to commit this soon.&lt;/p&gt;</comment>
                </comments>
                <issuelinks>
                        <issuelinktype id="10001">
                <name>dependent</name>
                                                <inwardlinks description="is depended upon by">
                            <issuelink>
            <issuekey id="12367718">LUCENE-866</issuekey>
        </issuelink>
                    </inwardlinks>
                            </issuelinktype>
                    </issuelinks>
                <attachments>
                    <attachment id="12358226" name="LUCENE-888.patch" size="26695" author="mikemccand" created="Fri, 25 May 2007 13:07:19 +0100" />
                    <attachment id="12358279" name="LUCENE-888.take2.patch" size="27032" author="mikemccand" created="Fri, 25 May 2007 22:09:40 +0100" />
                </attachments>
            <subtasks>
        </subtasks>
                <customfields>
                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                <customfieldname>Attachment count</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>2.0</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                <customfieldname>Date of First Response</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>Thu, 24 May 2007 14:20:48 +0000</customfieldvalue>

                </customfieldvalues>
            </customfield>
                                                                                                        <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Global Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>12854</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                <customfieldname>Lucene Fields</customfieldname>
                <customfieldvalues>
                        <customfieldvalue key="10121"><![CDATA[New]]></customfieldvalue>
    
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>26841</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                <customfieldname>Time in Status</customfieldname>
                <customfieldvalues>
                    
                </customfieldvalues>
            </customfield>
                            </customfields>
    </item>
</channel>
</rss>