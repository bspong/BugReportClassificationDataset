<!-- 
RSS generated by JIRA (5.2.8#851-sha1:3262fdc28b4bc8b23784e13eadc26a22399f5d88) at Tue Jul 16 13:06:34 UTC 2013

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/LUCENE-1749/LUCENE-1749.xml?field=key&field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>5.2.8</version>
        <build-number>851</build-number>
        <build-date>26-02-2013</build-date>
    </build-info>

<item>
            <title>[LUCENE-1749] FieldCache introspection API</title>
                <link>https://issues.apache.org/jira/browse/LUCENE-1749</link>
                <project id="12310110" key="LUCENE">Lucene - Core</project>
                        <description>&lt;p&gt;FieldCache should expose an Expert level API for runtime introspection of the FieldCache to provide info about what is in the FieldCache at any given moment.  We should also provide utility methods for sanity checking that the FieldCache doesn&apos;t contain anything &quot;odd&quot;...&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;entries for the same reader/field with different types/parsers&lt;/li&gt;
	&lt;li&gt;entries for the same field/type/parser in a reader and it&apos;s subreader(s)&lt;/li&gt;
	&lt;li&gt;etc...&lt;/li&gt;
&lt;/ul&gt;


</description>
                <environment></environment>
            <key id="12430699">LUCENE-1749</key>
            <summary>FieldCache introspection API</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                    <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png">Closed</status>
                    <resolution id="1">Fixed</resolution>
                                <assignee username="hossman">Hoss Man</assignee>
                                <reporter username="hossman">Hoss Man</reporter>
                        <labels>
                    </labels>
                <created>Thu, 16 Jul 2009 20:36:37 +0100</created>
                <updated>Thu, 2 May 2013 03:29:21 +0100</updated>
                    <resolved>Wed, 12 Aug 2009 20:32:13 +0100</resolved>
                                            <fixVersion>2.9</fixVersion>
                                <component>core/search</component>
                        <due></due>
                    <votes>1</votes>
                        <watches>2</watches>
                                                    <comments>
                    <comment id="12732110" author="hossman" created="Thu, 16 Jul 2009 20:37:22 +0100"  >
&lt;p&gt;The motivation for this issue is all of the changes coming in 2.9 in how Lucene internally uses the FieldCache API &amp;#8211; the biggest change being per Segment sorting, but there may be others not immediately obvious.&lt;/p&gt;

&lt;p&gt;While these changes are backwards compatible from an API and functionality perspective, they could have some pretty serious performance impacts for existing apps that also use the FieldCache directly and after upgrading the apps suddenly seem slower to start (because of redundant FieldCache initialization) and require 2X as much RAM as they did before.  This could lead people people to assume Lucene has suddenly became a major memory hog.  &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-1111&quot; title=&quot;fix FieldCache usage in Solr&quot;&gt;SOLR-1111&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-1247&quot; title=&quot;StatsComponent uses top-level FieldCache&quot;&gt;SOLR-1247&lt;/a&gt; are some quick examples of the types of problems that apps could encounter.&lt;/p&gt;

&lt;p&gt;Currently the only way for a User to even notice the problem is to do memory profiling, and the FieldCache data structure isn&apos;t the easiest to understand.  It would be a lot nicer to have some methods for doing this inspection programaticly, so users could write automated tests for incorrect/redundent usage.&lt;/p&gt;</comment>
                    <comment id="12732116" author="hossman" created="Thu, 16 Jul 2009 20:41:02 +0100"  >&lt;p&gt;Here&apos;s the start of a patch to provide this functionality &amp;#8211; it just provides a new method/datastructure for inspecting the cache; the sanity checking utility methods should be straightforward assuming people think this is a good idea.&lt;/p&gt;

&lt;p&gt;The new method itself is fairly simple, but quite a bit of refactoring to how the caches are managed was necessary to make it possible to implement the method sanely.  These changes to the FieldCache internals seem like they are generally a good idea from a maintenance standpoint even if people don&apos;t like the new method.&lt;/p&gt;</comment>
                    <comment id="12732117" author="hossman" created="Thu, 16 Jul 2009 20:43:19 +0100"  >&lt;p&gt;Technically this isn&apos;t a bug, so i probably shouldn&apos;t add it to the 2.9 blocker list, but i really think it would be a good idea to have something like this in the 2.9 release.&lt;/p&gt;

&lt;p&gt;At the very least: i&apos;d like to put it on the list until/unless there is consensus that it&apos;s not needed.&lt;/p&gt;</comment>
                    <comment id="12732123" author="markrmiller@gmail.com" created="Thu, 16 Jul 2009 21:01:24 +0100"  >&lt;p&gt;nice - would be great if it could estimate ram usage as well.&lt;/p&gt;</comment>
                    <comment id="12732157" author="mikemccand" created="Thu, 16 Jul 2009 22:01:20 +0100"  >&lt;p&gt;+1 &amp;#8211; this&apos;d be great to get into 2.9.&lt;/p&gt;</comment>
                    <comment id="12732166" author="thetaphi" created="Thu, 16 Jul 2009 22:12:28 +0100"  >&lt;p&gt;Looks good as a start, one question about a comment:&lt;/p&gt;

&lt;p&gt;What do you mean with:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;:TODO: is the &quot;int&quot; sort type still needed? ... doesn&apos;t seem to be used anywhere, code just tests &quot;custom&quot; for SortComparator vs Parser.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I do not understand, do you want to remove the IntCache? What is different with it in comparison with the other ones?&lt;/p&gt;

&lt;p&gt;Uwe&lt;/p&gt;</comment>
                    <comment id="12732190" author="hossman" created="Thu, 16 Jul 2009 22:43:26 +0100"  >&lt;blockquote&gt;&lt;p&gt;:TODO: is the &quot;int&quot; sort type still needed? ... doesn&apos;t seem to be used anywhere, code just tests &quot;custom&quot; for SortComparator vs Parser.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;sorry ... badly placed quotes ... that was in referent to Entry.type. &lt;/p&gt;

&lt;p&gt;Until i changed getStrings, getStringIndex, and getAuto to construct Entry objects as part of my refactoring the &quot;type&quot; attribute (and the constructor that takes a type argument) didnt&apos; seem to be used anywhere (as far as i could tell)&lt;/p&gt;

&lt;p&gt;My guess: maybe some previous changes refactored logic that switched on type up into the SortFields?, so the FieldCache no longer needs to care about it?&lt;/p&gt;</comment>
                    <comment id="12732288" author="markrmiller@gmail.com" created="Fri, 17 Jul 2009 02:15:12 +0100"  >&lt;p&gt;Here is a start towards guessing the fieldcache ram usage.&lt;/p&gt;

&lt;p&gt;It probably works fairly well, though it will be limited by stack space on a very heavily nested object graph.&lt;/p&gt;

&lt;p&gt;I&apos;ve added the size guess for getValue in the introspection output.&lt;/p&gt;

&lt;p&gt;Its a start anyway.&lt;/p&gt;</comment>
                    <comment id="12732297" author="markrmiller@gmail.com" created="Fri, 17 Jul 2009 02:32:08 +0100"  >&lt;p&gt;We prob would want to provide an alternate toString that includes the ram guess and the default that skips it - i havn&apos;t tested performance, but it might take a while to check a gigantic string array.&lt;/p&gt;

&lt;p&gt;Also, JavaImpl should probably actually be JavaMemoryModel or MemoryModel.&lt;/p&gt;</comment>
                    <comment id="12733945" author="hossman" created="Wed, 22 Jul 2009 02:38:00 +0100"  >&lt;p&gt;More progress building on Mark&apos;s patch.&lt;/p&gt;

&lt;p&gt;added some sanity checking that reader/fieldname combos aren&apos;t reused in odd ways &amp;#8211; i made it ignore cases where different parsers ultimately resolve to identical cache objects (ie null vs DEFAULT_LONG_PARSER) and it ignores any CreationPlaceholder objects (not sure about that one)&lt;/p&gt;

&lt;p&gt;some tests were modified to make their pathological behavior more &quot;sane&quot; and hooks were addded so that future tests can bypass the sanity testing in the tearDown method if they really need to.&lt;/p&gt;

&lt;p&gt;Still need sanity testing of the Reader/subreader variety.  also lots of docs and code cleanup. &lt;/p&gt;

&lt;p&gt;BTW: i was focused on test-core ... still waiting on test-contrib to finish running, so i&apos;m not yet sure if i broke anything there.&lt;/p&gt;</comment>
                    <comment id="12733955" author="hossman" created="Wed, 22 Jul 2009 03:32:07 +0100"  >&lt;p&gt;note to self: of the contribs, TestRemoteSort had two failed tests (not horribly surprising) and PatternAnalyzerTest generated an Error (?!?!) ...&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
java.lang.IllegalStateException: termText
    at org.apache.lucene.index.memory.PatternAnalyzerTest.assertEquals(PatternAnalyzerTest.java:213)
    at org.apache.lucene.index.memory.PatternAnalyzerTest.run(PatternAnalyzerTest.java:148)
    at org.apache.lucene.index.memory.PatternAnalyzerTest.testMany(PatternAnalyzerTest.java:87)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                    <comment id="12734423" author="hossman" created="Thu, 23 Jul 2009 02:52:08 +0100"  >&lt;p&gt;minor checkpoint: improved assert messages, and massaged TestRemoteSort so that it appearers more sane.&lt;/p&gt;

&lt;p&gt;problem with PatternAnalyzerTest was unrelated (see &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1756&quot; title=&quot;contrib/memory: PatternAnalyzerTest is a very, very, VERY, bad unit test&quot;&gt;&lt;del&gt;LUCENE-1756&lt;/del&gt;&lt;/a&gt;)&lt;/p&gt;</comment>
                    <comment id="12734433" author="hossman" created="Thu, 23 Jul 2009 03:40:43 +0100"  >&lt;p&gt;Hmmm... somehow i overlooked the fact that even after i &quot;fixed&quot; TestRemoteSort in the last patch, it&apos;s still failing. Here&apos;s the assertion failure...&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
junit.framework.AssertionFailedError: testRemoteCustomSort Comparator: multi FieldCaches &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; same reader/fieldname with diff types
   at org.apache.lucene.util.LuceneTestCase.assertSaneFieldCaches(LuceneTestCase.java:110)
   at org.apache.lucene.search.TestRemoteSort.testRemoteCustomSort(TestRemoteSort.java:261)
   at org.apache.lucene.util.LuceneTestCase.runTest(LuceneTestCase.java:265)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;...and here&apos;s the debugging dump of the FieldCache...&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
*** BEGIN testRemoteCustomSort Comparator: FieldCache Losers ***
&apos;org.apache.lucene.index.DirectoryReader@1108727&apos;=&amp;gt;&apos;custom&apos;,&lt;span class=&quot;code-keyword&quot;&gt;interface&lt;/span&gt; java.lang.Comparable,9,org.apache.lucene.search.SampleComparable$2@651e95,&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;=&amp;gt;[Ljava.lang.Comparable;#22056753 size guess:2 KB
&apos;org.apache.lucene.index.DirectoryReader@1108727&apos;=&amp;gt;&apos;custom&apos;,&lt;span class=&quot;code-keyword&quot;&gt;interface&lt;/span&gt; java.lang.Comparable,9,org.apache.lucene.search.SampleComparable$2@5b78cf,&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;=&amp;gt;[Ljava.lang.Comparable;#32045680 size guess:2 KB
*** END testRemoteCustomSort Comparator: FieldCache Losers ***
*** BEGIN org.apache.lucene.search.TestRemoteSort.testRemoteCustomSort: FieldCache Losers ***
&apos;org.apache.lucene.index.DirectoryReader@1108727&apos;=&amp;gt;&apos;custom&apos;,&lt;span class=&quot;code-keyword&quot;&gt;interface&lt;/span&gt; java.lang.Comparable,9,org.apache.lucene.search.SampleComparable$2@651e95,&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;=&amp;gt;[Ljava.lang.Comparable;#22056753 size guess:2 KB
&apos;org.apache.lucene.index.DirectoryReader@1108727&apos;=&amp;gt;&apos;custom&apos;,&lt;span class=&quot;code-keyword&quot;&gt;interface&lt;/span&gt; java.lang.Comparable,9,org.apache.lucene.search.SampleComparable$2@5b78cf,&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;=&amp;gt;[Ljava.lang.Comparable;#32045680 size guess:2 KB
*** END org.apache.lucene.search.TestRemoteSort.testRemoteCustomSort: FieldCache Losers ***
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;What really confuses me about this is that the same SampleComparable instance is being used with two different queries &amp;#8211; once with reverse=true and once with reverse=false, yet two different SampleComparable instances are showing up in cache keys &amp;#8211; the probably only happens when SampleComparable is used to get a SortComparator &amp;#8211; not when it uses a ComparatorSource earlier in the test. &lt;/p&gt;

&lt;p&gt;Is this a real bug in remote sorting?&lt;/p&gt;</comment>
                    <comment id="12735190" author="markrmiller@gmail.com" created="Fri, 24 Jul 2009 23:29:47 +0100"  >&lt;blockquote&gt;&lt;p&gt;Is this a real bug in remote sorting&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think so.&lt;/p&gt;

&lt;p&gt;SortField is constructed on the client side and passed as a param to the remote Searchable. It seems you get a new factory every time this happens, not the client factory on the SortField (of course, because its constructed on the other side of the wire).&lt;/p&gt;

&lt;p&gt;So every search call adds a new factory to the mix. If you just make the call once, the test will pass.&lt;/p&gt;

&lt;p&gt;Its a nice find.&lt;/p&gt;</comment>
                    <comment id="12735198" author="markrmiller@gmail.com" created="Fri, 24 Jul 2009 23:53:18 +0100"  >&lt;p&gt;Here is a patch that just updates the ram usage estimator code.&lt;/p&gt;</comment>
                    <comment id="12735242" author="psmith@apache.org" created="Sat, 25 Jul 2009 05:24:24 +0100"  >&lt;p&gt;You know what would be absolute icing on the cake here would be some way during the introspection by some code looking for large sort fields that perhaps can be discarded/unloaded as needed (programmatically).&lt;/p&gt;

&lt;p&gt;What I&apos;m thinking here is a use case we&apos;ve come into where we have had to sort by subject.  Well the unique # subjects gets pretty large, and while we still need to support the use case, it&apos;d be nice to be able to periodically &apos;toss&apos; sort fields like this so they don&apos;t hog memory permanently while the IndexReader is still in memory.  (sorting by subject is used, just not often so a good candidate for tossing)&lt;/p&gt;

&lt;p&gt;Because we have multiple large IndexReaders open concurrently, it&apos;d be nice to be able to scan periodically and kick out any unneeded ones.&lt;/p&gt;

&lt;p&gt;It&apos;s nice to be able to inspect and print out these, but even better if one can make changes based on what one finds.&lt;/p&gt;
</comment>
                    <comment id="12736304" author="hossman" created="Tue, 28 Jul 2009 22:21:47 +0100"  >&lt;p&gt;Mark: i have a little time to work on this today ... do you have any updates that youv&apos;e been working on locally (i noticed some patch add/retract from you in hte history)&lt;/p&gt;

&lt;p&gt;Paul: over in &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-831&quot; title=&quot;Complete overhaul of FieldCache API/Implementation&quot;&gt;LUCENE-831&lt;/a&gt; there was a lot of discussion and work done towards making the entire FieldCAche internals pluggable so you could customize the cache behavior all sorts of ways ... i feel out of the loop on that issue, but my understanding is that it was pushed back to 3.1 at the earliest because it wasn&apos;t clear how the APIs should be setup given the work being done with reopen and with moving FieldCache usage down to the subreaders.&lt;/p&gt;

&lt;p&gt;for now my goal with this issue (&lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1749&quot; title=&quot;FieldCache introspection API&quot;&gt;&lt;del&gt;LUCENE-1749&lt;/del&gt;&lt;/a&gt;) is purely to provide an experimental  (ie: no back compat expectations) API for app developers to use to sanity check that the changes in 2.9 havne&apos;t blown their RAM usage sky high.&lt;/p&gt;</comment>
                    <comment id="12736309" author="markrmiller@gmail.com" created="Tue, 28 Jul 2009 22:26:19 +0100"  >&lt;p&gt;I do - I removed that last patch because I just realized that it was missing everything but one class.&lt;/p&gt;

&lt;p&gt;Go ahead though - I&apos;ll merge with what you have.&lt;/p&gt;</comment>
                    <comment id="12736316" author="hossman" created="Tue, 28 Jul 2009 22:32:06 +0100"  >&lt;p&gt;uh ... ok .. what kind of updates do you have locally?  (no point in merging later if i&apos;m just going to write stuff you&apos;ve already written)&lt;/p&gt;</comment>
                    <comment id="12736320" author="markrmiller@gmail.com" created="Tue, 28 Jul 2009 22:35:01 +0100"  >&lt;p&gt;No worries, the updates are to the ram estimator and other minor things (eg if something fails the sanity check, the error output comes out twice because of the double check in teardown ) - nothing feature wise at the moment. I&apos;ll see what you add first.&lt;/p&gt;</comment>
                    <comment id="12736399" author="hossman" created="Wed, 29 Jul 2009 01:57:40 +0100"  >&lt;p&gt;checkpoint: really hack implementation of checkFieldCacheSubReaderSanity that tells you when a FieldCache contains entries on the same field in a both wrapper/inner readers ... but it doesn&apos;t tell you which entries (and unlike checkFieldCacheTypeSanity it&apos;s no obvious just looking at the toString())&lt;/p&gt;

&lt;p&gt;This patch causes an error in TestStressSort and &lt;b&gt;LOTS&lt;/b&gt; of errors in TestCustomScoreQuery, TestFieldScoreQuery, and TestOrdValues.&lt;/p&gt;

&lt;p&gt;I&apos;d like to think these errors are just from tests doing abnormal things, and in the case of TesStressSort that may be true (it looks like it has some hinky reuse of readers in a MultiReader) but in the other test cases where it&apos;s a little easier to see at a glance what&apos;s going on, there&apos;s really nothing odd here &amp;#8211; simple use of a single IndexSearcher to execute a CustomScoreQuery, ValueSourceQuery, etc... these are each causing multiple FieldCache instances to pop up for a single field (one keyed on the DirectoryReader and another keyed on a CompoundFileReader$CSIndexInput)&lt;/p&gt;

&lt;p&gt;i&apos;m try to work on refactoring the sanity checking methods so they are easier to use (and write some tests for them to prove the work as expected on both sane/insane) but it would be helpful if someone who understands more about how FieldCaches should look (pushed into the subreaders) could tyr out this patch and let me know if these failures look legit.&lt;/p&gt;</comment>
                    <comment id="12736660" author="hossman" created="Wed, 29 Jul 2009 16:21:13 +0100"  >&lt;p&gt;checkpoint: refactored the sanity checking code into a utility class and wrote tests specifically for it to prove it finds insane stuff.&lt;/p&gt;

&lt;p&gt;TODO:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;clean up the api, make it less clunky (and not static)
	&lt;ul&gt;
		&lt;li&gt;return structured data showing exactly which combinations in FieldCache are insane&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;javadocs&lt;/li&gt;
	&lt;li&gt;figure out why previously mentioned tests are breaking (need help with this one ... don&apos;t know enough about the code these tests excercise)&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12736732" author="markrmiller@gmail.com" created="Wed, 29 Jul 2009 19:13:45 +0100"  >&lt;blockquote&gt;&lt;p&gt;figure out why previously mentioned tests are breaking (need help with this one ... don&apos;t know enough about the code these tests excercise&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Eh - its yucky. There are parts where the tests are passing the top level reader (say to a collector) when it should be using the sub readers. I fixed one &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
But then there is more - looked at a couple more difficult ones that also pass the top level reader for the test.&lt;/p&gt;

&lt;p&gt;And then there is explain - IndexSearcher passes the top level reader to the weight explain, and valuesourcequery will get a fieldcache based on that reader. I guess that one is a bug.&lt;/p&gt;

&lt;p&gt;And there are prob a few other similar type things...&lt;/p&gt;</comment>
                    <comment id="12736750" author="markrmiller@gmail.com" created="Wed, 29 Jul 2009 19:54:12 +0100"  >&lt;blockquote&gt;&lt;p&gt;And then there is explain - IndexSearcher passes the top level reader to the weight explain, and valuesourcequery will get a fieldcache based on that reader. I guess that one is a bug.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don&apos;t even know what to do about this one. All I can think is that you pump out an explain for each sub reader - but thats pretty unhelpful.&lt;/p&gt;

&lt;p&gt;Perhaps the best we can do is javadoc the extra requirements that may be needed when you use explain?&lt;/p&gt;</comment>
                    <comment id="12736903" author="markrmiller@gmail.com" created="Thu, 30 Jul 2009 00:17:16 +0100"  >&lt;p&gt;Updates:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;merged in updated ram usage estimator code&lt;/li&gt;
	&lt;li&gt;updated most failing tests to work without creating top level FieldCaches&lt;/li&gt;
	&lt;li&gt;removed offending calls to explain - I left nocommit comments here - depending on what we decide, we could turn off the subreader check for these&lt;/li&gt;
	&lt;li&gt;Turned off the subreader check for stress sort test - it sorts in back compat mode and compares to the new mode - so it loads both on purpose.&lt;/li&gt;
	&lt;li&gt;I don&apos;t remember if I touched anything else.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;tests pass now&lt;/p&gt;</comment>
                    <comment id="12737217" author="hossman" created="Thu, 30 Jul 2009 19:26:01 +0100"  >&lt;p&gt;Mark: thanks for looking into the tests.&lt;/p&gt;

&lt;p&gt;If the CustomScoreQuery class(es) push the FieldCache sage into the subReaders during scoring, then shouldn&apos;t the explain methods do the same thing?  it definitely seems like a bug if getting score explanation from a query causes your memory footprint to double.&lt;/p&gt;

&lt;p&gt;Last night i thought over what a more useful API for hte sanity checker would like like ... &lt;br/&gt;
My power is getting turned off for a few hours this afternoon so i&apos;ll work on it them and should have a much cleaner looking patch to post this evening.&lt;/p&gt;

&lt;p&gt;(BTW: random thought that occurred to me last night: wouldn&apos;t the simplest way to implement the RamEstimator just be to use vanilla java serialization to a custom OutputStream that just counted the bytes and sent them to /dev/null) ?&lt;/p&gt;</comment>
                    <comment id="12737247" author="markrmiller@gmail.com" created="Thu, 30 Jul 2009 20:35:06 +0100"  >&lt;blockquote&gt;&lt;p&gt;(BTW: random thought that occurred to me last night: wouldn&apos;t the simplest way to implement the RamEstimator just be to use vanilla java serialization to a custom OutputStream that just counted the bytes and sent them to /dev/null) ?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That&apos;s one way to go. Its got its own little issues though - some bookkeeping stuff is not serialized, and extra info about class, fields is serialzied. Transient fields (niche issue for sure) would also not be serialized. Its def another way to get an estimate. I chose a different route after considering both (googled the topic for a bit and looked at some examples before choosing). I&apos;d be open to another route, but I thought this method was fairly fast, accurate, and generic.&lt;/p&gt;</comment>
                    <comment id="12737254" author="markrmiller@gmail.com" created="Thu, 30 Jul 2009 20:48:51 +0100"  >&lt;blockquote&gt;&lt;p&gt;If the CustomScoreQuery class(es) push the FieldCache sage into the subReaders during scoring, then shouldn&apos;t the explain methods do the same thing? it definitely seems like a bug if getting score explanation from a query causes your memory footprint to double.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It &lt;b&gt;should&lt;/b&gt; do the same thing - but thats sticky. If you push explain to the sub readers, you will get why it scored as it did for each subreader - not one top level explain. I won&apos;t deny its kind of bug - but I&apos;m not sure at the moment what the best way to address it is. I&apos;ll look into the possibility of pushing the fieldcache access to the subreaders while leaving everything else at the top reader - I have no thoughts about the feasibility of that at the moment though. I guess it might be doable.&lt;/p&gt;</comment>
                    <comment id="12737284" author="markrmiller@gmail.com" created="Thu, 30 Jul 2009 21:57:23 +0100"  >&lt;p&gt;Here is a rough draft for an explain fix.&lt;/p&gt;

&lt;p&gt;Explain for custom and valuesource now drop to per segment to retrieve fieldcache values. Resolving this issue will also resolve &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1771&quot; title=&quot;Using explain may double ram reqs for fieldcaches when using ValueSourceQuery/CustomScoreQuery or for ConstantScoreQuerys that use a caching Filter.&quot;&gt;&lt;del&gt;LUCENE-1771&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                    <comment id="12737294" author="markrmiller@gmail.com" created="Thu, 30 Jul 2009 22:18:45 +0100"  >&lt;p&gt;This issue was a fantastic idea by the way!&lt;/p&gt;</comment>
                    <comment id="12737423" author="hossman" created="Fri, 31 Jul 2009 06:43:06 +0100"  >&lt;p&gt;This is a complete overhaul of the internals of FieldCacheSanityChecker, and it&apos;s API so that it&apos;s a lot cleaner and easier to use programaticly.  &lt;/p&gt;

&lt;p&gt;This also makes it easier for tests to run an analsis, and then ignore the &lt;em&gt;types&lt;/em&gt; of errors they &quot;expect&quot; without ignoring whole cache entries (so a test that expects to have subreader problems can ignore those, even if one of those cache entires also fails a sanity check with another entry for a different reason (ie: different parser on same reader)&lt;/p&gt;

&lt;p&gt;And in the long run: this should make it easier for us to add new types of sanity checks (which i&apos;m guessing we&apos;ll think of when the internals get overhauled) without changing the API too much.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;NOTE:&lt;/b&gt; This is based on Miller&apos;s attachment #12414960 (29/Jul/09) ... i haven&apos;t merged in or looked at any of the changes he made after that.  i suspect the only overlap (if any) is how CacheEntry uses the Ram Estimation code ... i switched to having estimateSize(RamUsageEstimator) cache the value and then toString uses it if it&apos;s there ... the FieldCacheSanityChecker takes care of calling it if the client code asks for it.&lt;/p&gt;

&lt;p&gt;Mark: viv&apos;s got all weekend off, so i&apos;m probably not going to have time to look at this again for 4 or 5 days, if you want to take a stab at merging the patches thta would be seriously awesome.&lt;/p&gt;
</comment>
                    <comment id="12737424" author="hossman" created="Fri, 31 Jul 2009 06:51:53 +0100"  >&lt;p&gt;Quick responses to some other comments...&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I chose a different route after considering both&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;i trust you to make the right call, just thought i&apos;d point it out in case you hadn&apos;t though of it.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;If you push explain to the sub readers, you will get why it scored as it did for each subreader - not one top level explain&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don&apos;t really follow you on this (i need to take a look at your proposed fix) .. i&apos;m not suggesting we push the whole explain down to the subreader, just that when the explain method wants to get hte FieldCache value for a doc, it should fetch the FieldCache for the SegmentReader the doc is in &amp;#8211; so it gets the exact same value (and same FieldCache entry) as the scoring code did when it scores the document.  (or maybe i&apos;m completley missunderstanding how these classes were reimplimented to use segment based field caches)&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;This issue was a fantastic idea by the way!&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;yeah ... i was pretty out of the loop on all the &quot;push sorting down into the segment&quot; discussion, but when i noticed yonik pointing out all the ways solr&apos;s fieldcache usage was going to explode if we didn&apos;t change it it occured to me that this would probably be a big problem for anyone doing non-trivial stuff with Lucene, so it would be nice to have a way to toruble shoot it (i also had very little faith in Lucene-Java&apos;s test coverage since we only have unit tests that verify &quot;correct&quot; behavior when we make changes &amp;#8211; but nothing sanity checks how that behavior happened (at least: not untill now)&lt;/p&gt;</comment>
                    <comment id="12737509" author="markrmiller@gmail.com" created="Fri, 31 Jul 2009 13:30:29 +0100"  >&lt;blockquote&gt;&lt;p&gt;I don&apos;t really follow you on this (i need to take a look at your proposed fix) .. i&apos;m not suggesting we push the whole explain down to the subreader, just that when the explain method wants to get hte FieldCache value for a doc, it should fetch the FieldCache for the SegmentReader the doc is in - so it gets the exact same value (and same FieldCache entry) as the scoring code did when it scores the document. (or maybe i&apos;m completley missunderstanding how these classes were reimplimented to use segment based field caches)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The way the per segment stuff went, we don&apos;t push down to the sub readers for the fieldcache per say - we just search each sub reader separately - so per reader fieldcache is just kind of a side effect. Then the top level reader is still used for things like stats and explain. &lt;/p&gt;

&lt;p&gt;I switched the explain for the offending stuff (custom/valuesource) to use a DocValues class that does push down to each subreader for the fieldcache though (while everything else still uses the top reader) - its in the scorer, so I added a switch to push down to subreaders for fieldcache access or not - only explain pushes  down, while regular scoring doesn&apos;t (regular scoring will be working per sub reader anyway, because they are searched one at a time). &lt;/p&gt;

&lt;p&gt;I can merge up the patches.&lt;/p&gt;</comment>
                    <comment id="12737517" author="markrmiller@gmail.com" created="Fri, 31 Jul 2009 13:48:38 +0100"  >&lt;blockquote&gt;&lt;p&gt;the explain method wants to get hte FieldCache value for a doc, it should fetch the FieldCache for the SegmentReader the doc is in&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;One more note to try and be a bit more clear:&lt;/p&gt;

&lt;p&gt;First, I wasn&apos;t sure how easy this was to do because I don&apos;t know explain code or the function package very well at all (eg I&apos;ve never used it). And the explain method itself did not grab values from the field cache, it loaded up a scorer that did so. So I just wasn&apos;t sure how doable this fix was. Thats why I was saying pushing down explain to the subreader wasn&apos;t great, but I wasn&apos;t sure what else you could do. The fix turned out to be fairly easy though - the scorer for valuesource just needed two modes - one for normal scoring and one for explain (that breaks up the requests for a fieldcache val per sub reader) - the explain method would work for both ways, but no reason to try and break down per reader when its going to score per reader anyway, so I have both. Standard scorer for valuesource works as it did, and explain trips a setting to break out subreaders and distrib fieldcache requests. And then the custom query needed a tweak to work right (flip that setting) with its underlying valuesource queries.&lt;/p&gt;
</comment>
                    <comment id="12737626" author="yseeley@gmail.com" created="Fri, 31 Jul 2009 19:11:50 +0100"  >&lt;p&gt;I believe that ConstantScoreQuery will need it&apos;s explain() fixed too?&lt;/p&gt;</comment>
                    <comment id="12737792" author="markrmiller@gmail.com" created="Sat, 1 Aug 2009 01:40:51 +0100"  >&lt;p&gt;In the case that it is a caching filter? I hadn&apos;t actually looked to see if there are any other FieldCache ones either - just what tripped the tests.&lt;/p&gt;

&lt;p&gt;I guess it could be dealt with the same way? A DocIdSet that distributes to sub readers ...&lt;/p&gt;</comment>
                    <comment id="12737825" author="markrmiller@gmail.com" created="Sat, 1 Aug 2009 04:47:49 +0100"  >&lt;ul&gt;
	&lt;li&gt;merged patches (and little tweaks to explain fix code)&lt;/li&gt;
	&lt;li&gt;added a MultiDocIdSet for handling constantscorequery explain - first draft - needs some thought. I just banged it out. Its got a couple simple tests.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12737832" author="markrmiller@gmail.com" created="Sat, 1 Aug 2009 05:32:55 +0100"  >&lt;p&gt;Already finding some corner cases with the multi docidset stuff - I&apos;ll keep working along those lines a bit, then maybe look at some of the code you have been working on and post another patch later this weekend.&lt;/p&gt;</comment>
                    <comment id="12737834" author="markrmiller@gmail.com" created="Sat, 1 Aug 2009 06:03:50 +0100"  >&lt;p&gt;In the insanity check, when you drop into the sequential subreaders - I think its got to be recursive - you might have a multi at the top with other subs, or any combo thereof. I can add to next patch.&lt;/p&gt;</comment>
                    <comment id="12737871" author="mikemccand" created="Sat, 1 Aug 2009 13:08:19 +0100"  >&lt;p&gt;This was an excellent idea, and it&apos;s great that it uncovered some&lt;br/&gt;
dangerous and very unexpected places where we are passing top-level&lt;br/&gt;
reader to the FieldCache (eg that explain() could suddenly populate&lt;br/&gt;
the FieldCache w/ top-level values is quite shocking!).&lt;/p&gt;

&lt;p&gt;ReaderUtil.subSearcher is doing the same thing as&lt;br/&gt;
DirectoryReader.readerIndex.&lt;/p&gt;

&lt;p&gt;I love the RAMUsageEstimator... we have other places that estimate RAM&lt;br/&gt;
(eg IndexWriter does so for added &amp;amp; deleted docs) that we should&lt;br/&gt;
eventually cutover to this new API.&lt;/p&gt;

&lt;p&gt;I particularly love the new class named Insanity:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; Insanity[] checkSanity(FieldCache cache)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;MultiDocIdSet/Iterator makes me a bit nervous, because it&apos;s further&lt;br/&gt;
&quot;propogating&quot; a non-segment-based iterator deeper into Lucene than I&lt;br/&gt;
think we want to.  It&apos;s similar to eg using&lt;br/&gt;
DirectoryReader.MultiTermDocs (what Lucene used to do), instead of&lt;br/&gt;
stepping through the segments yourself.&lt;/p&gt;

&lt;p&gt;Also, shouldn&apos;t explain most closely match what was done during&lt;br/&gt;
searching (ie, run &quot;per segment&quot;)?  So simply pushing explain down to&lt;br/&gt;
the sub-reader that has the doc seems appropriate?  Ie we want it to&lt;br/&gt;
share as much of the code path as possible with how searching was in&lt;br/&gt;
fact done?&lt;/p&gt;

&lt;p&gt;EG for ConstantScoreQuery.explain, it seems like we should 1) locate&lt;br/&gt;
the sub-reader that this doc falls in, and 2) get a scorer against&lt;br/&gt;
that reader, then 3) build up the explanation from that?  Likewise for&lt;br/&gt;
CustomScoreQuery? &lt;/p&gt;

&lt;p&gt;In fact.... maybe we should simply fix IndexSearcher.explain to do&lt;br/&gt;
this for all queries?  Ie, get the top-level weight, locate sub-reader&lt;br/&gt;
that has the doc, un-base the doc, and then invoke QueryWeight.explain&lt;br/&gt;
with that sub-reader and un-based doc?  Then we don&apos;t have to do&lt;br/&gt;
anything special for each query.  I think QueryWeight.scorer()&lt;br/&gt;
shouldn&apos;t be expected to handle a &quot;top level reader&quot; being passed in.&lt;br/&gt;
Ie, higher up in Lucene we should do that switch, so that we don&apos;t&lt;br/&gt;
have to do it (this &quot;valuesFromSubReaders&quot; arg) for every scorer.&lt;/p&gt;

&lt;p&gt;Hmm: why do we even have explain at both the QueryWeight and Scorer&lt;br/&gt;
&quot;levels&quot;?  It seems like we should pick one level and do it there,&lt;br/&gt;
consistently.  Most queries seem to only implement the QueryWeight one&lt;br/&gt;
and often simply throw UOE in the Scorer&apos;s explain, but eg PhraseQuery&lt;br/&gt;
implements in both places.&lt;/p&gt;

&lt;p&gt;(BTW: I&apos;ll be offline for approx the next 36 hours or so!)&lt;/p&gt;</comment>
                    <comment id="12737877" author="yseeley@gmail.com" created="Sat, 1 Aug 2009 13:40:32 +0100"  >&lt;blockquote&gt;&lt;p&gt;In fact.... maybe we should simply fix IndexSearcher.explain to do this for all queries?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That was my first thought... but it would probably break more than it helped right now (by exposing more limitations) - for example idf in TermWeight.explain()&lt;/p&gt;</comment>
                    <comment id="12737889" author="markrmiller@gmail.com" created="Sat, 1 Aug 2009 15:33:57 +0100"  >&lt;p&gt;bq . Ie we want it to share as much of the code path as possible with how searching was in fact done&lt;/p&gt;

&lt;p&gt;Well of course &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; I was a bit hazy on explain, so for some reason I had it in my head that you would have to combine the explanations from multiple subreaders - but of course its a doc at a time, so the doc will only come from one subreader, and the sim/weight will be top level. So easy peasy fix. That boolean valuesFromSubReaders def had some code smell - just didn&apos;t have an alternative at the moment - fix then improve !&lt;/p&gt;

&lt;p&gt;I&apos;ll leave the &apos;explain at multiple levels&apos; for another issue - I havn&apos;t even started thinking about this issue yet - I prefer to code &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; Which is kind of an oxymoron.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;i don&apos;t have the code in front of me, but i thought i was adding the sub&lt;br/&gt;
readers to the list it&apos;s iterating over, so it will eventually recurse all&lt;br/&gt;
the way to the bottom.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Ah right, sorry about the false alarm. One of the few times I&apos;ve seen .size() in a for loop where its actually needed &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="12737890" author="markrmiller@gmail.com" created="Sat, 1 Aug 2009 15:35:25 +0100"  >&lt;p&gt;changes to just go per reader for each doc - and a couple other unrelated tiny tweaks.&lt;/p&gt;</comment>
                    <comment id="12737953" author="markrmiller@gmail.com" created="Sat, 1 Aug 2009 22:31:03 +0100"  >&lt;p&gt;Patch cleanup - more suitable for browsing.&lt;/p&gt;</comment>
                    <comment id="12737984" author="markrmiller@gmail.com" created="Sun, 2 Aug 2009 04:27:23 +0100"  >&lt;blockquote&gt;&lt;p&gt;I was a bit hazy on explain, so for some reason I had it in my head that you would have to combine the explanations from multiple subreaders&lt;/p&gt;&lt;/blockquote&gt;

&lt;blockquote&gt;&lt;p&gt;but it would probably break more than it helped right now (by exposing more limitations) - for example idf in TermWeight.explain()&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;To be a little more clear - this was originally why I went the direction I did - I assumed the reader was being used for stats that needed to come from the top level reader. Gut reaction seeing it go into scorer. I hadn&apos;t really checked that, at least for these queries, that wasn&apos;t the case - they just use it for the filter/fieldcache.&lt;/p&gt;</comment>
                    <comment id="12738100" author="mikemccand" created="Sun, 2 Aug 2009 18:40:40 +0100"  >&lt;blockquote&gt;&lt;p&gt;That was my first thought... but it would probably break more than it helped right now (by exposing more limitations) - for example idf in TermWeight.explain()&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Ugh, you&apos;re right.&lt;/p&gt;

&lt;p&gt;I think It shouldn&apos;t be doing that?  Ie, a Weight instance should&lt;br/&gt;
&quot;capture&quot; all stats needed from the top-level searcher, on creation,&lt;br/&gt;
and then when we ask for a scorer or an explain (or other future&lt;br/&gt;
things that take an IndexReader) we should always pass in a single&lt;br/&gt;
segment reader.  This way we don&apos;t have to duplicate the &quot;go find the&lt;br/&gt;
right sub-reader&quot; in many places.&lt;/p&gt;

&lt;p&gt;It&apos;s interesting that we didn&apos;t (I think?) have a similar problem w/&lt;br/&gt;
scorer when we switched to passing it the sub-reader.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I&apos;ll leave the &apos;explain at multiple levels&apos; for another issue&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It looks like it&apos;s up to each query, which level does what.&lt;br/&gt;
IndexSearcher&apos;s explain always calls Weight.explain, but then some&lt;br/&gt;
Query impls (eg BooleanQuery) do everything in Weight.explain, while&lt;br/&gt;
others (eg TermQuery, PhraseQuery) do some work in Weight.explain and&lt;br/&gt;
some in the scorer.&lt;/p&gt;

&lt;p&gt;I guess this makes sense: &quot;atomic&quot; Queries (TermQuery, PhraseQuery)&lt;br/&gt;
will need to fire up a scorer since there&apos;s real work to be done to&lt;br/&gt;
see the specifics of how that doc was matched.  Whereas BooleanQuery simply&lt;br/&gt;
&quot;glues&quot; together other queries so it doesn&apos;t need to forward to its&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;many&amp;#93;&lt;/span&gt; scorers.&lt;/p&gt;

&lt;p&gt;So the only odd thing is why explain is part of Scorer base&lt;br/&gt;
class... seems like the method could/should live &quot;privately&quot; to only&lt;br/&gt;
those queries that need it.&lt;/p&gt;

&lt;p&gt;But I agree let&apos;s leave this be for now...&lt;/p&gt;</comment>
                    <comment id="12738140" author="yseeley@gmail.com" created="Sun, 2 Aug 2009 23:27:22 +0100"  >&lt;blockquote&gt;&lt;p&gt;It&apos;s interesting that we didn&apos;t (I think?) have a similar problem w/ scorer when we switched to passing it the sub-reader.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Right - that code was well tested and exercised via MultiSearcher in the past (all idf values had to come from Weight to avoid getting idfs per sub-searcher).&lt;br/&gt;
One thing that&apos;s missing for explain() is that there is no way to get &quot;df&quot; as opposed to &quot;idf&quot; from the Weight.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;So the only odd thing is why explain is part of Scorer base class&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Right.. it doesn&apos;t belong there.  Perhaps deprecate and remove from the Scorer base in 3.0? (since one can&apos;t reliably call it now anyway).&lt;/p&gt;</comment>
                    <comment id="12738698" author="markrmiller@gmail.com" created="Tue, 4 Aug 2009 01:14:56 +0100"  >&lt;p&gt;I&apos;ve got one more draft here with the smallest of tweaks - javadoc spelling errors, and one perhaps one or two other tiny things - stuff I just would toss out rather than merge - but are you doing anything here right now Hoss? I think not at the moment, so if thats the case I&apos;ll put up one more patch before you grab the conch back. Otherwise I&apos;ll hold off on anything till you put something up.&lt;/p&gt;</comment>
                    <comment id="12738721" author="hossman_lucene@fucit.org" created="Tue, 4 Aug 2009 01:57:20 +0100"  >

&lt;p&gt;: I&apos;ve got one more draft here with the smallest of tweaks - javadoc &lt;br/&gt;
: spelling errors, and one perhaps one or two other tiny things - stuff I &lt;br/&gt;
: just would toss out rather than merge - but are you doing anything here &lt;br/&gt;
: right now Hoss? I think not at the moment, so if thats the case I&apos;ll put &lt;br/&gt;
: up one more patch before you grab the conch back. Otherwise I&apos;ll hold &lt;br/&gt;
: off on anything till you put something up.&lt;/p&gt;


&lt;p&gt;you have the conch ... i haven&apos;t worked on anything related to this issue &lt;br/&gt;
since my last patch.&lt;/p&gt;

&lt;p&gt;i&apos;ll try to look at it again tomorow.&lt;/p&gt;



&lt;p&gt;-Hoss&lt;/p&gt;
</comment>
                    <comment id="12739080" author="mikemccand" created="Tue, 4 Aug 2009 19:26:59 +0100"  >&lt;blockquote&gt;&lt;p&gt;Right - that code was well tested and exercised via MultiSearcher in the past (all idf values had to come from Weight to avoid getting idfs per sub-searcher).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Ahh right.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;One thing that&apos;s missing for explain() is that there is no way to get &quot;df&quot; as opposed to &quot;idf&quot; from the Weight.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;But this only affects the &quot;atomic&quot; queries, right?  So eg TermWeight&lt;br/&gt;
could simply hold onto this value and then use it during explain.&lt;br/&gt;
Hmm... though TermQuery&apos;s ctor doesn&apos;t get the df directly, because it&lt;br/&gt;
calls similarity.idf(term, searcher).  I don&apos;t really like making a&lt;br/&gt;
separate additional call to docFreq.&lt;/p&gt;

&lt;p&gt;How about, for queries that need to go and look up docFreq, their&lt;br/&gt;
QueryWeight impls simply hold onto the &lt;span class=&quot;error&quot;&gt;&amp;#91;top-level&amp;#93;&lt;/span&gt; IndexSearcher that&lt;br/&gt;
had been passed to their ctor, and then do the docFreq call against&lt;br/&gt;
that, if explain is invoked?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Right.. it doesn&apos;t belong there. Perhaps deprecate and remove from the Scorer base in 3.0? (since one can&apos;t reliably call it now anyway).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;+1&lt;/p&gt;

&lt;p&gt;Hoss/Mark do you want to fold it in to the patch, here?  Or I can open&lt;br/&gt;
a new issue?&lt;/p&gt;</comment>
                    <comment id="12739089" author="yseeley@gmail.com" created="Tue, 4 Aug 2009 19:46:52 +0100"  >&lt;blockquote&gt;
&lt;p&gt;How about, for queries that need to go and look up docFreq, their QueryWeight impls simply hold onto the &lt;span class=&quot;error&quot;&gt;&amp;#91;top-level&amp;#93;&lt;/span&gt; IndexSearcher that&lt;br/&gt;
had been passed to their ctor, and then do the docFreq call against&lt;br/&gt;
that, if explain is invoked?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Asking the searcher for the docFreq is the right thing to do... but people who rely on Weight being serializable might be in for a nasty surprise.&lt;br/&gt;
Of course... one might wonder if we should bother supporting serializable in Lucene longer term at all - anyone dealing with distributed systems has found it to have too many shortcomings anyway.&lt;/p&gt;</comment>
                    <comment id="12739092" author="hossman" created="Tue, 4 Aug 2009 19:57:50 +0100"  >&lt;p&gt;General Comments on mark&apos;s latest patch...&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;the changes that i understand all seem good ... some of the details in reader/searcher/query internals elude me but it sounds Yonik &amp;amp; McCandless have their eyes on them so i trust the three of you have it covered.&lt;/li&gt;
	&lt;li&gt;we still need to fill in some empty/sparse javadocs, but that can be done after an initial commit.&lt;/li&gt;
	&lt;li&gt;is it a bug that AverageGuessMemoryModel.getSize() will NPE on a non primitive class ... or should/will the docs for that API say it only works on primitives?&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Big Questions I Still Have....&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;does anyone have any reservations about the new APIs introduced?&lt;/li&gt;
	&lt;li&gt;FieldCache.CreationPlaceholder (promoted from FieldCacheImpl)&lt;/li&gt;
	&lt;li&gt;FieldCache.CacheEntry&lt;/li&gt;
	&lt;li&gt;FieldCache.getCacheEntries()&lt;/li&gt;
	&lt;li&gt;FieldCache.purgeAllCaches()&lt;/li&gt;
	&lt;li&gt;FieldCacheSanityChecker&lt;/li&gt;
	&lt;li&gt;RamUsageEstimator&lt;/li&gt;
	&lt;li&gt;does anyone have any reservations about the refactoring done in FieldCacheImpl to make this new API possible? (ie: did i break the thread safety in a way i&apos;m not noticing?)&lt;/li&gt;
	&lt;li&gt;is the FieldCacheImpl.Entry.type (the &quot;SortField&quot; int type) still needed by FieldCacheImpl.Entry? ... nothing seems to use it so it would be nice to eliminate it and simplify the CacheEntry API as well.  (i suspect it got refactored into obsolescence when the Sorting got moved into the subreaders)&lt;/li&gt;
	&lt;li&gt;The sanity checking ignores CreationPlaceholder &amp;#8211; largely because of the way the numeric caches first try one parser, and then if they get an NFE try a different parser &amp;#8211; but this leaves the CreationPlaceholder in the cache.  It&apos;s not a big object, so i assume it was implemented this way on purpose and the sanity checker is doing the correct thing by ignoring it, but i wanted to make sure people are aware/ok with this behavior.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Lastly: This patch feels unnecessarily large at this point.  Several of the bugs/improvements we&apos;ve uncovered here don&apos;t seem like belong in this patch, and should be tracked in separate Jira issues, which can be committed independently and enumerated in CHANGES.txt....&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;new ReaderUtil and the usage in DirectoryReader, MultiReader, MultiSearcher &amp;amp; IndexSearcher&lt;/li&gt;
	&lt;li&gt;explain subreader bug fixes in ConstantScoreQuery, QueryWeight, ValueSourceQuery, CustomScoreQuery, etc...&lt;br/&gt;
...i think this issue (and this patch) should be reduced to just the new sanity checkig API, and &lt;b&gt;tests&lt;/b&gt; that have been changed to be more sane (where the underlying code was already fine)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Mark: would you mind splitting up the latest patch you have (you mentioned some additional minor tweaks) and opening new issues for these peripheral changes and then attaching back what&apos;s left for this patch.  Then I&apos;ll take the conch back and work on the missing javadocs.&lt;/p&gt;

&lt;p&gt;(I&apos;ll happily commit once i get at least one thumbs up from someone on the &quot;Big Questions&quot; above ... we can always tweak the javadocs further in subsequent commits)&lt;/p&gt;
</comment>
                    <comment id="12739093" author="hossman" created="Tue, 4 Aug 2009 20:00:02 +0100"  >&lt;blockquote&gt;&lt;p&gt;Hoss/Mark do you want to fold it in to the patch, here? Or I can open a new issue?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;as i alluded to above, i&apos;m in favor of individual issues for each &quot;bug&quot; uncovered by this issue so they can be tracked separately.&lt;/p&gt;</comment>
                    <comment id="12739097" author="markrmiller@gmail.com" created="Tue, 4 Aug 2009 20:03:41 +0100"  >&lt;blockquote&gt;&lt;p&gt;Mark: would you mind splitting up the latest patch you have (you mentioned some additional minor tweaks) and opening new issues for these peripheral changes and then attaching back what&apos;s left for this patch. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;ve already got separate issues and patches up were it makes sense (not the last one Mike mentions) - I wanted to keep them here too though until the insanity tests were complete - the tests that the fixes are somewhat correct are in this patch, and I don&apos;t like to manage layers of patches. if we don&apos;t plan on doing anymore with the insanity tests here though, I&apos;ll spin them out of this patch now.&lt;/p&gt;

&lt;p&gt;I&apos;ll put up one more version and then you can have it back.&lt;/p&gt;</comment>
                    <comment id="12739098" author="yseeley@gmail.com" created="Tue, 4 Aug 2009 20:05:38 +0100"  >&lt;blockquote&gt;&lt;p&gt;Asking the searcher for the docFreq is the right thing to do... but people who rely on Weight being serializable might be in for a nasty surprise.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;If we decide not to ask weight to hang onto it&apos;s searcher, then the other way to do it right is to change explain() to accept a Searcher as well as a IndexReader.&lt;/p&gt;</comment>
                    <comment id="12739108" author="markrmiller@gmail.com" created="Tue, 4 Aug 2009 20:15:25 +0100"  >&lt;blockquote&gt;&lt;p&gt;is it a bug that AverageGuessMemoryModel.getSize() will NPE on a non primitive class ... or should/will the docs for that API say it only works on primitives?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Its only meant to work with primitives. I&apos;ll change the name to getPrimitiveSize - on my last pass through, I&apos;ll also review the javadoc for the classes I added.&lt;/p&gt;</comment>
                    <comment id="12739120" author="mikemccand" created="Tue, 4 Aug 2009 20:54:33 +0100"  >&lt;blockquote&gt;
&lt;p&gt;Asking the searcher for the docFreq is the right thing to do... but people who rely on Weight being serializable might be in for a nasty surprise.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Argh, right.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;If we decide not to ask weight to hang onto it&apos;s searcher, then the other way to do it right is to change explain() to accept a Searcher as well as a IndexReader.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;+1&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Of course... one might wonder if we should bother supporting serializable in Lucene longer term at all - anyone dealing with distributed systems has found it to have too many shortcomings anyway.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yeah this was never really &quot;settled&quot; in &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1473&quot; title=&quot;Implement standard Serialization across Lucene versions&quot;&gt;&lt;del&gt;LUCENE-1473&lt;/del&gt;&lt;/a&gt;.  Lucene currently&lt;br/&gt;
supports live serialization, but not cross-version&lt;br/&gt;
serialization... and we have moved RemoteSearchable to contrib and&lt;br/&gt;
removed RMI from Searchable.&lt;/p&gt;

&lt;p&gt;Does Solr ever rely on Lucene&apos;s &quot;implements Serializable&quot;?&lt;/p&gt;</comment>
                    <comment id="12739122" author="mikemccand" created="Tue, 4 Aug 2009 20:56:04 +0100"  >&lt;blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Hoss/Mark do you want to fold it in to the patch, here? Or I can open a new issue?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;as i alluded to above, i&apos;m in favor of individual issues for each &quot;bug&quot; uncovered by this issue so they can be tracked separately.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;OK I&apos;ll open a new issue for this one (deprecate Scorer.explain).&lt;/p&gt;</comment>
                    <comment id="12739163" author="yseeley@gmail.com" created="Tue, 4 Aug 2009 22:01:10 +0100"  >&lt;blockquote&gt;&lt;p&gt;Does Solr ever rely on Lucene&apos;s &quot;implements Serializable&quot;?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Nope - itra-node communications use the same mechanism as clients... a generic data structures (Map,List,Document,etc) that has custom serialization to XML,JSON,Python,Ruby or Binary (and binary is now used by default).&lt;/p&gt;</comment>
                    <comment id="12739743" author="markrmiller@gmail.com" created="Wed, 5 Aug 2009 21:54:21 +0100"  >&lt;p&gt;patch is coming soon - I&apos;ve merged to trunk and pulled the separate issues - just want to look over some a bit later. Would have had this sooner, but Eclipse decided to start crashing every 5 minutes this morning because firefox brought in a new xulrunner and ... ugg - at least its not Windows ... coming though.&lt;/p&gt;</comment>
                    <comment id="12740039" author="markrmiller@gmail.com" created="Thu, 6 Aug 2009 14:01:08 +0100"  >&lt;p&gt;I still havn&apos;t looked at this in the detail that I want to, but time is my enemy at the moment, so take it back and at least you can finish up what you have planned.&lt;/p&gt;

&lt;p&gt;Hopefully its all in good working order after all the extracting and to trunking - let me know if you see anything off and I&apos;ll spin another. &lt;/p&gt;</comment>
                    <comment id="12740155" author="markrmiller@gmail.com" created="Thu, 6 Aug 2009 18:16:27 +0100"  >&lt;p&gt;P.S. I&apos;m not sure we want to go with the way I have changed the tests here.&lt;/p&gt;

&lt;p&gt;I switched things to go per subreader rather than use the overall reader - this is how things happen in IndexSearcher now. But we lose the top level reader test. We might want to do it both ways, and when doing it by top reader, ignore the triggered insanity check?&lt;/p&gt;</comment>
                    <comment id="12740256" author="hossman" created="Thu, 6 Aug 2009 22:33:00 +0100"  >&lt;p&gt;Mark: I&apos;ll start working on improving the docs (and other things from my previous todo list)&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;P.S. I&apos;m not sure we want to go with the way I have changed the tests here.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Are you talking about TestOrdValues and TestFieldScoreQuery ?&lt;/p&gt;

&lt;p&gt;if we expect OrdValues and FieldScoreQuery to use subReader based field caches, then the test seems to be doing the correct thing (in your patch) .. inspecting the fieldcaches per subreader.  Is there a code path where we expect those methods to get called on a MultiReader?&lt;/p&gt;

&lt;p&gt;(Actually: that seems like a wroth while improvement to make to these classes: a MultiDocValues impl that all of the getValues(IndexReader) methods use when passed a MultiReader ... it uses getSequentialSubReaders to construct DocValue instances for each so you don&apos;t get FieldCache expolsions if code inadvertenly passes the wrong reader to getValues.  What do you think? ... new issue?)&lt;/p&gt;</comment>
                    <comment id="12740265" author="hossman" created="Thu, 6 Aug 2009 22:45:40 +0100"  >&lt;p&gt;Hmmmm...&lt;/p&gt;

&lt;p&gt;actually mark, testing our your latest patch against hte trunk i&apos;m seeing (FieldCache sanity) failures from TestCustomScoreQuery, TestFieldScoreQuery, TestOrdValues, and TestSort ... have you seen these?  did some other recent change on the trunk trigger these?&lt;/p&gt;</comment>
                    <comment id="12740272" author="markrmiller@gmail.com" created="Thu, 6 Aug 2009 23:04:56 +0100"  >&lt;p&gt;I think that TestCustomScoreQuery, TestFieldScoreQuery, and TestOrdValues all fail because the fix for them is now in another issue.&lt;/p&gt;

&lt;p&gt;TestSort I didn&apos;t notice. It looks like its considering String[] and StringIndex the same for the two multi and parallel sort tests - merged to trunk, so perhaps something has gone awry there? I&apos;ve looked over the patch and I don&apos;t see any obvious mistake - I don&apos;t know that I have time to dig more now, but since you are more familiar with that code anyway, perhaps you can tell me why its now considering them the same anyway? Otherwise I will look more before too long.&lt;/p&gt;</comment>
                    <comment id="12740275" author="markrmiller@gmail.com" created="Thu, 6 Aug 2009 23:06:50 +0100"  >&lt;p&gt;Here is the output - it appears to think String[] and StringIndex are both string:&lt;/p&gt;

&lt;p&gt;VALUEMISMATCH: Multiple distinct value objects for org.apache.lucene.index.CompoundFileReader$CSIndexInput@56d73c7a+string&lt;br/&gt;
	&apos;org.apache.lucene.index.CompoundFileReader$CSIndexInput@56d73c7a&apos;=&amp;gt;&apos;string&apos;,class org.apache.lucene.search.FieldCache$StringIndex,3,null,null=&amp;gt;org.apache.lucene.search.FieldCache$StringIndex#279807577 (size =~ 152 bytes)&lt;br/&gt;
	&apos;org.apache.lucene.index.CompoundFileReader$CSIndexInput@56d73c7a&apos;=&amp;gt;&apos;string&apos;,class java.lang.String,11,null,null=&amp;gt;[Ljava.lang.String;#647057258 (size =~ 108 bytes)&lt;/p&gt;</comment>
                    <comment id="12740278" author="markrmiller@gmail.com" created="Thu, 6 Aug 2009 23:12:17 +0100"  >&lt;blockquote&gt;&lt;p&gt;(Actually: that seems like a wroth while improvement to make to these classes: a MultiDocValues impl that all of the getValues(IndexReader) methods use when passed a MultiReader ... it uses getSequentialSubReaders to construct DocValue instances for each so you don&apos;t get FieldCache expolsions if code inadvertenly passes the wrong reader to getValues. What do you think? ... new issue?)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Very interesting idea - def a new issue I think. Not sure its worth it if you can&apos;t protect general fieldcache access as well though ...&lt;/p&gt;</comment>
                    <comment id="12740305" author="hossman" created="Fri, 7 Aug 2009 00:04:27 +0100"  >&lt;p&gt;checkpoint: no functional change from mark&apos;s previous patch, just improved all the javadocs, including explanation of SanityCheckers purpose and experimental/expert warnings where appropriate.&lt;/p&gt;</comment>
                    <comment id="12740308" author="markrmiller@gmail.com" created="Fri, 7 Aug 2009 00:24:01 +0100"  >&lt;p&gt;Okay, sorry - I messed up when merging with trunk.&lt;/p&gt;

&lt;p&gt;In TestSort you had moved the local sorting to the bottom in the multi sort test - I kept that, but I also kept them higher up. So thats the fail - they just have to be removed.&lt;/p&gt;

&lt;p&gt;Line 953-957 it looks - sorry bout that - just didn&apos;t notice it fail with the other 3.&lt;/p&gt;</comment>
                    <comment id="12740311" author="hossman" created="Fri, 7 Aug 2009 00:32:47 +0100"  >&lt;blockquote&gt;&lt;p&gt;I think that TestCustomScoreQuery, TestFieldScoreQuery, and TestOrdValues all fail because the fix for them is now in another issue.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;ah ... are you talking about &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1771&quot; title=&quot;Using explain may double ram reqs for fieldcaches when using ValueSourceQuery/CustomScoreQuery or for ConstantScoreQuerys that use a caching Filter.&quot;&gt;&lt;del&gt;LUCENE-1771&lt;/del&gt;&lt;/a&gt; ? (the jira dependency sems backwards in that case)&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;In TestSort you had moved the local sorting to the bottom in the multi sort test - I kept that, but I also kept them higher up. So thats the fail - they just have to be removed.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;yeah .. i just caught that and was starting to reply ... the interestingthing is that the CacheEntry.toString() doesn&apos;t show the Local.US was used when getting the Strings[] FieldCache. .. i&apos;m currently trying to figure out why (because that could confuse people as well)&lt;/p&gt;</comment>
                    <comment id="12740314" author="markrmiller@gmail.com" created="Fri, 7 Aug 2009 00:36:11 +0100"  >&lt;p&gt;Right - I set that up when the code was in this issue - reversed now!&lt;/p&gt;</comment>
                    <comment id="12740317" author="hossman" created="Fri, 7 Aug 2009 00:46:50 +0100"  >
&lt;blockquote&gt;&lt;p&gt;the interestingthing is that the CacheEntry.toString() doesn&apos;t show the Local.US was used when getting the Strings[] FieldCache&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;m an idiot ... the Locale isn&apos;t used like a FieldCache Parser ... the same String[] is used regardless of the Localed, so it&apos;s never part of the CacheKey.  the output is correct.&lt;/p&gt;

&lt;p&gt;revised patch fixes TestSort as mark pointed out, and updates some javadocs where i missleading suggested different Locales might trigger InsanityType.VALUEMISMATCH&lt;/p&gt;</comment>
                    <comment id="12740341" author="hossman" created="Fri, 7 Aug 2009 02:05:35 +0100"  >&lt;p&gt;confirmed that patch in &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1771&quot; title=&quot;Using explain may double ram reqs for fieldcaches when using ValueSourceQuery/CustomScoreQuery or for ConstantScoreQuerys that use a caching Filter.&quot;&gt;&lt;del&gt;LUCENE-1771&lt;/del&gt;&lt;/a&gt; fixes the remaining broken tests in this issue.&lt;/p&gt;</comment>
                    <comment id="12740624" author="mikemccand" created="Fri, 7 Aug 2009 17:36:14 +0100"  >&lt;p&gt;Maybe we should simply print a warning, eg to System.err, on detecting that 2X RAM usage has occurred, pointing people to the sanity checker?  We could eg do it once only so we don&apos;t spam the stderr logs...&lt;/p&gt;</comment>
                    <comment id="12741479" author="hossman" created="Mon, 10 Aug 2009 19:37:46 +0100"  >&lt;blockquote&gt;&lt;p&gt;Maybe we should simply print a warning, eg to System.err, on detecting that 2X RAM usage has occurred, pointing people to the sanity checker? We could eg do it once only so we don&apos;t spam the stderr logs&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;m not really comfortable dumping anything to System.err without user requesting it ... but this is a really interesting idea.  (I suppose we could add an infoStream type idea to FieldCache to expose this)&lt;/p&gt;

&lt;p&gt;FieldCacheImpl.Cache.get could use the FieldCacheSanityChecker to inspect itself immediately after calling createValue, and could even test if any of the Insanity instances returned are related to the current call (by comparing the CacheEntry with the Entry it&apos;s using) ... it could even log a useful stack trace since the sanity check would be happening in the same call stack as at least one of the CacheEntries in the Insanity object.&lt;/p&gt;

&lt;p&gt;I&apos;ve opened &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1798&quot; title=&quot;FieldCacheSanityChecker called directly by FieldCache.get*&quot;&gt;&lt;del&gt;LUCENE-1798&lt;/del&gt;&lt;/a&gt; to track implmenting somehting like this once the FieldCacheSanityChecker gets committed.&lt;/p&gt;</comment>
                    <comment id="12741707" author="hossman" created="Tue, 11 Aug 2009 07:16:52 +0100"  >&lt;p&gt;slightly revised patch based on java-dev@lucene discussion...&lt;/p&gt;

&lt;p&gt;the sortFieldTYpe and Locale portions of Cache.Entry are never used by FieldCache &amp;#8211; just a deprecated class that abuses the Entry api out of lazyiness... so the CacheEntry debugging abstraction shouldn&apos;t expose them (but i left in code to manifest them in the toString() if they are atypical just in case).  Also added some deprecation notices so we remember to remove them once they are no longer needed.&lt;/p&gt;
</comment>
                    <comment id="12742476" author="hossman" created="Wed, 12 Aug 2009 18:46:32 +0100"  >&lt;p&gt;updated patch to trunk (QueryWeight-&amp;gt;Weight) and tweaked some FieldCacheImpl methods to use the non-deprecated Entry constructors (forgot that part before)&lt;/p&gt;

&lt;p&gt;I&apos;ll commit as soon as my test run is finished.&lt;/p&gt;</comment>
                    <comment id="12742535" author="hossman" created="Wed, 12 Aug 2009 20:29:30 +0100"  >&lt;p&gt;one last updated: the Locale.US asserts in TestRemoteSort had the same problem as TestSort, they were suppose to be moved, but instead they were just copied (not sure how i missed that before)&lt;/p&gt;</comment>
                    <comment id="12742537" author="hossman" created="Wed, 12 Aug 2009 20:32:13 +0100"  >&lt;p&gt;Committed revision 803676.&lt;/p&gt;</comment>
                </comments>
                <issuelinks>
                        <issuelinktype id="10032">
                <name>Blocker</name>
                                <outwardlinks description="blocks">
                            <issuelink>
            <issuekey id="12430734">SOLR-1292</issuekey>
        </issuelink>
                    </outwardlinks>
                                            </issuelinktype>
                        <issuelinktype id="10030">
                <name>Reference</name>
                                                <inwardlinks description="is related to">
                            <issuelink>
            <issuekey id="12432496">LUCENE-1791</issuekey>
        </issuelink>
                    </inwardlinks>
                            </issuelinktype>
                        <issuelinktype id="10001">
                <name>dependent</name>
                                <outwardlinks description="depends upon">
                            <issuelink>
            <issuekey id="12431840">LUCENE-1771</issuekey>
        </issuelink>
                    </outwardlinks>
                                                <inwardlinks description="is depended upon by">
                            <issuelink>
            <issuekey id="12432713">LUCENE-1798</issuekey>
        </issuelink>
                    </inwardlinks>
                            </issuelinktype>
                    </issuelinks>
                <attachments>
                    <attachment id="12413729" name="fieldcache-introspection.patch" size="24561" author="hossman" created="Thu, 16 Jul 2009 20:41:02 +0100" />
                    <attachment id="12415096" name="LUCENE-1749-hossfork.patch" size="95755" author="hossman" created="Fri, 31 Jul 2009 06:43:06 +0100" />
                    <attachment id="12416353" name="LUCENE-1749.patch" size="104097" author="hossman" created="Wed, 12 Aug 2009 20:29:30 +0100" />
                    <attachment id="12416341" name="LUCENE-1749.patch" size="102615" author="hossman" created="Wed, 12 Aug 2009 18:46:32 +0100" />
                    <attachment id="12416168" name="LUCENE-1749.patch" size="102719" author="hossman" created="Tue, 11 Aug 2009 07:16:52 +0100" />
                    <attachment id="12415795" name="LUCENE-1749.patch" size="101053" author="hossman" created="Fri, 7 Aug 2009 00:46:50 +0100" />
                    <attachment id="12415792" name="LUCENE-1749.patch" size="100404" author="hossman" created="Fri, 7 Aug 2009 00:04:27 +0100" />
                    <attachment id="12415739" name="LUCENE-1749.patch" size="93139" author="markrmiller@gmail.com" created="Thu, 6 Aug 2009 14:01:08 +0100" />
                    <attachment id="12415248" name="LUCENE-1749.patch" size="105383" author="markrmiller@gmail.com" created="Sat, 1 Aug 2009 22:31:03 +0100" />
                    <attachment id="12415238" name="LUCENE-1749.patch" size="108965" author="markrmiller@gmail.com" created="Sat, 1 Aug 2009 15:35:25 +0100" />
                    <attachment id="12415220" name="LUCENE-1749.patch" size="109785" author="markrmiller@gmail.com" created="Sat, 1 Aug 2009 04:47:49 +0100" />
                    <attachment id="12415059" name="LUCENE-1749.patch" size="89030" author="markrmiller@gmail.com" created="Thu, 30 Jul 2009 21:57:23 +0100" />
                    <attachment id="12414960" name="LUCENE-1749.patch" size="84632" author="markrmiller@gmail.com" created="Thu, 30 Jul 2009 00:17:16 +0100" />
                    <attachment id="12414915" name="LUCENE-1749.patch" size="61613" author="hossman" created="Wed, 29 Jul 2009 16:21:13 +0100" />
                    <attachment id="12414830" name="LUCENE-1749.patch" size="53410" author="hossman" created="Wed, 29 Jul 2009 01:57:40 +0100" />
                    <attachment id="12414295" name="LUCENE-1749.patch" size="51167" author="hossman" created="Thu, 23 Jul 2009 02:52:08 +0100" />
                    <attachment id="12414174" name="LUCENE-1749.patch" size="48414" author="hossman" created="Wed, 22 Jul 2009 02:38:00 +0100" />
                    <attachment id="12413764" name="LUCENE-1749.patch" size="32197" author="markrmiller@gmail.com" created="Fri, 17 Jul 2009 02:15:12 +0100" />
                </attachments>
            <subtasks>
        </subtasks>
                <customfields>
                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                <customfieldname>Attachment count</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>18.0</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                <customfieldname>Date of First Response</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>Thu, 16 Jul 2009 20:01:24 +0000</customfieldvalue>

                </customfieldvalues>
            </customfield>
                                                                                                        <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Global Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>12011</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                <customfieldname>Lucene Fields</customfieldname>
                <customfieldvalues>
                        <customfieldvalue key="10121"><![CDATA[New]]></customfieldvalue>
    <customfieldvalue key="10120"><![CDATA[Patch Available]]></customfieldvalue>
    
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>25977</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                <customfieldname>Time in Status</customfieldname>
                <customfieldvalues>
                    
                </customfieldvalues>
            </customfield>
                            </customfields>
    </item>
</channel>
</rss>