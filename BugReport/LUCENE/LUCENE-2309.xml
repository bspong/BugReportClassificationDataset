<!-- 
RSS generated by JIRA (5.2.8#851-sha1:3262fdc28b4bc8b23784e13eadc26a22399f5d88) at Tue Jul 16 13:08:46 UTC 2013

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/LUCENE-2309/LUCENE-2309.xml?field=key&field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>5.2.8</version>
        <build-number>851</build-number>
        <build-date>26-02-2013</build-date>
    </build-info>

<item>
            <title>[LUCENE-2309] Fully decouple IndexWriter from analyzers</title>
                <link>https://issues.apache.org/jira/browse/LUCENE-2309</link>
                <project id="12310110" key="LUCENE">Lucene - Core</project>
                        <description>&lt;p&gt;IndexWriter only needs an AttributeSource to do indexing.&lt;/p&gt;

&lt;p&gt;Yet, today, it interacts with Field instances, holds a private&lt;br/&gt;
analyzers, invokes analyzer.reusableTokenStream, has to deal with a&lt;br/&gt;
wide variety (it&apos;s not analyzed; it is analyzed but it&apos;s a Reader,&lt;br/&gt;
String; it&apos;s pre-analyzed).&lt;/p&gt;

&lt;p&gt;I&apos;d like to have IW only interact with attr sources that already&lt;br/&gt;
arrived with the fields.  This would be a powerful decoupling &amp;#8211; it&lt;br/&gt;
means others are free to make their own attr sources.&lt;/p&gt;

&lt;p&gt;They need not even use any of Lucene&apos;s analysis impls; eg they can&lt;br/&gt;
integrate to other things like &lt;a href=&quot;http://www.openpipeline.org&quot; class=&quot;external-link&quot;&gt;OpenPipeline&lt;/a&gt;.&lt;br/&gt;
Or make something completely custom.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-2302&quot; title=&quot;Replacement for TermAttribute+Impl with extended capabilities (byte[] support, CharSequence, Appendable)&quot;&gt;&lt;del&gt;LUCENE-2302&lt;/del&gt;&lt;/a&gt; is already a big step towards this: it makes IW agnostic&lt;br/&gt;
about which attr is &quot;the term&quot;, and only requires that it provide a&lt;br/&gt;
BytesRef (for flex).&lt;/p&gt;

&lt;p&gt;Then I think &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-2308&quot; title=&quot;Separately specify a field&amp;#39;s type&quot;&gt;&lt;del&gt;LUCENE-2308&lt;/del&gt;&lt;/a&gt; would get us most of the remaining way &amp;#8211; ie, if the&lt;br/&gt;
FieldType knows the analyzer to use, then we could simply create a&lt;br/&gt;
getAttrSource() method (say) on it and move all the logic IW has today&lt;br/&gt;
onto there.  (We&apos;d still need existing IW code for back-compat).&lt;/p&gt;</description>
                <environment></environment>
            <key id="12458723">LUCENE-2309</key>
            <summary>Fully decouple IndexWriter from analyzers</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                    <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png">Closed</status>
                    <resolution id="1">Fixed</resolution>
                                <assignee username="cmale">Chris Male</assignee>
                                <reporter username="mikemccand">Michael McCandless</reporter>
                        <labels>
                        <label>gsoc2011</label>
                        <label>lucene-gsoc-11</label>
                        <label>mentor</label>
                    </labels>
                <created>Wed, 10 Mar 2010 20:34:35 +0000</created>
                <updated>Fri, 10 May 2013 11:44:15 +0100</updated>
                    <resolved>Fri, 23 Sep 2011 17:23:29 +0100</resolved>
                                            <fixVersion>4.0-ALPHA</fixVersion>
                                <component>core/index</component>
                        <due></due>
                    <votes>1</votes>
                        <watches>3</watches>
                                                    <comments>
                    <comment id="12843772" author="mikemccand" created="Wed, 10 Mar 2010 21:10:51 +0000"  >&lt;p&gt;We can&apos;t use attr source directly &amp;#8211; we&apos;d need to factor out&lt;br/&gt;
the minimal API from TokenStream (.incrToken &amp;amp; .end?) and&lt;br/&gt;
use that (thanks Robert!).&lt;/p&gt;</comment>
                    <comment id="12844155" author="shaie" created="Thu, 11 Mar 2010 18:12:34 +0000"  >&lt;p&gt;Would this mean that after that we can move all of core Analyzers to contrib/analyzers, making one step towards getting them completely out of Lucene and into their own Apache project?&lt;/p&gt;

&lt;p&gt;That way, we can keep in core only the AttributeSource and accompanying classes, and really allow people to pass AttributeSource which is not even an Analyzer (like you said). We can move the specific Analyzer tests to contrib/analyzers as well. The other tests in core, who don&apos;t care about analysis, can use a src/test specific AttributeSource, like TestAttributeSourceImpl ...&lt;/p&gt;

&lt;p&gt;I&apos;m thinking - it&apos;s ok for contrib to depend on core but not the other way around. It will however take out of core a useful feature for new users which allows fast bootstrap. That won&apos;t be the case when analyzers move out of Lucene entirely, but while they are in Lucene, we&apos;ll force everyone to download contrib/analyzers as well. So maybe we keep in core only Standard, or maybe even something simpler, again, for easy bootstrapping (like Whitespace + lowercase).&lt;/p&gt;

&lt;p&gt;This is just a thought.&lt;/p&gt;</comment>
                    <comment id="12844177" author="mikemccand" created="Thu, 11 Mar 2010 19:20:21 +0000"  >&lt;blockquote&gt;&lt;p&gt;Would this mean that after that we can move all of core Analyzers to contrib/analyzers&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes, though, I think that&apos;s orthogonal (can and should be separately&lt;br/&gt;
done, anyway).&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;making one step towards getting them completely out of Lucene and into their own Apache project?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;We may simply &quot;standardize&quot; on contrib/analyzers as the one place,&lt;br/&gt;
instead of a new &lt;span class=&quot;error&quot;&gt;&amp;#91;sub-&amp;#93;&lt;/span&gt;project.  To be discussed... but we really do&lt;br/&gt;
need one place.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;That way, we can keep in core only the AttributeSource and accompanying classes, and really allow people to pass AttributeSource which is not even an Analyzer (like you said).  We can move the specific Analyzer tests to contrib/analyzers as well. The other tests in core, who don&apos;t care about analysis, can use a src/test specific AttributeSource, like TestAttributeSourceImpl ...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Right.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I&apos;m thinking - it&apos;s ok for contrib to depend on core but not the other way around.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I agree.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;It will however take out of core a useful feature for new users which allows fast bootstrap.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Well.. I suspect with this change users would not typically use&lt;br/&gt;
lucene-core alone.  Ie, they&apos;d get analyzers and queryparser (if we&lt;br/&gt;
also move it out as its own module).&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;That won&apos;t be the case when analyzers move out of Lucene entirely, but while they are in Lucene, we&apos;ll force everyone to download contrib/analyzers as well.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think a single source for all analyzers will be a great step&lt;br/&gt;
forwards for users.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;So maybe we keep in core only Standard, or maybe even something simpler, again, for easy bootstrapping (like Whitespace + lowercase).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Or remove them entirely (but, then, core tests will need to use&lt;br/&gt;
contrib analyzers for their testing)...&lt;/p&gt;</comment>
                    <comment id="12844180" author="rcmuir" created="Thu, 11 Mar 2010 19:24:21 +0000"  >&lt;blockquote&gt;
&lt;p&gt;Or remove them entirely (but, then, core tests will need to use&lt;br/&gt;
contrib analyzers for their testing)...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I agree, lets not get caught up on how our tests run from build.xml!&lt;br/&gt;
We should decouple analysis from IW as much as possible, at least to support &lt;br/&gt;
more flexible analysis: e.g. someone doesnt want to use the TokenStream &lt;br/&gt;
concept at all, for example.&lt;/p&gt;

&lt;p&gt;I don&apos;t really have any opinion practically where all the analyzers go, but I do agree&lt;br/&gt;
it would be nice if they were in one place. For example, in contrib/analyzers now&lt;br/&gt;
we have analyzers by language, and in most cases, users should really be looking&lt;br/&gt;
at EnglishAnalyzer as their &quot;default&quot; instead of StandardAnalyzer for English language,&lt;br/&gt;
as it does Porter stemming, too.&lt;/p&gt;</comment>
                    <comment id="12844182" author="shaie" created="Thu, 11 Mar 2010 19:25:22 +0000"  >&lt;blockquote&gt;&lt;p&gt;Or remove them entirely (but, then, core tests will need to use contrib analyzers for their testing)...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;For that I proposed to have a default TestAttributeSourceImpl, which does whitespace tokenization or something. If other &apos;core&apos; tests need something else, we can write specific AttributeSources for them. I hope we can avoid introducing any dependency of core on contrib.&lt;/p&gt;</comment>
                    <comment id="12844189" author="rcmuir" created="Thu, 11 Mar 2010 19:31:57 +0000"  >&lt;blockquote&gt;&lt;p&gt;For that I proposed to have a default TestAttributeSourceImpl&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;We need a bit more than AttributeSource, at least if the text has &lt;br/&gt;
more than one token, it must at least support incrementToken()&lt;/p&gt;

&lt;p&gt;We could try factoring out incrementToken() and end() from&lt;br/&gt;
TokenStream to create a &quot;more-generic&quot; interface, but really,&lt;br/&gt;
there isn&apos;t much more to Tokenstream (except close and reset)&lt;/p&gt;

&lt;p&gt;At the same time, while I really like the decorator API of &lt;br/&gt;
TokenStream, it should be easier for someone to use a completely&lt;br/&gt;
different API, perhaps one that feels less like you are writing&lt;br/&gt;
a finite-state machine by hand (capture/restoreState, etc)&lt;/p&gt;</comment>
                    <comment id="12844207" author="mikemccand" created="Thu, 11 Mar 2010 19:55:37 +0000"  >&lt;blockquote&gt;

&lt;blockquote&gt;&lt;p&gt;Or remove them entirely (but, then, core tests will need to use contrib analyzers for their testing)...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;For that I proposed to have a default TestAttributeSourceImpl, which does whitespace tokenization or something. If other &apos;core&apos; tests need something else, we can write specific AttributeSources for them. I hope we can avoid introducing any dependency of core on contrib.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Only tests would rely on the analyzers module.  I think that&apos;s OK?  core itself would have no dependence.&lt;/p&gt;</comment>
                    <comment id="12844214" author="shaie" created="Thu, 11 Mar 2010 20:06:53 +0000"  >&lt;p&gt;Today when I &quot;ant test-core&quot; contrib is not built, and I like it. Also &quot;ant test-backwards&quot; will be affected I think ... I think if core does not depend on contrib, its tests shouldn&apos;t also. It&apos;s weird if it will.&lt;/p&gt;</comment>
                    <comment id="12844420" author="simonw" created="Fri, 12 Mar 2010 08:29:20 +0000"  >&lt;p&gt;The IndexWriter or rather DocInverterPerField are simply an attribute consumer. None of them needs to know about Analyzer or TokenStream at all. Neither needs the analyzer to iterate over tokens. The IndexWriter should instead implement an interface or use a class that is called for each successful &quot;incrementToken()&quot; no matter how this increment is implemented.&lt;/p&gt;

&lt;p&gt;I could imagine a really simple interface like&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;

&lt;span class=&quot;code-keyword&quot;&gt;interface&lt;/span&gt; AttributeConsumer {
  
  void setAttributeSource(AttributeSource src);

  void next();

  void end();

}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;IW would then pass itself or an istance it uses (DocInverterPerField) to an API expecting such a consumer like:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
field.consume(&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;or something similar. That way we have not dependency on whatever Attribute producer is used. The default implementation is for sure based on an analyzer / tokenstream and alternatives can be exposed via expert API. Even Backwards compatibility could be solved that way easily.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Only tests would rely on the analyzers module. I think that&apos;s OK? core itself would have no dependence.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;+1 test dependencies should not block modularization, its just about configuring the classpath though!&lt;/p&gt;
</comment>
                    <comment id="12844450" author="mikemccand" created="Fri, 12 Mar 2010 10:36:30 +0000"  >&lt;blockquote&gt;&lt;p&gt;The IndexWriter or rather DocInverterPerField are simply an attribute consumer. None of them needs to know about Analyzer or TokenStream at all. Neither needs the analyzer to iterate over tokens.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;Carrying over discussions on IRC with Chris Male &amp;amp; Uwe...&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;Actually, TokenStream is already AttrSource + incrementing, so it&lt;br/&gt;
seems like the right start...&lt;/p&gt;

&lt;p&gt;However, the .reset() method is redundant from indexer&apos;s standpoint &amp;#8211;&lt;br/&gt;
ie when indexer calls Field.getTokenStream (say) whatever init&apos;ing /&lt;br/&gt;
reset&apos;ing should already have be done by that method by the time it&lt;br/&gt;
returns the TokenStream.&lt;/p&gt;

&lt;p&gt;Also, .close and .end are redundant &amp;#8211; seems like we should only have&lt;br/&gt;
.end (few token streams do anything in .close...).  But coalescing&lt;br/&gt;
those two would be a good chunk of work at this point &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; Or maybe we&lt;br/&gt;
make a .finish that simply both by default &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;Finally, indexer doesn&apos;t really need a Document; it just needs&lt;br/&gt;
something abstract that&apos;s provides an iterator over all fields that&lt;br/&gt;
need indexing (and separately, storing).&lt;/p&gt;</comment>
                    <comment id="12844464" author="simonw" created="Fri, 12 Mar 2010 11:42:21 +0000"  >&lt;blockquote&gt;&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;Carrying over discussions on IRC with Chris Male &amp;amp; Uwe...&amp;#93;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That make it very hard to participate. I can not afford to read through all IRC stuff and I don&apos;t get the chance to participate directly unless I watch IRC constantly. We should really move back to JIRA / devlist for such discussions. There is too much going on in IRC.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Actually, TokenStream is already AttrSource + incrementing, so it&lt;br/&gt;
seems like the right start...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;But that binds the Indexer to a tokenstream which is unnecessary IMO. What if I want to implement something aside the TokenStream delegator API?&lt;/p&gt;
</comment>
                    <comment id="12844467" author="rcmuir" created="Fri, 12 Mar 2010 11:53:27 +0000"  >&lt;p&gt;Hello, i commented yesterday but did not receive much feedback, so&lt;br/&gt;
I want to elaborate some more:&lt;/p&gt;

&lt;p&gt;I suppose what I was trying to mention in my earlier comment here:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-2309?focusedCommentId=12844189&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#action_12844189&quot; class=&quot;external-link&quot;&gt;https://issues.apache.org/jira/browse/LUCENE-2309?focusedCommentId=12844189&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#action_12844189&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;is that while I really like the new TokenStream API, i would prefer&lt;br/&gt;
it if we thought about making this flexible enough to support&lt;br/&gt;
&quot;different paradigms&quot;, including perhaps something that looks a lot&lt;br/&gt;
like the old TokenStream API. &lt;/p&gt;

&lt;p&gt;The reason is, I notice a lot of existing code still under this old API,&lt;br/&gt;
and I think that in some cases, perhaps its easier to work with, even&lt;br/&gt;
if you aren&apos;t a new user. I definitely think for newer users the old API&lt;br/&gt;
might have some advantages.&lt;/p&gt;

&lt;p&gt;I think its useful to consider supporting such an API, perhaps as an extension&lt;br/&gt;
in contrib/analyzers, even if its not as fast or flexible as the new API,&lt;br/&gt;
perhaps the tradeoff of speed and flexibility would be worth the ease&lt;br/&gt;
for newer users.&lt;/p&gt;</comment>
                    <comment id="12844489" author="thetaphi" created="Fri, 12 Mar 2010 13:15:04 +0000"  >&lt;blockquote&gt;&lt;p&gt;I could imagine a really simple interface like&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;During lunch an idea evolved:&lt;/p&gt;

&lt;p&gt;If you look at current DocInverter code, it does not use a consumer-like API. The code just has an add/accept-method that accepts tokens. The idea is to, as Simon proposed, let the docinverter implement something like AttributeAcceptor. But still we must have the attribute api and the acceptor (DocInverter) must always &quot;see&quot; the same attribute instances (else much time would be spent to each time call getAttribute(...) for each token, if the accept method would take an AttributeSource).&lt;/p&gt;

&lt;p&gt;The current TokenStream api could get a method taking AttributeAcceptor and simply do a while incrementToken() loop, calling accept() on DocInverter (the AttributeAcceptor). Another approach for users would be to not use the TokenStream API at all and simply call the accept() method for each token on the Acceptor.&lt;/p&gt;

&lt;p&gt;But both approaches still have te problem with the shared attributes. If you want to &quot;record&quot; tokens you have to implement something like my Proxy attributes. Else (as mentioned) above, most time would be spent in getAttribute() calls.&lt;/p&gt;</comment>
                    <comment id="12844498" author="mikemccand" created="Fri, 12 Mar 2010 13:49:35 +0000"  >&lt;blockquote&gt;&lt;p&gt;The idea is to, as Simon proposed, let the docinverter implement something like AttributeAcceptor.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This is interesting!  It inverts the stack/control flow, but, would continue to use shared attrs.&lt;/p&gt;

&lt;p&gt;So then somehow the indexer would pass its AttrAcceptor to the field?  And the field would have whatever control logic it wants to feed the tokens...&lt;/p&gt;</comment>
                    <comment id="12844500" author="mikemccand" created="Fri, 12 Mar 2010 13:52:14 +0000"  >&lt;blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Actually, TokenStream is already AttrSource + incrementing, so it seems like the right start...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;But that binds the Indexer to a tokenstream which is unnecessary IMO. What if I want to implement something aside the TokenStream delegator API?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;True, but we need at least some way to increment?  AttrSource doesn&apos;t have that.&lt;/p&gt;

&lt;p&gt;But I don&apos;t think we need reset nor close from TokenStream.&lt;/p&gt;

&lt;p&gt;Maybe we could factor out an abstract class / interface that TokenStream impls, minus the reset &amp;amp; close methods?&lt;/p&gt;

&lt;p&gt;Then people could freely use Lucene to index off a foreign analysis chain...&lt;/p&gt;</comment>
                    <comment id="12844509" author="shaie" created="Fri, 12 Mar 2010 14:20:11 +0000"  >&lt;blockquote&gt;&lt;p&gt;We should really move back to JIRA / devlist for such discussions&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;+1 !! I also find it very hard to track so many sources of discussions (JIRA, java-dev, java-user, general, and now IRC). Also IRC is not logged/archived and searchable (I think?) which makes it impossible to trace back a discussion, and/or randomly stumble upon it in Google.&lt;/p&gt;

&lt;p&gt;I&apos;d like to donate my two cents here - we&apos;ve just recently changed the TokenStream API, but we still kept its concept - i.e. IW consumes tokens, only now the API has changed slightly. The proposals here, w/ the AttConsumer/Acceptor, that IW will delegate itself to a Field, so the Field will call back to IW seems too much complicated to me. Users that write Analyzers/TokenStreams/AttributeSources, should not care how they are indexed/stored etc. Forcing them to implement this push logic to IW seems to me like a real unnecessary overhead and complexity.&lt;/p&gt;

&lt;p&gt;And having the Field control the flow of indexing seems also dangerous ... might expose Lucene to lots of bugs by users. Today when IW controls it, it&apos;s one place to look for, but tomorrow when Field will control it, where do we look? In the app&apos;s custom Field code? In IW&apos;s atts consuming methods?&lt;/p&gt;

&lt;p&gt;Will the Field also control how stored fields are added? Or only AttributeSourced ones?&lt;/p&gt;

&lt;p&gt;Maybe I need to get used to this change, but currently it looks wrong to reverse the control flow. Maybe in principle the DocInverter now accepts tokens from IW, and so it looks as if we can pass it to the Field (as IW&apos;s AttAcceptor), but still the concept is different. We (IW) control the indexing flow, and not the user.&lt;/p&gt;

&lt;p&gt;I also may not understand what will that give to users. Shouldn&apos;t users get enough flexibility w/ the current API and the Flex (once out) stuff? Do they really need to be bothered w/ pushing tokens to IW?&lt;/p&gt;</comment>
                    <comment id="12844515" author="thetaphi" created="Fri, 12 Mar 2010 14:31:06 +0000"  >&lt;blockquote&gt;&lt;p&gt;I&apos;d like to donate my two cents here - we&apos;ve just recently changed the TokenStream API, but we still kept its concept - i.e. IW consumes tokens, only now the API has changed slightly. The proposals here, w/ the AttConsumer/Acceptor, that IW will delegate itself to a Field, so the Field will call back to IW seems too much complicated to me. Users that write Analyzers/TokenStreams/AttributeSources, should not care how they are indexed/stored etc. Forcing them to implement this push logic to IW seems to me like a real unnecessary overhead and complexity.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The idea was not to change this behaviour, but also give the user the posibility to reverse that. For some tokenstreams it would simplify things much. The current IndexWriter code works exactly like that:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;DocInverter gets TokenStream&lt;/li&gt;
	&lt;li&gt;DocInverter calls reset() &amp;#8211; to be left out and moved to field/analyzer&lt;/li&gt;
	&lt;li&gt;DocInverter does while-loop on incrementToken - it iterates. On each Token it calls add() on the field consumer&lt;/li&gt;
	&lt;li&gt;DocInverter calls end() and updates end offset&lt;/li&gt;
	&lt;li&gt;DocInverter calls close() &amp;#8211; to be left out and moved to field/analyzer&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;The change is simply that step (3) is removed from DocInverter which only provides the add() method for accepting Tokens. The current while loop simply is done in the current TokenStream/Field code, so nobody needs to change his code. But somebody that actively wants to push tokens can now do this. If he wants to do this currently he has no chance without heavy buffering.&lt;/p&gt;

&lt;p&gt;So the push API will be very expert and the current TokenStreams is just a user of this API.&lt;/p&gt;</comment>
                    <comment id="12844516" author="markrmiller@gmail.com" created="Fri, 12 Mar 2010 14:32:27 +0000"  >&lt;blockquote&gt;&lt;p&gt;Also IRC is not logged/archived and searchable (I think?) which makes it impossible to trace back a discussion, and/or randomly stumble upon it in Google.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Apaches rule is, if it didn&apos;t happen on this lists, it didn&apos;t happen. #IRC is a great way for people to communicate and hash stuff out, but its not necessary you follow it. If you have questions or want further elaboration, just ask. No one can expect you to follow IRC, nor is it a valid reference for where something was decided. IRC is great - I think its really benefited having devs discuss there - but the official position is, if it didn&apos;t happen on the list, it didnt actually happen.&lt;/p&gt;</comment>
                    <comment id="12844523" author="simonw" created="Fri, 12 Mar 2010 14:43:48 +0000"  >&lt;blockquote&gt;&lt;p&gt;Then people could freely use Lucene to index off a foreign analysis chain...&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;That is what I was talking about!&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I&apos;d like to donate my two cents here - we&apos;ve just recently changed the TokenStream API, but we still kept its concept - i.e. IW consumes tokens, only now the API has changed slightly. The proposals here, w/ the AttConsumer/Acceptor, that IW will delegate itself to a Field, so the Field will call back to IW seems too much complicated to me. Users that write Analyzers/TokenStreams/AttributeSources, should not care how they are indexed/stored etc. Forcing them to implement this push logic to IW seems to me like a real unnecessary overhead and complexity.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;We can surely hide this implementation completely from field. I consider this being similar to Collector where you pass it explicitly to the search method if you want to have a different behavior. Maybe something like a AttributeProducer. I don&apos;t think adding this to field makes a lot of sense at all and it is not worth the complexity.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Will the Field also control how stored fields are added? Or only AttributeSourced ones?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;IMO this is only about inverted fields.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;We (IW) control the indexing flow, and not the user.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The user only gets the possibility to exchange the analysis chain but not the control flow. The user already can mess around with stuff in incrementToken(), the only thing we change / invert is that the indexer does not know about TokenStreams anymore. it does not change the controlflow though.&lt;/p&gt;
</comment>
                    <comment id="12844528" author="thetaphi" created="Fri, 12 Mar 2010 14:58:22 +0000"  >&lt;p&gt;There is one problem that cannot be easy solved (for all proposals here), if we want to provide an old-style API that does not require reuse of tokens:&lt;br/&gt;
The problem with AttributeProvider is that if we want to support something (like rmuir proposed before) that looks like the old &quot;Token next()&quot;, we need an AttributeProvider that passes the AttributeSource to the indexer on each Token! And that would lead to lots of getAttribute() calls, that would slowdown indexing! So with the current APIs we cannot get around the requirement to reuse the same Attribute instances during the whole indexing without a major speed impact. This can only be solved with my nice BCEL proxy Attributes, so you can exchange the inner attribute impl. Or do it like TokenWrapper in 2.9 (yes, we can reactivate that API somehow as an easy use-addendum).&lt;/p&gt;</comment>
                    <comment id="12844533" author="rcmuir" created="Fri, 12 Mar 2010 15:07:00 +0000"  >&lt;blockquote&gt;
&lt;p&gt;So with the current APIs we cannot get around the requirement to reuse the same Attribute instances during the whole indexing without a major speed impact.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I agree. I guess I&apos;ll try to simplifiy my concern: maybe we don&apos;t necessarily &lt;br/&gt;
need something that looks like the old TokenStream API, but I feel it would&lt;br/&gt;
be worth our time to think about supporting &apos;some alternative API&apos; that makes&lt;br/&gt;
it easier to work with lots of context across different Tokens.&lt;/p&gt;

&lt;p&gt;I personally do not mind how this is done with the capture/restore state API,&lt;br/&gt;
but I feel that its pretty unnatural for many developers, and in the future folks&lt;br/&gt;
might want to do more complex analysis (maybe even light pos-tagging, etc)&lt;br/&gt;
that requires said context, and we should plan for this.&lt;/p&gt;

&lt;p&gt;I feel this wasn&apos;t such an issue with the old TokenStream API, but maybe there&lt;br/&gt;
is another way to address this potential problem.&lt;/p&gt;</comment>
                    <comment id="13058146" author="cmale" created="Fri, 1 Jul 2011 01:07:57 +0100"  >&lt;p&gt;I&apos;d like to pick this issue up and run with it.  Anyone have any new thoughts?&lt;/p&gt;</comment>
                    <comment id="13058548" author="mikemccand" created="Fri, 1 Jul 2011 14:25:25 +0100"  >&lt;p&gt;Great!&lt;/p&gt;

&lt;p&gt;This will overlap w/ the field type work (we have branch for this now), where we already have decoupled indexer from concrete Field/Document impls, by adding a minimal IndexableField.&lt;/p&gt;

&lt;p&gt;I think this issue should further that, ie pare back IndexableField so that there&apos;s only a getTokenStream for indexing (ie indexer will no longer try for String then Reader then tokenStream), and Analyzer must move to the FieldType and not be passed to IndexWriterConfig.  Multi-valued fields will be tricky, since IW now asks analyzer for the gaps...&lt;/p&gt;</comment>
                    <comment id="13064485" author="mikemccand" created="Wed, 13 Jul 2011 12:06:19 +0100"  >&lt;p&gt;Once Analyzer moves onto FieldTypes, I think we can deprecate/remove PerFieldAnalyzerWrapper.&lt;/p&gt;

&lt;p&gt;I&apos;m not sure what to do about multi-valued fields; we may have to move the getPosIncr/OffsetGap onto IndexableField, since it&apos;s not easy to ask a TokenStream to do this shifting for us?&lt;/p&gt;</comment>
                    <comment id="13064517" author="mikemccand" created="Wed, 13 Jul 2011 13:31:27 +0100"  >&lt;p&gt;Hmm, with this cutover comes a new spooky degree of freedom: the ability to specify a different analyzer for each value of a multi-value&apos;d field.&lt;/p&gt;

&lt;p&gt;Maybe we need an explicit FieldType that is &quot;multi-valued&quot;, and so the document would have only one instance of Field for that field name, and within that Field are multiple values?  Problem is, this would lose a degree of freedom we have today, ie the ability for different values of the same field name to have wildly different types...&lt;/p&gt;</comment>
                    <comment id="13064533" author="erickerickson" created="Wed, 13 Jul 2011 14:07:31 +0100"  >&lt;p&gt;&amp;lt;&amp;lt;&amp;lt;Hmm, with this cutover comes a new spooky degree of freedom: the ability to specify a different analyzer for each value of a multi-value&apos;d field.&amp;gt;&amp;gt;&amp;gt;&lt;/p&gt;

&lt;p&gt;Call me a coward, but this scares me! Answering the question &quot;why didn&apos;t I get the results I was expecting&quot; would become...er...somewhat more difficult (I&apos;m studying the understatement thing). Although I guess this wouldn&apos;t be accessible from Solr, so maybe it would be another one of those &quot;expert&quot; features?&lt;/p&gt;</comment>
                    <comment id="13064537" author="sokolov" created="Wed, 13 Jul 2011 14:20:56 +0100"  >&lt;p&gt;Would there be any valid use for that &quot;feature&quot; that couldn&apos;t be accomplished in some more straightforward manner?  It would be like a union, maybe: a field that is sometimes fish and other times fowl, or just a menagerie?  But I can always create a group of fields of various types (in an application) that work together?&lt;/p&gt;</comment>
                    <comment id="13066641" author="cmale" created="Sun, 17 Jul 2011 14:50:11 +0100"  >&lt;p&gt;Note, this patch is against the FieldType branch and is very, very, VERY POC patch.&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Adds the ability to set Analyzer on FieldType (I haven&apos;t removed it from IWC and haven&apos;t addressed the OffSetGap issue)&lt;/li&gt;
	&lt;li&gt;Adds AttributeConsumer abstraction which has callbacks like Simon described above.&lt;/li&gt;
	&lt;li&gt;Added consume(AttributeConsumer) to Field, AttributeSource and TokenStream.  TokenStream.consume() handles calling reset, incrementToken, end and close.  AttributeSource provides a simple implementation.  Field.consume() instantiates a TokenStream from the Analyzer in the FieldType (or uses an an existing one) and then passes on the consume call.&lt;/li&gt;
	&lt;li&gt;DocInverterPerField now uses AttributeConsumer when the Field is tokenized.&lt;/li&gt;
	&lt;li&gt;ReusableStringReader has been quickly made public so it can be used in Field&lt;/li&gt;
	&lt;li&gt;I changed one test (TestDemo) to have the Analyzer set on the FieldType.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Very POC!&lt;/p&gt;</comment>
                    <comment id="13066650" author="rcmuir" created="Sun, 17 Jul 2011 15:22:44 +0100"  >&lt;blockquote&gt;&lt;p&gt;haven&apos;t addressed the OffSetGap issue&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I actually think these gaps are what we should address first. here&apos;s a rough idea:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;remove offset/position increment gap from Analyzer.&lt;/li&gt;
	&lt;li&gt;instead for multivalued fields, the field handles this internally. so it returns a MultiValuedTokenstream? that does the &apos;concatenation&apos;/offset/position increasing between fields itself. IndexWriter just sees one tokenstream for the field and doesn&apos;t know about this, e.g. it just consumes positions and offsets.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;To do this, I think there could be problems if the analyzer does not reuse, as it should be one set of attributes to the indexer across the multivalued field.&lt;/p&gt;

&lt;p&gt;so first to solve this problem: I think first we should remove Analyzer.tokenStream so all analyzers are reusable, and push ReusableAnalyzerBase&apos;s API down into Analyzer. We want to do this improvement anyway to solve that trap.&lt;/p&gt;
</comment>
                    <comment id="13066656" author="cmale" created="Sun, 17 Jul 2011 15:33:54 +0100"  >&lt;p&gt;While I digest your suggestion on handling the gap values,&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;so first to solve this problem: I think first we should remove Analyzer.tokenStream so all analyzers are reusable, and push ReusableAnalyzerBase&apos;s API down into Analyzer. We want to do this improvement anyway to solve that trap.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Beyond the heavy lifting of doing this (which I&apos;m fine with doing), do you know off hand whether this is going to be a problem for any of the Analyzers/Tokenizer/TokenFilter impls we have? I seem to recall an issue where you looked into this.&lt;/p&gt;</comment>
                    <comment id="13066657" author="rcmuir" created="Sun, 17 Jul 2011 15:42:18 +0100"  >&lt;p&gt;Yes, so my idea is basically that Analyzer gets ReusableAnalyzerBase&apos;s API completely, so its reusableTokenStream() is final.&lt;/p&gt;

&lt;p&gt;In order for this to work, we need to first fix the limitation of ReusableAnalyzerBase:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt; * ReusableAnalyzerBase is a simplification of Analyzer that supports easy reuse
 * for the most common use-cases. Analyzers such as
 * {@link PerFieldAnalyzerWrapper} that behave differently depending upon the
 * field name need to subclass Analyzer directly instead.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;this looks easy to do, the current implementation always puts a TokenStreamComponents into the &apos;previousTokenStream&apos;. Instead, reusableAnalyzerBase can have an optional ctor with something like ReuseStrategy, of which there are two:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;GLOBAL: this is what it does now, reuse across all fields, and should be the default&lt;/li&gt;
	&lt;li&gt;PERFIELD: this one instead puts a Map&amp;lt;String,TokenStreamComponents&amp;gt; into the previous tokenstream and reuses on a per-field basis.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;then the problem is solved, and we could name this thing Analyzer, make all analyzers extend it directly, remove the non-reusable TokenStream(), it would only have a final reusableTokenStream() for the consumers.&lt;/p&gt;
</comment>
                    <comment id="13066658" author="cmale" created="Sun, 17 Jul 2011 15:47:46 +0100"  >&lt;p&gt;Fortunately, the patch I put up means PerFieldAnalyzerWrapper can be removed (since Analyzer becomes per FieldType).  But I take your point and it will be necessary to implement what you describe to support SolrAnalyzer.&lt;/p&gt;</comment>
                    <comment id="13066662" author="rcmuir" created="Sun, 17 Jul 2011 15:51:37 +0100"  >&lt;blockquote&gt;
&lt;p&gt;Fortunately, the patch I put up means PerFieldAnalyzerWrapper can be removed (since Analyzer becomes per FieldType).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;How does this work with QueryParser and other consumers of Analyzer though?&lt;/p&gt;</comment>
                    <comment id="13066665" author="cmale" created="Sun, 17 Jul 2011 15:58:16 +0100"  >&lt;p&gt;Good point.  I guess it will continue to have a place in those instances yes.&lt;/p&gt;</comment>
                    <comment id="13066667" author="rcmuir" created="Sun, 17 Jul 2011 16:04:18 +0100"  >&lt;p&gt;I&apos;m just asking the question because, maybe i have a different idea of &quot;fully decouple IndexWriter from Analyzer&quot;.&lt;/p&gt;

&lt;p&gt;If we setup an API where its different at indextime versus query-time, I&apos;m not going to be happy because this is setting up users to fail: in general i should be able to pass my &apos;analysis configuration&apos; to all the various consumers and if its the same at index/time versus query/time, things should work.&lt;/p&gt;

&lt;p&gt;I dont think we should expose a different per-field configuration at index-time versus query-time versus this or that, I think thats a step backwards.&lt;/p&gt;</comment>
                    <comment id="13066669" author="cmale" created="Sun, 17 Jul 2011 16:17:13 +0100"  >&lt;p&gt;You make good points and I don&apos;t have answers for you at this stage.&lt;/p&gt;

&lt;p&gt;What I&apos;m exploring with this direction currently is how best to consume the terms of a Field while minimizing the exposure of Analyzer / TokenStream in the indexing process.  What has felt nature to me is having Analyzer at the Field level.  This is already kind of implemented anyway - if a Field returns a tokenStreamValue() then thats used for indexing, no matter what the &apos;analysis configuration&apos; is.&lt;/p&gt;

&lt;p&gt;Do you have any suggestions for other directions to follow?&lt;/p&gt;</comment>
                    <comment id="13066672" author="rcmuir" created="Sun, 17 Jul 2011 16:34:37 +0100"  >&lt;blockquote&gt;
&lt;p&gt;What I&apos;m exploring with this direction currently is how best to consume the terms of a Field while minimizing the exposure of Analyzer / TokenStream in the indexing process.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I thought about this a lot, I&apos;m not sure we need to minimize TokenStream, I think it might be fine! There is really nothing much more minimal than this, its just attributesource + incrementToken() + reset() + end() + close()...&lt;/p&gt;

&lt;p&gt;This issue is a little out of date, I actually think we have been decoupling indexwriter from analysis even more... for example the indexwriter just pulls bytes from the tokenstream, etc.&lt;/p&gt;

&lt;p&gt;I think we have been going in the right direction and should just be factoring out the things that don&apos;t belong in the indexer or in analyzer (like this gap manipulation)&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;What has felt nature to me is having Analyzer at the Field level. This is already kind of implemented anyway - if a Field returns a tokenStreamValue() then thats used for indexing, no matter what the &apos;analysis configuration&apos; is.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yeah but thats currently an expert option, not the normal case. In general if we are saying IndexWriter doesn&apos;t take Analyzer but has some schema that is a list of Fields, then QueryParser etc need to take this list of fields also, so that queryparsing is consistent with analysis. But i&apos;m not sure I like this either: I think it only couples QueryParser with IndexWriter.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Do you have any suggestions for other directions to follow?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don&apos;t think we should try to do a huge mega-change right now given that there are various &quot;problems&quot; we should fix... some of this I know is my pet peeves but:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;fixing the Analyzers to only be reusable is important, its a performance trap. we should do this regardless... and we can even backport this one easily to 3.x (backporting improvements to reusableAnalyzerBase, deprecating tokenStream(), etc)&lt;/li&gt;
	&lt;li&gt;removing the positionIncrement/offsetGaps from Analyzer makes total sense to me, this is &quot;decoupling indexwriter from analyzer&quot; because these gaps make no sense to other analyzer consumers. So I think these gaps are in the wrong place, and should instead be in Field or whatever, which creates ConcatenatedTokenStream behind the scenes to provide to IndexWriter. This is also good too, maybe you need to do other things than munge offsets/positions across these gaps and this concatenation would no longer be hardcoded in indexwriter.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I&apos;ve looked at doing e.g. the first of these and I know its a huge mondo pain in the ass, these &quot;smaller&quot; changes are really hard and a ton of work.&lt;/p&gt;</comment>
                    <comment id="13066673" author="thetaphi" created="Sun, 17 Jul 2011 16:37:07 +0100"  >&lt;p&gt;I like the idea here, that is &quot;hey analyzer, give me your tokens!&quot;. For lots of use-cases this is much easier to implement than TokenStreams. Its just a change from pull to more push tokens. The impl in TokenStream is just consuming insself and pushing the tokens. From the abstraction point of view thats much easier to understand.&lt;/p&gt;</comment>
                    <comment id="13066675" author="rcmuir" created="Sun, 17 Jul 2011 16:44:03 +0100"  >&lt;p&gt;And that might be a good way, my point is if this is how we want to go, then Analyzer should instead provide AttributeConsumer, and the queryparsers etc should consume it with the same API (and tokenstream is an implementation detail behind the scenes).&lt;/p&gt;

&lt;p&gt;But i don&apos;t think queryparser should take PerFieldAnalyzerWrapper while IndexWriter takes per-Field analyzers, I think thats confusing.&lt;/p&gt;</comment>
                    <comment id="13066676" author="thetaphi" created="Sun, 17 Jul 2011 16:48:26 +0100"  >&lt;p&gt;I think Chris only started with the indexer as an example to show that it works. Of cource we can rewrite all other consumers to use this new api. Also BaseTSTestCase &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="13066677" author="rcmuir" created="Sun, 17 Jul 2011 16:52:46 +0100"  >&lt;p&gt;well if thats the direction here, then we should describe the jira issue differently: something like &quot;abstract away TokenStream API&quot;.&lt;/p&gt;

&lt;p&gt;because it just looks to me as if IndexWriter works off a different analysis API than other analysis consumers and I don&apos;t like that.&lt;/p&gt;</comment>
                    <comment id="13066682" author="cmale" created="Sun, 17 Jul 2011 17:08:51 +0100"  >&lt;p&gt;I just want to re-iterate the point that I&apos;m just exploring options here.  I&apos;m really glad to be getting feedback but no direction has been set in stone.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I thought about this a lot, I&apos;m not sure we need to minimize TokenStream, I think it might be fine! There is really nothing much more minimal than this, its just attributesource + incrementToken() + reset() + end() + close()...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Okay interesting.  I admit I don&apos;t really have any concrete thoughts on an &apos;alternative&apos; to TokenStream, but wouldn&apos;t you agree that exposing a more limited API to the Indexer is beneficial here?  I agree we&apos;re only talking about a handful of methods currently.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Yeah but thats currently an expert option, not the normal case. In general if we are saying IndexWriter doesn&apos;t take Analyzer but has some schema that is a list of Fields, then QueryParser etc need to take this list of fields also, so that queryparsing is consistent with analysis. But i&apos;m not sure I like this either: I think it only couples QueryParser with IndexWriter.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Two things that jump out at me here. Firstly, IndexWriter does take a list of Fields, the Fields it indexes in each Document. We&apos;ve also identified that people might want to apply different analysis per field, thats why we have PerFieldAnalyzerWrapper isn&apos;t it? &lt;/p&gt;

&lt;p&gt;Secondly, we now have multiple QueryParsing implementations consolidated together.  I hope over time we&apos;ll add more / different implementations which do things differently.  So while I totally agree with the sentiment that we shouldn&apos;t make this confusing for users and that searching and indexing should work together, I&apos;m certainly open to exploring other ways to do that.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I&apos;ve looked at doing e.g. the first of these and I know its a huge mondo pain in the ass, these &quot;smaller&quot; changes are really hard and a ton of work.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Independent of what&apos;s decided here, I&apos;m definitely happy to do the heavy lifting on the improvements you&apos;ve suggested.&lt;/p&gt;</comment>
                    <comment id="13066683" author="cmale" created="Sun, 17 Jul 2011 17:17:40 +0100"  >&lt;blockquote&gt;
&lt;p&gt;But i don&apos;t think queryparser should take PerFieldAnalyzerWrapper while IndexWriter takes per-Field analyzers, I think thats confusing.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes it is.  &lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I think Chris only started with the indexer as an example to show that it works. Of cource we can rewrite all other consumers to use this new api. Also BaseTSTestCase.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Absolutely.  &lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;well if thats the direction here, then we should describe the jira issue differently: something like &quot;abstract away TokenStream API&quot;.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don&apos;t think what I&apos;ve implemented in the patch is so different to what has been discussed in this issue earlier.  I did consider opening another issue, but I thought this JIRA issue captured the conceptual issue quite well.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;because it just looks to me as if IndexWriter works off a different analysis API than other analysis consumers and I don&apos;t like that.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;m happy to explore those other consumers and strive to provide a user friend API to limit bugs.  But I&apos;m not getting the impression you like the concept at all. &lt;/p&gt;
</comment>
                    <comment id="13066684" author="rcmuir" created="Sun, 17 Jul 2011 17:23:32 +0100"  >&lt;blockquote&gt;
&lt;p&gt;I&apos;m happy to explore those other consumers and strive to provide a user friend API to limit bugs. But I&apos;m not getting the impression you like the concept at all.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That&apos;s totally not it, but I do like the fact of having an &quot;Analyzer&quot; that is the central API for analysis that anything uses: IndexWriter, QueryParser, MoreLikeThis, Synonyms parsing, SpellChecking, or wherever we need it...&lt;/p&gt;

&lt;p&gt;I think if we want this to take AttributesConsumer or whatever, then thats cool, Analyzer returns this instead of TokenStream and we fix all these consumers to consume the more general API.&lt;/p&gt;

&lt;p&gt;I just want to make sure, that all consumers, not just IndexWriter, use the consistent API. This way, like today, someone declares FooAnalyzer, uses it everywhere, and stuff is consistent everywhere.&lt;/p&gt;
</comment>
                    <comment id="13066688" author="cmale" created="Sun, 17 Jul 2011 17:35:39 +0100"  >&lt;blockquote&gt;
&lt;p&gt;I think if we want this to take AttributesConsumer or whatever, then thats cool, Analyzer returns this instead of TokenStream and we fix all these consumers to consume the more general API.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I just don&apos;t see how this would work.  As it is in the patch, AttributeConsumer is a callback mechanism where the consumer provides their logic.  Its nothing to do with Analyzers really and will be implemented differently depending on what the consumer wants to do in that instance.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I just want to make sure, that all consumers, not just IndexWriter, use the consistent API. This way, like today, someone declares FooAnalyzer, uses it everywhere, and stuff is consistent everywhere.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Absolutely desirable.  AttributeConsumer isn&apos;t changing the Analyzer concept, its just changing how we consume from Analyzer.  With that in mind, I very much agree with your assertion that this shouldn&apos;t change the Analyzer used in search and indexing.  Whats prompted that concern here is the shift to per Field Analyzer.  I&apos;ll reassess that change while waiting for other feedback. &lt;/p&gt;</comment>
                    <comment id="13066689" author="rcmuir" created="Sun, 17 Jul 2011 17:41:36 +0100"  >&lt;blockquote&gt;
&lt;p&gt;I just don&apos;t see how this would work.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;As long as it implements an interface that provides: &lt;br/&gt;
void consume(AttributeConsumer attributeConsumer)&lt;/p&gt;

&lt;p&gt;?&lt;/p&gt;

&lt;p&gt;then, this coudl be what Analyzer returns, Consumable or whatever you want to call this &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="13066697" author="thetaphi" created="Sun, 17 Jul 2011 18:51:35 +0100"  >&lt;p&gt;To come back to decoupling:&lt;br/&gt;
With the new API, we no longer need NumericTokenStream, as NumericField can simply push the tokens to DocInverter. So TokenStream can move out of core, but NumericField &amp;amp; NumericRangeQuery can stay - nice!&lt;/p&gt;</comment>
                    <comment id="13066875" author="cmale" created="Mon, 18 Jul 2011 11:14:20 +0100"  >&lt;p&gt;Okay, I thought about this overnight and have tried to come up with a middle ground.  Again, very proof-of-concept.&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Analyzer now moves away from exposing TokenStream (although I&apos;ve left the methods there) and now returns an AttributeSource.&lt;/li&gt;
	&lt;li&gt;Field.consume() now becomes Field.consume(AttributeConsumer, Analyzer).  Here, the Analyzer is that passed into IW.  This means that the Field can decide how it wants to expose its terms.  The default implementation uses the Analyzer, but others can do what they like.&lt;/li&gt;
	&lt;li&gt;I&apos;ve removed adding Analyzer to FieldType, but it could still be exposed as an expert option.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The overall idea is that the Fields now control how terms are given to DocInverter.&lt;/p&gt;</comment>
                    <comment id="13067009" author="mikemccand" created="Mon, 18 Jul 2011 14:06:37 +0100"  >
&lt;p&gt;I think there are two rather separate ideas here?&lt;/p&gt;

&lt;p&gt;First, IW should not have to &quot;know&quot; how to get a TokenStream from a&lt;br/&gt;
IndexableField; it should only ask the Field for the token stream and get that&lt;br/&gt;
back and iterate its tokens.&lt;/p&gt;

&lt;p&gt;Under the hood (in the IndexableField impl) is where the logic for&lt;br/&gt;
tokenized or not, Reader vs String vs pre-created token stream,&lt;br/&gt;
etc. should live, instead of hardwired inside indexer.  Maybe an app&lt;br/&gt;
has a fully custom way to make a token stream for the field...&lt;/p&gt;

&lt;p&gt;Likewise, for multi-valued fields, IW shouldn&apos;t &quot;see&quot; the separate&lt;br/&gt;
values; it should just receive a single token stream, and under the&lt;br/&gt;
hood (in Document/Field impl) it&apos;s concatenating separate token&lt;br/&gt;
streams, adding posIncr/offset gaps, etc.  This too is now hardwired&lt;br/&gt;
in indexer but shouldn&apos;t be.  Maybe an app wants to insert custom&lt;br/&gt;
&quot;separator&quot; tokens between the values...&lt;/p&gt;

&lt;p&gt;(And I agree: as a pre-req we need to fix Analyzer to not allow&lt;br/&gt;
non-reused token streams; else we can&apos;t concatenate w/o attr&lt;br/&gt;
proxying/copying).&lt;/p&gt;

&lt;p&gt;If IW still receives analyzer and simply passes it through when asking&lt;br/&gt;
for the tokenStream I think that&apos;s fine for now.  In the future, I&lt;br/&gt;
think IW should not receive analyzer (ie, it should be agnostic to how&lt;br/&gt;
the app creates token streams); rather, each FieldType would hold the&lt;br/&gt;
analyzer for that field.  However, that sounds contentious, so let&apos;s&lt;br/&gt;
leave it for another day.&lt;/p&gt;

&lt;p&gt;Second, this new idea to &quot;invert&quot; TokenStream into an AttrConsumer,&lt;br/&gt;
which I think is separate?  I&apos;m actually not sure I like such an&lt;br/&gt;
approach... it seems more confusing for simple usage?  Ie, if I want&lt;br/&gt;
to analyze some text and iterate over the tokens... suddenly, instead&lt;br/&gt;
of a few lines of local code, I have to make a class instance with a&lt;br/&gt;
method that receives each token?  It seems more convoluted?  I&lt;br/&gt;
mean, for Lucene&apos;s limited internal usage of token stream, this is&lt;br/&gt;
fine, but for others who consume token streams... it seems more&lt;br/&gt;
cumbersome.&lt;/p&gt;

&lt;p&gt;Anyway, I think we should open a separate issue for &quot;invert&lt;br/&gt;
TokenStream into AttrConsumer&quot;?&lt;/p&gt;</comment>
                    <comment id="13069502" author="cmale" created="Fri, 22 Jul 2011 12:02:53 +0100"  >&lt;p&gt;I&apos;ve thought about this issue some more and I feel there&apos;s a middle ground to be had.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;First, IW should not have to &quot;know&quot; how to get a TokenStream from a&lt;br/&gt;
IndexableField; it should only ask the Field for the token stream and get that&lt;br/&gt;
back and iterate its tokens.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;You&apos;re absolutely right and this should be our first step.  It should be up to the Field to produce its terms, IW should just iterate through them.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Likewise, for multi-valued fields, IW shouldn&apos;t &quot;see&quot; the separate&lt;br/&gt;
values; it should just receive a single token stream, and under the&lt;br/&gt;
hood (in Document/Field impl) it&apos;s concatenating separate token&lt;br/&gt;
streams, adding posIncr/offset gaps, etc. This too is now hardwired&lt;br/&gt;
in indexer but shouldn&apos;t be. Maybe an app wants to insert custom&lt;br/&gt;
&quot;separator&quot; tokens between the values...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I also totally agree.  We should strive to reduce as much hardwiring at make it as flexible as possible.  But again I see this as a step in the process.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Second, this new idea to &quot;invert&quot; TokenStream into an AttrConsumer,&lt;br/&gt;
which I think is separate? I&apos;m actually not sure I like such an&lt;br/&gt;
approach... it seems more confusing for simple usage? Ie, if I want&lt;br/&gt;
to analyze some text and iterate over the tokens... suddenly, instead&lt;br/&gt;
of a few lines of local code, I have to make a class instance with a&lt;br/&gt;
method that receives each token? It seems more convoluted? I&lt;br/&gt;
mean, for Lucene&apos;s limited internal usage of token stream, this is&lt;br/&gt;
fine, but for others who consume token streams... it seems more&lt;br/&gt;
cumbersome.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don&apos;t agree that this is separate.  For me the purpose of this issue is to fully decouple IndexWriter from analyzers &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; As such the how IW consumes the terms it indexes is at the heart of the issue.  The inversion approach is a suggestion for how we might tackle this in a flexible and extensible way.  So I don&apos;t see any reason to push it to another issue.  Its a way of fulfilling this issue.&lt;/p&gt;

&lt;p&gt;I think there is also some confusion here.  I&apos;m not suggesting we change all usage of analysis.  If someone wants to consume TokenStream as is, so be it.  What I&apos;m looking at changing here is how IW gets the terms it indexes, thats all.  We&apos;ve introduced abstractions like IndexableField to be flexible and extensible.  I don&apos;t think there&apos;s anything wrong with examining the same thing with TokenStream here.&lt;/p&gt;

&lt;p&gt;I think Robert has stated here that he&apos;s comfortable continuing to use TokenStream as the API for IW to get the terms it indexes, is that what others feel too? I agree the inverted API I proposed is a little convoluted and I&apos;m sure we can come up with a simple Consumable like abstraction (which Robert did also suggest above).  But if people are content with TokenStream then theres no need.&lt;/p&gt;</comment>
                    <comment id="13069504" author="thetaphi" created="Fri, 22 Jul 2011 12:20:23 +0100"  >&lt;blockquote&gt;&lt;p&gt;I think Robert has stated here that he&apos;s comfortable continuing to use TokenStream as the API for IW to get the terms it indexes, is that what others feel too? I agree the inverted API I proposed is a little convoluted and I&apos;m sure we can come up with a simple Consumable like abstraction (which Robert did also suggest above). But if people are content with TokenStream then theres no need.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I feel the same. The API of TokenStream is so stupid-simple, why replace it by another push-like API that is not simplier nor more complicated, just different? I see no reason in this. IW should simply request a TokenStream from the field and consume it.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Likewise, for multi-valued fields, IW shouldn&apos;t &quot;see&quot; the separate&lt;br/&gt;
values; it should just receive a single token stream, and under the&lt;br/&gt;
hood (in Document/Field impl) it&apos;s concatenating separate token&lt;br/&gt;
streams, adding posIncr/offset gaps, etc. This too is now hardwired&lt;br/&gt;
in indexer but shouldn&apos;t be. Maybe an app wants to insert custom&lt;br/&gt;
&quot;separator&quot; tokens between the values...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I agree with that, too. There is one problem with this: Concenatting TokenStreams is not easy to do, as they have different attribute instances, so IW getting all attributes at the start would then somehow in the middle of the TS have to change the attributes.&lt;/p&gt;

&lt;p&gt;To implement this fast (without wrapping and copying), we need some notification that the consumer of a TokenStream needs to &quot;request&quot; the attribute instances again, but this is a &quot;bad&quot; idea. For me the only simple solutions to this problem is to make the Field return an iterator of TokenStreams and IW consumes them one after each other, and doing the addAttribute before each separate instance.&lt;/p&gt;

&lt;p&gt;About the PosIncr Gap: The field can change the final offsets/posIncr in end() before handling over to a new TokenStream. IW would only consume TokenStreams one by one.&lt;/p&gt;</comment>
                    <comment id="13069506" author="cmale" created="Fri, 22 Jul 2011 12:29:24 +0100"  >&lt;blockquote&gt;
&lt;p&gt;I feel the same. The API of TokenStream is so stupid-simple, why replace it by another push-like API that is not simplier nor more complicated, just different? I see no reason in this. IW should simply request a TokenStream from the field and consume it.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;But you do favour a pull-like API as an alternative?&lt;/p&gt;</comment>
                    <comment id="13069510" author="thetaphi" created="Fri, 22 Jul 2011 12:36:09 +0100"  >&lt;blockquote&gt;&lt;p&gt;But you do favour a pull-like API as an alternative?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;TokenStream is pull and I do favour this one.&lt;/p&gt;</comment>
                    <comment id="13069512" author="cmale" created="Fri, 22 Jul 2011 12:41:00 +0100"  >&lt;p&gt;Err yes sorry you&apos;re right.&lt;/p&gt;</comment>
                    <comment id="13069517" author="rcmuir" created="Fri, 22 Jul 2011 13:00:40 +0100"  >&lt;blockquote&gt;
&lt;p&gt;I agree with that, too. There is one problem with this: Concenatting TokenStreams is not easy to do, as they have different attribute instances, so IW getting all attributes at the start would then somehow in the middle of the TS have to change the attributes.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don&apos;t think the attributes should be allowed to change here. This is why above i already said, we should enforce reusability. Then there is no problem.&lt;/p&gt;</comment>
                    <comment id="13112416" author="cmale" created="Thu, 22 Sep 2011 09:47:06 +0100"  >&lt;p&gt;Getting back on this after the Analyzer work.&lt;/p&gt;

&lt;p&gt;New patch is far more traditional and adds tokenStream(Analyzer) to IndexableField.  This replaces tokenStreamValue().  Consumers wishing to index a field now call tokenStream(Analyzer) which is responsible to create the appropriate TokenStream for the field.&lt;/p&gt;</comment>
                    <comment id="13112423" author="thetaphi" created="Thu, 22 Sep 2011 10:02:25 +0100"  >&lt;p&gt;Looks much more straigtforward now. I like this implementation.&lt;/p&gt;</comment>
                    <comment id="13112469" author="simonw" created="Thu, 22 Sep 2011 11:55:19 +0100"  >&lt;blockquote&gt;&lt;p&gt;Looks much more straigtforward now. I like this implementation.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;+1 looks good though. much simpler too!&lt;/p&gt;</comment>
                    <comment id="13112902" author="mikemccand" created="Thu, 22 Sep 2011 21:57:49 +0100"  >&lt;p&gt;This looks great!  I love all the -&apos;d code from DocInverterPerField &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;In Field.java do we already check that if the field is not tokenized then it has a non-null stringValue()?&lt;/p&gt;

&lt;p&gt;I would like to for IW to not have to pass through the Analyzer here (ie FieldType should know the Analyzer for that field), but let&apos;s save that for another issue/time.&lt;/p&gt;

&lt;p&gt;Likewise, multi-valued field should ideally be &quot;under the hood&quot; from IW&apos;s standpoint, ie we should have a MultiValuedField and you append to a List inside it, and then IW gets a single TokenStream from that, which does its own concatenating of the separate TokenStreams, but we should tackle that under a separate issue.&lt;/p&gt;</comment>
                    <comment id="13113117" author="cmale" created="Fri, 23 Sep 2011 03:44:46 +0100"  >&lt;blockquote&gt;&lt;p&gt;In Field.java do we already check that if the field is not tokenized then it has a non-null stringValue()?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don&apos;t think we do.  Its always been implied (which could cause a bug).  I&apos;ll add the appropriate checks but we really need to revisit the constructors of Field at some stage.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I would like to for IW to not have to pass through the Analyzer here (ie FieldType should know the Analyzer for that field), but let&apos;s save that for another issue/time.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I totally agree.  Theoretically FieldType could have Analyzer added to it now and it could make use of it.  But removing the Analyzer from IW seems controversial, alas &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Likewise, multi-valued field should ideally be &quot;under the hood&quot; from IW&apos;s standpoint, ie we should have a MultiValuedField and you append to a List inside it, and then IW gets a single TokenStream from that, which does its own concatenating of the separate TokenStreams, but we should tackle that under a separate issue.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Its nearly possible.  We&apos;ve almost there on the reusable Analyzers.  This can already begin actually for non-tokenized fields and for NumericFields.&lt;/p&gt;

&lt;p&gt;I&apos;ll make the non-null StringValue checks and then commit.&lt;/p&gt;</comment>
                    <comment id="13113127" author="cmale" created="Fri, 23 Sep 2011 04:17:37 +0100"  >&lt;p&gt;Committed revision 1174506.&lt;/p&gt;

&lt;p&gt;I think this issue is wrapped and we can spin the other improvements off?&lt;/p&gt;</comment>
                    <comment id="13113381" author="mikemccand" created="Fri, 23 Sep 2011 13:48:00 +0100"  >&lt;p&gt;Yeah I think we are done here!  Nice work.&lt;/p&gt;</comment>
                    <comment id="13113533" author="cmale" created="Fri, 23 Sep 2011 17:23:29 +0100"  >&lt;p&gt;Change has been committed.  We&apos;ll spin the multiValued fields work off as a separate issue.&lt;/p&gt;</comment>
                </comments>
                    <attachments>
                    <attachment id="12486808" name="LUCENE-2309-analyzer-based.patch" size="13589" author="cmale" created="Mon, 18 Jul 2011 11:14:20 +0100" />
                    <attachment id="12496081" name="LUCENE-2309-getTSFromField.patch" size="19096" author="cmale" created="Thu, 22 Sep 2011 09:47:06 +0100" />
                    <attachment id="12486766" name="LUCENE-2309.patch" size="14174" author="cmale" created="Sun, 17 Jul 2011 14:50:11 +0100" />
                </attachments>
            <subtasks>
        </subtasks>
                <customfields>
                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                <customfieldname>Attachment count</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>3.0</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                <customfieldname>Date of First Response</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>Thu, 11 Mar 2010 18:12:34 +0000</customfieldvalue>

                </customfieldvalues>
            </customfield>
                                                                                                        <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Global Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>3948</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                <customfieldname>Lucene Fields</customfieldname>
                <customfieldvalues>
                        <customfieldvalue key="10121"><![CDATA[New]]></customfieldvalue>
    
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>25416</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                <customfieldname>Time in Status</customfieldname>
                <customfieldvalues>
                    
                </customfieldvalues>
            </customfield>
                            </customfields>
    </item>
</channel>
</rss>