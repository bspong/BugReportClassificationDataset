<!-- 
RSS generated by JIRA (5.2.8#851-sha1:3262fdc28b4bc8b23784e13eadc26a22399f5d88) at Tue Jul 16 13:01:59 UTC 2013

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/LUCENE-510/LUCENE-510.xml?field=key&field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>5.2.8</version>
        <build-number>851</build-number>
        <build-date>26-02-2013</build-date>
    </build-info>

<item>
            <title>[LUCENE-510] IndexOutput.writeString() should write length in bytes</title>
                <link>https://issues.apache.org/jira/browse/LUCENE-510</link>
                <project id="12310110" key="LUCENE">Lucene - Core</project>
                        <description>&lt;p&gt;We should change the format of strings written to indexes so that the length of the string is in bytes, not Java characters.  This issue has been discussed at:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.mail-archive.com/java-dev@lucene.apache.org/msg01970.html&quot; class=&quot;external-link&quot;&gt;http://www.mail-archive.com/java-dev@lucene.apache.org/msg01970.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;We must increment the file format number to indicate this change.  At least the format number in the segments file should change.&lt;/p&gt;

&lt;p&gt;I&apos;m targetting this for 2.1, i.e., we shouldn&apos;t commit it to trunk until after 2.0 is released, to minimize incompatible changes between 1.9 and 2.0 (other than removal of deprecated features).&lt;/p&gt;</description>
                <environment></environment>
            <key id="12329686">LUCENE-510</key>
            <summary>IndexOutput.writeString() should write length in bytes</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                    <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png">Closed</status>
                    <resolution id="1">Fixed</resolution>
                                <assignee username="mikemccand">Michael McCandless</assignee>
                                <reporter username="cutting">Doug Cutting</reporter>
                        <labels>
                    </labels>
                <created>Fri, 3 Mar 2006 03:30:51 +0000</created>
                <updated>Sat, 11 Oct 2008 13:49:33 +0100</updated>
                    <resolved>Fri, 9 May 2008 13:05:06 +0100</resolved>
                            <version>2.1</version>
                                <fixVersion>2.4</fixVersion>
                                <component>core/store</component>
                        <due></due>
                    <votes>5</votes>
                        <watches>3</watches>
                                                    <comments>
                    <comment id="12368562" author="cutting" created="Fri, 3 Mar 2006 03:32:00 +0000"  >&lt;p&gt;Link to &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-510&quot; title=&quot;IndexOutput.writeString() should write length in bytes&quot;&gt;&lt;del&gt;LUCENE-510&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                    <comment id="12378519" author="creamyg" created="Tue, 9 May 2006 05:02:36 +0100"  >&lt;p&gt;The following patch...&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Changes Lucene to use bytecounts as the prefix to all written Strings&lt;/li&gt;
	&lt;li&gt;Changes Lucene to write standard UTF-8 rather than Modified UTF-8&lt;/li&gt;
	&lt;li&gt;Adds the new test classes MockIndexOutput and TestIndexOutput&lt;/li&gt;
	&lt;li&gt;Increases the number of tests in TestIndexInput&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;It also slows Lucene down &amp;#8211; indexing takes around a 20% speed hit.  It would be possible to submit a patch which had a smaller impact on performance, but this one is already over 700 lines long, and it&apos;s goal is to achieve standard UTF-8 compliance and modify the definition of Lucene strings as simply and reliably as possible.  Optimization patches can now be submitted which build upon this one.&lt;/p&gt;

&lt;p&gt;Marvin Humphrey&lt;br/&gt;
Rectangular Research&lt;br/&gt;
&lt;a href=&quot;http://www.rectangular.com/&quot; class=&quot;external-link&quot;&gt;http://www.rectangular.com/&lt;/a&gt;&lt;/p&gt;
</comment>
                    <comment id="12414678" author="creamyg" created="Mon, 5 Jun 2006 09:54:50 +0100"  >&lt;p&gt;Greets,&lt;/p&gt;

&lt;p&gt;I&apos;ve ported KinoSearch&apos;s external sorting module to java, along with its tests.  This class is the linchpin for the KinoSearch merge model, as it allows serialized postings to be dumped into a sort pool of effectively unlimited size.&lt;/p&gt;

&lt;p&gt;At some point, I&apos;ll submit patches implementing the KinoSearch merge model in Lucene.  I&apos;m reasonably confident that it will more than make up for the index-time performance hit caused by using bytecounts as string headers.&lt;/p&gt;

&lt;p&gt;Thematically, this class belongs in org.apache.lucene.util, and that&apos;s where I&apos;ve put it for now.  The classes that will use it are in org.apache.lucene.index, so if it stays in util, it will have to be public.  However, it shouldn&apos;t be part of Lucene&apos;s documented public API.  The process by which Lucene&apos;s docs are generated is not clear to me, so access control advice would be appreciated.&lt;/p&gt;

&lt;p&gt;There are a number of other areas where this code could stand review, especially considering my relatively limited experience using Java.  I&apos;d single out exception handling and thread safety, but of course anything else is fair game.&lt;/p&gt;

&lt;p&gt;Marvin Humphrey&lt;br/&gt;
Rectangular Research&lt;br/&gt;
&lt;a href=&quot;http://www.rectangular.com/&quot; class=&quot;external-link&quot;&gt;http://www.rectangular.com/&lt;/a&gt;&lt;/p&gt;</comment>
                    <comment id="12462114" author="gsingers" created="Thu, 4 Jan 2007 02:05:40 +0000"  >&lt;p&gt;Hi Marvin,&lt;/p&gt;

&lt;p&gt;This no longer applies cleanly to trunk, care to update? &lt;/p&gt;

&lt;p&gt;Thanks,&lt;br/&gt;
Grant&lt;/p&gt;</comment>
                    <comment id="12462122" author="manawiz" created="Thu, 4 Jan 2007 03:15:49 +0000"  >&lt;p&gt;Has an improvement been made to eliminate the reported 20% indexing hit?  That would be a big price to pay.&lt;/p&gt;

&lt;p&gt;To me the performance benefits in algorithms that scan for selected fields (e.g., FieldsReader.doc() with a FieldSelector) are much more important than standard UTF-8 compliance.&lt;/p&gt;

&lt;p&gt;A 20% hit seems suprising.  The pre-scan over the string to be written shouldn&apos;t cost much compared to the cost of tokenizing and indeixng that string (assuming it is in an indexed field).&lt;/p&gt;

&lt;p&gt;In case it is relevant, I had a related issue in my bulk updater, a case where a vint required at the beginning of a record by the lucene index format was not known until after the end.  I solved this with a fixed length vint record that was estimated up front and revised if necessary after the whole record was processed.  The vint representation still works if more bytes than necessary are written.&lt;/p&gt;</comment>
                    <comment id="12462138" author="yseeley@gmail.com" created="Thu, 4 Jan 2007 05:46:13 +0000"  >&lt;p&gt;I&apos;d like to see everything kept as bytes for as long as possible (right up into Term).&lt;br/&gt;
A nice bonus would be to reduce the size of things like the FieldCache, and to allow true binary data.&lt;/p&gt;</comment>
                    <comment id="12462285" author="creamyg" created="Thu, 4 Jan 2007 19:01:43 +0000"  >&lt;p&gt;Grant... At the moment I am completely consumed by the task of getting a devel release of KinoSearch version 0.20 out the door.  Once that is taken care of, I will be glad to update this patch, and to explore how to compensate for the performance hit it causes.&lt;/p&gt;

&lt;p&gt;Chuck... If bytecount-based strings are adopted, standard UTF-8 probably comes along for the ride.  There&apos;s actually a 1-2% performance gain to be had using standard over modified because of simplified conditionals.  What holds us back is backwards compatibility &amp;#8211; but we&apos;ll have wrecked backwards compat with the bytecounts.  However, I no longer have a strong objection to using Modified UTF-8 (for Lucene, that is &amp;#8211; Modified UTF-8 would be a deal-breaker for Lucy), so if somewhere along the way we find a compelling reason to stick with modified UTF-8, so be it.&lt;/p&gt;

&lt;p&gt;If bytecount-based strings get adopted, it will be because they hold up on their own merits.  They&apos;re required for KinoSearch merge model; once KS 0.20 is out, I&apos;ll port the new benchmarking stuff, we can study the numbers, and assess whether the significant effort needed to pry that algo into Lucene would be worthwhile.&lt;/p&gt;

&lt;p&gt;Yonik... yes, I agree.  Even better for indexing time, leave postings in serialized form for the entire indexing session.  &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="12500762" author="gsingers" created="Fri, 1 Jun 2007 18:07:37 +0100"  >&lt;p&gt;I don&apos;t have time at the moment&lt;/p&gt;</comment>
                    <comment id="12557937" author="michaelbusch" created="Fri, 11 Jan 2008 09:07:22 +0000"  >&lt;p&gt;I think it makes total sense to change this. And this issue seems to be&lt;br/&gt;
very popular with 5 votes.&lt;/p&gt;

&lt;p&gt;Mike, you&apos;ve done so much performance &amp;amp; indexing work recently. Are&lt;br/&gt;
you interested in taking this?&lt;/p&gt;</comment>
                    <comment id="12557953" author="mikemccand" created="Fri, 11 Jan 2008 10:03:23 +0000"  >&lt;p&gt;Yup, I&apos;ll take this!&lt;/p&gt;</comment>
                    <comment id="12575138" author="mikemccand" created="Tue, 4 Mar 2008 20:55:49 +0000"  >&lt;p&gt;Attached patch.&lt;/p&gt;

&lt;p&gt;I modernized Marvin&apos;s original patch and added full backwards&lt;br/&gt;
compatibility to it so that old indices can be opened for reading or&lt;br/&gt;
writing.  New segments are written in the new format.&lt;/p&gt;

&lt;p&gt;All tests pass.  I think it&apos;s close, but, I need to run performance&lt;br/&gt;
tests now to measure the impact to indexing throughput.&lt;/p&gt;

&lt;p&gt;I think future optimizations can keep the byte[] further, eg, into&lt;br/&gt;
Term and FieldCache, as Yonik mentioned.  We could also fix&lt;br/&gt;
DocumentsWriter to use byte[] for its terms storage which would&lt;br/&gt;
improve RAM efficiency for single-byte (ascii) content.&lt;/p&gt;

&lt;p&gt;I also updated the TestBackwardsCompatibility testcase to properly&lt;br/&gt;
test non-ascii terms.&lt;/p&gt;
</comment>
                    <comment id="12576205" author="gsingers" created="Fri, 7 Mar 2008 14:09:38 +0000"  >&lt;p&gt;So, with this we should be able to skip ahead in the FieldsReader, right?  I will try to update your patch with that.  Should improve lazy loading, etc.&lt;/p&gt;</comment>
                    <comment id="12576256" author="mikemccand" created="Fri, 7 Mar 2008 16:10:15 +0000"  >&lt;p&gt;Yes, exactly.  But I think the current patch is already doing this? &amp;#8211; ie, using seek instead of skipChars, if the fdt is new.&lt;/p&gt;</comment>
                    <comment id="12576316" author="gsingers" created="Fri, 7 Mar 2008 18:23:47 +0000"  >&lt;p&gt;Cool.  I just downloaded and applied, but hadn&apos;t looked at it yet.  &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="12579577" author="mikemccand" created="Mon, 17 Mar 2008 20:04:12 +0000"  >&lt;p&gt;New rev of the patch.  I think it&apos;s ready to commit.  I&apos;ll wait a few&lt;br/&gt;
days.&lt;/p&gt;

&lt;p&gt;I made some performance improvements by factoring out a new&lt;br/&gt;
UnicodeUtil class that does not allocate new objects for every&lt;br/&gt;
conversion to/from UTF8.&lt;/p&gt;

&lt;p&gt;One new issue I fixed is the handling of invalid UTF-16 strings.&lt;br/&gt;
Specifically if the UTF16 text has invalid surrogate pairs, UTF-8 is&lt;br/&gt;
unable to represent it (unlike the current modified UTF-8 Lucene&lt;br/&gt;
format).  I changed DocumentsWriter &amp;amp; UnicodeUtil to substitute the&lt;br/&gt;
replacement char U+FFFD for such invalid surrogate characters.  This&lt;br/&gt;
affects terms, stored String fields and term vectors.&lt;/p&gt;

&lt;p&gt;Indexing performance has a small slowdown (3.5%); details are below.&lt;/p&gt;

&lt;p&gt;Unfortunately, time to enumerate terms was more affected.  I made a&lt;br/&gt;
simple test that enumerates all terms from the index (= ~3.3 million&lt;br/&gt;
terms) created below:&lt;/p&gt;

&lt;p&gt;  public class TestTermEnum {&lt;br/&gt;
    public static void main(String[] args) throws Exception &lt;/p&gt;
{
      IndexReader r = IndexReader.open(args[0]);
      TermEnum terms = r.terms();
      int count = 0;
      long t0 = System.currentTimeMillis();
      while(terms.next())
        count++;
      long t1 = System.currentTimeMillis();
      System.out.println(count + &quot; terms in &quot; + (t1-t0) + &quot; millis&quot;);
      r.close();
    }
&lt;p&gt;  }&lt;/p&gt;

&lt;p&gt;On trunk with current index format this takes 3104 msec (best of 5).&lt;br/&gt;
With the patch with UTF8 index format it takes 3443 msec = 10.9%&lt;br/&gt;
slower.  I don&apos;t see any further ways to make this faster.&lt;/p&gt;

&lt;p&gt;Details on the indexing performance test:&lt;/p&gt;

&lt;p&gt;  analyzer=org.apache.lucene.analysis.standard.StandardAnalyzer&lt;/p&gt;

&lt;p&gt;  doc.maker=org.apache.lucene.benchmark.byTask.feeds.LineDocMaker&lt;/p&gt;

&lt;p&gt;  docs.file=/Volumes/External/lucene/wiki.txt&lt;br/&gt;
  doc.stored = true&lt;br/&gt;
  doc.term.vector = true&lt;br/&gt;
  doc.add.log.step=2000&lt;/p&gt;

&lt;p&gt;  directory=FSDirectory&lt;br/&gt;
  autocommit=false&lt;br/&gt;
  compound=false&lt;/p&gt;

&lt;p&gt;  ram.flush.mb=64&lt;/p&gt;

&lt;p&gt;  { &quot;Rounds&quot;&lt;br/&gt;
    ResetSystemErase&lt;br/&gt;
    { &quot;BuildIndex&quot;&lt;br/&gt;
      CreateIndex&lt;/p&gt;
      { &quot;AddDocs&quot; AddDoc &amp;gt; : 200000
      - CloseIndex
    }
&lt;p&gt;    NewRound&lt;br/&gt;
  } : 5&lt;/p&gt;

&lt;p&gt;  RepSumByPrefRound BuildIndex&lt;/p&gt;

&lt;p&gt;I ran it on a quad-core Intel Mac Pro, with 4 drive RAID 0 array,&lt;br/&gt;
running OS 10.4.11, java 1.5, run with these command-line args:&lt;/p&gt;

&lt;p&gt;  -server -Xbatch -Xms1024m -Xmx1024m&lt;/p&gt;

&lt;p&gt;Best of 5 with current trunk is 921.2 docs/sec and with patch it&apos;s&lt;br/&gt;
888.7 = 3.5% slowdown.&lt;/p&gt;
</comment>
                    <comment id="12579708" author="kawai" created="Tue, 18 Mar 2008 02:28:19 +0000"  >&lt;p&gt;I&apos;m wondering why the patch doesn&apos;t utilize java.nio.charset.CharsetEncoder, CharsetDecoder....?&lt;/p&gt;</comment>
                    <comment id="12580592" author="mikemccand" created="Wed, 19 Mar 2008 22:39:40 +0000"  >&lt;blockquote&gt;
&lt;p&gt;I&apos;m wondering why the patch doesn&apos;t utilize java.nio.charset.CharsetEncoder, CharsetDecoder....?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think there are two reasons for rolling our own instead of using&lt;br/&gt;
CharsetEncoder/Decoder.  First is performance.  If I use&lt;br/&gt;
CharsetEncoder, like this:&lt;/p&gt;

&lt;p&gt;  CharsetEncoder encoder = Charset.forName(&quot;UTF-8&quot;).newEncoder();&lt;br/&gt;
  CharBuffer cb = CharBuffer.allocate(5000);&lt;br/&gt;
  ByteBuffer bb = ByteBuffer.allocate(5000);&lt;br/&gt;
  byte[] bbArray = bb.array();&lt;br/&gt;
  UnicodeUtil.UTF8Result utf8Result = new UnicodeUtil.UTF8Result();&lt;/p&gt;

&lt;p&gt;  t0 = System.currentTimeMillis();&lt;br/&gt;
  for(int i=0;i&amp;lt;count;i++) &lt;/p&gt;
{
    cb.clear();
    cb.put(strings[i]);
    cb.flip();
    bb.clear();
    encoder.reset();
    encoder.encode(cb, bb, true);
  }

&lt;p&gt;Then it takes 676 msec to convert ~3.3 million strings from the terms&lt;br/&gt;
from indexing first 200K Wikipedia docs.  If I replace for loop with:&lt;/p&gt;

&lt;p&gt;  UnicodeUtil.UTF16toUTF8(strings&lt;span class=&quot;error&quot;&gt;&amp;#91;i&amp;#93;&lt;/span&gt;, 0, strings&lt;span class=&quot;error&quot;&gt;&amp;#91;i&amp;#93;&lt;/span&gt;.length(), utf8Result);&lt;/p&gt;

&lt;p&gt;It&apos;s 441 msec.&lt;/p&gt;

&lt;p&gt;Second reason is some API mismatch.  EG we need to convert char[] that&lt;br/&gt;
end in the 0xffff character.  Also, we need to do incremental&lt;br/&gt;
conversion (only convert changed bytes), which is used by TermEnum.&lt;br/&gt;
CharsetEncoder/Decoder doesn&apos;t do this.&lt;/p&gt;
</comment>
                    <comment id="12580739" author="kawai" created="Thu, 20 Mar 2008 12:43:47 +0000"  >&lt;p&gt;To the first reason of performance issue,&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;CharsetEncoder encoder = Charset.forName(&quot;UTF-8&quot;).newEncoder();&lt;br/&gt;
CharBuffer cb = CharBuffer.allocate(5000);&lt;br/&gt;
ByteBuffer bb = ByteBuffer.allocate(5000);&lt;br/&gt;
byte[] bbArray = bb.array();&lt;br/&gt;
UnicodeUtil.UTF8Result utf8Result = new UnicodeUtil.UTF8Result();&lt;/p&gt;

&lt;p&gt;t0 = System.currentTimeMillis();&lt;br/&gt;
for(int i=0;i&amp;lt;count;i++) &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: { cb.clear(); cb.put(strings[i]); cb.flip(); bb.clear(); encoder.reset(); encoder.encode(cb, bb, true); }&lt;/span&gt; &lt;/div&gt;&lt;/blockquote&gt;

&lt;p&gt;How about this code?&lt;/p&gt;

&lt;p&gt;CharsetEncoder encoder = Charset.forName(&quot;UTF-8&quot;).newEncoder();&lt;br/&gt;
CharBuffer cb;&lt;br/&gt;
ByteBuffer bb = ByteBuffer.allocate(5000);&lt;br/&gt;
byte[] bbArray = bb.array();&lt;br/&gt;
UnicodeUtil.UTF8Result utf8Result = new UnicodeUtil.UTF8Result();&lt;/p&gt;

&lt;p&gt;t0 = System.currentTimeMillis();&lt;br/&gt;
for(int i=0;i&amp;lt;count;i++) {&lt;br/&gt;
  bb.clear();&lt;br/&gt;
  encoder.reset();&lt;br/&gt;
  encoder.encode(CharBuffer.wrap(strings&lt;span class=&quot;error&quot;&gt;&amp;#91;i&amp;#93;&lt;/span&gt;), bb, true); &lt;br/&gt;
}&lt;/p&gt;
</comment>
                    <comment id="12580768" author="mikemccand" created="Thu, 20 Mar 2008 13:49:41 +0000"  >&lt;p&gt;That version takes 1067 msec (best of 3).&lt;/p&gt;</comment>
                    <comment id="12580797" author="kawai" created="Thu, 20 Mar 2008 15:41:53 +0000"  >&lt;p&gt;Ah interesting !&lt;/p&gt;

&lt;p&gt;I&apos;m not tried yet, but...&lt;/p&gt;

&lt;p&gt;CharBuffer cb = ByteBuffer.allocateDirect(5000).asCharBuffer();&lt;br/&gt;
ByteBuffer bb = ByteBuffer.allocateDirect(5000);&lt;/p&gt;

&lt;p&gt;will improve the performance.&lt;/p&gt;</comment>
                    <comment id="12580820" author="kawai" created="Thu, 20 Mar 2008 16:11:47 +0000"  >&lt;blockquote&gt;
&lt;p&gt;Second reason is some API mismatch. EG we need to convert char[] that&lt;br/&gt;
end in the 0xffff character. Also, we need to do incremental&lt;br/&gt;
conversion (only convert changed bytes), which is used by TermEnum.&lt;br/&gt;
CharsetEncoder/Decoder doesn&apos;t do this.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;IMHO, the char 0xffff is not telling that the string is the end. The marker is not to be used to dermine the termination, but is for assertion, I think (in DocumentsWriterThreadState.java). And we should rewrite DocumentsWriterFieldMergeState.java to provide &quot;private int postingUpto&quot; outside via public method, to use it in DocumentsWriter.java and DocumentsWriterField.java.&lt;/p&gt;</comment>
                    <comment id="12580828" author="mikemccand" created="Thu, 20 Mar 2008 16:18:02 +0000"  >&lt;p&gt;Using allocateDirect is surprisingly slower: 1050 msec.&lt;/p&gt;</comment>
                    <comment id="12580831" author="mikemccand" created="Thu, 20 Mar 2008 16:25:00 +0000"  >&lt;blockquote&gt;
&lt;p&gt;IMHO, the char 0xffff is not telling that the string is the end. The marker is not to be used to dermine the termination, but is for assertion, I think (in DocumentsWriterThreadState.java). &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The 0xffff is used for more than assertion.  It marks the end of the text for each term.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;And we should rewrite DocumentsWriterFieldMergeState.java to provide &quot;private int postingUpto&quot; outside via public method, to use it in DocumentsWriter.java and DocumentsWriterField.java.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The &quot;private int postingUpto&quot; in DocumentsWriterFieldMergeState is very different from the usage of 0xffff marker; I&apos;m not sure what you&apos;re suggesting here?&lt;/p&gt;</comment>
                    <comment id="12580846" author="kawai" created="Thu, 20 Mar 2008 16:58:46 +0000"  >&lt;p&gt;I&apos;m sorry I mistook something in DocumentsWriterFieldMergeState.java.&lt;/p&gt;

&lt;p&gt;But, my suggestion here, is use 0xffff only for assertion.&lt;/p&gt;

&lt;p&gt;To achive this, we should add textLength property to DocumentsWriterFieldMergeState and use it in DocumentsWriter.java, modify DocumentsWriter#compareText.&lt;/p&gt;

&lt;p&gt;I&apos;ll submit a patch.&lt;/p&gt;</comment>
                    <comment id="12580860" author="mikemccand" created="Thu, 20 Mar 2008 17:21:43 +0000"  >&lt;p&gt;OK.  Can you open a separate issue for that?&lt;/p&gt;</comment>
                    <comment id="12580868" author="kawai" created="Thu, 20 Mar 2008 17:34:09 +0000"  >&lt;p&gt;OK. I&apos;ll open another ticket. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;I&apos;ll try measuring the performance, too. I still believe that we should use java.nio.charset for our code maintainance.&lt;/p&gt;</comment>
                    <comment id="12580869" author="mikemccand" created="Thu, 20 Mar 2008 17:40:48 +0000"  >&lt;p&gt;I think using java.nio.charset is too much of a performance hit.  I think it will especially further slow down enumerating terms since we can&apos;t convert the characters incrementally if we use java.nio.charset.&lt;/p&gt;</comment>
                    <comment id="12580985" author="kawai" created="Fri, 21 Mar 2008 02:11:23 +0000"  >&lt;p&gt;I think performance issue is yet another issue, and I believe we can find the way to speed up.&lt;/p&gt;</comment>
                    <comment id="12595426" author="markrmiller@gmail.com" created="Fri, 9 May 2008 00:43:29 +0100"  >&lt;p&gt;I suspect that this issue is not reading old indexes perfectly. I am very suspicious that this patch caused what I thought was index corruption the other day. I didn&apos;t notice it was a format change and should have paid more attention.&lt;/p&gt;

&lt;p&gt;I seem to be able to replicate the issue so hopefully I will have more to report soon.&lt;/p&gt;

&lt;p&gt;If my thoughts are unlikely, please let me know.&lt;/p&gt;</comment>
                    <comment id="12595526" author="mikemccand" created="Fri, 9 May 2008 10:59:25 +0100"  >&lt;p&gt;Whoa, I think you are correct Mark!&lt;/p&gt;

&lt;p&gt;On inspecting my changes here, I think the bulk-merging of stored fields is to blame.  Specifically, when we bulk merge the stored fields we fail to check whether the segments being merged are the pre-UTF8 format.  And so that code bulk-copies stored fields in the older format into a file that claims it&apos;s using the newer format.&lt;/p&gt;

&lt;p&gt;This only affects trunk, not 2.3.&lt;/p&gt;

&lt;p&gt;Thanks for being such a brave early-adopter trunk tester, Mark.  And, sorry &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="12595559" author="markrmiller@gmail.com" created="Fri, 9 May 2008 12:15:03 +0100"  >&lt;p&gt;No problem Michael. Brave/Foolish, I certainly am one. Can&apos;t keep myself away from these fresh issues &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; My fault for not understanding the release process really though. I thought I was roughly getting 2.3.2 ahead of time. Live and learn &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; I got a little lax inspecting all the issues for someone grabbing from trunk...once all my tests pass I usually feel pretty good about it. Time to add some upgrade index tests &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;Thanks so much for checking into this so quick - certainly saves me some time today.&lt;/p&gt;
</comment>
                    <comment id="12595565" author="mikemccand" created="Fri, 9 May 2008 12:28:07 +0100"  >&lt;blockquote&gt;&lt;p&gt;Time to add some upgrade index tests&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;In fact Lucene already has TestBackwardsCompatibility ... so my first step is to add a test case there that shows this bug...&lt;/p&gt;</comment>
                    <comment id="12595575" author="mikemccand" created="Fri, 9 May 2008 13:04:18 +0100"  >&lt;p&gt;OK, I&apos;ve fixed TestBackwardsCompatibility to catch this, and then fixed merging of stored fields to work properly.  Will commit shortly...&lt;/p&gt;

&lt;p&gt;Thanks again Mark!&lt;/p&gt;</comment>
                </comments>
                <issuelinks>
                        <issuelinktype id="10030">
                <name>Reference</name>
                                <outwardlinks description="relates to">
                            <issuelink>
            <issuekey id="12329682">LUCENE-509</issuekey>
        </issuelink>
                    </outwardlinks>
                                                <inwardlinks description="is related to">
                            <issuelink>
            <issuekey id="12344354">HADOOP-302</issuekey>
        </issuelink>
                    </inwardlinks>
                            </issuelinktype>
                    </issuelinks>
                <attachments>
                    <attachment id="12377123" name="LUCENE-510.patch" size="51869" author="mikemccand" created="Tue, 4 Mar 2008 20:55:49 +0000" />
                    <attachment id="12378068" name="LUCENE-510.take2.patch" size="122886" author="mikemccand" created="Mon, 17 Mar 2008 20:04:12 +0000" />
                    <attachment id="12335016" name="SortExternal.java" size="15247" author="creamyg" created="Mon, 5 Jun 2006 09:54:50 +0100" />
                    <attachment id="12326413" name="strings.diff" size="27207" author="creamyg" created="Tue, 9 May 2006 05:04:08 +0100" />
                    <attachment id="12335017" name="TestSortExternal.java" size="5751" author="creamyg" created="Mon, 5 Jun 2006 09:54:50 +0100" />
                </attachments>
            <subtasks>
        </subtasks>
                <customfields>
                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                <customfieldname>Attachment count</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>5.0</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                <customfieldname>Date of First Response</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>Tue, 9 May 2006 04:02:36 +0000</customfieldvalue>

                </customfieldvalues>
            </customfield>
                                                                                                        <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Global Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>13240</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>27217</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                <customfieldname>Time in Status</customfieldname>
                <customfieldvalues>
                    
                </customfieldvalues>
            </customfield>
                            </customfields>
    </item>
</channel>
</rss>