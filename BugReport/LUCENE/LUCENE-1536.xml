<!-- 
RSS generated by JIRA (5.2.8#851-sha1:3262fdc28b4bc8b23784e13eadc26a22399f5d88) at Tue Jul 16 13:14:12 UTC 2013

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/LUCENE-1536/LUCENE-1536.xml?field=key&field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>5.2.8</version>
        <build-number>851</build-number>
        <build-date>26-02-2013</build-date>
    </build-info>

<item>
            <title>[LUCENE-1536] if a filter can support random access API, we should use it</title>
                <link>https://issues.apache.org/jira/browse/LUCENE-1536</link>
                <project id="12310110" key="LUCENE">Lucene - Core</project>
                        <description>&lt;p&gt;I ran some performance tests, comparing applying a filter via&lt;br/&gt;
random-access API instead of current trunk&apos;s iterator API.&lt;/p&gt;

&lt;p&gt;This was inspired by &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1476&quot; title=&quot;BitVector implement DocIdSet, IndexReader returns DocIdSet deleted docs&quot;&gt;&lt;del&gt;LUCENE-1476&lt;/del&gt;&lt;/a&gt;, where we realized deletions should&lt;br/&gt;
really be implemented just like a filter, but then in testing found&lt;br/&gt;
that switching deletions to iterator was a very sizable performance&lt;br/&gt;
hit.&lt;/p&gt;

&lt;p&gt;Some notes on the test:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Index is first 2M docs of Wikipedia.  Test machine is Mac OS X&lt;br/&gt;
    10.5.6, quad core Intel CPU, 6 GB RAM, java 1.6.0_07-b06-153.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;I test across multiple queries.  1-X means an OR query, eg 1-4&lt;br/&gt;
    means 1 OR 2 OR 3 OR 4, whereas +1-4 is an AND query, ie 1 AND 2&lt;br/&gt;
    AND 3 AND 4.  &quot;u s&quot; means &quot;united states&quot; (phrase search).&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;I test with multiple filter densities (0, 1, 2, 5, 10, 25, 75, 90,&lt;br/&gt;
    95, 98, 99, 99.99999 (filter is non-null but all bits are set),&lt;br/&gt;
    100 (filter=null, control)).&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Method high means I use random-access filter API in&lt;br/&gt;
    IndexSearcher&apos;s main loop.  Method low means I use random-access&lt;br/&gt;
    filter API down in SegmentTermDocs (just like deleted docs&lt;br/&gt;
    today).&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Baseline (QPS) is current trunk, where filter is applied as iterator up&lt;br/&gt;
    &quot;high&quot; (ie in IndexSearcher&apos;s search loop).&lt;/li&gt;
&lt;/ul&gt;
</description>
                <environment></environment>
            <key id="12414034">LUCENE-1536</key>
            <summary>if a filter can support random access API, we should use it</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                    <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png">Closed</status>
                    <resolution id="1">Fixed</resolution>
                                <assignee username="thetaphi">Uwe Schindler</assignee>
                                <reporter username="mikemccand">Michael McCandless</reporter>
                        <labels>
                        <label>gsoc2011</label>
                        <label>lucene-gsoc-11</label>
                        <label>mentor</label>
                    </labels>
                <created>Wed, 4 Feb 2009 20:29:49 +0000</created>
                <updated>Fri, 10 May 2013 11:43:02 +0100</updated>
                    <resolved>Tue, 25 Oct 2011 13:09:38 +0100</resolved>
                            <version>2.4</version>
                                <fixVersion>4.0-ALPHA</fixVersion>
                                <component>core/search</component>
                        <due></due>
                    <votes>2</votes>
                        <watches>4</watches>
                                                    <comments>
                    <comment id="12670449" author="mikemccand" created="Wed, 4 Feb 2009 20:30:14 +0000"  >&lt;p&gt;Test results:&lt;/p&gt;

&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;%tg Filter&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Query&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Method&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Hits&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;QPS&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;QPSNew&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;%tg change&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;      0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;18992.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 142.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;-99.2%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;      0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;18992.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 109.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;-99.4%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   3863&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 133.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 135.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  1.2%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   3863&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 133.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  99.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;-25.4%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   7714&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 108.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 133.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 23.6%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   7714&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 108.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 100.5&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; -7.1%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  19333&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  76.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 128.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 67.2%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  19333&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  76.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  97.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 26.4%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  38673&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  62.5&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 119.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 90.6%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  38673&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  62.5&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  92.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 47.2%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;25%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  96670&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  47.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 102.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;116.3%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;25%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  96670&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  47.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  90.5&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 91.3%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;50%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 193098&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  40.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  85.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;114.0%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;50%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 193098&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  40.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  79.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 99.0%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;75%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 289765&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  38.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  82.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;117.9%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;75%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 289765&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  38.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  79.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;107.9%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;90%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 347762&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  37.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  82.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;122.3%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;90%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 347762&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  37.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  72.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 95.7%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;95%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 367102&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  36.5&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  82.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;127.1%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;95%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 367102&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  36.5&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  73.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;100.3%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;98%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 378721&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  37.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  81.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;119.3%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;98%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 378721&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  37.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  73.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 95.7%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;99%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 382572&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  36.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  83.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;127.6%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;99%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 382572&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  36.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  71.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 96.2%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;99.99999%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 386435&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  38.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  83.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;120.5%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;99.99999%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 386435&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  38.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  70.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 86.6%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;100%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 386435&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  88.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  89.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  1.2%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;100%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 386435&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  88.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  89.5&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  1.7%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;      0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;18808.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  71.5&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;-99.6%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;      0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;18808.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  22.4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;-99.9%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5363&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  46.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  65.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 39.3%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5363&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  46.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  22.5&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;-51.9%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  10675&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  37.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  61.4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 63.3%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  10675&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  37.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  22.4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;-40.4%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  26880&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  28.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  53.4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 85.4%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  26880&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  28.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  22.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;-22.6%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  53673&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  23.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  48.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;103.0%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  53673&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  23.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  21.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; -8.0%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;25%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 133988&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  19.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  37.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 86.9%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;25%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 133988&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  19.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  21.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  5.5%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;50%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 267757&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  17.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  27.4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 59.3%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;50%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 267757&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  17.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  20.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 18.0%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;75%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 401596&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  16.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  23.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 36.7%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;75%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 401596&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  16.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  20.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 20.1%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;90%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 481911&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  17.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  21.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 24.7%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;90%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 481911&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  17.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  20.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 21.2%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;95%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 508704&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  17.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  20.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 21.1%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;95%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 508704&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  17.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  20.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 21.1%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;98%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 524909&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  17.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  20.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 19.7%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;98%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 524909&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  17.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  20.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 19.7%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;99%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 530221&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  17.4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  20.5&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 17.8%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;99%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 530221&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  17.4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  20.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 19.5%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;99.99999%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 535584&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  17.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  20.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 18.7%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;99.99999%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 535584&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  17.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  20.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 18.7%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;100%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 535584&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  21.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  20.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; -1.4%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;100%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 535584&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  21.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  20.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; -1.0%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;      0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;17961.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  42.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;-99.8%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;      0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;17961.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  11.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;-99.9%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   6544&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  27.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  38.4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 41.7%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   6544&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  27.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  12.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;-55.7%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  13062&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  21.4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  36.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 68.2%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  13062&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  21.4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  11.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;-44.4%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  32815&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  16.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  31.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 94.4%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  32815&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  16.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  11.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;-26.7%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  65491&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  13.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  27.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;109.0%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  65491&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  13.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  11.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;-12.0%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;25%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 163600&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  10.5&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  21.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;100.0%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;25%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 163600&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  10.5&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  11.5&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  9.5%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;50%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 327302&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   9.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  15.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 54.5%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;50%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 327302&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   9.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  11.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 13.1%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;75%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 490881&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   9.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  12.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 29.9%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;75%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 490881&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   9.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  11.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 14.4%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;90%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 588990&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   9.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  11.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 20.8%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;90%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 588990&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   9.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  11.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 15.6%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;95%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 621666&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   9.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  11.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 17.7%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;95%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 621666&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   9.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  11.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 16.7%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;98%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 641419&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   9.4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  11.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 18.1%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;98%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 641419&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   9.4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  11.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 19.1%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;99%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 647937&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   9.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  11.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 13.3%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;99%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 647937&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   9.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  11.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 14.3%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;99.99999%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 654481&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  10.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  11.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 11.0%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;99.99999%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 654481&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  10.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  11.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 12.0%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;100%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 654481&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  11.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  11.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  0.0%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;100%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 654481&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  11.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  11.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; -0.9%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;      0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;15990.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  22.5&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;-99.9%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;      0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;15990.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;-100.0%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   8406&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  13.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  20.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 54.2%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   8406&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  13.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;-55.7%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  16756&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  10.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  18.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 85.3%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  16756&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  10.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;-43.1%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  41937&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   7.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  16.5&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;114.3%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  41937&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   7.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;-26.0%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  83828&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   6.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  14.5&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;130.2%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  83828&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   6.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; -9.5%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;25%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 209328&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  10.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;105.7%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;25%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 209328&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  7.5%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;50%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 418668&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   4.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   7.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 59.2%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;50%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 418668&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   4.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5.5&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 12.2%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;75%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 628338&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   4.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   6.4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 30.6%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;75%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 628338&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   4.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5.5&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 12.2%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;90%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 753838&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   4.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 20.4%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;90%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 753838&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   4.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5.5&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 12.2%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;95%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 795729&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 14.0%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;95%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 795729&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 12.0%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;98%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 820910&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  9.8%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;98%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 820910&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  9.8%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;99%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 829260&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  9.8%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;99%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 829260&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  9.8%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;99.99999%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 837666&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  7.7%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;99.99999%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 837666&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  7.7%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;100%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 837666&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  0.0%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;100%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 837666&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; -1.8%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;      0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;18848.4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 138.4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;-99.3%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;      0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;18848.4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  27.4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;-99.9%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   2308&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  63.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  77.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 22.0%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   2308&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  63.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  27.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;-57.1%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   4621&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  50.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  69.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 38.6%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   4621&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  50.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  26.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;-46.7%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  11706&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  36.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  56.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 57.6%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  11706&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  36.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  26.5&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;-26.6%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  23272&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  28.4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  48.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 71.1%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  23272&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  28.4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  26.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; -7.7%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;25%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  58401&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  23.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  36.4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 53.6%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;25%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  58401&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  23.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  24.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  5.1%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;50%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 117083&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  20.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  28.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 34.9%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;50%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 117083&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  20.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  23.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 14.4%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;75%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 176233&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  19.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  24.4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 26.4%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;75%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 176233&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  19.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  22.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 18.1%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;90%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 211362&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  18.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  22.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 23.1%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;90%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 211362&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  18.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  22.5&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 21.0%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;95%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 222928&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  18.5&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  22.5&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 21.6%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;95%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 222928&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  18.5&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  22.5&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 21.6%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;98%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 230013&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  18.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  22.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 20.2%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;98%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 230013&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  18.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  22.4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 22.4%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;99%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 232326&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  18.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  22.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 20.8%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;99%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 232326&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  18.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  22.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 21.9%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;99.99999%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 234634&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  17.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  21.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 23.0%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;99.99999%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 234634&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  17.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  22.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 24.7%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;100%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 234634&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  22.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  22.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; -0.9%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;100%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 234634&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  22.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  22.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; -1.3%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;      0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;17987.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 137.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;-99.2%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;      0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;17987.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  18.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;-99.9%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;    923&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  34.5&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  58.4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 69.3%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;    923&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  34.5&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  17.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;-48.1%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   1849&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  28.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  51.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 80.8%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   1849&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  28.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  17.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;-37.6%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   4794&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  22.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  39.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 76.5%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   4794&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  22.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  17.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;-19.5%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   9595&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  19.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  35.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 77.4%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   9595&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  19.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  17.5&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;-12.1%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;25%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  24136&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  17.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  25.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 48.6%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;25%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  24136&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  17.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  17.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; -0.6%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;50%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  48328&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  16.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  19.5&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 21.1%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;50%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  48328&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  16.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  16.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  4.3%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;75%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  72718&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  15.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  17.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  7.6%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;75%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  72718&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  15.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  16.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  5.1%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;90%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  87259&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  15.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  16.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  6.5%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;90%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  87259&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  15.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  16.4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  7.2%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;95%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  92060&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  15.4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  16.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  3.9%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;95%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  92060&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  15.4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  16.4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  6.5%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;98%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  95005&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  15.4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  15.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  2.6%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;98%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  95005&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  15.4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  16.4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  6.5%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;99%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  95931&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  15.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  15.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  4.0%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;99%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  95931&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  15.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  16.4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  8.6%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;99.99999%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  96854&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  14.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  15.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 11.2%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;99.99999%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  96854&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  14.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  16.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 13.3%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;100%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  96854&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  16.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  16.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  0.0%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;100%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  96854&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  16.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  16.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  0.0%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;u s&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;      0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;19123.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 124.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;-99.3%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;0%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;u s&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;      0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;19123.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   7.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;-100.0%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;u s&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   3192&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  23.5&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  27.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 16.2%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;u s&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   3192&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  23.5&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   7.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;-69.8%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;u s&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   6179&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  17.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  24.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 36.5%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;u s&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   6179&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  17.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   7.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;-60.7%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;u s&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  15446&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  12.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  20.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 59.8%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;u s&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  15446&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  12.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   7.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;-44.9%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;u s&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  30858&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  10.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  16.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 59.4%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;u s&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  30858&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  10.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   6.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;-32.7%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;25%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;u s&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  77138&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   7.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  13.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 68.8%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;25%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;u s&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  77138&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   7.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   6.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;-11.7%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;50%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;u s&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 154331&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   6.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   9.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 47.8%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;50%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;u s&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 154331&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   6.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   7.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  4.5%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;75%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;u s&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 231412&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   6.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   8.4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 33.3%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;75%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;u s&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 231412&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   6.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   7.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 11.1%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;90%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;u s&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 277692&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   7.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 24.1%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;90%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;u s&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 277692&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   7.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 20.7%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;95%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;u s&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 293104&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   7.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 22.4%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;95%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;u s&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 293104&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   7.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 20.7%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;98%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;u s&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 302371&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   7.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 20.7%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;98%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;u s&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 302371&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   6.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 19.0%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;99%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;u s&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 305358&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   6.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 19.0%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;99%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;u s&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 305358&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   6.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 19.0%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;99.99999%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;u s&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 308550&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   6.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 17.2%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;99.99999%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;u s&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 308550&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   6.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 19.0%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;100%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;u s&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;low&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 308550&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   7.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   6.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; -1.4%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;100%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&quot;u s&quot;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;high&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 308550&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   7.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   6.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; -1.4%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
</comment>
                    <comment id="12670451" author="mikemccand" created="Wed, 4 Feb 2009 20:34:30 +0000"  >&lt;p&gt;Attaching patch I&apos;m using to run tests.  NOTE: this is nowhere near&lt;br/&gt;
committable.  It&apos;s just a hack to allow testing the different ways of&lt;br/&gt;
applying filters.&lt;/p&gt;</comment>
                    <comment id="12670452" author="mikemccand" created="Wed, 4 Feb 2009 20:37:17 +0000"  >&lt;p&gt;It&apos;s a ridiculous amount of data to digest, but here are some initial&lt;br/&gt;
observations/thoughts:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;There are very sizable gains here by switching to random-access&lt;br/&gt;
    low (ie, handling top-level filter the way we now handle deletes).&lt;br/&gt;
    I&apos;m especially interested in gains in the slowest queries.  EG the&lt;br/&gt;
    phrase query &quot;united states&quot; sees QPS gains from 16%-69%.  The&lt;br/&gt;
    10-clause OR query 1-10 sees QPS gains between 8% and 130%.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Results are consistent with &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1476&quot; title=&quot;BitVector implement DocIdSet, IndexReader returns DocIdSet deleted docs&quot;&gt;&lt;del&gt;LUCENE-1476&lt;/del&gt;&lt;/a&gt;: random-access low gives&lt;br/&gt;
    the best performance when filter density is &amp;gt;= 1%.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;High is worse than trunk up until ~25% density, which makes sense&lt;br/&gt;
    since we are asking Scorer to do alot of work producing docIDs&lt;br/&gt;
    that we then nix with the filter.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Low is consistently better than high, though as filter density&lt;br/&gt;
    gets higher the gap between them narrows.  I&apos;ll drop high from&lt;br/&gt;
    future tests.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;The gains are generally strongest in the &quot;moderate&quot; density range,&lt;br/&gt;
    5-25%.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;The degenerate 0% case is clearly far far worse, which is expected&lt;br/&gt;
    since the iterator scans the bits, finds none set, and quickly&lt;br/&gt;
    ends the search.  For very low density filters we should continue&lt;br/&gt;
    to use iterator.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;The &quot;control&quot; 100% case (where filter is null) is about the same,&lt;br/&gt;
    which is expected.&lt;/li&gt;
&lt;/ul&gt;

</comment>
                    <comment id="12670455" author="mikemccand" created="Wed, 4 Feb 2009 20:43:04 +0000"  >&lt;p&gt;Some ideas / further things to explore:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Deletions, top-level filters, and BooleanQuery that &quot;factors&quot; to a&lt;br/&gt;
    toplevel AND really should be handled by the same code.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Even an AND&apos;d filter on a sub-clause of a BooleanQuery can be&lt;br/&gt;
    pushed down to the TermDocs under that tree.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;That common code should send a top-level filter down to the lowest&lt;br/&gt;
    level, used by random access API, if the filter supports random&lt;br/&gt;
    access (not all do) and it&apos;s not super sparse.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;I think one thing slowing down trunk is the lack of a&lt;br/&gt;
    Scorer.skipToButNotNext API.  We now ask the filter for its&lt;br/&gt;
    next(), which gives us a filterDocID.  Then we call&lt;br/&gt;
    Scorer.skipTo(filterDocID).  If the scorer does not match that&lt;br/&gt;
    filterDocID, it internally does next(), which for an expensive&lt;br/&gt;
    scorer is alot of likely wasted work: it advances to a docID that&lt;br/&gt;
    the filter may not accept.  If we had a &quot;skipToButNotNext&quot; API we&lt;br/&gt;
    could avoid that wasted work.  I&apos;m curious what gains this change&lt;br/&gt;
    alone would provide.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;I&apos;m thinking (but haven&apos;t tested this) if the filter is relatively&lt;br/&gt;
    sparse compared to the other iterators, it&apos;d be better to convert&lt;br/&gt;
    it to a sparse repr (eg SortedVIntList) and drive the search by&lt;br/&gt;
    iteration through the filter, after fixing the above skipTo issue.&lt;br/&gt;
    Maybe a &quot;low iterator&quot; access.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;We may need a &quot;filter optimizer&quot; utility class somewhere, somehow.&lt;br/&gt;
    For filters you do not plan to re-use, you would not bother with&lt;br/&gt;
    this.  But for filters that will be re-used, you should 1) convert&lt;br/&gt;
    them to sparse or non-sparse repr depending on their density, 2)&lt;br/&gt;
    maybe invert them and make sparse if they are close to 100%&lt;br/&gt;
    density, 3) maybe factor in deletions to the filter so there is&lt;br/&gt;
    only a single top-level filter to apply.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;I&apos;m not yet sure how to make this change cleanly to the APIs...&lt;/li&gt;
&lt;/ul&gt;

</comment>
                    <comment id="12672005" author="mikemccand" created="Mon, 9 Feb 2009 20:51:14 +0000"  >
&lt;p&gt;OK I tested a different approach for matching when the filter is&lt;br/&gt;
relatively sparse filter (&amp;lt;= 10% of index size), by implementing a&lt;br/&gt;
simplistic prototype &quot;random access&quot; scorer API (JumpScorer), which&lt;br/&gt;
only exposes the method &quot;boolean jump(int docID)&quot; that returns true if&lt;br/&gt;
that doc matches, else false (and no next() under the hood).&lt;/p&gt;

&lt;p&gt;I only implemented JumpScorer for pure AND/OR queries (ie no excluded&lt;br/&gt;
terms), so I only test for these queries.&lt;/p&gt;

&lt;p&gt;I convert the filter to SortedVIntList up front, so iteration is fast.&lt;br/&gt;
Then during matching I iterate through each doc in the filter, and ask&lt;br/&gt;
the random-access scoring API to test whether it accepts the doc, and&lt;br/&gt;
collect it if so.&lt;/p&gt;

&lt;p&gt;This only performs better when the filter is sparse relative to the&lt;br/&gt;
query.  Once we merge Query/Filter, I think this optimization can more&lt;br/&gt;
generally be used whenever one sub-query is very restrictive compared&lt;br/&gt;
to the rest of the sub-queries.&lt;/p&gt;

&lt;p&gt;This is basically the reverse of what I first tested, which was to&lt;br/&gt;
take a filter that can support random access API and &quot;distribute&quot; it&lt;br/&gt;
down to each TermQuery, which gives very good gains especially when&lt;br/&gt;
filter is in the middle of the sparse/dense range.  Whereas this test&lt;br/&gt;
keeps the iterator API on the filter, but switches to a random access&lt;br/&gt;
API on the scorer.&lt;/p&gt;

&lt;p&gt;Results:&lt;/p&gt;

&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;%tg Filter&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Query&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Hits&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;QPS&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;QPSNew&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;%tg change&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5363&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  47.4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  66.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 40.7%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  10675&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  37.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  50.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 34.6%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  26880&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  28.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  37.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 29.4%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  53673&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  23.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  26.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 10.1%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   6544&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  26.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  37.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 38.3%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  13062&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  21.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  29.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 37.7%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  32815&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  16.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  21.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 31.7%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  65491&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  13.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  15.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 15.2%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   8406&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  13.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  17.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 35.4%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  16756&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  10.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  14.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 39.2%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  41937&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   7.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  10.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 33.8%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1-10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  83828&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   6.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   7.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 23.8%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   2308&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  63.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  82.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 30.3%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   4621&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  49.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  60.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 21.6%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  11706&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  35.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  47.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 33.0%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  23272&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  28.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  35.5&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 25.4%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;    923&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  34.4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  58.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 68.6%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   1849&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  28.5&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  44.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 57.5%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   4794&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  22.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  33.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 53.2%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   9595&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  19.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  25.4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 28.3%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;    292&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  17.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  36.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;115.3%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;    579&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  15.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  30.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 98.7%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;5%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   1517&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  13.5&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  22.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 64.4%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;+1-10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   2999&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  12.4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  17.4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 40.3%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
</comment>
                    <comment id="12679665" author="paul.elschot@xs4all.nl" created="Fri, 6 Mar 2009 17:46:10 +0000"  >&lt;p&gt;For the skipToButNotNext() did you mean sth like &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1252&quot; title=&quot;Avoid using positions when not all required terms are present&quot;&gt;LUCENE-1252&lt;/a&gt;  ?&lt;/p&gt;</comment>
                    <comment id="12679690" author="mikemccand" created="Fri, 6 Mar 2009 19:04:35 +0000"  >
&lt;p&gt;Ahh, that&apos;s actually something different but also a neat idea to&lt;br/&gt;
explore.&lt;/p&gt;

&lt;p&gt;I want a way to skipTo(docID) without having it then internally do a&lt;br/&gt;
next() if the docID was not accepted.  Basically a random-access&lt;br/&gt;
&quot;accepts(int docID)&quot; API, that&apos;s called only on increasing docIDs.&lt;br/&gt;
Implementing &quot;accepts&quot; for queries is often alot simpler than&lt;br/&gt;
implementing next/skipTo.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1252&quot; title=&quot;Avoid using positions when not all required terms are present&quot;&gt;LUCENE-1252&lt;/a&gt; wants a way to expose access to the two constraints within&lt;br/&gt;
a single query separately.  EG a phrase search 1) must have all N&lt;br/&gt;
terms, and 2) must have them in the right positions.  But if you could&lt;br/&gt;
check only 1), and if it passes next check the filter on the search,&lt;br/&gt;
and if it still passes go back and check 2), then that could give&lt;br/&gt;
better search performance.&lt;/p&gt;

&lt;p&gt;I think there&apos;s decent room for improving search performance of&lt;br/&gt;
complex queries.&lt;/p&gt;</comment>
                    <comment id="12698755" author="mikemccand" created="Tue, 14 Apr 2009 13:31:10 +0100"  >&lt;p&gt;Given the sizable performance gains, I think we should try to do this for 2.9, if possible.&lt;/p&gt;</comment>
                    <comment id="12699558" author="thetaphi" created="Thu, 16 Apr 2009 08:18:31 +0100"  >&lt;p&gt;How about DocIdSet adds a&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; isRandomAccess() { &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;; }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;That is implemented to return false in the default abstract class for backwards compatibility.&lt;br/&gt;
If a DocIdSet is random access (backed by OpenBitSet or is the empty iterator), isRandomAccess() is overridden to return true and an additional method in DocIdSet is implemented, the default would be:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; acceptDoc(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; docid) { &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; UnsupportedOperationException(); }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Both changes are backwards compatible, but filters using OpenBitSet would automatically be random access and support acceptDoc().&lt;/p&gt;</comment>
                    <comment id="12699571" author="thetaphi" created="Thu, 16 Apr 2009 08:53:36 +0100"  >&lt;p&gt;The empty docidset instance should &lt;b&gt;not&lt;/b&gt; be random access &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;, so the only change would affect OpenBitSet to overwrite these two new methods from the default abstract class:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; isRandomAccess() { &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;; }
&lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; acceptDoc(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; docid) { &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; fastGet(docid); /* possibly inlined */ }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                    <comment id="12699573" author="thetaphi" created="Thu, 16 Apr 2009 08:57:04 +0100"  >&lt;p&gt;And the switch for different densities:&lt;br/&gt;
OpenBitSet could calculate its density in isRandomAccess() and return true or false depending on the density factors above. The search code then would only check initially isRandomAccess() (before starting filtering) and then switch between iterator or random acess api.&lt;/p&gt;</comment>
                    <comment id="12699669" author="mikemccand" created="Thu, 16 Apr 2009 13:20:04 +0100"  >&lt;p&gt;I like this approach!&lt;/p&gt;

&lt;p&gt;But should we somehow decouple the density check vs the is random access check?  Ie, isRandomAccess should return true or false based on the underlying datastructure.  Then, somehow, I think the search code should determine whether a given docIdSet should be randomly accessed vs iterated?  (I&apos;m not sure how yet!)&lt;/p&gt;

&lt;p&gt;Also, we somehow need the mechanism to &quot;denormalize&quot; the application of the filter from top to bottom, ie, each leaf TermQuery involved in the full query needs to know to apply the random access filter just like it applies deletes.&lt;/p&gt;</comment>
                    <comment id="12699675" author="thetaphi" created="Thu, 16 Apr 2009 13:34:27 +0100"  >&lt;p&gt;I coupled the density check inside the OpenBitSet, because the internals of OpenBitset are responsible for determining how fast a sequential vs. random approach is. Maybe someone invents an new hyper-bitset that can faster do sequential accesses even in sparingly filled bitsets (e.g. fragmented bitset, bitset with RDBMS-like &quot;index&quot;). In this case, it has the responsibility to say: if density is between this and this i would use sequential.&lt;/p&gt;</comment>
                    <comment id="12699680" author="mikemccand" created="Thu, 16 Apr 2009 13:43:34 +0100"  >&lt;p&gt;OK, if we do choose to couple, maybe we should name it &quot;useRandomAccess()&quot;?&lt;/p&gt;

&lt;p&gt;Another filter optimization that&apos;d be nice to get in is to somehow &quot;know&quot; that a filter has pre-incorporated deleted documents.  This way, once we have a solution for the &quot;push filter down to all TermScorers&quot;, we could have it only check the filter and not also deleted docs.  (This is one of the optimizations in &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1594&quot; title=&quot;Use source code specialization to maximize search performance&quot;&gt;&lt;del&gt;LUCENE-1594&lt;/del&gt;&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;We might eventually want/need some sort of external FilterManager that would handle this (ie, convert a filter to sparse vs random-access as appropriate, multiply in deleted docs, handle caching, etc).&lt;/p&gt;</comment>
                    <comment id="12699892" author="jasonrutherglen" created="Thu, 16 Apr 2009 22:52:23 +0100"  >&lt;p&gt;I thought we are going to get &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1518&quot; title=&quot;Merge Query and Filter classes&quot;&gt;LUCENE-1518&lt;/a&gt; working to compare the performance against passing the filter into TermDocs? &lt;/p&gt;</comment>
                    <comment id="12699939" author="mikemccand" created="Fri, 17 Apr 2009 01:18:11 +0100"  >&lt;p&gt;Ahh right, we should re-test performance of this after &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1518&quot; title=&quot;Merge Query and Filter classes&quot;&gt;LUCENE-1518&lt;/a&gt; is done.&lt;/p&gt;</comment>
                    <comment id="12700984" author="jasonrutherglen" created="Tue, 21 Apr 2009 00:26:19 +0100"  >&lt;p&gt;Perhaps we can go ahead with this patch given we&apos;re not sure how&lt;br/&gt;
to do an optimized version of &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1518&quot; title=&quot;Merge Query and Filter classes&quot;&gt;LUCENE-1518&lt;/a&gt; yet. This patch&lt;br/&gt;
entails passing the RandomAccessFilter to TermScorer, what&apos;s a&lt;br/&gt;
good way to do this without rewriting too much of the Lucene API?&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;TermQuery.createWeight -&amp;gt; TermWeight.scorer instantiates the&lt;br/&gt;
TermScorer which is where we need to pass in the filter? So we&lt;br/&gt;
could somehow pass the filter in via multiple constructors? I&lt;br/&gt;
didn&apos;t see a clean API way though.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Or we can add a new method to Scorer, something like&lt;br/&gt;
getSequentialSubScorers? Which we then iterate over and if one&lt;br/&gt;
is a TermScorer set the filter(s). This setting of the RAF would&lt;br/&gt;
happen in IndexSearcher.doSearch. &lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12701024" author="jasonrutherglen" created="Tue, 21 Apr 2009 03:48:11 +0100"  >&lt;p&gt;The patch is a start at something that will work within the API&lt;br/&gt;
(I think). &lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Created a RandomAccessDocIdSet class that BitVector and&lt;br/&gt;
OpenBitSet implement. &lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;SegmentTermDocs has a setter for RandomAccessDocIdSet with the&lt;br/&gt;
option of including the deletedDocs&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;IndexSearcher.doSearch does the main work of setting the&lt;br/&gt;
RandomAccessDocIdSet on the TermScorers&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;BooleanScorer2 and other classes implement&lt;br/&gt;
getSequentialSubScorers&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;AndRandomAccessDocIdSet iterates over an array of&lt;br/&gt;
RandomAccessDocIdSets&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12701216" author="jasonrutherglen" created="Tue, 21 Apr 2009 18:45:23 +0100"  >&lt;ul&gt;
	&lt;li&gt;Filter has a parameter for included deletes. IndexSearcher&lt;br/&gt;
uses it for setting the RandomAccessDocIdSet on the Scorers&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;MatchAllDocsScorer in addition to TermScorer properly supports&lt;br/&gt;
setting a RandomAccessDocIdSet &lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Added more test cases&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;AndRandomAccessDocIdSet.iterator() and BitVector.iterator()&lt;br/&gt;
needs to be implemented &lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12704590" author="yseeley@gmail.com" created="Thu, 30 Apr 2009 12:42:05 +0100"  >&lt;p&gt;Interesting stuff!&lt;br/&gt;
Has anyone tested if this results in a performance degradation on SegmentTermDocs?&lt;br/&gt;
This is very inner loop stuff, and it&apos;s replacing a &quot;non virtual&quot; BitVector.get() which can be easily inlined with two dispatches through base classes.  Hopefully hotspot could handle it, but it&apos;s tough to figure out, esp in a real system where sometimes a user RAF will be used and sometimes not.&lt;/p&gt;</comment>
                    <comment id="12705008" author="mikemccand" created="Fri, 1 May 2009 15:46:25 +0100"  >&lt;blockquote&gt;&lt;p&gt;Has anyone tested if this results in a performance degradation on SegmentTermDocs?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I haven&apos;t, and I&apos;m also nervous.&lt;/p&gt;

&lt;p&gt;One thing we could do is require a concrete impl (eg OpenBitSet) in order to use this optimization?&lt;/p&gt;

&lt;p&gt;I also think we should require pre-multiplication of the deleted docs, and possibly inversion of the filter, rather than doing it on the fly per docID.  Also, we shouldn&apos;t negate the deleted docs per doc when there&apos;s no RAF.  We may want/need to switch to OpenBitSet for deleted docs, in order to not make 2 copies of the STD code.&lt;/p&gt;</comment>
                    <comment id="12705012" author="mikemccand" created="Fri, 1 May 2009 15:56:58 +0100"  >&lt;p&gt;I don&apos;t think it should be the caller&apos;s job to getSequentialSubScorers&lt;br/&gt;
and push down a RAF?  Rather, I think when requesting a scorer we&lt;br/&gt;
should pass in a RAF, requiring that the returned scorer factors it&lt;br/&gt;
in (passing on to its own sub-scorers if needed).&lt;/p&gt;</comment>
                    <comment id="12705013" author="mikemccand" created="Fri, 1 May 2009 15:58:31 +0100"  >
&lt;p&gt;I don&apos;t think it should be the caller&apos;s job to getSequentialSubScorers&lt;br/&gt;
and push down a RAF?  Rather, I think when requesting a scorer we&lt;br/&gt;
should pass in a RAF, requiring that the returned scorer factors it&lt;br/&gt;
in (passing on to its own sub-scorers if needed).&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;One thing we could do is require a concrete impl (eg OpenBitSet) in order to use this optimization?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This may be too restrictive, because another use case (touched on&lt;br/&gt;
already in &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1593&quot; title=&quot;Optimizations to TopScoreDocCollector and TopFieldCollector&quot;&gt;&lt;del&gt;LUCENE-1593&lt;/del&gt;&lt;/a&gt;, but actually much more similar to this issue)&lt;br/&gt;
is when sorting by field.&lt;/p&gt;

&lt;p&gt;EG say we are sorting by int ascending, and from the&lt;br/&gt;
FieldValueHitQueue we know the bottom value is 17.  Then, within&lt;br/&gt;
TermScorer if we see a docID we should check if its value is greater&lt;br/&gt;
than 17 and skip it if so.&lt;/p&gt;

&lt;p&gt;Very likely this will be a sizable performance gain, but it would be a&lt;br/&gt;
major change because you can only do this if you do not need the&lt;br/&gt;
precise totalHits back.&lt;/p&gt;

&lt;p&gt;So... maybe we need to allow an abstract RandomAccesDocIdSet, to allow&lt;br/&gt;
this use case.  But perhaps we should negate its API?  Ie it exposes&lt;br/&gt;
&quot;boolean reject(int docID)&quot;.&lt;/p&gt;</comment>
                    <comment id="12705029" author="creamyg" created="Fri, 1 May 2009 16:50:22 +0100"  >&lt;p&gt;&amp;gt; it would be amajor change because you can only do this if &lt;br/&gt;
&amp;gt; you do not need the precise totalHits back.&lt;/p&gt;

&lt;p&gt;Early termination (pruning) also messes with totalHits.  I think &lt;br/&gt;
it would be good to get away from the idea that totalHits is &lt;br/&gt;
reliable side effect.&lt;/p&gt;</comment>
                    <comment id="12705257" author="mikemccand" created="Sat, 2 May 2009 12:01:55 +0100"  >&lt;blockquote&gt;
&lt;p&gt;Early termination (pruning) also messes with totalHits. I think &lt;br/&gt;
it would be good to get away from the idea that totalHits is &lt;br/&gt;
reliable side effect.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Agreed.  Does KS/Lucy not guarantee accurate totalHits returned?  Lucene today always returns the precise total hits.&lt;/p&gt;

&lt;p&gt;If we can move away from that (optionally) then we can gain sizable performance.&lt;/p&gt;

&lt;p&gt;But: we&apos;d then presumably need to return an approx hit count.&lt;/p&gt;</comment>
                    <comment id="12718430" author="mikemccand" created="Thu, 11 Jun 2009 13:48:29 +0100"  >&lt;p&gt;Moving out.&lt;/p&gt;</comment>
                    <comment id="12722472" author="jasonrutherglen" created="Mon, 22 Jun 2009 04:41:28 +0100"  >&lt;blockquote&gt;&lt;p&gt; I don&apos;t think it should be the caller&apos;s job to&lt;br/&gt;
getSequentialSubScorers and push down a RAF? Rather, I think&lt;br/&gt;
when requesting a scorer we should pass in a RAF, requiring that&lt;br/&gt;
the returned scorer factors it in (passing on to its own&lt;br/&gt;
sub-scorers if needed). &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;True, however that requires adding a scorer(IndexReader, RAF)&lt;br/&gt;
method to the Weight interface? Which means adding it to I think&lt;br/&gt;
20 classes or so. Which is fine, however is that definitely what&lt;br/&gt;
we want to do? &lt;/p&gt;

&lt;p&gt;Also I forget if we created a patch or benchmarked AND NOT&lt;br/&gt;
deleteDocs?&lt;/p&gt;</comment>
                    <comment id="12722538" author="mikemccand" created="Mon, 22 Jun 2009 10:47:29 +0100"  >&lt;blockquote&gt;&lt;p&gt;that requires adding a scorer(IndexReader, RAF) method to the Weight interface?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Well, to QueryWeight (abstract class, not interface) that we are migrating to with &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1630&quot; title=&quot;Mating Collector and Scorer on doc Id orderness&quot;&gt;&lt;del&gt;LUCENE-1630&lt;/del&gt;&lt;/a&gt;.  We&apos;d make a default impl, probably a static method somewhere, so that any external QueryWeight&apos;s &quot;out there&quot; would just work.&lt;/p&gt;

&lt;p&gt;Though, since QueryWeight is new in 2.9, we are free to make this an abstract method, and put the default only in QueryWeightWrapper, if we could get this issue done for 2.9.&lt;/p&gt;

&lt;p&gt;I think we&apos;d also want control on whether the Scorer should apply deletes or not, so that for filters that are often re-used, we have the option to pre-fold deletes in.&lt;/p&gt;</comment>
                    <comment id="12722761" author="jasonrutherglen" created="Mon, 22 Jun 2009 19:54:26 +0100"  >&lt;blockquote&gt;&lt;p&gt; since QueryWeight is new in 2.9, we are free to make&lt;br/&gt;
this an abstract method, and put the default only in&lt;br/&gt;
QueryWeightWrapper, &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Sounds good.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt; we&apos;d also want control on whether the Scorer should&lt;br/&gt;
apply deletes or not &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Filter.hasDeletes can be used know whether to apply deletes or&lt;br/&gt;
not. &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;migrating to with &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1630&quot; title=&quot;Mating Collector and Scorer on doc Id orderness&quot;&gt;&lt;del&gt;LUCENE-1630&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Looks this this will be committed soon, so I&apos;ll wait for that&lt;br/&gt;
then make the changes, then benchmark.&lt;/p&gt;</comment>
                    <comment id="12755738" author="jasonrutherglen" created="Tue, 15 Sep 2009 23:14:53 +0100"  >&lt;ul&gt;
	&lt;li&gt;Added a IndexReader.termDocs(term, filter) method which&lt;br/&gt;
  culminates in passing a RandomAccessDocIdSet to the scorers.&lt;br/&gt;
  ConstantScoreQuery and FilterQuery need to AND the filters&lt;br/&gt;
  together. &lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Does explain need the filter?&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Spans aren&apos;t supported yet&lt;/li&gt;
&lt;/ul&gt;



</comment>
                    <comment id="12755900" author="jasonrutherglen" created="Wed, 16 Sep 2009 07:25:33 +0100"  >&lt;ul&gt;
	&lt;li&gt;The test case includes testConstantCoreQuery&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;If &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1632&quot; title=&quot;boolean docid set iterator improvement&quot;&gt;LUCENE-1632&lt;/a&gt; were updated to use the new DocIdSetIterator API,&lt;br/&gt;
  it could be useful for the iterators of AndRandomAccessDocIdSet&lt;br/&gt;
  and NotRandomAccessDocIdSet.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12854612" author="mikemccand" created="Wed, 7 Apr 2010 18:36:00 +0100"  >&lt;p&gt;With flex, you can now get the deleted docs from a reader (returns a Bits, yet another interface for bitsets), and, Docs/AndPositionsEnums require that you pass in the skipDocs.  Ie they no longer skip deleted docs by default.&lt;/p&gt;

&lt;p&gt;I think this makes this issue quite a bit simpler?  EG OpenBitSets implements Bits (as of flex landing), so... we just need a way to pass this Bits down to the low level scorers that actually pull a postings list.  But, we should only do this if the filter is not sparse.&lt;/p&gt;

&lt;p&gt;Also: the filter must be inverted, and, ORd with the deleted docs.&lt;/p&gt;

&lt;p&gt;This can result in enormous perf gains for searches doing filtering where the filter is relatively static (can be cached &amp;amp; shared across searches).&lt;/p&gt;</comment>
                    <comment id="12908914" author="mikemccand" created="Mon, 13 Sep 2010 19:44:58 +0100"  >&lt;p&gt;By subclassing FilterIndexReader, and taking advantage of how the flex&lt;br/&gt;
APIs now let you pass a custom skipDocs when pulling the postings, I&lt;br/&gt;
created a prototype class (attached, named CachedFilterIndexReader) that&lt;br/&gt;
up-front compiles the deleted docs for each segment with the negation&lt;br/&gt;
of a Filter (that you provide), and returns a reader that applies that&lt;br/&gt;
filter.&lt;/p&gt;

&lt;p&gt;This is nice because it&apos;s fully external to Lucene, and it gives&lt;br/&gt;
awesome gains in many cases (see&lt;br/&gt;
&lt;a href=&quot;http://chbits.blogspot.com/2010/09/fast-search-filters-using-flex.html&quot; class=&quot;external-link&quot;&gt;http://chbits.blogspot.com/2010/09/fast-search-filters-using-flex.html&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;I don&apos;t think we should commit this class &amp;#8211; we should instead fix&lt;br/&gt;
Filters correctly!  But it&apos;s a nice workaround until we do that.&lt;/p&gt;</comment>
                    <comment id="12928859" author="kimchy" created="Fri, 5 Nov 2010 22:49:44 +0000"  >&lt;p&gt;Hi Mike,&lt;/p&gt;

&lt;p&gt;   Wondering what are your thoughts on fixing filters correctly are? I think that the initial thought of getting filters all the way down to postings enumeration if they support random access is a great one. A random access doc id set can be added (interface), and if a filter returns it (can be checked using instanceof), then the that doc set can be passed all the way to the enumeration (and intersected per doc with the deleted docs).&lt;/p&gt;

&lt;p&gt;   I think that any type of solution should support the great feature of Lucene queries, for example, FilteredQuery should use that, allowing to build complex query expressions without having the mentioned optimization only applied on the top level search.&lt;/p&gt;

&lt;p&gt;   As most filters results do support random access, either because they use OpenBitSet, or because they are built on top of FieldCache functionality, I think this feature will give great speed improvements to the query execution time.&lt;/p&gt;</comment>
                    <comment id="12928948" author="mikemccand" created="Sat, 6 Nov 2010 10:29:47 +0000"  >&lt;blockquote&gt;&lt;p&gt;Wondering what are your thoughts on fixing filters correctly are?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think the approach you outlined is the right one!&lt;/p&gt;

&lt;p&gt;We already have the APIs in flex (Bits interface for random access, postings APIs take a Bits skipDocs); in backporting to 3.x I think we&apos;d just port Bits back.&lt;/p&gt;

&lt;p&gt;There are some challenges though:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;We should add a method to Filter to ask it if its already folded in deleted docs or not.  So eg if a Filter is random access but doesn&apos;t factor in del docs we&apos;d have to wrap it so that every random access check also checks del docs (&quot;AND NOT deleted.get(docID)&quot;).&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;We need a coarse heuristic in IndexSearcher to decide when a filter &quot;merits&quot; down low application.  Ie, even if a filter is random access, if it&apos;s rather sparse (&amp;lt; 1% or 2% or something) it&apos;s better to apply it the way we do today (&quot;up high&quot;).  In the current patch it&apos;s too coarse (it&apos;s either globally on or off); it should be based on the filter instead, or maybe the filter provides a method and that method defaults to the 1/2% threshold check.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;I suspect we should invert the &quot;Bits skipDocs&quot; now passed to the flex APIs, to be &quot;Bits acceptDocs&quot; instead, so that we don&apos;t have to invert every filter.  This&apos;d also mean changing IndexReader.getDeletedDocs to IndexReader.getNotDeleteDocs.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Then I think we simply pass the Bits filter into the Weight.scorer API.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I think that any type of solution should support the great feature of Lucene queries, for example, FilteredQuery should use that, allowing to build complex query expressions without having the mentioned optimization only applied on the top level search.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Good point &amp;#8211; FilteredQuery should use this same low level API if its filter is random access and &quot;dense enough&quot;.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;As most filters results do support random access, either because they use OpenBitSet, or because they are built on top of FieldCache functionality, I think this feature will give great speed improvements to the query execution time.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Right, the speed gains are often awesome!&lt;/p&gt;</comment>
                    <comment id="13055143" author="mikemccand" created="Sun, 26 Jun 2011 19:27:14 +0100"  >&lt;p&gt;Initial patch for trunk... lots of nocommits, but tests all pass and I&lt;br/&gt;
think this is &lt;span class=&quot;error&quot;&gt;&amp;#91;roughly&amp;#93;&lt;/span&gt; the approach we should take to get fast(er)&lt;br/&gt;
Filter perf.&lt;/p&gt;

&lt;p&gt;Conceptually, this change is fairly easy, because the flex APIs all&lt;br/&gt;
accept a Bits to apply low-level filtering.  However, this Bits is&lt;br/&gt;
inverted vs the Filter that callers pass to IndexSearcher (skipDocs vs&lt;br/&gt;
keepDocs), so, my patch inverts 1) the meaning of this first arg to&lt;br/&gt;
the Docs/AndPositions enums (it becomes an acceptDocs instead of&lt;br/&gt;
skipDocs), and 2) deleted docs coming back from IndexReaders (renames&lt;br/&gt;
IR.getDeletedDocs -&amp;gt; IR.getNotDeletedDocs).&lt;/p&gt;

&lt;p&gt;That change (inverting the Bits to be keepDocs not skipDocs) is the&lt;br/&gt;
vast majority of the patch.&lt;/p&gt;

&lt;p&gt;The &quot;real&quot; change is to add DocIdSet.getRandomAccessBits and&lt;br/&gt;
bitsIncludesDeletedDocs, which IndexSearcher then consults to figure&lt;br/&gt;
out whether to push the filter &quot;low&quot; instead of &quot;high&quot;.  I then fixed&lt;br/&gt;
OpenBitSet to return this from getRandomAccessBits, and fixed&lt;br/&gt;
CachingWrapperFilter to turn this on/off as well as state whether&lt;br/&gt;
deleted docs were folded into the filter.&lt;/p&gt;

&lt;p&gt;This means filters cached with CachingWrapperFilter will apply &quot;low&quot;,&lt;br/&gt;
and if it&apos;s DeletesMode.RECACHE then it&apos;s a single filter that&apos;s&lt;br/&gt;
applied (else I wrap with an AND NOT deleted check per docID), but&lt;br/&gt;
custom filters are also free to impl these methods to have their&lt;br/&gt;
filters applied &quot;low&quot;.&lt;/p&gt;</comment>
                    <comment id="13055169" author="thetaphi" created="Sun, 26 Jun 2011 21:41:01 +0100"  >&lt;p&gt;Hi Mike,&lt;br/&gt;
nicae patch, only little bit big. I reviewed the essential parts like applying the filter in IndexSearcher, real cool. Also CachingWrapperFilter looks fine (not closely reviewed).&lt;/p&gt;

&lt;p&gt;My question: Do we really need to make the delDocs inverse in &lt;b&gt;this&lt;/b&gt; issue? The IndexSearcher impl can also be done using a simple OrNotBits(delDocs, filterDocs) wrapper (instead AndBits) implementation and NotBits (if no delDocs available)? The patch is unreadable because of that. In general, reversing the delDocs might be a good idea, but we should do it separate and hard (not allow both variants implemented by IndexReader &amp;amp; Co.). The method name getNotDeletedDocs() should also be getVisibleDocs() or similar &lt;span class=&quot;error&quot;&gt;&amp;#91;I don&amp;#39;t like double negation&amp;#93;&lt;/span&gt;.&lt;/p&gt;

&lt;p&gt;About the filters: I like the new API (it is as discussed before), so the DocIdSet is extended by an optional getBits() method, defaulting to null.&lt;/p&gt;

&lt;p&gt;About the impls: FieldCacheRangeFilter can also implement getBits() directly as FieldCache is random access. It should just return an own Bits impl for the DocIdSet that checks the filtering in get(index).&lt;/p&gt;</comment>
                    <comment id="13055181" author="thetaphi" created="Sun, 26 Jun 2011 22:16:40 +0100"  >&lt;p&gt;One more comment about DocIdSet.bitsIncludesDeletedDocs(). I think the default in DocIdSet and of course OpenBitSet should be true, because current filters always respect deleted docs (this was a requirement: MTQ uses deleted docs, FCRF explicitely ands it in). So the default is fine here. Of course CachingWrapperFilter sets this to false if the SegmentReader got new deletes.&lt;/p&gt;</comment>
                    <comment id="13055544" author="mikemccand" created="Mon, 27 Jun 2011 14:38:38 +0100"  >&lt;blockquote&gt;&lt;p&gt;My question: Do we really need to make the delDocs inverse in this issue?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I agree, let&apos;s break this (inverting delDocs/skipDocs) into a new issue and do it first, then come back to this issue.  There&apos;s still more work to do here, eg the bits should be stored inverted too (and the sparse encoding &quot;flipped&quot;).&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The method name getNotDeletedDocs() should also be getVisibleDocs() or similar &lt;span class=&quot;error&quot;&gt;&amp;#91;I don&amp;#39;t like double negation&amp;#93;&lt;/span&gt;.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;+1 for getVisibleDocs &amp;#8211; I also don&apos;t like double negation!&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;In general, reversing the delDocs might be a good idea, but we should do it separate and hard (not allow both variants implemented by IndexReader &amp;amp; Co.).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I agree it must be hard cutover &amp;#8211; no more getDelDocs, and getVisibleDocs is abstract in IR.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;About the impls: FieldCacheRangeFilter can also implement getBits() directly as FieldCache is random access. It should just return an own Bits impl for the DocIdSet that checks the filtering in get(index).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Ahh, right: FCRF has no trouble being random access, and it can re-use the already created matchDoc in the subclasses.&lt;/p&gt;</comment>
                    <comment id="13055581" author="rcmuir" created="Mon, 27 Jun 2011 15:38:25 +0100"  >&lt;blockquote&gt;
&lt;p&gt;+1 for getVisibleDocs &#8211; I also don&apos;t like double negation!&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I agree... getVisibleDocs() or another alternative would be getLiveDocs()&lt;/p&gt;</comment>
                    <comment id="13062392" author="mikemccand" created="Sat, 9 Jul 2011 15:53:02 +0100"  >&lt;p&gt;Patch.  Lots of nocommits still but tests pass.&lt;/p&gt;</comment>
                    <comment id="13112611" author="cmale" created="Thu, 22 Sep 2011 15:21:11 +0100"  >&lt;p&gt;I think I have managed to update this to trunk.  The only dated aspect is the use of OpenBitSet, which if I understand correctly, has been replaced by FixedBitSet for most cases.&lt;/p&gt;</comment>
                    <comment id="13112621" author="thetaphi" created="Thu, 22 Sep 2011 15:35:37 +0100"  >&lt;blockquote&gt;&lt;p&gt;The only dated aspect is the use of OpenBitSet, which if I understand correctly, has been replaced by FixedBitSet for most cases.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;YES!&lt;/p&gt;</comment>
                    <comment id="13112782" author="mikemccand" created="Thu, 22 Sep 2011 19:16:48 +0100"  >&lt;p&gt;Looks good Chris; thanks for bringing up to date, and feel free to fix the nocommits too &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;I think a couple trunk changes got lost in your merging &amp;#8211; eg MultiPhraseQuery.rewrite lost the &quot;if (termsArray.isEmpty())&quot; case?  (Also PhraseQuery.rewrite: I didn&apos;t mean to remove that; I think that was committed after my last patch?).  And PayloadTermQuery lost an &quot;if (includeSpanScore)&quot;?&lt;/p&gt;

&lt;p&gt;We should certainly cutover to FixedBitSet!&lt;/p&gt;</comment>
                    <comment id="13113165" author="cmale" created="Fri, 23 Sep 2011 06:33:43 +0100"  >&lt;p&gt;New patch which includes the missed merging, some small tidy-ups and converting over to FixedBitSet.&lt;/p&gt;</comment>
                    <comment id="13113167" author="cmale" created="Fri, 23 Sep 2011 06:44:22 +0100"  >&lt;p&gt;Few questions:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Would it make more sense to use the &apos;LiveDocs&apos; notion in this API too? So rather than it being bitsIncludeDeletedDocs, it would be liveDocsOnly.&lt;/li&gt;
	&lt;li&gt;In what situations would a DocIdSet return a different Bits implementation for getRandomAccessBits? If the DocIdSet impl doesn&apos;t support random access, then converting to a random-access Bits implementation could be intensive, right? which would probably out-weigh the benefits.  Therefore could we simply check if the DocIdSet is also a Bits impl?  If it isn&apos;t, then we do the traditional filtering approach.&lt;/li&gt;
	&lt;li&gt;When would a Bits implementation not want to support random-access? It seems its interface is implicitly random-access.  If so, could we cut the setter from FixedBitSet (I&apos;m moved it from OpenBitSet).&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="13113542" author="mikemccand" created="Fri, 23 Sep 2011 17:40:16 +0100"  >
&lt;blockquote&gt;&lt;p&gt;Would it make more sense to use the &apos;LiveDocs&apos; notion in this API too? So rather than it being bitsIncludeDeletedDocs, it would be liveDocsOnly.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;+1&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;In what situations would a DocIdSet return a different Bits implementation for getRandomAccessBits? If the DocIdSet impl doesn&apos;t support random access, then converting to a random-access Bits implementation could be intensive, right? which would probably out-weigh the benefits. Therefore could we simply check if the DocIdSet is also a Bits impl? If it isn&apos;t, then we do the traditional filtering approach.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;You mean instanceof check instead of getRandomAccessBits?  I think&lt;br/&gt;
that&apos;s good?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;When would a Bits implementation not want to support random-access? It seems its interface is implicitly random-access. If so, could we cut the setter from FixedBitSet (I&apos;m moved it from OpenBitSet).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Random access is actually slower when the number of docs that match&lt;br/&gt;
the filter is tiny (like less than 1% of the index), so I think if&lt;br/&gt;
it&apos;s a Bits instance we still need a way to force it to use the&lt;br/&gt;
old way?&lt;/p&gt;</comment>
                    <comment id="13113552" author="cmale" created="Fri, 23 Sep 2011 17:52:05 +0100"  >&lt;blockquote&gt;&lt;p&gt;You mean instanceof check instead of getRandomAccessBits? I think that&apos;s good?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Thats exactly what I mean.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Random access is actually slower when the number of docs that match&lt;br/&gt;
the filter is tiny (like less than 1% of the index), so I think if&lt;br/&gt;
it&apos;s a Bits instance we still need a way to force it to use the&lt;br/&gt;
old way?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;What if we were to expose cardinality through the Bits interface? We could then define some point in IndexSearcher where it decides which Query + Filter execution Strategy to use.    &lt;/p&gt;</comment>
                    <comment id="13113598" author="mikemccand" created="Fri, 23 Sep 2011 18:41:40 +0100"  >&lt;blockquote&gt;&lt;p&gt;What if we were to expose cardinality through the Bits interface? We could then define some point in IndexSearcher where it decides which Query + Filter execution Strategy to use.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Hmm that makes me nervous, since computing cardinality isn&apos;t that cheap.&lt;/p&gt;

&lt;p&gt;Ie, it&apos;s better if this is done once up front and recorded on the DocIdSet, like CachingWrapperFilter does when the filter is cached.&lt;/p&gt;</comment>
                    <comment id="13113899" author="cmale" created="Sat, 24 Sep 2011 06:38:48 +0100"  >&lt;blockquote&gt;&lt;p&gt;Hmm that makes me nervous, since computing cardinality isn&apos;t that cheap.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Okay, good point.&lt;/p&gt;

&lt;p&gt;Another alternative (just throwing out ideas) is to keep the getRandomAccessBits on DocIdSet, but pass into it the Bits liveDocs.  Then it&apos;d be up to the implementation to incorporate the liveDocs Bits (if it hasn&apos;t already).  If it hadn&apos;t, it could use the AndBits like the patch currently does in IndexSearcher.  IS would then become a little cleaner.&lt;/p&gt;

&lt;p&gt;If the DocIdSet didn&apos;t want random-access, then it would return null.&lt;/p&gt;</comment>
                    <comment id="13113912" author="cmale" created="Sat, 24 Sep 2011 07:34:25 +0100"  >&lt;p&gt;Actually, the more I look at the nocommits, the less I like what I&apos;ve suggested.  I think having getRandomAccessBits as it is in the patch is fine.  But I like we should maybe make setLiveDocsOnly and setAllowRandomAccessFiltering 1st class features of the Bits interface.&lt;/p&gt;</comment>
                    <comment id="13113965" author="mikemccand" created="Sat, 24 Sep 2011 13:47:12 +0100"  >&lt;blockquote&gt;&lt;p&gt;But I like we should maybe make setLiveDocsOnly and setAllowRandomAccessFiltering 1st class features of the Bits interface.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Hmm... that also makes me a bit nervous &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; Bits is too low-level for&lt;br/&gt;
these concepts?  Ie whether a filter/DIS &quot;folded in&quot; live docs&lt;br/&gt;
already, and whether the filter/DIS is best applied by iteration vs by&lt;br/&gt;
random access, are higher level filter concepts, not low level Bits&lt;br/&gt;
concepts, I think?&lt;/p&gt;

&lt;p&gt;Also, Bits by definition is random-access so I don&apos;t think it should&lt;br/&gt;
have set/getAllowRandomAccessFiltering.&lt;/p&gt;</comment>
                    <comment id="13114041" author="rcmuir" created="Sat, 24 Sep 2011 19:39:53 +0100"  >&lt;p&gt;I didnt look too hard here at whats going on, but maybe we could use the RandomAccess marker interface from the jdk?&lt;/p&gt;</comment>
                    <comment id="13115395" author="cmale" created="Tue, 27 Sep 2011 11:51:10 +0100"  >&lt;p&gt;New patch which adds greater control over the random-access to DocIdSet.&lt;/p&gt;

&lt;p&gt;Also fixes most of the nocommits.&lt;/p&gt;</comment>
                    <comment id="13115783" author="mikemccand" created="Tue, 27 Sep 2011 19:30:47 +0100"  >&lt;p&gt;New patch, fixing a few failing tests, adding a couple comments.  I&lt;br/&gt;
downgraded the 2 nocommits in LTC to TODOs, and removed the other one&lt;br/&gt;
(false is correct default for those two?).&lt;/p&gt;

&lt;p&gt;For DocIdSet, can we nuke getRandomAccessBits?  Ie, if&lt;br/&gt;
supportRandomAccess() returns true, then we can cast the instance to&lt;br/&gt;
Bits?  Maybe we should rename supportRandomAccess to useRandomAccess?&lt;br/&gt;
(Ie, it may support it, but we only want to use random access when the&lt;br/&gt;
filter is dense enough).&lt;/p&gt;

&lt;p&gt;I changed MTQWF&apos;s and CachingWrapperFilter&apos;s threshold to a double&lt;br/&gt;
percent (of the reader&apos;s maxDoc) instead, default 1.0%.&lt;/p&gt;

&lt;p&gt;Hmm FieldCacheRangeFilter never enables random access... not sure&lt;br/&gt;
how/when we should compute that.&lt;/p&gt;

&lt;p&gt;I think we are getting close!&lt;/p&gt;</comment>
                    <comment id="13115806" author="thetaphi" created="Tue, 27 Sep 2011 20:01:24 +0100"  >&lt;p&gt;Wouldn&apos;t it make sense for FCRF to always return random access=true? This filter has a very ineffective DISI, as it has to check each doc using the match method, so random access is much better for this one (maps to current matchDoc-method, which should be renamed to a simple Bits.get(int docId)). What&apos;s the sense to use a DISI for this one?&lt;/p&gt;</comment>
                    <comment id="13115811" author="thetaphi" created="Tue, 27 Sep 2011 20:05:08 +0100"  >&lt;p&gt;Why does CachingWrapperFilter refers to OpenBitSetDISI again? It should only use FixedBitSet as it already has al DISI methods?&lt;/p&gt;</comment>
                    <comment id="13116123" author="cmale" created="Wed, 28 Sep 2011 05:16:06 +0100"  >&lt;p&gt;I haven&apos;t had a chance to look at the latest patch, but:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;For DocIdSet, can we nuke getRandomAccessBits? Ie, if&lt;br/&gt;
supportRandomAccess() returns true, then we can cast the instance to&lt;br/&gt;
Bits? Maybe we should rename supportRandomAccess to useRandomAccess?&lt;br/&gt;
(Ie, it may support it, but we only want to use random access when the&lt;br/&gt;
filter is dense enough).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;m definitely +1 to useRandomAccess() but I think there is a usability question mark around removing getRandomAccessBits().  If we assume that if DocIdSet.useRandomAccess() returns true then the DocIdSet must be also be a Bits implementation, then we need to prevent non-Bits implementations from returning true, or setting true in setUseRandomAccess.  If we don&apos;t, we&apos;re likely to confuse even expert users because this all comes together in a method deep inside IndexSearcher.&lt;/p&gt;

&lt;p&gt;But if we&apos;re going to constrain useRandomAccess to only Bits implementations, then I once again feel these should be on Bits.  What if we added to Bits allowRandomAccessFiltering() or something like that? So even though Bits is inherently random-access, we control whether the Bits should be used to do filtering.&lt;/p&gt;

&lt;p&gt;Alternatively we keep getRandomAccessBits() and see DocIdSet as a random-access Bits factory which currently just returns itself in most cases, but potentially might not in the future?&lt;/p&gt;</comment>
                    <comment id="13116371" author="mikemccand" created="Wed, 28 Sep 2011 13:24:37 +0100"  >&lt;blockquote&gt;&lt;p&gt;Wouldn&apos;t it make sense for FCRF to always return random access=true? This filter has a very ineffective DISI, as it has to check each doc using the match method, so random access is much better for this one (maps to current matchDoc-method, which should be renamed to a simple Bits.get(int docId)). What&apos;s the sense to use a DISI for this one?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;+1 let&apos;s do that!&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Why does CachingWrapperFilter refers to OpenBitSetDISI again? It should only use FixedBitSet as it already has al DISI methods?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Hmm I thought I fixed this in my last patch?  Oh I see, I fixed the code but not the jdocs... I&apos;ll fix the jdocs.&lt;/p&gt;</comment>
                    <comment id="13116378" author="mikemccand" created="Wed, 28 Sep 2011 13:39:50 +0100"  >&lt;blockquote&gt;&lt;p&gt;I&apos;m definitely +1 to useRandomAccess() but I think there is a usability question mark around removing getRandomAccessBits(). If we assume that if DocIdSet.useRandomAccess() returns true then the DocIdSet must be also be a Bits implementation, then we need to prevent non-Bits implementations from returning true, or setting true in setUseRandomAccess. If we don&apos;t, we&apos;re likely to confuse even expert users because this all comes together in a method deep inside IndexSearcher.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Well it&apos;s quite expert to implement your own random-access filter?&lt;/p&gt;

&lt;p&gt;We can fix IS so that if the DIS fails to cast you get a clear exception stating that useRandomAccess returned true yet the DIS isn&apos;t a Bits?  Or it could be silent and fall back to iteration, if the cast fails... but I prefer the former (so you know your &quot;true&quot; isn&apos;t working).&lt;/p&gt;

&lt;p&gt;I really don&apos;t think we should pollute Bits w/ useRandomAccess method; random-access is the entire point of the Bits interface.  It&apos;s too low-level to push it down there.&lt;/p&gt;

&lt;p&gt;And actually having a getter (getRandomAccessBits) is trappy I think, because the user may not realize it&apos;s called for every search and may do something crazy like allocate a new FixedBitSet every time.&lt;/p&gt;</comment>
                    <comment id="13116380" author="mikemccand" created="Wed, 28 Sep 2011 13:41:08 +0100"  >&lt;p&gt;New patch folding in Uwe&apos;s ideas &amp;#8211; FCRF always uses random access; remove matchDoc and just override Bits.get; fixed CWF jdocs to not reference OpenBitSetDISI.&lt;/p&gt;</comment>
                    <comment id="13116407" author="cmale" created="Wed, 28 Sep 2011 13:58:13 +0100"  >&lt;blockquote&gt;&lt;p&gt;I really don&apos;t think we should pollute Bits w/ useRandomAccess method; random-access is the entire point of the Bits interface. It&apos;s too low-level to push it down there.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Its not about marking whether random-access should be used or not, my idea was to mark whether it should be used to filter or not.&lt;/p&gt;</comment>
                    <comment id="13116645" author="rcmuir" created="Wed, 28 Sep 2011 19:07:20 +0100"  >&lt;p&gt;As a first (committable) step towards this, I think we should break out a new issue&lt;br/&gt;
where we remove the hardcoded calls to IR.getLiveDocs() in all the Scorers?&lt;/p&gt;

&lt;p&gt;Then deleted docs could be supplied via the ScorerContext with something like acceptDocs.&lt;/p&gt;

&lt;p&gt;This seems cleaner and more flexible to me regardless of what we do.&lt;/p&gt;</comment>
                    <comment id="13116651" author="mikemccand" created="Wed, 28 Sep 2011 19:11:04 +0100"  >&lt;p&gt;+1, that change is a rote cutover.&lt;/p&gt;

&lt;p&gt;Then separately we can figure out how a Filter/DIS/Bits conveys the &quot;strategy&quot; to IS.  Really this is a part of the wider question of how Lucene should do query optimization in general...&lt;/p&gt;</comment>
                    <comment id="13116702" author="rcmuir" created="Wed, 28 Sep 2011 20:09:28 +0100"  >&lt;blockquote&gt;
&lt;p&gt;Then separately we can figure out how a Filter/DIS/Bits conveys the &quot;strategy&quot; to IS. Really this is a part of the wider question of how Lucene should do query optimization in general...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think once we do this, we should just add &quot;Bits acceptDocs&quot; parameter to IndexSearcher&apos;s searchWithFilter method?&lt;br/&gt;
And I think a simple (protected) heuristic to IndexSearcher whether it should execute the filter &apos;via acceptDocs&apos;: the default just be instanceof Bits &amp;amp;&amp;amp; firstSetBit &amp;lt; X, like what BQ does?&lt;br/&gt;
Then we might add optional boolean method to Filter for whether it already &apos;incorporates deletes&apos;.&lt;/p&gt;

&lt;p&gt;Then we can optimize for the 4 cases:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;sparse/non-random-access filter, doesn&apos;t incorporate deletes: same logic as today&lt;/li&gt;
	&lt;li&gt;sparse/non-random-access filter, incorporates deletes: Here we might pass null as &apos;acceptDocs&apos; to the scorercontext, so we no longer redundantly check deleted docs.&lt;/li&gt;
	&lt;li&gt;heavy random-access filter, doesn&apos;t incorporate deletes: no filter instead with acceptDocs=AndBits(filter, liveDocs)&lt;/li&gt;
	&lt;li&gt;heavy random-access filter, incorporates deletes: no filter instead with acceptDocs=filter (don&apos;t need to use AndBits since we know it incorporates liveDocs).&lt;/li&gt;
&lt;/ol&gt;

</comment>
                    <comment id="13117242" author="mikemccand" created="Thu, 29 Sep 2011 13:30:31 +0100"  >&lt;blockquote&gt;&lt;p&gt;And I think a simple (protected) heuristic to IndexSearcher whether it should execute the filter &apos;via acceptDocs&apos;: the default just be instanceof Bits &amp;amp;&amp;amp; firstSetBit &amp;lt; X, like what BQ does?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That&apos;s a neat idea!  Then we can sidestep this whole question about who/where/what &quot;computes&quot; whether the Bits is very sparse (&amp;lt; 1%) and so we should apply &quot;up high&quot;, or not and so we should apply &quot;down low&quot;.&lt;/p&gt;

&lt;p&gt;So this logic would run after we have a Bits... we could actually go and test every Mth bit (not just first N), to hopefully reduce false negatives (ie, a dense filter that appeared sparse just because it&apos;s first N docs were not set).&lt;/p&gt;

&lt;p&gt;It&apos;d still be a heuristic and thus make mistakes sometimes... (vs actually calling .cardinality and making the &quot;right&quot; decision), but most of the time it should work.&lt;/p&gt;

&lt;p&gt;Separately we still need someone to declare whether the filter AND&apos;d live docs already; maybe we put this on the Filter class, since it would not normally vary per-segment?&lt;/p&gt;</comment>
                    <comment id="13117246" author="cmale" created="Thu, 29 Sep 2011 13:36:19 +0100"  >&lt;p&gt;+1 to this approach.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Separately we still need someone to declare whether the filter AND&apos;d live docs already; maybe we put this on the Filter class, since it would not normally vary per-segment?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I kind of like how Filter doesn&apos;t have any properties associated with it.  So perhaps we can keep the liveDocsOnly on DocIdSet?&lt;/p&gt;</comment>
                    <comment id="13117288" author="mikemccand" created="Thu, 29 Sep 2011 14:22:14 +0100"  >&lt;p&gt;OK, DocIdSet seems good too?  It already has isCacheable, so there&apos;s a precent of putting such &quot;hints&quot; on it.&lt;/p&gt;

&lt;p&gt;Maybe .containsOnlyLiveDocs()?&lt;/p&gt;</comment>
                    <comment id="13117291" author="cmale" created="Thu, 29 Sep 2011 14:24:46 +0100"  >&lt;blockquote&gt;&lt;p&gt;Maybe .containsOnlyLiveDocs()?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;+1&lt;/p&gt;</comment>
                    <comment id="13119000" author="cmale" created="Sun, 2 Oct 2011 13:25:15 +0100"  >&lt;p&gt;Patch updated following the changes in &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-3474&quot; title=&quot;pass liveDocs Bits down in scorercontext, instead of Weights pulling from the reader &quot;&gt;&lt;del&gt;LUCENE-3474&lt;/del&gt;&lt;/a&gt;.  (Note, this patch also fixes a missed change in &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-3474&quot; title=&quot;pass liveDocs Bits down in scorercontext, instead of Weights pulling from the reader &quot;&gt;&lt;del&gt;LUCENE-3474&lt;/del&gt;&lt;/a&gt;, in MultiPhraseQuery.UnionDocsAndPositionsEnum).&lt;/p&gt;

&lt;p&gt;New patch features:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;liveDocsOnly() -&amp;gt; containsOnlyLiveDocs()&lt;/li&gt;
	&lt;li&gt;getRandomAccessBits() and useRandomAccess() are gone, replaced by some additional logic in IS.  Now we check if the DocIdSet is a Bits impl, and then we consult a protected method in IS called useRandomAccess().&lt;/li&gt;
	&lt;li&gt;At the moment useRandomAccess() just returns true, while we discuss what heuristics are best to apply here.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="13119005" author="rcmuir" created="Sun, 2 Oct 2011 14:03:27 +0100"  >&lt;p&gt;I don&apos;t understand the de-optimizations to termquery in the patch.&lt;/p&gt;</comment>
                    <comment id="13119006" author="cmale" created="Sun, 2 Oct 2011 14:05:25 +0100"  >&lt;p&gt;I used what has been in the patches so far.  If its out of date, just tell me.&lt;/p&gt;</comment>
                    <comment id="13119007" author="rcmuir" created="Sun, 2 Oct 2011 14:07:22 +0100"  >&lt;p&gt;it doesnt have anything to do with this issue.&lt;/p&gt;</comment>
                    <comment id="13120252" author="mikemccand" created="Tue, 4 Oct 2011 17:27:07 +0100"  >&lt;p&gt;What a tiny patch this has turned into!&lt;/p&gt;

&lt;p&gt;It looks great.&lt;/p&gt;

&lt;p&gt;I agree the TQ changes look like a merge mistake?  We should just keep&lt;br/&gt;
trunk here?&lt;/p&gt;

&lt;p&gt;Can we name it DocIdSet.containsOnlyLiveDocs?  I don&apos;t think we need&lt;br/&gt;
the &quot;is&quot; prefix?  Can you add @lucene.experimental to it?&lt;/p&gt;

&lt;p&gt;For the default IS heuristic, how about testing 100 evenly spaced&lt;br/&gt;
bits?  If more than 1 is set, and we can early-exit during the&lt;br/&gt;
testing, we use random access?  We can make the two values (100 and 1)&lt;br/&gt;
settable in expert IS ctors?&lt;/p&gt;</comment>
                    <comment id="13120264" author="rcmuir" created="Tue, 4 Oct 2011 17:37:42 +0100"  >&lt;blockquote&gt;
&lt;p&gt;For the default IS heuristic, how about testing 100 evenly spaced&lt;br/&gt;
bits? &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;How about grab an iterator like today, pull the first bit, if this takes a long time because the filter is sparse, &lt;br/&gt;
we dive into the conjunction alg we do today anyway, no wasted effort.&lt;/p&gt;

&lt;p&gt;Otherwise if its &amp;lt; 100, use it as liveDocs.&lt;/p&gt;

&lt;p&gt;we can nuke the &apos;boolean&apos; protected method and figure out if/how to add abstractions later.&lt;/p&gt;</comment>
                    <comment id="13120293" author="rcmuir" created="Tue, 4 Oct 2011 18:18:12 +0100"  >&lt;p&gt;Also, when we pass filter &quot;down low&quot; as liveDocs, we should ensure we set the appropriate inOrder/topLevel params so we can get BooleanScorer,&lt;br/&gt;
since we won&apos;t need to advance() it.&lt;/p&gt;</comment>
                    <comment id="13120356" author="rcmuir" created="Tue, 4 Oct 2011 19:22:21 +0100"  >&lt;p&gt;and current patch is missing the optimization for case 2 described above:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;2. sparse/non-random-access filter, incorporates deletes: Here we might pass null as &apos;acceptDocs&apos; to the scorercontext, so we no longer redundantly check deleted docs.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;ll update the patch to support BooleanScorer and optimize this case.&lt;/p&gt;</comment>
                    <comment id="13120362" author="mikemccand" created="Tue, 4 Oct 2011 19:31:14 +0100"  >&lt;blockquote&gt;
&lt;p&gt;How about grab an iterator like today, pull the first bit, if this takes a long time because the filter is sparse, &lt;br/&gt;
we dive into the conjunction alg we do today anyway, no wasted effort.&lt;/p&gt;

&lt;p&gt;Otherwise if its &amp;lt; 100, use it as liveDocs.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;+1, I like that.&lt;/p&gt;

&lt;p&gt;But, &amp;lt; maxDoc()/100; and maybe we make expert setter for that 100.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Also, when we pass filter &quot;down low&quot; as liveDocs, we should ensure we set the appropriate inOrder/topLevel params so we can get BooleanScorer,&lt;br/&gt;
since we won&apos;t need to advance() it.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Good catch, yes!&lt;/p&gt;</comment>
                    <comment id="13120372" author="mikemccand" created="Tue, 4 Oct 2011 19:43:27 +0100"  >&lt;p&gt;Duh, nevermind: I think it is just a &amp;lt; 100 check (no maxDoc involved).  It&apos;s as if we are &lt;span class=&quot;error&quot;&gt;&amp;#91;approximately&amp;#93;&lt;/span&gt; checking how many set bits in first 100 docs, and if we hit at least 1 such but we assume that means filter is &amp;gt; 1% dense.&lt;/p&gt;</comment>
                    <comment id="13120383" author="rcmuir" created="Tue, 4 Oct 2011 20:03:03 +0100"  >&lt;p&gt;updated patch:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;implements heuristic with getter/setter (defaults to random access if we estimate filter accepts &amp;gt; 1% of documents)&lt;/li&gt;
	&lt;li&gt;sets the inOrder/topLevel stuff correct when we use random access &amp;lt;-- but we should add a test that we get BS1 here!&lt;/li&gt;
	&lt;li&gt;when the filter is sparse, but contains only live docs, we pass null as liveDocs.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="13120388" author="mikemccand" created="Tue, 4 Oct 2011 20:10:11 +0100"  >&lt;p&gt;Patch looks great!&lt;/p&gt;</comment>
                    <comment id="13120421" author="rcmuir" created="Tue, 4 Oct 2011 20:55:46 +0100"  >&lt;p&gt;just a code style tweak, a test to make sure we get BS1 with random access filters, and randomization of the parameter value in LuceneTestCase.&lt;/p&gt;</comment>
                    <comment id="13120649" author="cmale" created="Wed, 5 Oct 2011 03:17:03 +0100"  >&lt;p&gt;Small improvements:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Changed isContainsOnlyLiveDocs to containsOnlyLiveDocs&lt;/li&gt;
	&lt;li&gt;Changed visibility of containsOnlyLiveDocs field since with the getter/setters it doesn&apos;t need to be protected.&lt;/li&gt;
	&lt;li&gt;Tidied the documentation on the getter/setters of the threshold in IS&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I think we&apos;re good to go?&lt;/p&gt;</comment>
                    <comment id="13120733" author="kimchy" created="Wed, 5 Oct 2011 08:30:20 +0100"  >&lt;p&gt;Hey, briefly checked the patch, and wondering out loud if it make sense to have similar random access logic in FilteredQuery?&lt;/p&gt;</comment>
                    <comment id="13120747" author="cmale" created="Wed, 5 Oct 2011 09:11:51 +0100"  >&lt;p&gt;It certainly shares alot of similarities with the logic in IS so I think there would be benefit yeah.&lt;/p&gt;</comment>
                    <comment id="13120784" author="rcmuir" created="Wed, 5 Oct 2011 10:58:04 +0100"  >&lt;p&gt;maybe for FilteredQuery just open a separate issue? In this case I think&lt;br/&gt;
we should just give it another Scorer impl.&lt;/p&gt;</comment>
                    <comment id="13121154" author="mikemccand" created="Wed, 5 Oct 2011 18:09:09 +0100"  >&lt;p&gt;+1 for new issue for FilteredQuery&lt;/p&gt;

&lt;p&gt;Patch looks great Chris &amp;#8211; I think it&apos;s ready!  Finally &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;Tiny fix to the jdocs for IS.setFilterRandomAccessThreshold &amp;#8211; &quot;Threshold use to heuristics&quot; -&amp;gt; &quot;Threshold used in heuristic&quot;.&lt;/p&gt;

&lt;p&gt;I think we should run before/after benchmarks before committing... I&apos;ll try to do this soon and post back.&lt;/p&gt;</comment>
                    <comment id="13121177" author="thetaphi" created="Wed, 5 Oct 2011 18:29:07 +0100"  >&lt;p&gt;Can you only remove the unchecked exception here (FieldCacheRangeFilter):&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;abstract&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; get(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; doc) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; ArrayIndexOutOfBoundsException;&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This exception is only used internally to ignore range checks, but we dont need to declare (and impl classes no longer declare it at all).&lt;/p&gt;

&lt;p&gt;Also FieldCacheDocIdSet does not implement Bits completely?&lt;/p&gt;</comment>
                    <comment id="13121316" author="thetaphi" created="Wed, 5 Oct 2011 19:17:43 +0100"  >&lt;p&gt;New patch:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Fixed FieldCacheRangeFilterDocIdSet to implement bits&lt;/li&gt;
	&lt;li&gt;Removed deleted docs handling in this filter. We explicitely pass false. No the iterator and get(bits) may return deleted docs.&lt;/li&gt;
	&lt;li&gt;Made AndBits final (speed and no need to subclass)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The question here: I see no filter that explicitely returns true for the deletedDocs handling. But e.g. most filters actually dont have deleted docs, like MultiTermQueryWF,...&lt;/p&gt;</comment>
                    <comment id="13121326" author="thetaphi" created="Wed, 5 Oct 2011 19:21:04 +0100"  >&lt;p&gt;I still disagree with the setter in DocIdSet to make it respect setContainsOnlyLiveDocs(). This is borken and only specific to FCRangeFilter. This method should not be there, instead the DocIdSet should return this info, e.g. FieldCacheRangeFilterDocIdSet should implement this method and return false.&lt;/p&gt;</comment>
                    <comment id="13121334" author="thetaphi" created="Wed, 5 Oct 2011 19:34:04 +0100"  >&lt;p&gt;I modified my patch for FieldCacheRangeFilter to enforce that it does not respect deletes (it throws UOE on the setter).&lt;/p&gt;

&lt;p&gt;I checked some combinations, setContainsOnlyLiveDocs() cannot go in like that!!!&lt;/p&gt;

&lt;p&gt;CachingWrapperFilter should have its own handling of this and return the correct setting, but not modify an already created bitset/whatever DocIdSet. My above patch does no longer respect deleted docs in FieldCacheRangeFilter and returns false from the beginning. But if you cache this filter, it suddenly tries to set the boolean to true -&amp;gt; test fail&lt;/p&gt;

&lt;p&gt;Also all Filters that internally use deleted docs, should return true from the beginning. We can maybe add the setter to FixedBitSet, so filter impls can easily set this bit, but it should not be a setter in DocIdSet!&lt;/p&gt;</comment>
                    <comment id="13121449" author="thetaphi" created="Wed, 5 Oct 2011 21:37:15 +0100"  >&lt;p&gt;Further investigations showed more problems:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;FilteredDocIdSet does never implement Bits, but it should if the wrapped filter implements Bits. This cannot be done as two different implementation would be needed. I have no idea how to solve this.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I uploaded a new patch that fixes the problems from before:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;CachingWrapperFilter now only set the flag for containsOnlyLiveDocs to true, if it was true before, too. If the orginal filter returned a DocIdSet without that flag, the cached filter cannot suddenly set it to true&lt;/li&gt;
	&lt;li&gt;CachingWrapperFilter also copies the liveDocs when it copies to FixedBitSet (e.g. QueryWrapperFilter).&lt;/li&gt;
	&lt;li&gt;The default for containsOnlyLiveDocs is true, as all current filters were always resepcting this (exept FieldCacheRangeFilter since the rewrite). All filters in Lucene use liveDocs, because this was a requirement in older Lucene versions!&lt;/li&gt;
	&lt;li&gt;QueryWrapperFilter may ignore liveDocs and simply return false for the flag.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;In general I would like it more to rip the deleted docs handling in CachingWrapperFilter, as it no longer needs to take care. CWF should simply return containsOnlyLiveDocs=false if the deleted docs need to be merged in. There is no need to and them in using FilteredDocIdSet (which slows down for the random access case, see above)&lt;/p&gt;</comment>
                    <comment id="13121560" author="thetaphi" created="Wed, 5 Oct 2011 23:45:16 +0100"  >&lt;p&gt;More problems (I am currently rewriting the whole liveDocs stuff):&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;DocIdBitSet does not implement Bits, but its random access.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Another idea I had:&lt;br/&gt;
We could do Filter.getDocIdSet like Weight.scorer: Pass the live docs down. This could improve e.g. ChainedFilter as it can simply pass the results of filter down the chain, if its random access. Also QueryWrapperFilter could directly pass the incoming bits downto the wrapped Query (see comment in current code).&lt;/p&gt;

&lt;p&gt;And finally we would not need the containsOnlyLiveDocs flag at all. If IndexSearcher does not need deleted docs to be handled in the filter, it could pass down null, if it passes liveDocs down to the filter, the filter is required to respect them (like scorers).&lt;/p&gt;

&lt;p&gt;CachingWrapperFilter would use AndBits/FilteredDocIdSet in all cases to combine the cached result (which it caches always without liveDocs). This is still faster than the current approcah where deldocs are handled quite oftenh multiple times in the query execution.&lt;/p&gt;</comment>
                    <comment id="13121677" author="cmale" created="Thu, 6 Oct 2011 03:11:23 +0100"  >&lt;p&gt;That is a lot to take in.  Let me see if I understand:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Basically you&apos;re saying that allowing external code to setContainsOnlyLiveDocs is broken in CachingWrapperFilter since it makes a decision that a Filter contains only live docs, when in fact the Filter might not.&lt;/li&gt;
	&lt;li&gt;You&apos;re also arguing that most Filters take liveDocs into consideration anyway.&lt;/li&gt;
	&lt;li&gt;You suggest we pass liveDocs into Filter.getDocIdSet requiring the Filter to uses them (mirroring the Weight/Scorer API).  I kind of like this idea.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I don&apos;t think its a crisis if some DocIdSet impls don&apos;t implement Bits.  I personally see this issue as providing the framework for doing random-access filtering, not necessarily making it happen with every DocIdSet.  &lt;/p&gt;</comment>
                    <comment id="13121680" author="rcmuir" created="Thu, 6 Oct 2011 03:24:19 +0100"  >&lt;p&gt;Thanks Uwe for the reviewing/policing!&lt;/p&gt;

&lt;p&gt;Chris, I do agree its not a crisis, but i think its best if we set everything up to work nicely.&lt;/p&gt;

&lt;p&gt;I do think its really bad news if a filter claims it containsOnlyLiveDocs but in fact it does not... this is a big blocker for committing anything, because it will only create bugs.&lt;/p&gt;</comment>
                    <comment id="13121693" author="cmale" created="Thu, 6 Oct 2011 04:12:40 +0100"  >&lt;p&gt;What do you think of the idea of passing liveDocs into Filter.getDocIdSet?&lt;/p&gt;</comment>
                    <comment id="13121779" author="thetaphi" created="Thu, 6 Oct 2011 08:52:14 +0100"  >&lt;p&gt;Hi Chris, hi Male,&lt;/p&gt;

&lt;p&gt;I was going to bed after my last post. I had a crisis with two facts in the new API, that do no play nicely together. I thought the whole night about it again and I also started to recode some details last evening, but all was not so fine (but I found lots of problems, so it&apos;s a good thing that I started to code - especially on several filters that are not so basic like those which only use FixedFitSet/OpenBitSet):&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;the hidden implementation of Bits is a nice idea, but has one big problem: Java is a strongly-typed language. If a DocIdSet implements Bits, but you want to wrap it using FilteredDocIdSet, this interface implementation  might suddenly go away, because the wrapper class does not implement Bits. If we make FilteredDocIdSet implement Bits, its also wrong, as it might wrap another DocIdSet that is not random access. So I tend to keep DocIdSet abstrcat and let it only expose functions that return a Bits interface. The same is that DocIdSet does not directly implement DocIdSetIterator, it can just return one. So I would strongly recommend to add a method like iterator() that returns a impl and not rely on &quot;marker interfaces&quot;. I would favor &quot;Bits DocIdSet.bits()&quot; - would be in line with the iterator method. If the implementing class like FixedBitSet implements it itsself and returns &quot;this&quot; is an implementation detail. If DocIdSet does not allow random access it should expose with an exception thrown by bits or if it returns null. Does not really matter to me. - In general a wrapper like FilteredDocIdSet can do this in one class, wrapping bits() would check if bits() returns non-null, and then wrap another wrapper around bits() that uses match() to filter. The impl of this class is fast and supports both (iterator and bits, if available).&lt;/li&gt;
	&lt;li&gt;the other thing, I dont like, is the setContainsOnlyLiveDocs setter on DocIdSet. It allows anybody to change the DocIdSet (which should have an API that exposes only read-access). Only classes like FixedBitSet that implement this read-only interface might be able to change it from their own API (means the setter might be in the various DocIdSet implementations in oal.util). A consumer of the filter should not be able to change the DocIdSet behaviour from outside using a public API. I started to rewrite this yesterday and only left the getter in DocIdSet, but added the setter to FixedBitSet, OpenBitSet, DocIdBitSet,... The setter in the abstract base class also violates unmodifiable of EMPTY_DOCIDSET. This impl should be &quot;containsOnlyLiveDocs=true&quot;) and this must be unchangeable fixed.&lt;/li&gt;
	&lt;li&gt;Also DocIdSet is a class not really related solely to Filters, e.g. Scorer extends DocIdSetIterator or DocsEnum extends DocIdSetIterator, Solr Facetting uses DocIdSet. DocIdSet is just a holder class for a bunch of documents exposing a iterator (and a Bits API - this is why I want two getter methods and no interface magic)). The existence of live docs is outside it&apos;s scope. I therefore would like a similar API like for scorers, so IndexSearcher can ask the Filter for a DocIdSet based on the given liveDocs (like the scorer method in Weights). The returned DocIdSet would not know if it only has live Docs or not (as the Scorer itsself also does not expose this information). CachingWrapperFilter is little bit special, but this one would always ask the wrapped Filter for a DocidSet without deletions and cache that one, but always return a FilteredDocIdSet bringing the liveDocs passed from IndexSearcher in. The cache would then always be without LiveDocs and easier to maintain. Reopening segments would never need to reload cache. CachingWrapperFilter would just decide on the fact if IndexSearcher passes a liveDocs BitSet or not, if it needs to use it or not (in its own getDocIdSet method). If we have a query and only filter some documents, IndexSearcher already knows about liveDocs from the main scorer and would pass null to the filter. This would remove lots of additional checks to liveDocs. Only the main scorer would know about them, the filter will ignore them (so there is no overhead in CachingWrapperFilter, as it can return the cached filter directly to IndexSearcher, without wrapping). QueryWrapperFilter could pass the liveDocs through the wrapped filter, too.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;I may have time today to implement some parts of this, should not be to difficult.&lt;/p&gt;</comment>
                    <comment id="13121786" author="cmale" created="Thu, 6 Oct 2011 09:01:07 +0100"  >&lt;p&gt;Okay thats alot to take in again.&lt;/p&gt;

&lt;p&gt;You&apos;ve made a good case for dropping setContainsOnlyLiveDocs, I totally agree.  I really do like the idea of adding the acceptDocs to Filter.getDocIdSet.&lt;/p&gt;

&lt;p&gt;I&apos;m also comfortable with adding .bits() to DocIdSet to address the typing problem.&lt;/p&gt;

&lt;p&gt;Should we bash out a quick patch making these changes and see how it looks?&lt;/p&gt;</comment>
                    <comment id="13121790" author="thetaphi" created="Thu, 6 Oct 2011 09:14:28 +0100"  >&lt;p&gt;+1, I have to revert here a lot again because I was trying to move the setLiveDocsOnly/liveDocsOnly down to FixedBitSet &amp;amp; Co, but this is too complicated.&lt;/p&gt;

&lt;p&gt;Should I start to hack something together? The biuggest change will be in all filter impls to add the parameter to getDocIdSet().&lt;/p&gt;</comment>
                    <comment id="13121807" author="cmale" created="Thu, 6 Oct 2011 10:08:06 +0100"  >&lt;p&gt;Yes please put something together and then we&apos;ll review / iterate.&lt;/p&gt;</comment>
                    <comment id="13121869" author="thetaphi" created="Thu, 6 Oct 2011 13:13:39 +0100"  >&lt;p&gt;A first rewrite of Lucene core to pass acceptDocs down to Filter.getDocIdSet:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;optimized and simpliefied CachingWrapper* - no deletesmode anymore&lt;/li&gt;
	&lt;li&gt;FieldCacheTermsFilter has optimized DocIdSet&lt;/li&gt;
	&lt;li&gt;Added bits() to all DocIdSet&lt;/li&gt;
	&lt;li&gt;IndexSearcher.searchWithFilter was rewritten to pass liveDocs down.&lt;/li&gt;
	&lt;li&gt;AndBits is no longer needed&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The tests are not yet rewritten, still 55 compile errors.... This patch is just for review&lt;/p&gt;</comment>
                    <comment id="13121877" author="rcmuir" created="Thu, 6 Oct 2011 13:29:17 +0100"  >&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;I therefore would like a similar API like for scorers, so IndexSearcher can ask the Filter for a DocIdSet based on the given liveDocs (like the scorer method in Weights).
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If this is the case, then in the !randomAccess path of indexsearcher.java please pass null as liveDocs.&lt;/p&gt;</comment>
                    <comment id="13121882" author="rcmuir" created="Thu, 6 Oct 2011 13:33:53 +0100"  >&lt;p&gt;adding back this optimization, again.&lt;/p&gt;

&lt;p&gt;before committing please give me time to write tests to ensure we aren&apos;t losing these optimizations.&lt;/p&gt;</comment>
                    <comment id="13121885" author="thetaphi" created="Thu, 6 Oct 2011 13:35:29 +0100"  >&lt;p&gt;Robert, thanks!&lt;/p&gt;

&lt;p&gt;I missed this line:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Bits acceptDocs = filterContainsLiveDocs ? &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; : context.reader.getLiveDocs();
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;As we now always use live docs in filter this would always be null!&lt;/p&gt;</comment>
                    <comment id="13121975" author="thetaphi" created="Thu, 6 Oct 2011 15:26:57 +0100"  >&lt;p&gt;Here a patch with almost all core tests rewritten (I left out the CachingWrapper tests, as I nuked DeletesMode). Its just for demonstartion.&lt;/p&gt;

&lt;p&gt;Some tests have really stupid filters and work only with optimized indexes. I added asserts in those filters (except one), that acceptDocs==null. The remaining one uses QueryUtils and I have no idea whats going on there, that the acceptDocs!=null.&lt;/p&gt;

&lt;p&gt;When looking at the code in IndexSearcher, I would propose to remove all Filter special handling in IndexSaercher and move all code over to FilteredQuery (with all our optimizations). If you call IS.search(query, filter,...), IndexSearcher would simply wrap with FilteredQuery and we would have no code duplication and much easier maintainability in IS.&lt;/p&gt;</comment>
                    <comment id="13121976" author="rcmuir" created="Thu, 6 Oct 2011 15:29:34 +0100"  >&lt;blockquote&gt;
&lt;p&gt;When looking at the code in IndexSearcher, I would propose to remove all Filter special handling in IndexSaercher and move all code over to FilteredQuery (with all our optimizations). If you call IS.search(query, filter,...), IndexSearcher would simply wrap with FilteredQuery and we would have no code duplication and much easier maintainability in IS.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;+1&lt;/p&gt;

&lt;p&gt;Also, we can nuke AndBits.java now?&lt;/p&gt;</comment>
                    <comment id="13121978" author="thetaphi" created="Thu, 6 Oct 2011 15:32:48 +0100"  >&lt;blockquote&gt;&lt;p&gt;Also, we can nuke AndBits.java now?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It was nuked here, but still made it into the patch &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="13122349" author="thetaphi" created="Thu, 6 Oct 2011 23:04:48 +0100"  >&lt;p&gt;New patch (still only Lucene Core, no contrib/modules/solr modified):&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Nuked Filter handling completely from IndexSearcher. Algorithms and Random access optimizations were added to FilteredQuery. IS.search(Query, Filter,...) now only wraps the query with the Filter, if filter!=null (small helper method).&lt;/li&gt;
	&lt;li&gt;The random access threshhold is still in IndexSearcher.setFilterRandomAccessThreshold(), FilteredQuery gets it in it&apos;s weight from IndexSearcher. This is maybe not the best solutions, we can also add a setter to FilteredQuery and IS passes it to FilteredQuery.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;What do you think? Mike: Can you do perf tests?&lt;/p&gt;</comment>
                    <comment id="13122355" author="mikemccand" created="Thu, 6 Oct 2011 23:16:54 +0100"  >&lt;p&gt;I will do perf tests!  Working on getting luceneutil to do random filters... but could be a few days (I&apos;m offline for the next 3 days) unless I can commit to luceneutil and someone else can run the tests...&lt;/p&gt;</comment>
                    <comment id="13122356" author="thetaphi" created="Thu, 6 Oct 2011 23:17:10 +0100"  >&lt;p&gt;I will add further tests tomorrow, to test all code paths in FilteredQuery. There is a short-circuit (it implements Scorer.score(Collector) for fast top-scorer as it existed in IndexSearcher.searchWithFilter before. To test the standard scorer behavior (nextDoc/advance), a test should be added that adds FilteredQuery as clause with others to a BQ, so ConjunctionScorer tries nextDoc/advance. &lt;/p&gt;

&lt;p&gt;Somebody else might look at the scorer and double check. I had to rewrite FilteredQuery#Weight#Scorer, as the filterIter is already advanced to first doc (to check the random access threshold).&lt;/p&gt;</comment>
                    <comment id="13122398" author="thetaphi" created="Fri, 7 Oct 2011 00:12:29 +0100"  >&lt;p&gt;New patch:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Fixed the FilteredQuery-Scorer&apos;s advance by logic change. Its now much easier to understand. The corresponding tests are in TestFilteredQuery: All tests are executed 2 times: as random access filter and as iterator filter. Also FilteredQuery is added to BQ, so the conventional scorer (nextDoc/advance) is tested.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The tests for CachingWrapper* are still disabled, have to rewrite them tomorrow. Then we can change contrib and Solr.&lt;/p&gt;</comment>
                    <comment id="13122691" author="thetaphi" created="Fri, 7 Oct 2011 12:05:47 +0100"  >&lt;p&gt;Improved patch with modules and contrib fixed, Solr still on TODO:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;BooleanFilter and ChainedFilter do not apply acceptDocs to their Filter clauses. Instead they apply the acceptDocs on the final DocIdSet using BitsFilteredDocIdSet (see below). This improves filter performance, as the deleted documents are not applied on each clause.&lt;/li&gt;
	&lt;li&gt;New helper class BitsFilteredDocIdSet, which supplies a wrap method, that can apply a Bits (e.g. acceptDocs) to a DocIdSet. This is useful for Filters, that build DocIdSets without respecting the acceptDocs parameter and only want to apply the deletions live.&lt;/li&gt;
	&lt;li&gt;CachingWrapperFilter and CachingSpanFilter now also use the acceptDocs wrapper, as the filters are cached without acceptDocs.&lt;/li&gt;
	&lt;li&gt;Fixed Javadocs, small changes to IndexSearcher&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="13122729" author="rcmuir" created="Fri, 7 Oct 2011 13:20:32 +0100"  >&lt;p&gt;This looks awesome!&lt;/p&gt;</comment>
                    <comment id="13122755" author="rcmuir" created="Fri, 7 Oct 2011 14:04:46 +0100"  >&lt;p&gt;updated patch: i fixed solr to the api changes and simply disabled the optimization in SolrIndexSearcher.&lt;/p&gt;

&lt;p&gt;I think this is the most conservative way to proceed, we can then open a followup issue to make whatever changes are necessary to Solr APIs so it can use the optimization (looks complex)&lt;/p&gt;</comment>
                    <comment id="13122760" author="cmale" created="Fri, 7 Oct 2011 14:08:10 +0100"  >&lt;p&gt;Awesome idea Robert, I was staring at the Solr code a little bewildered about how to integrate the optimization.&lt;/p&gt;</comment>
                    <comment id="13122771" author="cmale" created="Fri, 7 Oct 2011 14:21:16 +0100"  >&lt;p&gt;Apart from Mike&apos;s benchmarks, are we waiting on any further changes to the patch?&lt;/p&gt;</comment>
                    <comment id="13122799" author="rcmuir" created="Fri, 7 Oct 2011 14:38:13 +0100"  >&lt;p&gt;Just until the policeman says &apos;final patch&apos; &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="13122802" author="thetaphi" created="Fri, 7 Oct 2011 14:46:25 +0100"  >&lt;p&gt;Chris: I have to fix the CachingWrapper tests (soon). And add some acceptDocs to solr, which Robert simply ignored.&lt;/p&gt;</comment>
                    <comment id="13122815" author="thetaphi" created="Fri, 7 Oct 2011 15:07:28 +0100"  >&lt;p&gt;Patch with Solr fixes by Robert improved. Now usage of acceptDocs is correct. There is room to optimize, but this is the correct way to solve (as Filters are required to respect deleted docs in trunk).&lt;/p&gt;

&lt;p&gt;Now the remaining caching wrapper changes, then we are ready.&lt;/p&gt;</comment>
                    <comment id="13122851" author="yseeley@gmail.com" created="Fri, 7 Oct 2011 16:06:14 +0100"  >&lt;p&gt;At what levels of bitset sparseness does it make sense to use random access?  I ask because sometimes Solr actually knows the sparseness of it&apos;s sets.&lt;/p&gt;</comment>
                    <comment id="13122854" author="cmale" created="Fri, 7 Oct 2011 16:12:31 +0100"  >&lt;p&gt;Mike suggested earlier in the issue anything denser than 1% sees benefits from random-access.&lt;/p&gt;</comment>
                    <comment id="13122856" author="yseeley@gmail.com" created="Fri, 7 Oct 2011 16:15:33 +0100"  >&lt;p&gt;OK, thanks Chris.  I&apos;ll take a shot at optimizing this patch for Solr a bit more.&lt;/p&gt;</comment>
                    <comment id="13122858" author="jasonrutherglen" created="Fri, 7 Oct 2011 16:17:15 +0100"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                    <comment id="13122866" author="thetaphi" created="Fri, 7 Oct 2011 16:25:38 +0100"  >&lt;p&gt;Final patch.&lt;/p&gt;

&lt;p&gt;The test for CachingWrapperFilter/CachingSpanFilter were simplified to only check that they actually respect deletions.&lt;/p&gt;

&lt;p&gt;I think thats ready to commit after some perf testing.&lt;/p&gt;

&lt;p&gt;Robert: If you have time?&lt;/p&gt;</comment>
                    <comment id="13122875" author="yseeley@gmail.com" created="Fri, 7 Oct 2011 16:34:23 +0100"  >&lt;p&gt;OK, I&apos;ll start again from the final patch.&lt;/p&gt;</comment>
                    <comment id="13122893" author="thetaphi" created="Fri, 7 Oct 2011 16:51:31 +0100"  >&lt;p&gt;Sorry for interrupting you. I only changed Lucene classes, if that helps. With TortoiseSVN you can partly apply patches.&lt;/p&gt;</comment>
                    <comment id="13122941" author="rcmuir" created="Fri, 7 Oct 2011 17:38:48 +0100"  >&lt;blockquote&gt;
&lt;p&gt;Robert: If you have time?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;m attempting to benchmark the patch now with the example tasks mike added to luceneutil early this morning:&lt;br/&gt;
&lt;a href=&quot;http://code.google.com/a/apache-extras.org/p/luceneutil/source/browse/eg.filter.tasks?spec=svn3ea6dafca66a00e1dbf4563d1098b7418e386cbf&amp;amp;r=3ea6dafca66a00e1dbf4563d1098b7418e386cbf&quot; class=&quot;external-link&quot;&gt;http://code.google.com/a/apache-extras.org/p/luceneutil/source/browse/eg.filter.tasks?spec=svn3ea6dafca66a00e1dbf4563d1098b7418e386cbf&amp;amp;r=3ea6dafca66a00e1dbf4563d1098b7418e386cbf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I&apos;ll report back if i&apos;m able to get results... takes a few hours here.&lt;/p&gt;</comment>
                    <comment id="13123072" author="rcmuir" created="Fri, 7 Oct 2011 20:03:06 +0100"  >&lt;p&gt;Here&apos;s the results... F0.1 for example means filter accepting a random 0.1% of documents.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;                Task   QPS trunkStdDev trunk   QPS patchStdDev patch      Pct diff
          PhraseF0.1       67.61        1.89       29.85        2.52  -60% -  -50%
          PhraseF0.5       20.08        0.72       13.09        1.11  -42% -  -26%
          PhraseF1.0       12.37        0.46        8.84        0.88  -37% -  -18%
      OrHighHighF0.1       78.84        1.19       59.96        2.87  -28% -  -19%
            TermF0.5      133.27        4.80      125.91        7.29  -14% -    3%
          OrHighHigh       12.73        0.45       12.13        0.92  -14% -    6%
              Fuzzy1       57.63        1.70       56.62        2.33   -8% -    5%
              Fuzzy2       96.92        2.25       96.19        2.63   -5% -    4%
   AndHighHighF100.0       16.99        0.50       16.92        1.38  -11% -   10%
    AndHighHighF99.0       17.00        0.48       16.94        1.37  -10% -   10%
    AndHighHighF95.0       17.00        0.48       16.98        1.35  -10% -   10%
          Fuzzy2F0.1      107.24        2.74      107.29        2.68   -4% -    5%
    AndHighHighF90.0       17.04        0.47       17.13        1.36   -9% -   11%
          Fuzzy1F0.1       74.60        1.58       75.03        1.55   -3% -    4%
  SloppyPhraseF100.0        7.82        0.16        7.89        0.24   -4% -    6%
   SloppyPhraseF99.0        7.82        0.16        7.92        0.23   -3% -    6%
        Fuzzy2F100.0       97.16        2.31       98.43        2.19   -3% -    6%
            PKLookup      171.71        6.83      174.15        7.28   -6% -   10%
        WildcardF0.1       67.96        1.06       69.08        1.95   -2% -    6%
            Wildcard       43.40        0.89       44.13        0.92   -2% -    5%
         Fuzzy2F99.0       96.83        2.46       98.49        2.21   -3% -    6%
         Fuzzy2F95.0       97.01        2.47       98.79        2.18   -2% -    6%
      SpanNearF100.0        3.11        0.04        3.18        0.09   -1% -    6%
    AndHighHighF75.0       17.13        0.48       17.57        1.36   -7% -   13%
         Fuzzy2F90.0       97.01        2.53       99.49        2.10   -2% -    7%
      OrHighHighF0.5       31.57        0.45       32.41        1.07   -2% -    7%
   SloppyPhraseF95.0        7.82        0.18        8.03        0.25   -2% -    8%
       SpanNearF99.0        3.11        0.04        3.20        0.09   -1% -    7%
     AndHighHighF0.1      136.96        3.21      140.94        5.15   -3% -    9%
    SloppyPhraseF0.1       56.27        0.88       57.97        1.47   -1% -    7%
          Fuzzy2F0.5      100.39        2.48      103.57        2.47   -1% -    8%
          PhraseF2.0        7.95        0.31        8.20        0.65   -8% -   15%
         AndHighHigh       17.97        0.46       18.55        0.84   -3% -   10%
            TermF0.1      351.76        9.38      363.42       16.25   -3% -   10%
        SloppyPhrase        7.90        0.16        8.19        0.19    0% -    8%
              Phrase        3.69        0.12        3.83        0.13   -3% -   10%
        WildcardF0.5       62.57        0.88       65.31        2.07    0% -    9%
   SloppyPhraseF90.0        7.83        0.16        8.18        0.24    0% -    9%
         Fuzzy2F75.0       96.77        2.46      101.14        2.41    0% -    9%
            SpanNear        3.15        0.04        3.30        0.07    1% -    8%
                Term       71.54        4.98       74.98        5.61   -9% -   21%
       SpanNearF95.0        3.11        0.05        3.26        0.09    0% -    9%
        PhraseF100.0        3.49        0.13        3.68        0.15   -2% -   14%
         PhraseF99.0        3.49        0.12        3.69        0.15   -2% -   14%
        SpanNearF0.1       31.54        0.48       33.49        0.73    2% -   10%
         PhraseF95.0        3.49        0.12        3.72        0.16   -1% -   15%
       SpanNearF90.0        3.12        0.04        3.35        0.09    3% -   11%
         Fuzzy2F50.0       97.08        2.32      104.79        2.66    2% -   13%
         PhraseF90.0        3.49        0.13        3.78        0.16    0% -   17%
        Fuzzy1F100.0       47.68        1.41       52.27        1.08    4% -   15%
         Fuzzy1F99.0       47.57        1.49       52.28        1.19    4% -   16%
    AndHighHighF50.0       17.30        0.48       19.12        1.47    0% -   22%
        WildcardF1.0       58.03        0.81       64.32        2.40    5% -   16%
         Fuzzy1F95.0       47.59        1.50       52.84        1.17    5% -   17%
   SloppyPhraseF75.0        7.85        0.15        8.73        0.24    6% -   16%
          Fuzzy2F1.0       98.59        2.36      110.12        2.89    6% -   17%
         Fuzzy1F90.0       47.51        1.40       53.54        1.09    7% -   18%
         PhraseF75.0        3.51        0.13        3.98        0.18    4% -   22%
            TermF1.0       92.28        3.05      104.56        7.44    1% -   25%
       WildcardF99.0       36.01        0.76       40.88        1.16    8% -   19%
          Fuzzy1F0.5       59.00        1.10       67.10        1.36    9% -   18%
      WildcardF100.0       35.92        0.79       40.86        1.19    8% -   19%
       WildcardF95.0       36.01        0.75       41.02        1.19    8% -   19%
       WildcardF90.0       36.06        0.70       41.14        1.20    8% -   19%
         Fuzzy2F20.0       98.32        2.34      112.69        2.91    9% -   20%
       WildcardF75.0       36.19        0.62       41.69        1.15   10% -   20%
     AndHighHighF0.5       49.93        1.37       57.85        4.13    4% -   27%
         Fuzzy1F75.0       47.25        1.50       55.55        1.11   11% -   23%
         Fuzzy2F10.0       98.47        2.46      116.18        3.00   12% -   24%
       WildcardF50.0       36.77        0.55       43.44        1.29   12% -   23%
      OrHighHighF1.0       24.37        0.38       28.99        1.90    9% -   28%
          Fuzzy1F2.0       52.64        1.05       63.12        1.32   15% -   24%
       SpanNearF75.0        3.11        0.04        3.74        0.10   15% -   24%
          Fuzzy2F5.0       97.96        2.31      118.02        3.48   14% -   27%
          Fuzzy2F2.0       98.02        2.22      119.13        3.42   15% -   27%
    OrHighHighF100.0        7.70        0.34        9.51        0.34   13% -   33%
     OrHighHighF99.0        7.70        0.36        9.56        0.34   14% -   34%
         Fuzzy1F50.0       47.46        1.24       59.15        1.18   19% -   30%
         PhraseF50.0        3.57        0.12        4.45        0.23   14% -   35%
     OrHighHighF95.0        7.73        0.35        9.73        0.35   16% -   36%
   SloppyPhraseF50.0        7.92        0.16       10.09        0.28   21% -   33%
        WildcardF2.0       53.32        0.69       68.29        3.44   20% -   36%
     OrHighHighF90.0        7.77        0.35        9.97        0.35   18% -   39%
       WildcardF20.0       41.13        0.60       54.63        2.12   25% -   39%
     OrHighHighF75.0        7.91        0.32       10.73        0.36   26% -   45%
        WildcardF5.0       47.44        0.57       65.42        3.11   29% -   46%
       WildcardF10.0       44.01        0.53       61.16        2.61   31% -   46%
         Fuzzy1F20.0       49.57        1.20       69.49        1.70   33% -   47%
          Fuzzy1F1.0       54.39        1.07       76.95        2.03   35% -   48%
     AndHighHighF1.0       34.63        1.07       50.01        4.02   28% -   60%
          PhraseF5.0        5.16        0.20        7.61        0.75   27% -   68%
         Fuzzy1F10.0       50.23        1.07       75.36        2.11   42% -   57%
     OrHighHighF50.0        8.36        0.29       12.58        0.48   39% -   61%
      OrHighHighF2.0       19.65        0.34       29.58        2.27   36% -   65%
       SpanNearF50.0        3.11        0.04        4.76        0.12   47% -   58%
            TermF2.0       68.99        2.38      106.22        8.65   36% -   72%
          Fuzzy1F5.0       50.74        1.06       79.90        2.38   49% -   65%
         PhraseF20.0        3.81        0.13        6.10        0.45   43% -   78%
           TermF50.0       42.19        1.41       67.96        4.63   45% -   77%
           TermF75.0       41.36        1.46       67.47        5.30   45% -   82%
           TermF90.0       41.05        1.47       68.08        5.85   46% -   86%
           TermF95.0       41.03        1.49       68.08        6.14   45% -   87%
         PhraseF10.0        4.22        0.16        7.02        0.62   46% -   87%
           TermF99.0       40.99        1.56       68.31        6.21   45% -   89%
          TermF100.0       40.88        1.61       68.28        6.32   45% -   89%
    SloppyPhraseF0.5       18.81        0.30       31.53        0.96   59% -   75%
    AndHighHighF20.0       17.62        0.52       30.63        2.79   53% -   95%
      OrHighHighF5.0       14.99        0.29       27.44        1.98   66% -  100%
        SpanNearF0.5        9.17        0.12       17.12        0.42   79% -   93%
           TermF20.0       45.25        1.50       84.63        6.04   68% -  107%
     OrHighHighF20.0       10.35        0.25       19.60        1.08   74% -  104%
            TermF5.0       52.49        1.71       99.90        8.02   69% -  112%
     AndHighHighF2.0       25.97        0.81       50.45        4.72   70% -  119%
     OrHighHighF10.0       12.36        0.22       24.25        1.56   80% -  112%
           TermF10.0       46.97        1.47       92.60        7.08   76% -  119%
   SloppyPhraseF20.0        8.18        0.16       16.35        0.58   89% -  111%
        SpanNearF1.0        6.05        0.09       12.21        0.28   94% -  109%
    AndHighHighF10.0       18.44        0.55       40.77        4.15   92% -  151%
     AndHighHighF5.0       20.34        0.63       50.83        5.67  115% -  186%
   SloppyPhraseF10.0        8.52        0.17       22.79        0.96  151% -  184%
       SpanNearF20.0        3.15        0.05        9.03        0.24  174% -  198%
    SloppyPhraseF1.0       13.62        0.23       42.77        2.29  192% -  236%
        SpanNearF2.0        4.45        0.06       14.31        0.37  209% -  234%
    SloppyPhraseF5.0        9.12        0.17       29.98        1.41  207% -  250%
    SloppyPhraseF2.0       10.85        0.19       38.31        2.00  229% -  278%
       SpanNearF10.0        3.25        0.05       13.71        0.39  303% -  339%
        SpanNearF5.0        3.52        0.05       19.51        0.67  428% -  481%
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                    <comment id="13123095" author="rcmuir" created="Fri, 7 Oct 2011 20:23:46 +0100"  >&lt;p&gt;by the way, luceneutil noticed some problems:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Traceback (most recent call last):
  File &quot;localrun.py&quot;, line 46, in &amp;lt;module&amp;gt;
    comp.benchmark(&quot;trunk_vs_patch&quot;)
  File &quot;/home/rmuir/workspace/util/competition.py&quot;, line 194, in benchmark
    search=self.benchSearch, index=self.benchIndex, debugs=self._debug, debug=self._debug, verifyScores=self._verifyScores)
  File &quot;/home/rmuir/workspace/util/searchBench.py&quot;, line 130, in run
    raise RuntimeError(&apos;results differ: %s&apos; % str(cmpDiffs))
RuntimeError: results differ: ([], [&apos;query=body:changer~1.0 filter=CachingWrapperFilter(PreComputedRandomFilter(pctAccept=95.0)): hit 2 has wrong id/s [8684145] vs [6260043, 8684145]&apos;, &apos;query=body:changer~1.0 filter=CachingWrapperFilter(PreComputedRandomFilter(pctAccept=75.0)): wrong collapsed hit count: 4 vs 5&apos;, &apos;query=body:changer~1.0 filter=CachingWrapperFilter(PreComputedRandomFilter(pctAccept=99.0)): hit 2 has wrong id/s [8684145] vs [8043795]&apos;])
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I have no idea whats going on, but i&apos;ll upload my modifications to these filters to make them work with the patch (maybe i jacked it up).&lt;/p&gt;</comment>
                    <comment id="13123172" author="thetaphi" created="Fri, 7 Oct 2011 21:49:14 +0100"  >&lt;p&gt;I nice improvements!&lt;/p&gt;

&lt;p&gt;I dont understand the errors luceneutil prints, sorry. The patch looks correct, I see no issues. acceptDocs are applied consistent and correct. Maybe Mike can help what the messages mean. The question is: How does Luceneutil verifies the hits?&lt;/p&gt;</comment>
                    <comment id="13123209" author="simonw" created="Fri, 7 Oct 2011 22:27:01 +0100"  >&lt;p&gt;robert, how do you create the index? do you have two different indices for benchmarking or one? if you have two indices it could happen that one contains doc X &amp;lt; doc Y while the other has doc Y &amp;lt; doc X (doc ID wise). if both have the same score you get different order and luceneutil might fail? Just an idea...&lt;/p&gt;</comment>
                    <comment id="13123239" author="thetaphi" created="Fri, 7 Oct 2011 22:54:55 +0100"  >&lt;p&gt;The strange thing that I see is - two docids for one hit instead of one: &quot;hit 2 has wrong id/s &lt;span class=&quot;error&quot;&gt;&amp;#91;8684145&amp;#93;&lt;/span&gt; vs &lt;span class=&quot;error&quot;&gt;&amp;#91;6260043, 8684145&amp;#93;&lt;/span&gt;&quot; and a little bit later: &quot;wrong collapsed hit count: 4 vs 5&quot; - maybe an unrelated issue with grouping module? Was grouping also enabled during benchmarking? Otherwise I cannot explain those results.&lt;/p&gt;

&lt;p&gt;Simon: Robert said, both tests used the same, &#228;hm, identical index created before.&lt;/p&gt;</comment>
                    <comment id="13123275" author="yseeley@gmail.com" created="Fri, 7 Oct 2011 23:54:17 +0100"  >&lt;p&gt;Here&apos;s an update that passes null where appropriate to prevent extra checking and implements bits() as appropriate.&lt;/p&gt;

&lt;p&gt;Sort of an open question if some of the function query stuff should be changed (ValueSourceScorer, getRangeScorer, etc).  That&apos;s a more extensive change and can be in a diff issue if necessary.&lt;/p&gt;</comment>
                    <comment id="13123400" author="thetaphi" created="Sat, 8 Oct 2011 08:23:04 +0100"  >&lt;p&gt;Hi Yonik, thanks!&lt;/p&gt;

&lt;p&gt;Just to note, if you implement something with &quot;new DocIdSet() &lt;/p&gt;
{....}
&lt;p&gt;&quot;, there is no need to override bits() to return null, as the default always returns null. Only OpenBitSet/FixedBitSet and some FieldCache filters in Lucene core automatically implement bits() if directly used as DocIdSet.&lt;/p&gt;

&lt;p&gt;So the major changes in your patch are BitDocSet to implement random access and passing null as acceptDocs at some places (see comments)? I will merge all your changes into my checkout.&lt;/p&gt;</comment>
                    <comment id="13123418" author="thetaphi" created="Sat, 8 Oct 2011 10:31:24 +0100"  >&lt;p&gt;Attached you will find a new patch &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1536&quot; title=&quot;if a filter can support random access API, we should use it&quot;&gt;&lt;del&gt;LUCENE-1536&lt;/del&gt;&lt;/a&gt;.patch, incorporating Yonik&apos;s changes plus some minor improvements:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;changed Javadocs of DIS.bits() to explain what you should do/not do.&lt;/li&gt;
	&lt;li&gt;Added another early exit condition in FilteredQuery#Weight.scorer(): As we already get the first matching doc of the filter iterator before looking at bits or creating the query scorer, we should erly exit, if the first matching doc is Disi.NO_MORE_DOCS. This   saves us from creating the Query Scorer.&lt;/li&gt;
	&lt;li&gt;I removed Robert&apos;s safety TODO in SolrIndexSearcher. It no longer disabled random access completely. After Yoniks changes, all places in Solr that are not random access secure are disabled - e.g. SolrIndexSearcher.FilterImpl (not sure what this class does, maybe it should also implement bits()?) - we should do that in a Solr specific optimization issue.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Some other cool thing with filters is ANDing filters without ChainedFilter (this approach is is very effective with random access as it does not allocate additional BitsSet). If you want to AND together several filters and apply them to a Query, do the following:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
IS.search(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; FilteredQuery(query,filter2), filter1,...);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;You can chain even more filters in by adding more FilteredQueries. What this does:&lt;br/&gt;
IS will automatically create another FilteredQuery to apply the filter and get the Weight of the top-level FilteredQuery. The scorer of this one will be top-level, get the filter and if it is random access, it will execute the filter with acceptDocs==liveDocs. The result bits of this filter will be passed to Weight.scorer of the second FilteredQuery as acceptDocs. This one will pass the acceptDocs (which are already filtered) to its Filter and if again random access pass those as acceptDocs to the inner Query&apos;s scorer. Finally the top-level IS will execute scorer.score(Collector), which in fact is the inner Query&apos;s scorer (no wrappers!) with all filtering applied in acceptDocs. This is incredible cool &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;One thing about large patches in an issue:&lt;br/&gt;
If you are working on an issue and have you local changes in your checkout and posted a patch to an issue and somebody else, posted an updated patch to an issue, it is often nice to see the diff between those patches. I wanted to see what Yonik changed, but a 140 K patch is not easy to handle. The trick is &quot;interdiff&quot; from patchutils package: You can call &quot;interdiff &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1536&quot; title=&quot;if a filter can support random access API, we should use it&quot;&gt;&lt;del&gt;LUCENE-1536&lt;/del&gt;&lt;/a&gt;-original.patch &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1536&quot; title=&quot;if a filter can support random access API, we should use it&quot;&gt;&lt;del&gt;LUCENE-1536&lt;/del&gt;&lt;/a&gt;-yonik.patch&quot; and you get a patch of only changes applied by Yonik. This patch can even be applied to your local already patched checkout.&lt;/p&gt;

&lt;p&gt;The changes-yonik-uwe.patch was generated that way and shows, what changes I did in my last patch in contrast to Yoniks original.&lt;/p&gt;</comment>
                    <comment id="13123421" author="cmale" created="Sat, 8 Oct 2011 10:47:43 +0100"  >&lt;p&gt;I really think we should commit this to trunk (assuming all tests are passing) as soon as possible.  The patch is massive and contains a lot of changes.  Any further optimizations can then be done in small chunks.&lt;/p&gt;</comment>
                    <comment id="13123433" author="rcmuir" created="Sat, 8 Oct 2011 12:13:54 +0100"  >&lt;p&gt;i dont think we should do that chris.&lt;/p&gt;

&lt;p&gt;Luceneutil hints that something is possibly wrong, I want to know what is going on there before any committing&lt;/p&gt;
</comment>
                    <comment id="13123438" author="cmale" created="Sat, 8 Oct 2011 12:47:44 +0100"  >&lt;p&gt;I agree, I count that as a test failing &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="13123474" author="yseeley@gmail.com" created="Sat, 8 Oct 2011 14:00:20 +0100"  >&lt;blockquote&gt;&lt;p&gt;Just to note, if you implement something with &quot;new DocIdSet() {....}&quot;, there is no need to override bits() to return null, as the default always returns null.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Right - but I felt more comfortable being explicit about what sets would definitely not be using random access.  A comment would have served in those cases too.&lt;/p&gt;</comment>
                    <comment id="13123475" author="yseeley@gmail.com" created="Sat, 8 Oct 2011 14:03:21 +0100"  >&lt;blockquote&gt;&lt;p&gt;The changes-yonik-uwe.patch was generated that way and shows, what changes I did in my last patch in contrast to Yoniks original.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Thanks for the diff-diff.  It is a pain trying to review differences between patches.&lt;/p&gt;</comment>
                    <comment id="13123479" author="rcmuir" created="Sat, 8 Oct 2011 14:15:42 +0100"  >&lt;blockquote&gt;
&lt;p&gt;I agree, I count that as a test failing&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yeah a 2 hour long test!&lt;/p&gt;

&lt;p&gt;Here&apos;s what I&apos;ll do: I&apos;ll run the benchmark again, against two clean checkouts of trunk.&lt;/p&gt;

&lt;p&gt;If it gives the same error message then I think we should chalk it up as some luceneutil problem... otherwise we should dig into it.&lt;/p&gt;</comment>
                    <comment id="13123499" author="rcmuir" created="Sat, 8 Oct 2011 14:46:08 +0100"  >&lt;blockquote&gt;
&lt;p&gt;I ask because sometimes Solr actually knows the sparseness of it&apos;s sets.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yonik, it knows this on a per-filter basis? &lt;/p&gt;

&lt;p&gt;One idea now that the heuristic is actually in FilteredQuery would be to add a (clearly marked expert/internal!) hook&lt;br/&gt;
to filteredquery to override the default heuristic for cases where someone &quot;knows&quot; for sure the density of the filter.&lt;/p&gt;

&lt;p&gt;So instead of IS.search(query, filter, ...) which will just wrap with FilteredQuery,&lt;br/&gt;
an expert could just do IS.search(new FilteredQuery(query, filter) {  &lt;br/&gt;
  @Override&lt;br/&gt;
  boolean whatever() &lt;/p&gt;
{
    return true;
  }
&lt;p&gt;});&lt;/p&gt;</comment>
                    <comment id="13123501" author="yseeley@gmail.com" created="Sat, 8 Oct 2011 15:01:47 +0100"  >&lt;p&gt;Hmmm, so solr passes null for acceptDocs where it can... but other methods like IndexSearcher.search still pass liveDocs (and filters derived from Solr&apos;s DocSets &lt;b&gt;always&lt;/b&gt; respect liveDocs).   Perhaps we should check if (acceptDocs==null || acceptDocs==liveDocs) and not wrap in that case.&lt;/p&gt;</comment>
                    <comment id="13123502" author="cmale" created="Sat, 8 Oct 2011 15:02:05 +0100"  >&lt;p&gt;Sounds like a good idea to me Robert.  &lt;/p&gt;

&lt;p&gt;Could we also possibly add another template method to return the threshold value used in the current heuristic (so it could be removed from IndexSearcher).  That way if anybody wanted to toy with either just the threshold or the full heuristic, they could just override the appropriate method.  Doing either are very expert.&lt;/p&gt;</comment>
                    <comment id="13123504" author="yseeley@gmail.com" created="Sat, 8 Oct 2011 15:12:10 +0100"  >&lt;blockquote&gt;&lt;p&gt;&amp;gt; I ask because sometimes Solr actually knows the sparseness of it&apos;s sets.&lt;/p&gt;&lt;/blockquote&gt;

&lt;blockquote&gt;&lt;p&gt;Yonik, it knows this on a per-filter basis?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;A per-filter-implementation basis.&lt;br/&gt;
It&apos;s the filters that are derived from DocSets (DocSets always have liveDocs baked in).&lt;/p&gt;

&lt;p&gt;Right now, at the point of calling IS.search(), we no longer know if the filter is of that type (since we also support filters that are not derived from DocSets), so it would seem easiest to just solve in the specific getDocIdSet() implementations to avoid wrapping if passed liveDocs.&lt;/p&gt;</comment>
                    <comment id="13123507" author="rcmuir" created="Sat, 8 Oct 2011 15:19:24 +0100"  >&lt;p&gt;Yonik, ok thanks.&lt;/p&gt;

&lt;p&gt;I still want to rework it this way because I don&apos;t like adding the strange parameters to IndexSearcher, it clutters it up with internal details.&lt;/p&gt;

&lt;p&gt;in my local, i removed this stuff entirely and just did this in FilteredQuery.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;  /**
   * Expert: decides if a filter should be executed as &quot;random-access&quot; or not.
   * random-access means the filter &quot;filters&quot; in a similar way as deleted docs are filtered
   * in lucene. This is faster when the filter accepts many documents.
   * However, when the filter is very sparse, it can be faster to execute the query+filter
   * as a conjunction in some cases.
   * 
   * The default implementation returns true if the first document accepted by the
   * filter is &amp;lt; 100.
   * 
   * @lucene.internal
   */
  protected boolean useRandomAccess(Bits bits, int firstFilterDoc) {
    return firstFilterDoc &amp;lt; 100;
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;patch coming after tests finish.&lt;/p&gt;</comment>
                    <comment id="13123508" author="yseeley@gmail.com" created="Sat, 8 Oct 2011 15:25:22 +0100"  >&lt;p&gt;Yeah, I agree there should be a way to control on a per-search/filter basis, regardless of how we end up solving solr&apos;s issues.&lt;/p&gt;</comment>
                    <comment id="13123509" author="rcmuir" created="Sat, 8 Oct 2011 15:25:53 +0100"  >&lt;p&gt;patch moving the heuristic to FilteredQuery, AssertingIndexSearcher overrides wrapFilter() and returns random.nextBoolean().&lt;/p&gt;

&lt;p&gt;In some tests we explicitly tested on/off, i fixed these to still do this, however i think its a little overkill (since newSearcher randomizes this anyway), but i left them working the same way.&lt;/p&gt;</comment>
                    <comment id="13123515" author="thetaphi" created="Sat, 8 Oct 2011 16:17:12 +0100"  >&lt;blockquote&gt;&lt;p&gt;Hmmm, so solr passes null for acceptDocs where it can... but other methods like IndexSearcher.search still pass liveDocs (and filters derived from Solr&apos;s DocSets always respect liveDocs). Perhaps we should check if (acceptDocs==null || acceptDocs==liveDocs) and not wrap in that case.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yonik: You can do this, but thats out of the scope of this issue. In my original Solr patches I added the BitsFilteredDocIdSet everywhere in Solr, as the Lucene trunk requirements are to 100% respect deleted docs / accept docs in Filter.getDocIdSet(). This was not needed before, as deleted docs were applied after the filters, so a Filter that contained deleted docs, was not a problem at all.&lt;/p&gt;

&lt;p&gt;Now: If you have a Filter that magically gets the deleted docs from outside like Solr&apos;s DocSet filters, then you can safely ignore the acceptDocs given to getDocIdSet(), but only if they are == getLiveDocs(). So simply add a check for that.&lt;/p&gt;

&lt;p&gt;If the acceptDocs &lt;span class=&quot;error&quot;&gt;Unable to render embedded object: File (= liveDocs, you have to respect them, otherwise your Filter may return wrong docs. An exaple is the chained filter case I explained above &lt;span class=&quot;error&quot;&gt;&amp;#91;new FilterQuery(new FilterQuery(query, filter2), filter1)&amp;#93;&lt;/span&gt;. In that case, the inner filter2 would get different acceptDocs) not found.&lt;/span&gt;&lt;/p&gt;</comment>
                    <comment id="13123518" author="rcmuir" created="Sat, 8 Oct 2011 16:20:39 +0100"  >&lt;blockquote&gt;
&lt;p&gt;Here&apos;s what I&apos;ll do: I&apos;ll run the benchmark again, against two clean checkouts of trunk.&lt;/p&gt;

&lt;p&gt;If it gives the same error message then I think we should chalk it up as some luceneutil problem... otherwise we should dig into it.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I ran the luceneutil benchmark against two clean checkouts, no errors from grouping.&lt;/p&gt;

&lt;p&gt;This doesn&apos;t mean there is a bug in the patch, it could be a bug in grouping or a false warning or bug in the benchmark itself,&lt;br/&gt;
but still i think we need to get to the bottom of this.&lt;/p&gt;</comment>
                    <comment id="13123519" author="yseeley@gmail.com" created="Sat, 8 Oct 2011 16:21:54 +0100"  >&lt;blockquote&gt;&lt;p&gt;Now: If you have a Filter that magically gets the deleted docs from outside like Solr&apos;s DocSet filters, then you can safely ignore the acceptDocs given to getDocIdSet(), but only if they are == getLiveDocs(). So simply add a check for that.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes, that&apos;s exactly what I was saying.&lt;/p&gt;</comment>
                    <comment id="13123524" author="thetaphi" created="Sat, 8 Oct 2011 16:51:11 +0100"  >&lt;p&gt;Roberts patch with TestFilteredQuery cleaned up a little bit (not thousands of anonymous subclasses)&lt;/p&gt;</comment>
                    <comment id="13123554" author="thetaphi" created="Sat, 8 Oct 2011 20:04:10 +0100"  >&lt;p&gt;Improved the test for random access with BucktScorer to also chain two filters. This should pass the acceptDocs down so both filters are ANDed together.&lt;/p&gt;

&lt;p&gt;Also made AssertingIndexSearcher also use the autodetection. In half of all cases it uses autodetection from parent class, in the other half it decides between random access and iterator access.&lt;/p&gt;</comment>
                    <comment id="13123563" author="thetaphi" created="Sat, 8 Oct 2011 22:04:58 +0100"  >&lt;p&gt;Robert and me were talking about causes of the problems in the luceneutil runs. One idea would be an until-now hidden failure in grouping: FilteredQuery does not pass liveDocs down the scorer-chain (if iterative filtering is used), in the case it knows, that the Filter already uses it. This may confuse grouping!&lt;/p&gt;

&lt;p&gt;We should also check grouping with filters and old-style-iterator collecting.&lt;/p&gt;</comment>
                    <comment id="13123666" author="cmale" created="Sun, 9 Oct 2011 12:53:08 +0100"  >&lt;p&gt;Are these errors in the luceneutil runs repeatable? Are we to get more information about them to possibly replicate in a smaller test?&lt;/p&gt;</comment>
                    <comment id="13123669" author="rcmuir" created="Sun, 9 Oct 2011 13:04:12 +0100"  >&lt;p&gt;I don&apos;t have the hardware or time to run this intensive thing over and over (takes hours here). &lt;/p&gt;</comment>
                    <comment id="13123715" author="simonw" created="Sun, 9 Oct 2011 17:09:29 +0100"  >&lt;blockquote&gt;&lt;p&gt;I don&apos;t have the hardware or time to run this intensive thing over and over (takes hours here).&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I will see if I can help here on monday! I will report back once I find something.&lt;/p&gt;</comment>
                    <comment id="13123818" author="mikemccand" created="Mon, 10 Oct 2011 01:37:45 +0100"  >&lt;p&gt;Hmm, with the latest patch have we lost the RECACHE option for CachingWrapperFilter?  Ie, to re-AND the filter bits with the latest live docs and cache that.  This is useful if you only periodically reopen the reader (and it has new deletes), so you don&apos;t have to AND the deletes in for every query.&lt;/p&gt;</comment>
                    <comment id="13123826" author="rcmuir" created="Mon, 10 Oct 2011 01:51:04 +0100"  >&lt;p&gt;+1 to keep this option nuked, otherwise it limits acceptDocs to liveDocs.&lt;/p&gt;</comment>
                    <comment id="13123828" author="rcmuir" created="Mon, 10 Oct 2011 02:07:47 +0100"  >&lt;p&gt;sounds like we should split out the &apos;add acceptDocs to getDocIdSet&apos; as a separate issue, just like we did for weight.scorer.&lt;/p&gt;</comment>
                    <comment id="13123839" author="cmale" created="Mon, 10 Oct 2011 03:21:23 +0100"  >&lt;p&gt;Isn&apos;t that what this issue has basically become? plus some magic in FilteredQuery.&lt;/p&gt;</comment>
                    <comment id="13123845" author="rcmuir" created="Mon, 10 Oct 2011 03:27:20 +0100"  >&lt;p&gt;except that api change could actually be committed... this issue can&apos;t because it grows too complex and has a bug.&lt;/p&gt;</comment>
                    <comment id="13123849" author="cmale" created="Mon, 10 Oct 2011 03:49:40 +0100"  >&lt;p&gt;I agree this has grown too big and complex.  Go for it.&lt;/p&gt;</comment>
                    <comment id="13123889" author="thetaphi" created="Mon, 10 Oct 2011 05:44:20 +0100"  >&lt;blockquote&gt;&lt;p&gt;Hmm, with the latest patch have we lost the RECACHE option for CachingWrapperFilter? Ie, to re-AND the filter bits with the latest live docs and cache that. This is useful if you only periodically reopen the reader (and it has new deletes), so you don&apos;t have to AND the deletes in for every query.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Mike: We can no longer do this, as the acceptDocs passed to the getDocIdSet() are no longer always liveDocs, they can be everything. Simple example is two chained FilteredQuery. At least you would need to add the liveDocs instance as key to the cache.&lt;/p&gt;

&lt;p&gt;Even without recache we are still faster than before for a query, as the liveDocs are now only applied once! Before they were not applied in the filter, but everywhere else in the query. Now they are applied &lt;b&gt;once&lt;/b&gt; per query. Putting them into the cache is stupid and wrong and would only save us one AND. The complexity in CachingWrapperFilter does not rectify this.&lt;/p&gt;

&lt;p&gt;About splitting that in two patches: I have no time to do it, I am on a business trip this week.&lt;/p&gt;</comment>
                    <comment id="13123900" author="thetaphi" created="Mon, 10 Oct 2011 06:15:06 +0100"  >&lt;blockquote&gt;&lt;p&gt;Before they were not applied in the filter, but everywhere else in the query. Now they are applied once per query&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Sorry this is only correct for the iterator based advancing. For the filter-down-low approach they are of-course still applied. But still we should show benchmarks, that this really hurts. Because caching acceptDocs (not liveDocs!!!!) is very hard to do. Of course a chained FilteredQuery with lots of chanined filters could be simplier (only one static BitSet cached for the whole filter chain).&lt;/p&gt;

&lt;p&gt;Robert and me had more ideas how to optimize the always appliying acceptDocs case in every scorer: E.g. ConjunctionTermScorer could pass null down for all but one sub-scorer. Ideally the one that gets the liveDocs should be the one with lowest docFreq. The others don&apos;t need liveDocs, as the lowDocFreq scorer already applied them and they can never be appear in hits, because the other scorers would then advance over it. We should open new issues for those optimizations.&lt;/p&gt;</comment>
                    <comment id="13123998" author="mikemccand" created="Mon, 10 Oct 2011 12:01:01 +0100"  >&lt;p&gt;On the diff that luceneutil hits, it looks like there&apos;s an float iota&lt;br/&gt;
difference:&lt;/p&gt;

&lt;p&gt;On trunk we get these results:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;TASK: cat=Fuzzy1F90.0 q=body:changer~1.0 s=null f=CachingWrapperFilter(PreComputedRandomFilter(pctAccept=90.0)) group=null hits=198715
  32.160243 msec
  thread 5
  doc=6199951 score=40.27584
  doc=6199960 score=40.27584
  doc=6200023 score=40.27584
  doc=7580697 score=40.27584
  doc=7995191 score=33.34529
  doc=8684145 score=31.100195
  doc=6260043 score=31.100193
  doc=7320778 score=31.100193
  doc=7454704 score=31.100193
  doc=7979518 score=26.333052
  50 expanded terms
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;With the patch we get this:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;TASK: cat=Fuzzy1F90.0 q=body:changer~1.0 s=null f=CachingWrapperFilter(PreComputedRandomFilter(pctAccept=90.0)) group=null hits=198715
  19.300811 msec
  thread 4
  doc=6199951 score=40.27584
  doc=6199960 score=40.27584
  doc=6200023 score=40.27584
  doc=7580697 score=40.27584
  doc=7995191 score=33.34529
  doc=6260043 score=31.100195
  doc=7454704 score=31.100195
  doc=7320778 score=31.100193
  doc=8684145 score=31.100193
  doc=7979518 score=26.333052
  50 expanded terms
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;several of the docs with score 31.100193 or 31.100195 flipped around.&lt;/p&gt;</comment>
                    <comment id="13124001" author="cmale" created="Mon, 10 Oct 2011 12:09:03 +0100"  >&lt;p&gt;So where does this leave us?&lt;/p&gt;</comment>
                    <comment id="13124003" author="rcmuir" created="Mon, 10 Oct 2011 12:26:02 +0100"  >&lt;p&gt;this patch shouldn&apos;t be changing scores, I think even a small difference could be indicative of a larger problem: we need to understand what is causing this.&lt;/p&gt;</comment>
                    <comment id="13124004" author="cmale" created="Mon, 10 Oct 2011 12:31:50 +0100"  >&lt;p&gt;Are any deletes made in the above benchmarking? Might try to simulate the same change in a small unit test.&lt;/p&gt;</comment>
                    <comment id="13124006" author="rcmuir" created="Mon, 10 Oct 2011 12:36:04 +0100"  >&lt;p&gt;deletes dont affect scoring.&lt;/p&gt;</comment>
                    <comment id="13124007" author="cmale" created="Mon, 10 Oct 2011 12:39:09 +0100"  >&lt;p&gt;I realise that, I was just wanting to replicate the same conditions.&lt;/p&gt;</comment>
                    <comment id="13124080" author="rcmuir" created="Mon, 10 Oct 2011 14:17:20 +0100"  >&lt;p&gt;well, i think you are on the right path.&lt;/p&gt;

&lt;p&gt;if our unit tests pass but luceneutil &apos;fails&apos; i think thats a bad sign of the quality of our tests... it sounds like&lt;br/&gt;
we need to improve the tests to have more coverage for filters &amp;amp; deletions?&lt;/p&gt;</comment>
                    <comment id="13124109" author="rcmuir" created="Mon, 10 Oct 2011 14:54:12 +0100"  >&lt;p&gt;one bug is that FilteredQuery in the patch runs some heuristics &lt;b&gt;per segment&lt;/b&gt; which determine how the booleans get set that drive the BS1 versus B2 decision.&lt;/p&gt;

&lt;p&gt;This means that some segments could get BS1, and others get BS2, meaning we will rank some documents arbitrarily higher than others when they actually have the same underlying index statistics... this is bad!&lt;/p&gt;

&lt;p&gt;So I think at least the parameters to subscorer (topLevel/inOrder) must be consistently applied to all segments from that Weight.&lt;/p&gt;</comment>
                    <comment id="13124129" author="mikemccand" created="Mon, 10 Oct 2011 15:33:30 +0100"  >&lt;p&gt;Hmm, another bug is: we are never using BS1 when the filter is applied &apos;down low&apos;; this is because FilteredQuery&apos;s Weight impl does not override scoresDocsOutOfOrder.  I think it should do so?  And if the filter will be applied &apos;down low&apos;, it should delegate to the wrapped Weight?&lt;/p&gt;</comment>
                    <comment id="13124135" author="thetaphi" created="Mon, 10 Oct 2011 15:39:07 +0100"  >&lt;p&gt;Mike: That could be the reason for the problems: Currently it delegates to the wrapped Weight, but id does not wrap all methods.&lt;/p&gt;</comment>
                    <comment id="13124138" author="thetaphi" created="Mon, 10 Oct 2011 15:45:05 +0100"  >&lt;blockquote&gt;&lt;p&gt;one bug is that FilteredQuery in the patch runs some heuristics per segment which determine how the booleans get set that drive the BS1 versus B2 decision.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;How can BS1 and BS2 return different scores, this would be a bug? Theoretically it should be possible to have one segment with BS1 the other one with BS2.&lt;/p&gt;

&lt;p&gt;By the way: That was not different without FilteredQuery in the older patches.&lt;/p&gt;

&lt;p&gt;Of course the selection of the right scorer based on out of order should be done based on scoresDocOutOfOrder returned by the weight. This is a bug in FilteredQuery#Weight. But easy to fix.&lt;/p&gt;

&lt;p&gt;By the way: This was also not different without FilteredQuery in the older patches.&lt;/p&gt;</comment>
                    <comment id="13124144" author="rcmuir" created="Mon, 10 Oct 2011 15:49:44 +0100"  >&lt;blockquote&gt;
&lt;p&gt;How can BS1 and BS2 return different scores, this would be a bug? Theoretically it should be possible to have one segment with BS1 the other one with BS2.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Well they are different Scorer.java&apos;s ? I think its bad to use different code to score different segments, in this case two different algorithms&lt;br/&gt;
could cause floating point operations to be done in different order?&lt;/p&gt;

&lt;p&gt;Its also a bug that the scoresDocsOutOfOrder is wrong: and this is really the whole bug. Somehow FilteredQuery#Weight needs to determine what its gonna do&lt;br/&gt;
up front so that collector specialization is working, so that we use BS1 or BS2 consistently across all segments, etc.&lt;/p&gt;</comment>
                    <comment id="13124293" author="rcmuir" created="Mon, 10 Oct 2011 18:02:12 +0100"  >&lt;p&gt;hack patch that computes the heuristic up front in weight init, so it scores all segments consistently and returns the proper scoresDocsOutOfOrder for BS1.&lt;/p&gt;

&lt;p&gt;Uwe&apos;s new test (the nestedFilterQuery) doesnt pass yet, don&apos;t know why.&lt;/p&gt;

&lt;p&gt;I recomputed the benchmarks:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;                Task   QPS trunkStdDev trunk   QPS patchStdDev patch      Pct diff
          PhraseF1.0       11.99        0.20        7.79        0.23  -37% -  -31%
            TermF0.5      135.14        7.62      116.57        0.36  -18% -   -8%
   AndHighHighF100.0       17.34        0.78       15.44        0.15  -15% -   -5%
    AndHighHighF95.0       17.28        0.66       15.48        0.17  -14% -   -5%
    AndHighHighF90.0       17.31        0.76       15.58        0.19  -14% -   -4%
    AndHighHighF99.0       17.05        1.02       15.45        0.17  -15% -   -2%
    AndHighHighF75.0       17.47        0.78       16.03        0.15  -12% -   -3%
     AndHighHighF5.0       20.69        0.95       19.78        0.23   -9% -    1%
     AndHighHighF1.0       35.11        1.46       33.64        0.36   -8% -    1%
     AndHighHighF0.1      136.04        3.70      132.00        1.41   -6% -    0%
         AndHighHigh       18.25        0.70       17.74        0.20   -7% -    2%
     AndHighHighF0.5       49.84        1.72       48.58        0.49   -6% -    1%
            TermF0.1      351.18       11.01      345.85        1.73   -4% -    2%
        Fuzzy2F100.0       95.52        4.21       94.33        2.07   -7% -    5%
  SloppyPhraseF100.0        8.01        0.28        7.91        0.09   -5% -    3%
         Fuzzy2F90.0       95.42        3.86       94.51        1.74   -6% -    5%
         Fuzzy2F95.0       95.20        4.86       94.33        1.83   -7% -    6%
          Fuzzy1F1.0       54.02        1.67       53.56        1.07   -5% -    4%
          PhraseF2.0        7.73        0.07        7.68        0.18   -3% -    2%
   SloppyPhraseF99.0        7.99        0.23        7.95        0.10   -4% -    3%
    AndHighHighF50.0       17.54        0.79       17.46        0.12   -5% -    4%
          Fuzzy2F0.1      105.39        3.93      105.34        3.74   -7% -    7%
      SpanNearF100.0        3.16        0.06        3.16        0.04   -2% -    2%
         Fuzzy2F99.0       94.02        6.86       94.21        1.97   -8% -   10%
         Fuzzy2F75.0       95.56        3.51       95.76        2.02   -5% -    6%
        WildcardF2.0       52.79        0.27       53.05        0.57   -1% -    2%
          Fuzzy1F0.5       58.12        1.83       58.43        1.22   -4% -    5%
          PhraseF0.1       66.34        0.78       66.73        1.68   -3% -    4%
    SloppyPhraseF0.1       56.15        1.52       56.79        0.64   -2% -    5%
        SloppyPhrase        8.08        0.26        8.18        0.08   -2% -    5%
            PKLookup      176.59        5.07      178.96        5.71   -4% -    7%
        SpanNearF0.1       32.36        0.56       32.83        0.54   -1% -    4%
      OrHighHighF0.1       78.20        0.52       79.44        0.74    0% -    3%
   SloppyPhraseF95.0        7.91        0.08        8.05        0.09    0% -    3%
              Fuzzy2       94.87        3.72       96.49        1.62   -3% -    7%
      OrHighHighF0.5       31.41        0.47       31.96        0.33    0% -    4%
       SpanNearF99.0        3.12        0.06        3.18        0.03    0% -    4%
        WildcardF0.5       61.97        0.56       63.28        0.82    0% -    4%
          PhraseF0.5       19.78        0.26       20.29        0.31    0% -    5%
            SpanNear        3.19        0.08        3.27        0.05   -1% -    6%
        WildcardF0.1       67.45        0.64       69.24        0.89    0% -    4%
   SloppyPhraseF90.0        8.00        0.29        8.21        0.12   -2% -    8%
       SpanNearF95.0        3.13        0.04        3.23        0.03    1% -    5%
            Wildcard       43.19        0.34       44.64        1.40    0% -    7%
         Fuzzy2F50.0       95.12        4.22       98.69        2.28   -2% -   11%
              Fuzzy1       55.28        4.53       57.68        0.76   -4% -   15%
          OrHighHigh       12.13        0.99       12.71        0.43   -6% -   18%
              Phrase        3.60        0.04        3.81        0.04    3% -    7%
       SpanNearF90.0        3.15        0.05        3.35        0.04    3% -    9%
                Term       71.69        0.40       76.53        4.13    0% -   13%
         PhraseF99.0        3.43        0.03        3.68        0.04    5% -    9%
        PhraseF100.0        3.39        0.05        3.67        0.04    5% -   10%
   SloppyPhraseF75.0        8.04        0.26        8.74        0.12    3% -   13%
         Fuzzy2F20.0       97.38        4.03      106.17        2.88    1% -   16%
         PhraseF95.0        3.38        0.03        3.70        0.05    6% -   11%
         PhraseF90.0        3.42        0.02        3.76        0.03    8% -   11%
         Fuzzy2F10.0       97.19        3.69      109.27        3.23    5% -   20%
         PhraseF75.0        3.44        0.02        3.94        0.04   12% -   16%
          Fuzzy2F5.0       96.77        4.17      112.60        3.30    8% -   25%
          Fuzzy1F0.1       73.61        2.43       86.22        2.79    9% -   25%
      WildcardF100.0       35.49        0.33       41.92        1.05   14% -   22%
       SpanNearF75.0        3.15        0.07        3.72        0.04   14% -   22%
       WildcardF95.0       35.43        0.24       41.90        0.99   14% -   21%
       WildcardF90.0       35.59        0.32       42.11        1.11   14% -   22%
       WildcardF99.0       35.43        0.34       41.94        1.09   14% -   22%
         Fuzzy1F99.0       47.41        1.79       56.45        0.78   13% -   25%
       WildcardF75.0       35.64        0.29       42.51        0.87   15% -   22%
        Fuzzy1F100.0       46.85        1.83       56.42        0.55   14% -   26%
          Fuzzy2F1.0       96.75        3.75      116.85        4.32   11% -   30%
         Fuzzy1F95.0       46.91        1.37       56.69        0.69   15% -   25%
          Fuzzy2F0.5       97.33        4.15      117.64        4.17   11% -   30%
          Fuzzy2F2.0       95.51        3.65      115.66        3.95   12% -   30%
         Fuzzy1F90.0       46.84        1.95       56.83        0.78   14% -   28%
       WildcardF50.0       36.28        0.23       44.23        0.58   19% -   24%
            TermF1.0       93.99        4.90      114.60        0.49   15% -   29%
         Fuzzy1F75.0       47.12        1.68       58.11        0.82   17% -   29%
        WildcardF1.0       56.94        0.80       71.15        0.80   21% -   28%
         PhraseF50.0        3.49        0.01        4.39        0.04   24% -   27%
   SloppyPhraseF50.0        8.03        0.28       10.12        0.13   20% -   32%
         Fuzzy1F50.0       46.64        2.22       60.78        0.95   22% -   38%
      OrHighHighF1.0       24.15        0.35       32.46        0.25   31% -   37%
       WildcardF20.0       40.55        0.30       55.72        0.73   34% -   40%
         Fuzzy1F20.0       49.29        1.52       69.91        1.26   35% -   48%
        WildcardF5.0       47.02        0.33       67.11        0.81   40% -   45%
          PhraseF5.0        5.03        0.06        7.29        0.13   40% -   49%
       WildcardF10.0       43.04        0.57       62.68        0.69   42% -   49%
       SpanNearF50.0        3.16        0.07        4.77        0.06   45% -   56%
    AndHighHighF20.0       17.76        0.64       27.44        0.25   47% -   61%
         Fuzzy1F10.0       48.53        2.47       75.31        1.60   44% -   66%
          Fuzzy1F5.0       50.45        1.70       79.01        2.08   47% -   66%
          Fuzzy1F2.0       52.03        1.54       82.41        2.46   49% -   68%
    OrHighHighF100.0        7.69        0.20       12.19        0.33   50% -   67%
     OrHighHighF99.0        7.72        0.35       12.25        0.34   47% -   70%
         PhraseF20.0        3.74        0.03        5.95        0.05   56% -   61%
     OrHighHighF95.0        7.79        0.28       12.43        0.33   49% -   69%
      OrHighHighF2.0       19.60        0.24       31.28        0.14   56% -   62%
            TermF2.0       70.16        3.78      112.18        0.53   51% -   69%
     OrHighHighF90.0        7.83        0.23       12.56        0.33   51% -   69%
         PhraseF10.0        4.14        0.04        6.76        0.09   59% -   66%
           TermF50.0       42.57        1.77       70.63        1.25   56% -   76%
           TermF75.0       41.43        1.61       70.40        2.44   57% -   82%
     OrHighHighF75.0        7.81        0.22       13.33        0.36   61% -   80%
           TermF95.0       41.07        1.65       70.96        3.30   58% -   88%
           TermF99.0       41.12        1.57       71.14        3.41   58% -   88%
           TermF90.0       40.92        1.58       70.81        3.00   59% -   87%
          TermF100.0       40.01        0.73       71.10        3.36   66% -   89%
     OrHighHighF50.0        8.39        0.24       14.92        0.29   69% -   86%
    AndHighHighF10.0       18.68        0.61       36.17        0.23   86% -  101%
           TermF20.0       45.66        1.98       88.55        0.52   84% -  103%
      OrHighHighF5.0       14.89        0.30       29.12        0.20   90% -  100%
   SloppyPhraseF20.0        8.34        0.29       16.36        0.26   86% -  106%
            TermF5.0       52.71        1.88      105.42        0.46   92% -  108%
           TermF10.0       47.53        1.99       97.62        0.51   96% -  115%
     AndHighHighF2.0       26.32        1.16       54.83        0.27   98% -  119%
     OrHighHighF20.0       10.36        0.19       22.12        0.22  107% -  119%
     OrHighHighF10.0       12.31        0.35       26.43        0.23  106% -  122%
   SloppyPhraseF10.0        8.73        0.28       22.70        0.38  147% -  172%
    SloppyPhraseF0.5       19.21        0.58       52.13        0.61  160% -  183%
       SpanNearF20.0        3.20        0.05        8.98        0.16  171% -  189%
    SloppyPhraseF5.0        9.30        0.33       30.17        0.44  208% -  241%
    SloppyPhraseF1.0       13.84        0.44       46.77        0.64  223% -  253%
    SloppyPhraseF2.0       11.00        0.36       39.85        0.54  246% -  279%
       SpanNearF10.0        3.31        0.07       13.57        0.23  294% -  325%
        SpanNearF0.5        9.25        0.14       39.86        0.39  320% -  341%
        SpanNearF5.0        3.54        0.07       19.35        0.38  425% -  468%
        SpanNearF1.0        6.15        0.11       34.27        0.48  439% -  474%
        SpanNearF2.0        4.52        0.09       28.11        0.43  500% -  543%
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                    <comment id="13124317" author="mikemccand" created="Mon, 10 Oct 2011 18:23:10 +0100"  >&lt;p&gt;I opened &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-3503&quot; title=&quot;DisjunctionSumScorer gives slightly (float iotas) different scores when you .nextDoc vs .advance&quot;&gt;&lt;del&gt;LUCENE-3503&lt;/del&gt;&lt;/a&gt; for the score diff issue; it&apos;s a pre-existing bug.&lt;/p&gt;</comment>
                    <comment id="13124385" author="mikemccand" created="Mon, 10 Oct 2011 19:45:53 +0100"  >&lt;p&gt;I also bench&apos;d Robert&apos;s patch (turned off verifyScores in lucenebench because of &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-3503&quot; title=&quot;DisjunctionSumScorer gives slightly (float iotas) different scores when you .nextDoc vs .advance&quot;&gt;&lt;del&gt;LUCENE-3503&lt;/del&gt;&lt;/a&gt;); results look very similar:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;
                Task    QPS base StdDev baseQPS filterlowStdDev filterlow      Pct diff
          PhraseF0.5       20.18        0.65        8.05        0.56  -64% -  -55%
          PhraseF1.0       12.26        0.33        7.96        0.54  -41% -  -28%
    AndHighHighF95.0       16.56        0.13       15.98        1.09  -10% -    3%
         Fuzzy2F99.0       80.52        4.67       77.72        2.34  -11% -    5%
    AndHighHighF99.0       16.55        0.12       15.97        1.05  -10% -    3%
   AndHighHighF100.0       16.54        0.13       15.98        1.06  -10% -    3%
        Fuzzy2F100.0       80.32        4.60       77.64        2.34  -11% -    5%
         Fuzzy2F90.0       80.80        5.17       78.19        2.77  -12% -    7%
    AndHighHighF90.0       16.57        0.15       16.05        1.13  -10% -    4%
      OrHighHighF0.1       72.17        3.60       70.11        3.69  -12% -    7%
      OrHighHighF0.5       29.26        1.23       28.44        1.50  -11% -    6%
         Fuzzy2F95.0       79.95        4.49       77.86        2.10  -10% -    5%
        WildcardF0.1       59.21        4.21       58.01        3.42  -13% -   11%
        WildcardF0.5       54.94        3.78       53.88        3.08  -13% -   11%
        WildcardF1.0       51.31        3.31       50.35        2.44  -12% -    9%
        WildcardF2.0       46.99        2.93       46.13        2.15  -11% -    9%
            Wildcard       38.73        1.94       38.14        1.78  -10% -    8%
         Fuzzy2F75.0       80.57        5.03       79.38        2.04   -9% -    7%
    AndHighHighF75.0       16.63        0.14       16.41        1.21   -9% -    6%
  SloppyPhraseF100.0        7.73        0.15        7.64        0.25   -6% -    4%
   SloppyPhraseF99.0        7.74        0.15        7.66        0.26   -6% -    4%
            TermF0.1      328.10       15.20      325.54       16.82  -10% -    9%
          OrHighHigh       10.68        1.11       10.61        0.75  -16% -   18%
            TermF0.5      127.55        3.70      126.88        6.02   -7% -    7%
          PhraseF0.1       63.93        2.25       63.62        2.87   -8% -    7%
          PhraseF2.0        7.88        0.19        7.86        0.31   -6% -    6%
     AndHighHighF0.1      129.64        5.02      129.28        6.98   -9% -    9%
    SloppyPhraseF0.1       53.80        0.79       53.86        1.84   -4% -    5%
   SloppyPhraseF95.0        7.74        0.15        7.75        0.27   -5% -    5%
    SloppyPhraseF0.5       18.44        0.31       18.47        0.64   -4% -    5%
    SloppyPhraseF1.0       13.10        0.23       13.13        0.47   -5% -    5%
        SloppyPhrase        7.81        0.10        7.83        0.30   -4% -    5%
     AndHighHighF0.5       47.61        1.00       47.76        2.33   -6% -    7%
          Fuzzy2F1.0       81.49        4.85       81.96        0.96   -6% -    8%
              Fuzzy1       47.97        3.71       48.35        1.94  -10% -   13%
          Fuzzy1F0.1       64.31        3.56       64.82        0.83   -5% -    8%
              Fuzzy2       80.93        6.15       81.61        1.74   -8% -   11%
              Phrase        3.58        0.10        3.63        0.18   -6% -    9%
      SpanNearF100.0        2.98        0.10        3.03        0.12   -5% -    9%
   SloppyPhraseF90.0        7.74        0.15        7.87        0.28   -3% -    7%
         AndHighHigh       17.31        0.24       17.62        0.64   -3% -    6%
          Fuzzy2F0.1       89.54        5.78       91.38        1.44   -5% -   10%
       SpanNearF99.0        2.98        0.09        3.04        0.13   -5% -    9%
                Term       58.94        6.06       60.38        4.40  -13% -   22%
        SpanNearF0.1       29.91        1.07       30.70        1.43   -5% -   11%
        SpanNearF0.5        8.73        0.30        8.98        0.41   -5% -   11%
        SpanNearF5.0        3.33        0.11        3.42        0.16   -5% -   11%
         Fuzzy2F50.0       80.90        5.19       83.29        2.28   -5% -   13%
            SpanNear        3.01        0.10        3.10        0.14   -4% -   11%
            TermF1.0       87.07        2.01       89.92        6.38   -6% -   13%
       SpanNearF95.0        2.98        0.10        3.10        0.13   -3% -   12%
        PhraseF100.0        3.37        0.06        3.51        0.17   -2% -   11%
         PhraseF99.0        3.37        0.05        3.52        0.17   -2% -   11%
         PhraseF95.0        3.37        0.06        3.56        0.18   -1% -   12%
            PKLookup      126.08        5.73      133.37        1.97    0% -   12%
       SpanNearF90.0        2.98        0.10        3.18        0.14   -1% -   15%
         PhraseF90.0        3.38        0.06        3.61        0.18    0% -   14%
      WildcardF100.0       32.22        1.76       34.59        1.43   -2% -   18%
       WildcardF99.0       32.23        1.79       34.61        1.39   -2% -   18%
   SloppyPhraseF75.0        7.74        0.16        8.32        0.33    1% -   14%
       WildcardF95.0       32.15        1.83       34.72        1.37   -1% -   19%
       WildcardF90.0       32.10        1.82       34.90        1.29    0% -   19%
        Fuzzy1F100.0       42.36        1.85       46.19        2.07    0% -   19%
    AndHighHighF50.0       16.76        0.10       18.30        1.44    0% -   18%
         Fuzzy1F99.0       42.21        1.84       46.21        1.96    0% -   19%
         Fuzzy2F20.0       81.24        5.06       88.97        2.11    0% -   19%
         Fuzzy1F95.0       42.25        1.85       46.54        2.10    0% -   20%
       WildcardF75.0       31.98        1.81       35.49        1.32    1% -   22%
         Fuzzy1F90.0       42.15        1.77       46.84        1.91    2% -   20%
         PhraseF75.0        3.39        0.06        3.82        0.20    4% -   20%
         Fuzzy1F75.0       42.01        1.55       47.63        1.98    4% -   22%
      OrHighHighF1.0       22.54        0.94       25.87        1.81    2% -   28%
         Fuzzy2F10.0       81.10        5.01       93.81        2.75    5% -   26%
       WildcardF50.0       32.66        1.88       37.81        1.33    5% -   27%
         Fuzzy1F50.0       42.25        1.68       49.68        1.91    8% -   27%
       SpanNearF75.0        2.98        0.10        3.51        0.16    9% -   27%
          Fuzzy2F5.0       80.39        4.38       96.21        2.19   10% -   29%
          Fuzzy2F0.5       83.14        4.67       99.73        1.75   11% -   29%
          Fuzzy2F2.0       80.95        4.92       98.00        1.76   12% -   31%
   SloppyPhraseF50.0        7.78        0.16        9.62        0.43   15% -   31%
         PhraseF50.0        3.45        0.06        4.36        0.24   17% -   35%
       WildcardF20.0       35.76        2.01       45.85        1.89   16% -   41%
        WildcardF5.0       41.47        2.41       53.54        2.38   16% -   43%
         Fuzzy1F20.0       43.60        1.76       57.50        2.00   22% -   42%
       WildcardF10.0       38.26        2.17       50.63        2.11   20% -   46%
           TermF99.0       40.49        1.22       54.84        4.93   19% -   52%
          TermF100.0       40.51        1.29       54.99        4.92   19% -   52%
           TermF95.0       40.44        1.19       54.95        4.82   20% -   52%
           TermF90.0       40.34        1.08       55.00        4.58   21% -   51%
      OrHighHighF2.0       18.15        0.69       24.94        1.69   23% -   52%
            TermF2.0       63.47        1.48       87.39        5.94   25% -   50%
           TermF75.0       40.05        0.92       55.28        4.38   24% -   52%
          Fuzzy1F0.5       51.14        2.45       71.30        1.82   29% -   50%
    OrHighHighF100.0        7.05        0.15        9.96        0.73   28% -   54%
     OrHighHighF99.0        7.04        0.15        9.97        0.72   28% -   55%
           TermF50.0       40.94        0.70       58.33        4.05   30% -   55%
         Fuzzy1F10.0       43.92        1.78       62.74        1.47   34% -   52%
     OrHighHighF95.0        7.08        0.14       10.12        0.70   30% -   56%
     OrHighHighF90.0        7.10        0.15       10.31        0.71   32% -   58%
          PhraseF5.0        5.02        0.10        7.33        0.48   33% -   58%
          Fuzzy1F1.0       47.45        2.15       70.55        1.95   38% -   60%
          Fuzzy1F5.0       44.47        1.99       66.38        1.89   38% -   60%
          Fuzzy1F2.0       46.09        1.98       69.35        1.65   40% -   60%
       SpanNearF50.0        2.98        0.10        4.51        0.23   39% -   64%
     OrHighHighF75.0        7.20        0.15       10.97        0.73   39% -   65%
    AndHighHighF20.0       16.92        0.14       26.80        2.77   40% -   76%
         PhraseF20.0        3.69        0.06        5.86        0.36   46% -   71%
           TermF20.0       42.65        0.76       69.54        4.48   49% -   76%
         PhraseF10.0        4.10        0.07        6.74        0.43   51% -   78%
     OrHighHighF50.0        7.61        0.17       12.77        0.76   54% -   81%
      OrHighHighF5.0       13.68        0.48       23.13        1.55   52% -   86%
            TermF5.0       47.37        1.30       81.16        5.35   55% -   87%
           TermF10.0       43.07        0.95       74.83        4.64   59% -   88%
     AndHighHighF1.0       32.98        0.48       59.25        8.46   51% -  108%
   SloppyPhraseF20.0        8.00        0.16       14.72        0.84   70% -   98%
     OrHighHighF10.0       11.20        0.34       21.25        1.38   72% -  108%
     OrHighHighF20.0        9.32        0.22       18.10        1.12   77% -  111%
    AndHighHighF10.0       17.54        0.16       35.08        4.05   75% -  125%
     AndHighHighF2.0       24.58        0.27       52.49        7.16   82% -  145%
     AndHighHighF5.0       19.26        0.17       43.11        5.37   94% -  154%
   SloppyPhraseF10.0        8.24        0.16       19.96        1.29  122% -  162%
       SpanNearF20.0        3.01        0.10        8.24        0.48  149% -  199%
    SloppyPhraseF5.0        8.75        0.17       26.13        1.80  172% -  225%
    SloppyPhraseF2.0       10.35        0.20       33.95        2.51  198% -  259%
       SpanNearF10.0        3.09        0.10       12.23        0.76  259% -  334%
        SpanNearF1.0        5.75        0.19       30.48        2.42  372% -  492%
        SpanNearF2.0        4.21        0.13       24.77        1.80  428% -  551%
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                    <comment id="13124414" author="mikemccand" created="Mon, 10 Oct 2011 20:33:59 +0100"  >&lt;blockquote&gt;&lt;p&gt;Mike: We can no longer do this, as the acceptDocs passed to the getDocIdSet() are no longer always liveDocs, they can be everything.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;But CWF&apos;s job is still the same with this patch?&lt;/p&gt;

&lt;p&gt;It&apos;s just that the cache key is now a reader + acceptDocs (instead of&lt;br/&gt;
just reader), and the &quot;policy&quot; must be more careful not to cache just&lt;br/&gt;
any acceptDocs.&lt;/p&gt;

&lt;p&gt;Ie, we could easily add back the RECACHE option (maybe just a boolean&lt;br/&gt;
&quot;cacheLiveDocs&quot; or something)?  Or am I missing something?&lt;/p&gt;

&lt;p&gt;The IGNORE option must go away, since no filter impl is allowed to ignore&lt;br/&gt;
the incoming acceptDocs.  The DYNAMIC option is what the patch now&lt;br/&gt;
hardwires.&lt;/p&gt;

&lt;p&gt;I think this use case (app using CWF, doing deletes and reopening&lt;br/&gt;
periodically) is important.  For this use case we should do the AND w/&lt;br/&gt;
liveDocs only once on each reopen, and cache &amp;amp; reuse that, instead of&lt;br/&gt;
re-ANDing over and over for every query.&lt;/p&gt;</comment>
                    <comment id="13124720" author="thetaphi" created="Tue, 11 Oct 2011 06:55:15 +0100"  >&lt;blockquote&gt;
&lt;p&gt;hack patch that computes the heuristic up front in weight init, so it scores all segments consistently and returns the proper scoresDocsOutOfOrder for BS1.&lt;/p&gt;

&lt;p&gt;Uwe&apos;s new test (the nestedFilterQuery) doesnt pass yet, don&apos;t know why.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Very easy to explain: Because it&apos;s a hack! The problem is simple: The new test explicitely checks that acceptDocs are correctly handled by the query, which is not the case for your modifications. In createWeight you get the first segemnt and create the filter&apos;s docidset on it, passing &lt;b&gt;liveDocs&lt;/b&gt; (because you have nothing else). You cache this first DocIdSet (to not need to execute getDocIdSet for the first filter 2 times) and by that miss the real acceptDocs (which are != liveDocs in this test). The firts segment therefore returns more documents that it should.&lt;/p&gt;

&lt;p&gt;Alltogether, the hack is of course uncommitable and the source of outr problem only lies in the out of order setting. The fix in your patch is fine, but too much. The scoresDocsOutOfOrder method should simply return, what the inner weight returns, because it &lt;b&gt;may&lt;/b&gt; return docs out of order. It can still retun them in order (if a filter needs to be applied using iterator). This is not different to behaviour before. So the fix is easy: Do the same like in ConstantScoreQuery, where we return the setting from the inner weight.&lt;/p&gt;

&lt;p&gt;Being consistent in selecting scorer implementations between segments is not an issue of this special case, it&apos;s a general problem and cannot be solved by a hack. The selection of Scorer for BooleanQuery can be different even without FilteredQuery, as BooleanWeight might return different different scorer, too (so the problem is BooleanScorer that does selection of its Scorer per-segment). To fix this, BooleanWeight must do all the scorer descisions in it&apos;s ctor, so we would need to pass also scoreInOrder and other parameters to the Weight&apos;s ctor.&lt;/p&gt;

&lt;p&gt;Please remove the hack, and only correctly implement scoresDocsOutOfOrder (which is the reason for the problem, as it suddenly returns documents in a different order). We can still get the documents with that patch in different order if we have random access enabled together with the filter but the old IndexSearcher used DocIdSetIterator (in-order). We should ignore those differences in document order, if score is identical (and Mike&apos;s output shows scores are equal). If we want to check that the results are identical, the benchmark test must explicitely request docs-in-order on trunk vs. patch to be consistent. But then it&apos;s no longer a benchmark.&lt;/p&gt;

&lt;p&gt;Conclusion: In general we explained the differences between the patches and I think, my original patch is fine except the Weight.scoresDocsOutOfOrder, which should return the inner Weight&apos;s setting (like CSQ does) - no magic needed. Our patch does &lt;b&gt;not&lt;/b&gt; return wrong documents, just the order of equal-scoring documents is different, which is perfectly fine.&lt;/p&gt;</comment>
                    <comment id="13124748" author="thetaphi" created="Tue, 11 Oct 2011 07:41:37 +0100"  >&lt;p&gt;Patch that fixes the Weight.scoreDocsOutOfOrder method to return the inner weight&apos;s setting. The scorer can still return docs in order, but that was identical behaviour in previous unpatched trunk (IS looked at the out-of- order setting of the weight and uses correct collector, but once a filter was applied, the documents came in order). My patch only missed to pass this setting to our wrapper query.&lt;/p&gt;

&lt;p&gt;Mike: If you have time, can you check this? We may need a test, that uses a larger index and tests FilteredQuery on top of it, the current indexes used for filtering are simply too small and in most cases have only one segment &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;There is no need for Robert&apos;s hack (that does not work correctly with aceptDocs != liveDocs), if different BooleanScorers return significant different scores, it as a bug, not a problem in FilteredQuery. Slight score changes and therefor different order in results is not a problem at all - this is just my opinion.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;If we want to check that the results are identical, the benchmark test must explicitely request docs-in-order on trunk vs. patch to be consistent. But then it&apos;s no longer a benchmark.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This is of course untrue, sorry. If the weight returns that docs &lt;b&gt;may&lt;/b&gt; come out of order, the collector should handle this.&lt;/p&gt;</comment>
                    <comment id="13124778" author="rcmuir" created="Tue, 11 Oct 2011 08:40:04 +0100"  >&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;There is no need for Robert&apos;s hack (that does not work correctly with aceptDocs != liveDocs), if different BooleanScorers return significant different scores, it as a bug, not a problem in FilteredQuery. Slight score changes and therefor different order in results is not a problem at all - this is just my opinion.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Uwe, you are very confused.&lt;/p&gt;

&lt;p&gt;BooleanWeight always returns BS1 or BS2, and BS2 always returns the same subscorer hierarchy, the decisions are based all on nothing IR-dependent.&lt;br/&gt;
We cannot do as your patch does, it is incorrect.&lt;/p&gt;

&lt;p&gt;Here is my standing -1 against this patch that returns different scorer implementations for different segments, it totally breaks scoring for&lt;br/&gt;
filtered queries in lucene. This is unacceptable, as filters should not affect the score.&lt;/p&gt;
</comment>
                    <comment id="13124787" author="rcmuir" created="Tue, 11 Oct 2011 08:54:41 +0100"  >&lt;p&gt;Its not even just the specific patch here thats broken, the design is broken too.&lt;/p&gt;

&lt;p&gt;Because things like whether a filter can be accessible random access or not are not per-segment things (since it must be scored in a consistent way: same scorer, across all segments).&lt;/p&gt;

&lt;p&gt;currently a filter could return non-null Bits for one segment and null for another.&lt;/p&gt;</comment>
                    <comment id="13124793" author="thetaphi" created="Tue, 11 Oct 2011 09:11:33 +0100"  >&lt;blockquote&gt;&lt;p&gt;currently a filter could return non-null Bits for one segment and null for another.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;And this also affects choosing scorers (and does also in current Lucene 3.x: because once a filter returns non-null or non-EMPTY_DOC_ID_SET for one segment, it will score in order). So you bring up another issue that has nothing to do with this patch. The current scorer design is that the Weight decides per segment which scorer to use. To make that consisten, we have to change the way how scorers are created. This has nothing to do with this patch.&lt;/p&gt;

&lt;p&gt;The &quot;bug&quot; (which is none in my opinion) is definitely not in this filter, it was there since the beginning.&lt;/p&gt;

&lt;p&gt;I still disagree with you: BooleanScorer1 and 2 should return same scores. PERIOD. If they don&apos;t they are buggy.&lt;/p&gt;</comment>
                    <comment id="13124799" author="rcmuir" created="Tue, 11 Oct 2011 09:23:16 +0100"  >&lt;blockquote&gt;
&lt;p&gt;And this also affects choosing scorers (and does also in current Lucene 3.x: because once a filter returns non-null or non-EMPTY_DOC_ID_SET for one segment, it will score in order).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Thats a good point, ill open a bug for this. &lt;/p&gt;

&lt;p&gt;We need to wrangle all these scoring bugs, get them under control, and add tests for this stuff.&lt;/p&gt;</comment>
                    <comment id="13124943" author="thetaphi" created="Tue, 11 Oct 2011 12:29:55 +0100"  >&lt;blockquote&gt;&lt;p&gt;Thats a good point, ill open a bug for this.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;We don&apos;t need for that case: if filter returns null, no docs are scored &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; So it doe snot matter which scorer is used.&lt;/p&gt;

&lt;p&gt;But still the Weight API is confusing an should be improved, I agree with you. BooleanWeight should ensure that it always returns the same score impl, not our filter handling is responsible. The problem with in-order/out-of order + autodetection of sparseness exists in all previous patches on this issue (since the addition of the autodetection); it&apos;s not my fault!&lt;/p&gt;</comment>
                    <comment id="13124945" author="thetaphi" created="Tue, 11 Oct 2011 12:41:20 +0100"  >&lt;p&gt;Sorry last patch upload was somehow corrupted, maybe because of JIRA issues. This is the one only implementing Weight.scoreDocsOutOfOrder(), no hacks - to have a clean start.&lt;/p&gt;</comment>
                    <comment id="13124947" author="thetaphi" created="Tue, 11 Oct 2011 12:45:43 +0100"  >&lt;p&gt;Strange things going on. With Google Chrome, uploading patch files corrupts the file. With MSIE it worked. Sorry for the noise. Yesterday it worked normally...&lt;/p&gt;</comment>
                    <comment id="13124959" author="rcmuir" created="Tue, 11 Oct 2011 13:06:19 +0100"  >&lt;p&gt;you still misunderstand my patch, btw:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;. You cache this first DocIdSet (to not need to execute getDocIdSet for the first filter 2 times) and by that miss the real acceptDocs (which are != liveDocs in this test).&lt;/p&gt;&lt;/blockquote&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;+        // try to reuse from our previous heuristic sampling
+        if (context == plan.firstLeaf &amp;amp;&amp;amp; acceptDocs == plan.liveDocs) {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So how is it != liveDocs? We only re-use the cache if this &apos;if&apos; is true...&lt;/p&gt;</comment>
                    <comment id="13124993" author="thetaphi" created="Tue, 11 Oct 2011 13:53:51 +0100"  >&lt;p&gt;Sorry Robert, if that works its fine, but test is still failing, so something is wrong.&lt;/p&gt;

&lt;p&gt;My problem with the patch here is more, that for most filters, the call to getDocIdSet() is the most expensive one. So you are right with caching the result. But we actually calculate the DocIdSet twice (unless we use CachingWrapperFilter), if the acceptDocs != liveDocs. And as the first segment is generally the largest one, this is even worse.&lt;/p&gt;

&lt;p&gt;In my opinion, the whole approach of looking into the sparseness of the DocIdSet is broken for this case, as we can correctly do this only per segment, but we later require all segments to use the same scorer implementation. I have no idea, how to solve this. It would not even be enough like Chris/Mikes orginal approaches to support something like DocIdSet.useBits()/isSparse() whatever, as this is also by segment.&lt;/p&gt;

&lt;p&gt;There is also a second problem: It might happen that one filter returns a DocIdSet that does not support bits() for one segment, but another one for other segments? How to handle that? There is one case where this happens (DocIdSet.EMPTY_DOCIDSET always returns null for bits) - but this one is grafefully handled by an early exit condition, so we won&apos;t get NPE.&lt;/p&gt;

&lt;p&gt;The only possible solution is to make Filters always request in-order scoring, but this would limit our optimization possibilities.&lt;/p&gt;

&lt;p&gt;Finally I still think we should fix BS1 and BS2 to return identical scores (and write a test for that which compares scores). Second, in Mike&apos;s document/score listing above with/wo patch, I see no score differences, only order of docs is different (which is caused by out-of-order missing), so where is the problem?&lt;/p&gt;</comment>
                    <comment id="13125000" author="rcmuir" created="Tue, 11 Oct 2011 14:02:59 +0100"  >&lt;blockquote&gt;
&lt;p&gt;There is also a second problem: It might happen that one filter returns a DocIdSet that does not support bits() for one segment, but another one for other segments? How to handle that? &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This is the most serious problem I think.&lt;/p&gt;

&lt;p&gt;One solution: we can always JUST only ever use BS2. This is all&lt;br/&gt;
filters/filteredquery does today so its no regression, just an optimization we leave on&lt;br/&gt;
the table until it can be implemented cleanly.&lt;/p&gt;

&lt;p&gt;If we decide to do that, we are still left with the random-access-or-not-heuristic. But we could safely do this per-segment because BS2 is going to return the same set of scorers with or without bits (we know this ourselves, so its safe to do). &lt;/p&gt;

&lt;p&gt;And I already committed &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-3503&quot; title=&quot;DisjunctionSumScorer gives slightly (float iotas) different scores when you .nextDoc vs .advance&quot;&gt;&lt;del&gt;LUCENE-3503&lt;/del&gt;&lt;/a&gt; so it should be consistent with itself &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="13125056" author="rcmuir" created="Tue, 11 Oct 2011 15:16:45 +0100"  >&lt;p&gt;Also is there a reason why indexsearcher/filteredquery wouldnt just use ReqExclScorer when its not random-access?&lt;/p&gt;</comment>
                    <comment id="13125063" author="rcmuir" created="Tue, 11 Oct 2011 15:25:44 +0100"  >&lt;p&gt;i see, we would have to negate the bits, maybe we should pull out FilteredQ&apos;s anon scorer into a separate .java file for consistency.&lt;/p&gt;</comment>
                    <comment id="13125068" author="cmale" created="Tue, 11 Oct 2011 15:31:46 +0100"  >&lt;p&gt;Doing that (pulling the anon scorer out) would make the classes more readable IMO too.&lt;/p&gt;</comment>
                    <comment id="13125092" author="mikemccand" created="Tue, 11 Oct 2011 15:57:21 +0100"  >&lt;p&gt;Uwe, there are tiny (iota) score diffs for a few docs... eg 8684145 has score 31.100195 in one case but 31.100193 in the other (last digit differs).&lt;/p&gt;</comment>
                    <comment id="13125115" author="mikemccand" created="Tue, 11 Oct 2011 16:27:56 +0100"  >
&lt;p&gt;Isn&apos;t it strange to ask each filter impl to do ANDing for us?&lt;/p&gt;

&lt;p&gt;Like shouldn&apos;t we AND &quot;on top&quot; ourselves?  Are there compelling&lt;br/&gt;
performance gains by requiring every filter impl to do this for us?&lt;br/&gt;
If the filter impl just delegates to BitsFilteredDocIdSet.wrap then we&lt;br/&gt;
may as well just do that on top instead?&lt;/p&gt;

&lt;p&gt;With the scorer API, it is compelling to do this since our enum impls&lt;br/&gt;
already take a liveDocs, so it&apos;s easy for scorers to respect this and&lt;br/&gt;
we get enormous perf gains by pushing the AND inside the scorers.&lt;/p&gt;

&lt;p&gt;So I&apos;m not sure this API change makes sense... unless there really is&lt;br/&gt;
no other (cleaner) way for us to note that a filter already contains&lt;br/&gt;
only live docs.&lt;/p&gt;

&lt;p&gt;But then implementing your own filter is rather expert so maybe it&apos;s&lt;br/&gt;
not such a big deal to ask you to AND this other bitset we hand you.&lt;br/&gt;
And this solution (I think!  see comment above) will still allow for&lt;br/&gt;
CachingWrapperFilter to re-AND liveDocs only once on reopen and then&lt;br/&gt;
cache and reuse that.&lt;/p&gt;</comment>
                    <comment id="13126469" author="thetaphi" created="Thu, 13 Oct 2011 11:15:19 +0100"  >&lt;p&gt;Patch that for now (until BooleanWeight is fixed) rewuires in-order scoring when a filter is applied, as suggested by Robert.&lt;/p&gt;

&lt;p&gt;There was also a silly bug in CachingWrapperFilter that made it not to apply acceptDocs on cached results. This may also be a reason for result differences.&lt;/p&gt;

&lt;p&gt;Mike: &quot;Normal Filters&quot; always respect acceptDocs, as they generally use the acceptDocs to pass them to IndexReader. E.g. MTQWF or all other filters. Only some special filters e.g. working on FieldCache have to respect acceptDocs. So there is no slowdown at all, it all exactly as before (pre-acceptDocs Filters always used getLiveDocs() - although they were not required to do so). The silly thing was that we applied accept docs simply at too many places, so we decided to make the filters do it themselves (as they can, because in previous patch they always called IR.getLiveDocs(); except FiledCacheFilters).&lt;/p&gt;

&lt;p&gt;The optimizations for CachingWrapperFilter to also cache acceptDocs should maybe done in a separate issue. We have currently no slowdown, as its still faster than before. Improvements can come later.&lt;/p&gt;

&lt;p&gt;I agree, we can make the pair (IR, acceptDocs) a key into the cache map, the only problem is that accpetDocs are not required to implement equals/hashCode - and if they do, like in FixedBitSet, it&apos;s slow. So the cache should do this using systemHashCode/IdentityHashMap-like algorithm (so only compare the Bits pointer, not contents).&lt;/p&gt;</comment>
                    <comment id="13126603" author="rcmuir" created="Thu, 13 Oct 2011 15:14:33 +0100"  >&lt;blockquote&gt;
&lt;p&gt;Patch that for now (until BooleanWeight is fixed) rewuires in-order scoring when a filter is applied, as suggested by Robert.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;m still not sure BooleanWeight needs to be fixed: given the same parameters it will always return the same scorers.&lt;/p&gt;

&lt;p&gt;It seems to me these parameters (topLevel/scoresInOrder) really shouldn&apos;t be parameters to weight.scorer()!&lt;/p&gt;</comment>
                    <comment id="13128209" author="mikemccand" created="Sat, 15 Oct 2011 15:46:55 +0100"  >&lt;blockquote&gt;&lt;p&gt;Mike: &quot;Normal Filters&quot; always respect acceptDocs, as they generally use the acceptDocs to pass them to IndexReader.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;OK this makes sense (that many filter impls will need to pass through the accept docs down to eventual enums).&lt;/p&gt;

&lt;p&gt;So I think the API change is good!&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The optimizations for CachingWrapperFilter to also cache acceptDocs should maybe done in a separate issue. We have currently no slowdown, as its still faster than before. Improvements can come later.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;OK we can add it back under a new issue after committing this; but I&lt;br/&gt;
think it&apos;s important to not lose this (CachingWrapperFilter today is&lt;br/&gt;
able to pre-AND the liveDocs and cache that).&lt;/p&gt;

&lt;p&gt;It sounds like the cache key just has to become a pair of reader and&lt;br/&gt;
identity(acceptDocs), but we should only cache when acceptDocs ==&lt;br/&gt;
reader.getLiveDocs, else we can easily over-cache if in the future we&lt;br/&gt;
pass &quot;more interesting&quot; acceptDocs down.&lt;/p&gt;

&lt;p&gt;Great!&lt;/p&gt;</comment>
                    <comment id="13128406" author="thetaphi" created="Sun, 16 Oct 2011 15:19:57 +0100"  >&lt;p&gt;Do we have a conclusion about the current patch, so we can commit and work in other issues to improve? I also want to open issues to remove broken SpanFilter from core and move to sandbox.&lt;/p&gt;</comment>
                    <comment id="13128744" author="cmale" created="Mon, 17 Oct 2011 10:24:21 +0100"  >&lt;p&gt;Is the only question mark remaining around the BooleanWeight work? If so, I think its definitely worth examining that in a wider separate issue after this is committed.&lt;/p&gt;</comment>
                    <comment id="13128749" author="thetaphi" created="Mon, 17 Oct 2011 10:49:09 +0100"  >&lt;blockquote&gt;&lt;p&gt;Is the only question mark remaining around the BooleanWeight work? If so, I think its definitely worth examining that in a wider separate issue after this is committed.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The patch requests scorer always in order for now, so BooleanWeight is not mixed up for different segments. This is not different as in current trunk, as Scorers are always requested in order if filters are used. The optimization in the future would be to use out-of-order scoring if random access bits are used.&lt;/p&gt;</comment>
                    <comment id="13128754" author="cmale" created="Mon, 17 Oct 2011 10:55:57 +0100"  >&lt;p&gt;I was more referring to Robert&apos;s comment: &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;It seems to me these parameters (topLevel/scoresInOrder) really shouldn&apos;t be parameters to weight.scorer()!&lt;/p&gt;&lt;/blockquote&gt;
</comment>
                    <comment id="13128767" author="thetaphi" created="Mon, 17 Oct 2011 11:16:15 +0100"  >&lt;p&gt;Yes, that should be sorted out in another issue. We have a working fix, the rest is optimization and unrelated api changes.&lt;/p&gt;</comment>
                    <comment id="13133990" author="thetaphi" created="Mon, 24 Oct 2011 12:33:20 +0100"  >&lt;p&gt;I will commit this tomorrow, if nobody objects and we will work on further issues to improve Weight.scorer() API, CachingWrapperFilter,... There is no slowdown, only speedups with room to improve.&lt;/p&gt;</comment>
                    <comment id="13133994" author="rcmuir" created="Mon, 24 Oct 2011 12:35:47 +0100"  >&lt;p&gt;+1, lets commit this one and make progress here.&lt;/p&gt;</comment>
                    <comment id="13134039" author="thetaphi" created="Mon, 24 Oct 2011 13:59:09 +0100"  >&lt;p&gt;Here the updated patch after some changes in trunk. It also adds missCount checks back to Caching*Filters, I lost then during cleanup.&lt;/p&gt;</comment>
                    <comment id="13134964" author="thetaphi" created="Tue, 25 Oct 2011 13:09:38 +0100"  >&lt;p&gt;Committed trunk revision: 1188624&lt;/p&gt;

&lt;p&gt;Thanks to all!&lt;/p&gt;</comment>
                    <comment id="13134967" author="cmale" created="Tue, 25 Oct 2011 13:12:52 +0100"  >&lt;p&gt;Yay!&lt;/p&gt;</comment>
                </comments>
                <issuelinks>
                        <issuelinktype id="10032">
                <name>Blocker</name>
                                                <inwardlinks description="is blocked by">
                            <issuelink>
            <issuekey id="12526471">LUCENE-3503</issuekey>
        </issuelink>
                    </inwardlinks>
                            </issuelinktype>
                        <issuelinktype id="10030">
                <name>Reference</name>
                                <outwardlinks description="relates to">
                            <issuelink>
            <issuekey id="12510755">LUCENE-3212</issuekey>
        </issuelink>
                    </outwardlinks>
                                                <inwardlinks description="is related to">
                            <issuelink>
            <issuekey id="12615312">LUCENE-4548</issuekey>
        </issuelink>
                    </inwardlinks>
                            </issuelinktype>
                        <issuelinktype id="12310050">
                <name>Regression</name>
                                <outwardlinks description="breaks">
                            <issuelink>
            <issuekey id="12539993">SOLR-3062</issuekey>
        </issuelink>
                    </outwardlinks>
                                            </issuelinktype>
                    </issuelinks>
                <attachments>
                    <attachment id="12454467" name="CachedFilterIndexReader.java" size="4102" author="mikemccand" created="Mon, 13 Sep 2010 19:44:57 +0100" />
                    <attachment id="12498289" name="changes-yonik-uwe.patch" size="2737" author="thetaphi" created="Sat, 8 Oct 2011 10:31:24 +0100" />
                    <attachment id="12498440" name="LUCENE-1536_hack.patch" size="153202" author="rcmuir" created="Mon, 10 Oct 2011 18:02:12 +0100" />
                    <attachment id="12500433" name="LUCENE-1536.patch" size="53259" author="thetaphi" created="Mon, 24 Oct 2011 13:59:09 +0100" />
                    <attachment id="12498865" name="LUCENE-1536.patch" size="151694" author="thetaphi" created="Thu, 13 Oct 2011 11:15:18 +0100" />
                    <attachment id="12498579" name="LUCENE-1536.patch" size="151697" author="thetaphi" created="Tue, 11 Oct 2011 12:43:33 +0100" />
                    <attachment id="12498326" name="LUCENE-1536.patch" size="151156" author="thetaphi" created="Sat, 8 Oct 2011 20:04:10 +0100" />
                    <attachment id="12498317" name="LUCENE-1536.patch" size="150296" author="thetaphi" created="Sat, 8 Oct 2011 16:51:11 +0100" />
                    <attachment id="12498314" name="LUCENE-1536.patch" size="150521" author="rcmuir" created="Sat, 8 Oct 2011 15:25:53 +0100" />
                    <attachment id="12498288" name="LUCENE-1536.patch" size="144715" author="thetaphi" created="Sat, 8 Oct 2011 10:31:24 +0100" />
                    <attachment id="12498253" name="LUCENE-1536.patch" size="143915" author="yseeley@gmail.com" created="Fri, 7 Oct 2011 23:54:17 +0100" />
                    <attachment id="12498150" name="LUCENE-1536.patch" size="125592" author="rcmuir" created="Fri, 7 Oct 2011 14:04:46 +0100" />
                    <attachment id="12497985" name="LUCENE-1536.patch" size="53259" author="rcmuir" created="Thu, 6 Oct 2011 13:33:53 +0100" />
                    <attachment id="12497887" name="LUCENE-1536.patch" size="29794" author="thetaphi" created="Wed, 5 Oct 2011 21:37:15 +0100" />
                    <attachment id="12497867" name="LUCENE-1536.patch" size="28911" author="thetaphi" created="Wed, 5 Oct 2011 19:34:04 +0100" />
                    <attachment id="12497863" name="LUCENE-1536.patch" size="28515" author="thetaphi" created="Wed, 5 Oct 2011 19:17:43 +0100" />
                    <attachment id="12497740" name="LUCENE-1536.patch" size="24333" author="cmale" created="Wed, 5 Oct 2011 03:17:03 +0100" />
                    <attachment id="12497689" name="LUCENE-1536.patch" size="24186" author="rcmuir" created="Tue, 4 Oct 2011 20:55:46 +0100" />
                    <attachment id="12497680" name="LUCENE-1536.patch" size="20361" author="rcmuir" created="Tue, 4 Oct 2011 20:03:03 +0100" />
                    <attachment id="12497400" name="LUCENE-1536.patch" size="24705" author="cmale" created="Sun, 2 Oct 2011 13:25:15 +0100" />
                    <attachment id="12496874" name="LUCENE-1536.patch" size="76839" author="mikemccand" created="Wed, 28 Sep 2011 13:41:08 +0100" />
                    <attachment id="12496781" name="LUCENE-1536.patch" size="72275" author="mikemccand" created="Tue, 27 Sep 2011 19:30:47 +0100" />
                    <attachment id="12496664" name="LUCENE-1536.patch" size="70107" author="cmale" created="Tue, 27 Sep 2011 11:51:10 +0100" />
                    <attachment id="12496227" name="LUCENE-1536.patch" size="69109" author="cmale" created="Fri, 23 Sep 2011 06:33:43 +0100" />
                    <attachment id="12496119" name="LUCENE-1536.patch" size="70385" author="cmale" created="Thu, 22 Sep 2011 15:21:10 +0100" />
                    <attachment id="12485822" name="LUCENE-1536.patch" size="64848" author="mikemccand" created="Sat, 9 Jul 2011 15:53:02 +0100" />
                    <attachment id="12483869" name="LUCENE-1536.patch" size="204262" author="mikemccand" created="Sun, 26 Jun 2011 19:27:14 +0100" />
                    <attachment id="12419735" name="LUCENE-1536.patch" size="56341" author="jasonrutherglen" created="Wed, 16 Sep 2009 07:25:33 +0100" />
                    <attachment id="12419694" name="LUCENE-1536.patch" size="51866" author="jasonrutherglen" created="Tue, 15 Sep 2009 23:14:53 +0100" />
                    <attachment id="12406046" name="LUCENE-1536.patch" size="26258" author="jasonrutherglen" created="Tue, 21 Apr 2009 18:45:23 +0100" />
                    <attachment id="12405982" name="LUCENE-1536.patch" size="19455" author="jasonrutherglen" created="Tue, 21 Apr 2009 03:48:11 +0100" />
                    <attachment id="12399482" name="LUCENE-1536.patch" size="11215" author="mikemccand" created="Wed, 4 Feb 2009 20:34:30 +0000" />
                    <attachment id="12498287" name="LUCENE-1536-rewrite.patch" size="90" author="thetaphi" created="Sat, 8 Oct 2011 10:31:24 +0100" />
                    <attachment id="12498173" name="LUCENE-1536-rewrite.patch" size="140099" author="thetaphi" created="Fri, 7 Oct 2011 16:25:38 +0100" />
                    <attachment id="12498158" name="LUCENE-1536-rewrite.patch" size="130709" author="thetaphi" created="Fri, 7 Oct 2011 15:07:28 +0100" />
                    <attachment id="12498135" name="LUCENE-1536-rewrite.patch" size="117394" author="thetaphi" created="Fri, 7 Oct 2011 12:05:47 +0100" />
                    <attachment id="12498090" name="LUCENE-1536-rewrite.patch" size="89834" author="thetaphi" created="Fri, 7 Oct 2011 00:12:29 +0100" />
                    <attachment id="12498079" name="LUCENE-1536-rewrite.patch" size="85968" author="thetaphi" created="Thu, 6 Oct 2011 23:04:47 +0100" />
                    <attachment id="12497996" name="LUCENE-1536-rewrite.patch" size="72954" author="thetaphi" created="Thu, 6 Oct 2011 15:26:57 +0100" />
                    <attachment id="12497980" name="LUCENE-1536-rewrite.patch" size="53419" author="thetaphi" created="Thu, 6 Oct 2011 13:13:39 +0100" />
                    <attachment id="12498229" name="luceneutil.patch" size="2674" author="rcmuir" created="Fri, 7 Oct 2011 20:24:05 +0100" />
                </attachments>
            <subtasks>
        </subtasks>
                <customfields>
                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                <customfieldname>Attachment count</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>41.0</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                <customfieldname>Date of First Response</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>Fri, 6 Mar 2009 17:46:10 +0000</customfieldvalue>

                </customfieldvalues>
            </customfield>
                                                                                                        <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Global Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>3953</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                <customfieldname>Lucene Fields</customfieldname>
                <customfieldvalues>
                        <customfieldvalue key="10121"><![CDATA[New]]></customfieldvalue>
    
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>26193</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                <customfieldname>Time in Status</customfieldname>
                <customfieldvalues>
                    
                </customfieldvalues>
            </customfield>
                            </customfields>
    </item>
</channel>
</rss>