<!-- 
RSS generated by JIRA (5.2.8#851-sha1:3262fdc28b4bc8b23784e13eadc26a22399f5d88) at Tue Jul 16 13:04:24 UTC 2013

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/LUCENE-966/LUCENE-966.xml?field=key&field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>5.2.8</version>
        <build-number>851</build-number>
        <build-date>26-02-2013</build-date>
    </build-info>

<item>
            <title>[LUCENE-966] A faster JFlex-based replacement for StandardAnalyzer</title>
                <link>https://issues.apache.org/jira/browse/LUCENE-966</link>
                <project id="12310110" key="LUCENE">Lucene - Core</project>
                        <description>&lt;p&gt;JFlex (&lt;a href=&quot;http://www.jflex.de/&quot; class=&quot;external-link&quot;&gt;http://www.jflex.de/&lt;/a&gt;) can be used to generate a faster (up to several times) replacement for StandardAnalyzer. Will add a patch and a simple benchmark code in a while.&lt;/p&gt;</description>
                <environment></environment>
            <key id="12374645">LUCENE-966</key>
            <summary>A faster JFlex-based replacement for StandardAnalyzer</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                    <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png">Closed</status>
                    <resolution id="1">Fixed</resolution>
                                <assignee username="-1">Unassigned</assignee>
                                <reporter username="stanislaw.osinski">Stanislaw Osinski</reporter>
                        <labels>
                    </labels>
                <created>Thu, 26 Jul 2007 14:04:57 +0100</created>
                <updated>Fri, 25 Jan 2008 03:24:01 +0000</updated>
                    <resolved>Wed, 8 Aug 2007 23:29:30 +0100</resolved>
                                            <fixVersion>2.3</fixVersion>
                                <component>modules/analysis</component>
                        <due></due>
                    <votes>2</votes>
                        <watches>2</watches>
                                                    <comments>
                    <comment id="12515655" author="stanislaw.osinski" created="Thu, 26 Jul 2007 14:12:47 +0100"  >&lt;p&gt;Here comes a somewhat rough (needing refactorings, see below) patch adding a JFlex-based repalcement for StandardAnalyzer called FastAnalyzer.  A few comments:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;all tests from TestStandardAnalyzer pass&lt;/li&gt;
	&lt;li&gt;tokenizer generation added to Ant build scripts&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Because FastAnalyzer shares some code with StandardAnalyzer, it might be worthwhile to do some refactorings:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;have a common test for both analyzers (only if we want to keep them in sync)&lt;/li&gt;
	&lt;li&gt;have a common superclass for FastFilter and StandardFilter&lt;/li&gt;
	&lt;li&gt;have a common superclass for FastAnalyzer and StandardAnalyzer&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12515658" author="stanislaw.osinski" created="Thu, 26 Jul 2007 14:15:55 +0100"  >&lt;p&gt;Here is a very simple benchmark I used to test the performance of StandardAnalyzer, FastAnalyzer and WhitespaceAnalyzer. I ran it on a number of JVMs and got the following results:&lt;/p&gt;

&lt;p&gt;Input: Reuters collection, the one used by contrib/benchmark, only documents&lt;br/&gt;
longer than 100 bytes&lt;/p&gt;

&lt;p&gt;Machine: AMD Sempron 2600+, 2G RAM, Windows XP&lt;/p&gt;

&lt;p&gt;Sun 1.4.2 Server&lt;br/&gt;
org.apache.lucene.analysis.standard.StandardAnalyzer: 15172 ms, 139667 tokens/s&lt;br/&gt;
org.apache.lucene.analysis.fast.FastAnalyzer: 2438 ms, 869170 tokens/s&lt;br/&gt;
org.apache.lucene.analysis.WhitespaceAnalyzer: 781 ms, 3547585 tokens/s&lt;/p&gt;

&lt;p&gt;Sun 1.4.2 Client&lt;br/&gt;
org.apache.lucene.analysis.standard.StandardAnalyzer: 24187 ms, 87610 tokens/s&lt;br/&gt;
org.apache.lucene.analysis.fast.FastAnalyzer: 3157 ms, 671218 tokens/s&lt;br/&gt;
org.apache.lucene.analysis.WhitespaceAnalyzer: 1453 ms, 1906857 tokens/s&lt;/p&gt;

&lt;p&gt;Sun 1.5.0 Server&lt;br/&gt;
org.apache.lucene.analysis.standard.StandardAnalyzer: 16062 ms, 131928 tokens/s&lt;br/&gt;
org.apache.lucene.analysis.fast.FastAnalyzer: 2641 ms, 802361 tokens/s&lt;br/&gt;
org.apache.lucene.analysis.WhitespaceAnalyzer: 750 ms, 3694218 tokens/s&lt;/p&gt;

&lt;p&gt;Sun 1.5.0 Client&lt;br/&gt;
org.apache.lucene.analysis.standard.StandardAnalyzer: 23891 ms, 88696 tokens/s&lt;br/&gt;
org.apache.lucene.analysis.fast.FastAnalyzer: 3641 ms, 581993 tokens/s&lt;br/&gt;
org.apache.lucene.analysis.WhitespaceAnalyzer: 1437 ms, 1928089 tokens/s&lt;/p&gt;

&lt;p&gt;Sun 1.6.0 Server&lt;br/&gt;
org.apache.lucene.analysis.standard.StandardAnalyzer: 13719 ms, 154460 tokens/s&lt;br/&gt;
org.apache.lucene.analysis.fast.FastAnalyzer: 2484 ms, 853074 tokens/s&lt;br/&gt;
org.apache.lucene.analysis.WhitespaceAnalyzer: 750 ms, 3694218 tokens/s&lt;/p&gt;

&lt;p&gt;Sun 1.6.0 Client&lt;br/&gt;
org.apache.lucene.analysis.standard.StandardAnalyzer: 22312 ms, 94972 tokens/s&lt;br/&gt;
org.apache.lucene.analysis.fast.FastAnalyzer: 2750 ms, 770558 tokens/s&lt;br/&gt;
org.apache.lucene.analysis.WhitespaceAnalyzer: 1297 ms, 2136209 tokens/s&lt;/p&gt;

&lt;p&gt;IBM 1.4.2&lt;br/&gt;
org.apache.lucene.analysis.standard.StandardAnalyzer: 11922 ms, 177741 tokens/s&lt;br/&gt;
org.apache.lucene.analysis.fast.FastAnalyzer: 3218 ms, 658495 tokens/s&lt;br/&gt;
org.apache.lucene.analysis.WhitespaceAnalyzer: 1407 ms, 1969199 tokens/s&lt;/p&gt;

&lt;p&gt;IBM 1.5.0&lt;br/&gt;
org.apache.lucene.analysis.standard.StandardAnalyzer: 11797 ms, 179625 tokens/s&lt;br/&gt;
org.apache.lucene.analysis.fast.FastAnalyzer: 2968 ms, 713961 tokens/s&lt;br/&gt;
org.apache.lucene.analysis.WhitespaceAnalyzer: 1000 ms, 2770664 tokens/s&lt;/p&gt;

&lt;p&gt;BEA 1.4.2&lt;br/&gt;
org.apache.lucene.analysis.standard.StandardAnalyzer: 16234 ms, 130530 tokens/s&lt;br/&gt;
org.apache.lucene.analysis.fast.FastAnalyzer: 3344 ms, 633683 tokens/s&lt;br/&gt;
org.apache.lucene.analysis.WhitespaceAnalyzer: 1343 ms, 2063040 tokens/s&lt;/p&gt;

&lt;p&gt;BEA 1.5.0 (looks really slow)&lt;br/&gt;
org.apache.lucene.analysis.standard.StandardAnalyzer: 33891 ms, 62525 tokens/s&lt;br/&gt;
org.apache.lucene.analysis.fast.FastAnalyzer: 12703 ms, 166813 tokens/s&lt;br/&gt;
org.apache.lucene.analysis.WhitespaceAnalyzer: 4860 ms, 570095 tokens/s&lt;/p&gt;
</comment>
                    <comment id="12515726" author="yseeley@gmail.com" created="Thu, 26 Jul 2007 16:05:37 +0100"  >&lt;p&gt;Thanks Staszek, very nice!&lt;br/&gt;
If FastTokenizer is compatible with StandardTokenizer, it should probably just replace it.&lt;br/&gt;
Have you tried this replacement and running all the lucene tests?&lt;/p&gt;</comment>
                    <comment id="12515768" author="markrmiller@gmail.com" created="Thu, 26 Jul 2007 17:35:50 +0100"  >&lt;p&gt;Great patch! And a very quick turnaround to boot!&lt;/p&gt;

&lt;p&gt;I am seeing a HUGE speed increase!&lt;/p&gt;

&lt;p&gt;I also think this should certainly become the new StandardAnalyzer.&lt;/p&gt;

&lt;p&gt;I am running into only one issue...when rebuilding, after a clean, FastTokenizer does not seem to get generated &amp;#8211; FastTokenizerImpl is there, but no FastTokenizer interface; it appears to be wiped out in the clean but not regenerated in the build. If I put it in manually, everything works great.&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Mark&lt;/li&gt;
&lt;/ul&gt;

</comment>
                    <comment id="12515882" author="psmith@apache.org" created="Thu, 26 Jul 2007 22:49:08 +0100"  >&lt;p&gt;We did pretty much the same thing here at Aconex,   The tokenization mechanism in the old javacc-based analyser is woeful compared to what JFlex outputs.&lt;/p&gt;

&lt;p&gt;Nice work!  &lt;/p&gt;</comment>
                    <comment id="12515986" author="stanislaw.osinski" created="Fri, 27 Jul 2007 09:05:43 +0100"  >&lt;p&gt;Here&apos;s another patch (against r560135) which:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;replaces JavaCC-based StandardTokenizer with a JFlex-based one (all tests pass), as suggested by Yonik&lt;/li&gt;
	&lt;li&gt;updates build scripts accordingly and fixes the issue of deleting one file to many, as reported by Mark&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Additionally, I noticed that ChainedFilterTest from contrib/miscellaneous would fail on machines with non-US locale, so this patch fixes that too.&lt;/p&gt;</comment>
                    <comment id="12516665" author="stanislaw.osinski" created="Tue, 31 Jul 2007 11:05:20 +0100"  >&lt;p&gt;Here is another (this time let&apos;s call it &quot;final&quot; &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; patch for this issue which comes with a simplified (but test-wise equivalent) grammar for numeric expressions that gives about 5% performance increase.&lt;/p&gt;</comment>
                    <comment id="12516745" author="mikemccand" created="Tue, 31 Jul 2007 18:12:22 +0100"  >&lt;p&gt;I took the patch from here (to use jflex for StandardAnalyzer) and&lt;br/&gt;
merged it with the patch from &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-969&quot; title=&quot;Optimize the core tokenizers/analyzers &amp;amp; deprecate Token.termText&quot;&gt;&lt;del&gt;LUCENE-969&lt;/del&gt;&lt;/a&gt; (re-use Token &amp;amp; TokenStream)&lt;br/&gt;
to measure the net performance gains.&lt;/p&gt;

&lt;p&gt;I measure the time to just tokenize all of Wikipedia using&lt;br/&gt;
StandardAnalyzer using contrib/benchmark plus patch from &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-967&quot; title=&quot;Add &amp;quot;tokenize documents only&amp;quot; task to contrib/benchmark&quot;&gt;&lt;del&gt;LUCENE-967&lt;/del&gt;&lt;/a&gt;&lt;br/&gt;
(test details are described in &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-969&quot; title=&quot;Optimize the core tokenizers/analyzers &amp;amp; deprecate Token.termText&quot;&gt;&lt;del&gt;LUCENE-969&lt;/del&gt;&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;With the jflex patch it takes 646 sec (best of 2 runs); when I then&lt;br/&gt;
merge in the patch from &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-969&quot; title=&quot;Optimize the core tokenizers/analyzers &amp;amp; deprecate Token.termText&quot;&gt;&lt;del&gt;LUCENE-969&lt;/del&gt;&lt;/a&gt; it takes 455 sec.  Subtracting off&lt;br/&gt;
the time to just load all Wikipedia docs (= 112 sec) that gives net&lt;br/&gt;
additional speedup of 36% (534 sec -&amp;gt; 343 sec) when using &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-969&quot; title=&quot;Optimize the core tokenizers/analyzers &amp;amp; deprecate Token.termText&quot;&gt;&lt;del&gt;LUCENE-969&lt;/del&gt;&lt;/a&gt;&lt;br/&gt;
in addition to jflex.&lt;/p&gt;

&lt;p&gt;A couple other things I noticed:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;The init cost of jflex (StandardTokenizerImpl) seems to be fairly&lt;br/&gt;
    high: when I repeat the above test with smallish docs (100 tokens&lt;br/&gt;
    each) instead, the gain is around 84%.  I think this just makes&lt;br/&gt;
    the new reusableTokenStream() in &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-969&quot; title=&quot;Optimize the core tokenizers/analyzers &amp;amp; deprecate Token.termText&quot;&gt;&lt;del&gt;LUCENE-969&lt;/del&gt;&lt;/a&gt; important to commit.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;I&apos;m seeing differing token counts with the jflex StandardAnalyzer&lt;br/&gt;
    vs the current one; I think there is some difference here.  I will&lt;br/&gt;
    track down which tokens differ and post back...&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12516752" author="mikemccand" created="Tue, 31 Jul 2007 18:36:07 +0100"  >&lt;p&gt;I tracked down at least some differences between the JavaCC vs JFlex&lt;br/&gt;
versions of StandardAnalyzer.&lt;/p&gt;

&lt;p&gt;I think we should resolve these before committing.&lt;/p&gt;

&lt;p&gt;I just printed all tokens for the first 20 Wikipedia docs and diff&apos;d&lt;br/&gt;
the outputs.&lt;/p&gt;

&lt;p&gt;Here are the categories of differences that I saw:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Only the type differs on a filename-like token:&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;      OLD: (2004.jpg,34461,34469,type=&amp;lt;HOST&amp;gt;)&lt;br/&gt;
      NEW: (2004.jpg,34461,34469,type=&amp;lt;NUM&amp;gt;)&lt;/p&gt;

&lt;p&gt;    In this case the old StandardAnalyzer called &quot;2004.jpg&quot; a HOST and&lt;br/&gt;
    the new one calls it a NUM.  Seems like neither one is right!&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Only the type differs on a number token:&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;      OLD: (62.46,37004,37009,type=&amp;lt;HOST&amp;gt;)&lt;br/&gt;
      NEW: (62.46,37004,37009,type=&amp;lt;NUM&amp;gt;)&lt;/p&gt;

&lt;p&gt;    The new tokenizer looks right here.  I guess the decimal point&lt;br/&gt;
    confuses the JavaCC (old) one.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Different number of tokens produced for number-like-token:&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;      OLD: (978-0-94045043-1,86408,86424,type=&amp;lt;NUM&amp;gt;)&lt;br/&gt;
      NEW: (978-0-94045043,86408,86422,type=&amp;lt;NUM&amp;gt;)&lt;br/&gt;
           (1,86423,86424,type=&amp;lt;ALPHANUM&amp;gt;)&lt;/p&gt;

&lt;p&gt;    The new one split off the final &quot;-1&quot; as its own token, and called&lt;br/&gt;
    it ALPHANUM not NUM.  I think the old behavior is correct.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Different number of tokens produced for filename:&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;      OLD: (78academyawards/rules/rule02.html,7194,7227,type=&amp;lt;NUM&amp;gt;)&lt;br/&gt;
      NEW: (78academyawards/rules/rule02,7194,7222,type=&amp;lt;NUM&amp;gt;)&lt;br/&gt;
           (html,7223,7227,type=&amp;lt;ALPHANUM&amp;gt;)&lt;/p&gt;

&lt;p&gt;    I think the old one is better, though it should not be called a&lt;br/&gt;
    NUM (maybe we need a new &quot;FILENAME&quot; token type?).&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Same as above, but split on final &apos;_&apos; instead of &apos;.&apos; (&apos;-&apos; also&lt;br/&gt;
    shows this behavior):&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;      OLD: (2006-03-11t082958z_01_ban130523_rtridst_0_ozabs,2076,2123,type=&amp;lt;NUM&amp;gt;)&lt;br/&gt;
      new: (2006-03-11t082958z_01_ban130523_rtridst_0,2076,2117,type=&amp;lt;NUM&amp;gt;)&lt;br/&gt;
           (ozabs,2118,2123,type=&amp;lt;ALPHANUM&amp;gt;)&lt;/p&gt;</comment>
                    <comment id="12516762" author="stanislaw.osinski" created="Tue, 31 Jul 2007 19:14:52 +0100"  >&lt;p&gt;Thanks for spotting the differences, I&apos;ll add them to the unit tests and will correct the tokenizer accordingly.&lt;/p&gt;

&lt;p&gt;One doubt I have is about the filename-like tokens, e.g.:&lt;/p&gt;

&lt;p&gt;      OLD: (2004.jpg,34461,34469,type=&amp;lt;HOST&amp;gt;)&lt;br/&gt;
      NEW: (2004.jpg,34461,34469,type=&amp;lt;NUM&amp;gt;) &lt;/p&gt;

&lt;p&gt;To be honest, both variants seem &quot;almost&quot; correct. If you try 2007.org &amp;#8211; this is a correct domain name (and has a funny website on it &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;, so, given the fact that we don&apos;t check for typical suffixes, such as &quot;.com&quot;, &amp;lt;HOST&amp;gt; doesn&apos;t seem wrong. On the other hand, 2004.jpg may well have been some sort of numerical code or a product number, so &amp;lt;NUM&amp;gt; is not totally irrelevant either.&lt;/p&gt;

&lt;p&gt;For the JFlex-based tokenizer, I put the &amp;lt;NUM&amp;gt; rule matching first, as it gives some nice performance benefits. We can put HOST first, and then we&apos;ll get compliance with the old version.&lt;/p&gt;

&lt;p&gt;Another option we might consider is:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;adding a new token type for file names (get a list of common extensions or even assume that an extension is simply three alphanumerical characters)&lt;/li&gt;
	&lt;li&gt;checking for common domain names in hosts (something along the lines of: &quot;mil&quot; | &quot;info&quot; | &quot;gov&quot; | &quot;edu&quot; | &quot;biz&quot; | &quot;com&quot; | &quot;org&quot; | &quot;net&quot; |  &quot;arpa&quot; | 
{LETTER}
{2}
&lt;p&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I&apos;m not sure how this will affect the performance of the tokenizer, but my rough guess is that if we don&apos;t come up with very complex/ backtracking-prone rules there should not be too much of a difference. On the other hand, if 100% compatibility with the old tokenizer is a priority, adding new token types is not a good idea, I guess.&lt;/p&gt;

&lt;p&gt;Finally, when it comes to the initialization time of the new tokenizer &amp;#8211; according to the JFlex documentation, some time is required to unpack the transition tables. But the unpacking takes place during the initialization of static fields, so once the class is loaded the overhead should be negligible.&lt;/p&gt;</comment>
                    <comment id="12516767" author="markrmiller@gmail.com" created="Tue, 31 Jul 2007 19:36:49 +0100"  >&lt;p&gt;I think it is important that we do not modify the StandardAnalyzer and that this improved version has results identical to the original. I believe that the StandardAnalyzer is pretty heavily used &amp;#8211; these performance increases could give many users huge gains. By changing this Analyzer at all we will be forcing users to effectively lose terms in their indexes if they want to upgrade core Lucene for use on an older index.&lt;/p&gt;

&lt;p&gt;I think any enhanced StandardAnalzyer should probably be released as a new Analyzer. This one should mimic the old though, as the performance gains will be very beneficial to a lot of current users.&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Mark&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12516775" author="mikemccand" created="Tue, 31 Jul 2007 20:03:29 +0100"  >
&lt;p&gt;I agree, let&apos;s try to perfectly match the tokens of the old&lt;br/&gt;
StandardAnalyzer so we have a way-faster drop-in replacement.&lt;/p&gt;

&lt;p&gt;The speedups of JFlex are amazing: based on a quick test, with JFlex +&lt;br/&gt;
patch from &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-969&quot; title=&quot;Optimize the core tokenizers/analyzers &amp;amp; deprecate Token.termText&quot;&gt;&lt;del&gt;LUCENE-969&lt;/del&gt;&lt;/a&gt;, the new StandardAnalyzer is only 2.09X slower&lt;br/&gt;
than WhitespaceAnalyzer even though it&apos;s doing so much more ...&lt;/p&gt;

&lt;p&gt;&amp;gt; Finally, when it comes to the initialization time of the new&lt;br/&gt;
&amp;gt; tokenizer &amp;#8211; according to the JFlex documentation, some time is&lt;br/&gt;
&amp;gt; required to unpack the transition tables. But the unpacking takes&lt;br/&gt;
&amp;gt; place during the initialization of static fields, so once the class&lt;br/&gt;
&amp;gt; is loaded the overhead should be negligible.&lt;/p&gt;

&lt;p&gt;Yeah I&apos;m baffled why it&apos;s that much slower, but on 100 token docs I&lt;br/&gt;
definitely see &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-969&quot; title=&quot;Optimize the core tokenizers/analyzers &amp;amp; deprecate Token.termText&quot;&gt;&lt;del&gt;LUCENE-969&lt;/del&gt;&lt;/a&gt; making things 84% faster but &quot;only&quot; 36%&lt;br/&gt;
faster if I use the full Wikipedia doc (which are much larger than 100&lt;br/&gt;
tokens on average).  If we tested even smaller docs I think the gains&lt;br/&gt;
would be even more.&lt;/p&gt;

&lt;p&gt;When I ran under the profiler it was the StandardTokenizerImpl&lt;br/&gt;
&amp;lt;init&amp;gt;(java.io.Reader) way on the top.  Maybe it&apos;s the cost of new&apos;ing&lt;br/&gt;
the 16 KB buffer each time?&lt;/p&gt;

&lt;p&gt;In any event I think it&apos;s OK, so long as we get &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-969&quot; title=&quot;Optimize the core tokenizers/analyzers &amp;amp; deprecate Token.termText&quot;&gt;&lt;del&gt;LUCENE-969&lt;/del&gt;&lt;/a&gt; in, and&lt;br/&gt;
document the importance of using reusableTokenStream() API for better&lt;br/&gt;
performance.&lt;/p&gt;</comment>
                    <comment id="12516776" author="cutting" created="Tue, 31 Jul 2007 20:03:57 +0100"  >&lt;p&gt;It is important that the same sequence of token text is produced, but I think we could live with different token types in some cases, if we must.  Few applications depend on token types, no?&lt;/p&gt;

&lt;p&gt;Provided the token text issues can be resolved, I&apos;d like to see StandardTokenizer replaced with this.  Performance is important, and ideally folks shouldn&apos;t have to change their applications to see performance improvements.&lt;/p&gt;</comment>
                    <comment id="12516893" author="stanislaw.osinski" created="Wed, 1 Aug 2007 08:53:20 +0100"  >&lt;p&gt;When digging deeper into the issues of compatibility with the original StandardAnalyzer, I stumbled upon something strange. Take the following text:&lt;/p&gt;

&lt;p&gt;78academyawards/rules/rule02.html,7194,7227,type&lt;/p&gt;

&lt;p&gt;which was tokenized by the original StandardAnalyzer as one &amp;lt;NUM&amp;gt;. If you look at the definition of the &amp;lt;NUM&amp;gt; token:&lt;/p&gt;

&lt;p&gt;// every other segment must have at least one digit&lt;br/&gt;
&amp;lt;NUM: (&amp;lt;ALPHANUM&amp;gt; &amp;lt;P&amp;gt; &amp;lt;HAS_DIGIT&amp;gt;&lt;/p&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &amp;lt;HAS_DIGIT&amp;gt; &amp;lt;P&amp;gt; &amp;lt;ALPHANUM&amp;gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &amp;lt;ALPHANUM&amp;gt; (&amp;lt;P&amp;gt; &amp;lt;HAS_DIGIT&amp;gt; &amp;lt;P&amp;gt; &amp;lt;ALPHANUM&amp;gt;)+&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &amp;lt;HAS_DIGIT&amp;gt; (&amp;lt;P&amp;gt; &amp;lt;ALPHANUM&amp;gt; &amp;lt;P&amp;gt; &amp;lt;HAS_DIGIT&amp;gt;)+&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &amp;lt;ALPHANUM&amp;gt; &amp;lt;P&amp;gt; &amp;lt;HAS_DIGIT&amp;gt; (&amp;lt;P&amp;gt; &amp;lt;ALPHANUM&amp;gt; &amp;lt;P&amp;gt; &amp;lt;HAS_DIGIT&amp;gt;)+&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &amp;lt;HAS_DIGIT&amp;gt; &amp;lt;P&amp;gt; &amp;lt;ALPHANUM&amp;gt; (&amp;lt;P&amp;gt; &amp;lt;HAS_DIGIT&amp;gt; &amp;lt;P&amp;gt; &amp;lt;ALPHANUM&amp;gt;)+&lt;br/&gt;
        )&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;


&lt;p&gt;you&apos;ll see that, as explained in the comment, every other segment must have at least one digit. But actually, according to my understanding, this rule should not match the above text as a whole (and with JFlex it doesn&apos;t , actually). Below is the text split by punctuation characters, and it looks like there is no way of splitting this text into alternating segments, every second of which must have a digit (A = ALPHANUM, H = HAS_DIGIT):&lt;/p&gt;

&lt;p&gt;78academyawards   /   rules   /   rule02   .   html   ,   7194   ,   7227   ,   type&lt;br/&gt;
                H                  P      A     P       H       P     A     P     H      P      A     P    H?*     (starting from the beginning)&lt;br/&gt;
                                                                              H?*    P     A      P      H     P     A       (starting from the end)&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;(would have to be H, but no digits in substring &quot;type&quot; or &quot;html&quot;)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I have no idea why JavaCC matched the whole text as a &amp;lt;NUM&amp;gt;, JFlex behaved &quot;more correctly&quot; here. &lt;/p&gt;

&lt;p&gt;Now I can see two solutions:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;try to patch the JFlex grammar to emulate JavaCC quirks (though I may not be aware of most of them...)&lt;/li&gt;
	&lt;li&gt;relax the &amp;lt;NUM&amp;gt; rule a little bit (JFlex notation):&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;// there must be at least one segment with a digit&lt;br/&gt;
NUM = (&lt;/p&gt;
{P} ({HAS_DIGIT} | {ALPHANUM}))* {HAS_DIGIT} ({P}
&lt;p&gt; (&lt;/p&gt;
{HAS_DIGIT}
&lt;p&gt; | &lt;/p&gt;
{ALPHANUM}
&lt;p&gt;))*&lt;/p&gt;

&lt;p&gt;With this definition, again, all StandardAnalyzer tests pass, plus all texts along the lines of:&lt;/p&gt;

&lt;p&gt;2006-03-11t082958z_01_ban130523_rtridst_0_ozabs,2076,2123,type&lt;br/&gt;
78academyawards/rules/rule02.html,7194,7227,type&lt;br/&gt;
978-0-94045043-1,86408,86424,type&lt;br/&gt;
62.46,37004,37009,type    (this one was parsed as &amp;lt;HOST&amp;gt; by the original analyzer)&lt;/p&gt;

&lt;p&gt;get parsed as a whole as one &amp;lt;NUM&amp;gt;, which is equivalent to what JavaCC-based version would do. I will attach a corresponding patch in a second.&lt;/p&gt;
</comment>
                    <comment id="12516895" author="stanislaw.osinski" created="Wed, 1 Aug 2007 09:33:18 +0100"  >&lt;p&gt;A patch for better compatibility with the StandardAnalyzer containing:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;relaxed definition of the &amp;lt;NUM&amp;gt; token&lt;/li&gt;
	&lt;li&gt;new test cases in TestStandardAnalyzer&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I noticed that with this patch org.apache.lucene.benchmark.quality.TestQualityRun.testTrecQuality fails, but I&apos;m not sure if this is related to the tokenizer.&lt;/p&gt;</comment>
                    <comment id="12517003" author="mikemccand" created="Wed, 1 Aug 2007 16:50:15 +0100"  >&lt;p&gt;Oddly, the patch for TestStandardAnalyzer failed to apply for me (but&lt;br/&gt;
the rest did), so I manually merged those changes in.  Oh, I see: it&lt;br/&gt;
was the &quot;Korean words&quot; test &amp;#8211; somehow the characters got mapped to&lt;br/&gt;
?&apos;s in your patch.  This is why the patch didn&apos;t apply, I think?&lt;br/&gt;
Maybe you used a diffing tool that wasn&apos;t happy with unicode or&lt;br/&gt;
something?&lt;/p&gt;

&lt;p&gt;I also see the quality test failing in contrib benchmark.  I fear&lt;br/&gt;
something about the new StandardAnalyzer is in fact causing this test&lt;br/&gt;
to fail (it passes on a clean checkout).  That test uses&lt;br/&gt;
StandardAnalyzer.&lt;/p&gt;

&lt;p&gt;KO I re-tested the old vs new StandardAnalyzer on Wikipedia and I&lt;br/&gt;
still found some differences, I think only on these very large&lt;br/&gt;
URL-like tokens.  Here&apos;s one:&lt;/p&gt;

&lt;p&gt;  OLD&lt;br/&gt;
    (money.cnn.com,1382,1395,type=&amp;lt;HOST&amp;gt;)&lt;br/&gt;
    (magazines,1396,1405,type=&amp;lt;ALPHANUM&amp;gt;)&lt;br/&gt;
    (fortune,1406,1413,type=&amp;lt;ALPHANUM&amp;gt;)&lt;br/&gt;
    (fortune,1414,1421,type=&amp;lt;ALPHANUM&amp;gt;)&lt;br/&gt;
    (archive/2007/03/19/8402357,1422,1448,type=&amp;lt;NUM&amp;gt;)&lt;br/&gt;
    (index.htm,1449,1458,type=&amp;lt;HOST&amp;gt;)&lt;/p&gt;

&lt;p&gt;  NEW&lt;br/&gt;
    (/money.cnn.com/magazines/fortune/fortune_archive/2007/03/19/8402357/index.htm,1381,1458,type=&amp;lt;NUM&amp;gt;)&lt;/p&gt;

&lt;p&gt;I like the NEW behavior better but I fear we should try to match the&lt;br/&gt;
old one?&lt;/p&gt;


&lt;p&gt;Here&apos;s another one:&lt;/p&gt;

&lt;p&gt;  OLD&lt;br/&gt;
    (mid-20th,2436,2444,type=&amp;lt;NUM&amp;gt;)&lt;/p&gt;

&lt;p&gt;  NEW&lt;br/&gt;
    (mid,2436,2439,type=&amp;lt;ALPHANUM&amp;gt;)&lt;br/&gt;
    (-20th,2439,2444,type=&amp;lt;NUM&amp;gt;)&lt;/p&gt;

&lt;p&gt;I like the old behavior better here.&lt;/p&gt;

&lt;p&gt;Another one:&lt;/p&gt;

&lt;p&gt;  OLD&lt;br/&gt;
    (safari-0-sheikh,12011,12026,type=&amp;lt;NUM&amp;gt;)&lt;br/&gt;
    (zayed,12027,12032,type=&amp;lt;ALPHANUM&amp;gt;)&lt;br/&gt;
    (grand,12033,12038,type=&amp;lt;ALPHANUM&amp;gt;)&lt;br/&gt;
    (mosque.jpg,12039,12049,type=&amp;lt;HOST&amp;gt;)&lt;/p&gt;

&lt;p&gt;  NEW&lt;br/&gt;
    (safari,12011,12017,type=&amp;lt;ALPHANUM&amp;gt;)&lt;br/&gt;
    (0-sheikh-zayed-grand-mosque.jpg,12018,12049,type=&amp;lt;NUM&amp;gt;)&lt;/p&gt;

&lt;p&gt;Another one:&lt;/p&gt;

&lt;p&gt;  OLD&lt;br/&gt;
    (semitica-01.png,616,631,type=&amp;lt;NUM&amp;gt;)&lt;/p&gt;

&lt;p&gt;  NEW&lt;br/&gt;
    (-semitica-01.png,615,631,type=&amp;lt;NUM&amp;gt;)&lt;/p&gt;
</comment>
                    <comment id="12517097" author="doronc" created="Wed, 1 Aug 2007 23:23:27 +0100"  >&lt;p&gt;The search quality test failure can be caused by the standard &lt;br/&gt;
analyzer generating different tokens than before. (has nothing &lt;br/&gt;
to do with token types.)&lt;/p&gt;

&lt;p&gt;This is because the test&apos;s topics (queries) and qrels (expected matches) &lt;br/&gt;
were created by examining an index that was created using the current &lt;br/&gt;
standard analyzer. Now, running this test with an analyzer that creates &lt;br/&gt;
other tokens is likely to fail. &lt;/p&gt;

&lt;p&gt;It is not difficult to update this test for a modified analyzer, but it seems &lt;br/&gt;
better to me to preserve the original standard analyzer behavior.&lt;/p&gt;</comment>
                    <comment id="12517184" author="stanislaw.osinski" created="Thu, 2 Aug 2007 09:44:35 +0100"  >&lt;p&gt;Thanks for more test cases. I guess the biggest problem here is that the scanner generated by JavaCC doesn&apos;t seem to strictly follow the specification (see &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-966#action_12516893&quot; class=&quot;external-link&quot;&gt;https://issues.apache.org/jira/browse/LUCENE-966#action_12516893&lt;/a&gt;), so I&apos;d need to emulate possible JavaCC &quot;bugs&quot; I&apos;m not aware of at the moment (I&apos;m not an expert on lexical scanner generation either, not yet at least &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;. I can add some workarounds to the grammar to make the known incompatibility examples work, but this won&apos;t guarantee consistency in general.&lt;/p&gt;

&lt;p&gt;As a side note, it&apos;s a shame there&apos;s no trace of the version of JavaCC that was used to generate the scanner for the original StandardAnalyzer. I&apos;m also curious if the results of the current JavaCC grammar would be the same with the newest version of the generator (4.0 I guess) &amp;#8211; I&apos;ll try to check that.&lt;/p&gt;

&lt;p&gt;Anyway, I&apos;ll take a look at the problem in more depth once again. And in the worst case scenario, we can keep the StandardAnalyzer as it was and add the new one next to it so that people can have a choice (on the other hand, this might be a problem for the quality tests).&lt;/p&gt;</comment>
                    <comment id="12517222" author="mikemccand" created="Thu, 2 Aug 2007 12:56:05 +0100"  >&lt;p&gt;If it really is down to emulating the bugs/oddities in JavaCC then I&lt;br/&gt;
think it&apos;s not worth polluting the new tokenizer with these legacy&lt;br/&gt;
bugs, unless one or two cases can match perfectly and not degrade&lt;br/&gt;
performance too badly?&lt;/p&gt;

&lt;p&gt;And maybe what we should do is make this a new tokenizer, calling it&lt;br/&gt;
StandardAnalyzer2, and then deprecate the existing StandardAnalyzer?&lt;br/&gt;
Then remove any &amp;amp; all JavaCC bug emulation from the new one.&lt;/p&gt;

&lt;p&gt;This way people relying on the precise bugs in JavaCC tokenization are&lt;br/&gt;
not hurt on upgrading to 2.3 and are given a chance to migrate to the&lt;br/&gt;
new one (with 1 release of deprecated StandardAnalyzer).  And new&lt;br/&gt;
people will use the new faster one.&lt;/p&gt;</comment>
                    <comment id="12517233" author="stanislaw.osinski" created="Thu, 2 Aug 2007 13:09:35 +0100"  >&lt;p&gt;To be precise &amp;#8211; I&apos;m not 100% sure that this is a bug in JavaCC (I&apos;ll try to browse/ask on their mailing list to find out), but it looks like the scanner generated by JavaCC does not really strictly follow the grammar. I discovered this when you gave the examples of different token produced by JFlex- and JavaCC-based scanners generated from equivalent grammars &amp;#8211; JFlex seemed to behave &quot;correctly&quot;, hence different tokens.&lt;/p&gt;

&lt;p&gt;I was about to start trying to hack the grammar to produce results simiar to StandardAnalyzer (based on a finite set of test cases &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;. I&apos;ll see how it compares performance-wise too.&lt;/p&gt;</comment>
                    <comment id="12517339" author="gsingers" created="Thu, 2 Aug 2007 19:55:23 +0100"  >&lt;p&gt;+1 for deprecating StandardAnalyzer, although it is a little weird to have a StandardAnalyzer2, which is it the standard or not?  Maybe we could call it the DefaultAnalyzer or something like that.  I never much cared for tacking on numbers on the end of class names.  &lt;/p&gt;

&lt;p&gt;I agree with Mike M&apos;s last comment and approach, though, if that proves to be the case for the differences.&lt;/p&gt;</comment>
                    <comment id="12517342" author="mikemccand" created="Thu, 2 Aug 2007 20:08:53 +0100"  >&lt;p&gt;I like the name DefaultAnalyzer.&lt;/p&gt;</comment>
                    <comment id="12517348" author="markrmiller@gmail.com" created="Thu, 2 Aug 2007 20:32:25 +0100"  >&lt;p&gt;These issues seem odd.&lt;/p&gt;

&lt;p&gt;Both JavaCC and Flex match with the same rules:&lt;br/&gt;
1. Longest match first&lt;br/&gt;
2. If match size is the same, use the first in the grammar&lt;/p&gt;

&lt;p&gt;OLD&lt;br/&gt;
    (money.cnn.com,1382,1395,type=&amp;lt;HOST&amp;gt;)&lt;br/&gt;
    (magazines,1396,1405,type=&amp;lt;ALPHANUM&amp;gt;)&lt;br/&gt;
    (fortune,1406,1413,type=&amp;lt;ALPHANUM&amp;gt;)&lt;br/&gt;
    (fortune,1414,1421,type=&amp;lt;ALPHANUM&amp;gt;)&lt;br/&gt;
    (archive/2007/03/19/8402357,1422,1448,type=&amp;lt;NUM&amp;gt;)&lt;br/&gt;
    (index.htm,1449,1458,type=&amp;lt;HOST&amp;gt;)&lt;/p&gt;

&lt;p&gt;  NEW&lt;br/&gt;
    (/money.cnn.com/magazines/fortune/fortune_archive/2007/03/19/8402357/index.htm,1381,1458,type=&amp;lt;NUM&amp;gt;)&lt;/p&gt;

&lt;p&gt;The old is correct and the NEW should not match &amp;lt;NUM&amp;gt;. &amp;lt;NUM&amp;gt; should break on &apos;/&apos; and &apos;.&apos; and every other token from the break should have a digit for a NUM match to occur. This is not the case.&lt;/p&gt;

&lt;p&gt;  OLD&lt;br/&gt;
    (mid-20th,2436,2444,type=&amp;lt;NUM&amp;gt;)&lt;/p&gt;

&lt;p&gt;  NEW&lt;br/&gt;
    (mid,2436,2439,type=&amp;lt;ALPHANUM&amp;gt;)&lt;br/&gt;
    (-20th,2439,2444,type=&amp;lt;NUM&amp;gt;)&lt;/p&gt;

&lt;p&gt;Something is wrong with the NEW one. &amp;lt;NUM&amp;gt; is certainly a valid longer match.&lt;/p&gt;

&lt;p&gt;  OLD&lt;br/&gt;
    (safari-0-sheikh,12011,12026,type=&amp;lt;NUM&amp;gt;)&lt;br/&gt;
    (zayed,12027,12032,type=&amp;lt;ALPHANUM&amp;gt;)&lt;br/&gt;
    (grand,12033,12038,type=&amp;lt;ALPHANUM&amp;gt;)&lt;br/&gt;
    (mosque.jpg,12039,12049,type=&amp;lt;HOST&amp;gt;)&lt;/p&gt;

&lt;p&gt;  NEW&lt;br/&gt;
    (safari,12011,12017,type=&amp;lt;ALPHANUM&amp;gt;)&lt;br/&gt;
    (0-sheikh-zayed-grand-mosque.jpg,12018,12049,type=&amp;lt;NUM&amp;gt;)&lt;/p&gt;

&lt;p&gt;Again, something seems wrong with the NEW.  (safari-0-sheikh,12011,12026,type=&amp;lt;NUM&amp;gt;) is a correct and longer match than  (safari,12011,12017,type=&amp;lt;ALPHANUM&amp;gt;)&lt;/p&gt;

&lt;p&gt;It would be nice to have the source text for these comparisons.&lt;/p&gt;

&lt;p&gt;Also, a hard vote against StandardAnalyzer2 &amp;lt;g&amp;gt; Default is arguable as well, as this wouldn&apos;t be the default analyzer you should use in many cases (don&apos;t like standard because of that either).&lt;/p&gt;

&lt;p&gt;From the latest samples, I would say something is off with the NEW and OLD appears mostly correct.&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Mark&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12517358" author="markrmiller@gmail.com" created="Thu, 2 Aug 2007 21:02:04 +0100"  >&lt;p&gt;By the way...you can see one of the issues here:&lt;/p&gt;

&lt;p&gt;OLD&lt;br/&gt;
    (money.cnn.com,1382,1395,type=&amp;lt;HOST&amp;gt;)&lt;br/&gt;
    (magazines,1396,1405,type=&amp;lt;ALPHANUM&amp;gt;)&lt;br/&gt;
    (fortune,1406,1413,type=&amp;lt;ALPHANUM&amp;gt;)&lt;br/&gt;
    (fortune,1414,1421,type=&amp;lt;ALPHANUM&amp;gt;)&lt;br/&gt;
    (archive/2007/03/19/8402357,1422,1448,type=&amp;lt;NUM&amp;gt;)&lt;br/&gt;
    (index.htm,1449,1458,type=&amp;lt;HOST&amp;gt;)&lt;/p&gt;

&lt;p&gt;  NEW&lt;br/&gt;
    (/money.cnn.com/magazines/fortune/fortune_archive/2007/03/19/8402357/index.htm,1381,1458,type=&amp;lt;NUM&amp;gt;) &lt;/p&gt;

&lt;p&gt;JavaCC StandardAnalyzer would never output a token that starts with a &apos;/&apos;. It would be cut off. The issues may be involved with how JFlex skips characters that are not part of a match compared to how JavaCC is doing it. Or perhaps the JFlex version is considering &apos;/&apos; and &apos;.&apos; to be ALPHANUM&apos;s.&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Mark&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12517368" author="markrmiller@gmail.com" created="Thu, 2 Aug 2007 21:42:50 +0100"  >&lt;p&gt;&amp;gt;When digging deeper into the issues of compatibility with the original StandardAnalyzer, I stumbled upon something strange. Take the following &amp;gt;text:&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt;78academyawards/rules/rule02.html,7194,7227,type&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt;which was tokenized by the original StandardAnalyzer as one &amp;lt;NUM&amp;gt;. If you look at the definition of the &amp;lt;NUM&amp;gt; token:&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt;// every other segment must have at least one digit&lt;br/&gt;
&amp;gt;&amp;lt;NUM: (&amp;lt;ALPHANUM&amp;gt; &amp;lt;P&amp;gt; &amp;lt;HAS_DIGIT&amp;gt;&lt;br/&gt;
&amp;gt;       | &amp;lt;HAS_DIGIT&amp;gt; &amp;lt;P&amp;gt; &amp;lt;ALPHANUM&amp;gt;&lt;br/&gt;
&amp;gt;       | &amp;lt;ALPHANUM&amp;gt; (&amp;lt;P&amp;gt; &amp;lt;HAS_DIGIT&amp;gt; &amp;lt;P&amp;gt; &amp;lt;ALPHANUM&amp;gt;)+&lt;br/&gt;
&amp;gt;       | &amp;lt;HAS_DIGIT&amp;gt; (&amp;lt;P&amp;gt; &amp;lt;ALPHANUM&amp;gt; &amp;lt;P&amp;gt; &amp;lt;HAS_DIGIT&amp;gt;)+&lt;br/&gt;
&amp;gt;       | &amp;lt;ALPHANUM&amp;gt; &amp;lt;P&amp;gt; &amp;lt;HAS_DIGIT&amp;gt; (&amp;lt;P&amp;gt; &amp;lt;ALPHANUM&amp;gt; &amp;lt;P&amp;gt; &amp;lt;HAS_DIGIT&amp;gt;)+&lt;br/&gt;
&amp;gt;       | &amp;lt;HAS_DIGIT&amp;gt; &amp;lt;P&amp;gt; &amp;lt;ALPHANUM&amp;gt; (&amp;lt;P&amp;gt; &amp;lt;HAS_DIGIT&amp;gt; &amp;lt;P&amp;gt; &amp;lt;ALPHANUM&amp;gt;)+&lt;br/&gt;
&amp;gt;        )&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt;you&apos;ll see that, as explained in the comment, every other segment must have at least one digit. But actually, according to my understanding, this &amp;gt;rule should not match the above text as a whole (and with JFlex it doesn&apos;t , actually). Below is the text split by punctuation characters, and it looks &amp;gt;like there is no way of splitting this text into alternating segments, every second of which must have a digit (A = ALPHANUM, H = HAS_DIGIT):&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt;78academyawards / rules / rule02 . html , 7194 , 7227 , type&lt;br/&gt;
&amp;gt;                H P A P H P A P H P A P H?* (starting from the beginning)&lt;br/&gt;
&amp;gt;                                                                              H?* P A P H P A (starting from the end)&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt;* (would have to be H, but no digits in substring &quot;type&quot; or &quot;html&quot;)&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt;I have no idea why JavaCC matched the whole text as a &amp;lt;NUM&amp;gt;, JFlex behaved &quot;more correctly&quot; here. &lt;/p&gt;

&lt;p&gt;I think that JavaCC is correct here. Every other segment must have a digit: 78academyawards / rules / rule02 . html &lt;br/&gt;
It looks to me like every other segment does have a digit. First segment has a digit, second does not, third does, fourth does not. Matches NUM correctly.&lt;/p&gt;</comment>
                    <comment id="12517371" author="stanislaw.osinski" created="Thu, 2 Aug 2007 22:08:58 +0100"  >&lt;p&gt;Okkkk &amp;#8211; only now I realized I made a really silly mistake &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; When using Mark&apos;s examples I somehow took the &quot;,type&quot; substring as part of the token image, which made the JavaCC tokenizer look &quot;buggy&quot;...  Apologies for the confusion, tomorrow in the morning I&apos;ll correct my tests and will see what&apos;s happening.&lt;/p&gt;

&lt;p&gt;One more important clarification &amp;#8211; the tokenizer from the last patch (jflex-analyzer-r561693-compatibility.txt) has a completely different definition of the &amp;lt;NUM&amp;gt; token &amp;#8211; it allows digits in any segment, hence the totally different results. If we want to be compatible with the StandardAnalyzer, we should forget about that patch.&lt;/p&gt;

&lt;p&gt;Mark &amp;#8211; have you tried the jflex-analyzer-r560135-patch.txt patch with your wikipedia diff test? That&apos;s the early one whose grammar was &quot;dot for dot&quot; translated from the original JavaCC spec &amp;#8211; for further patches I did some &quot;optimizations&quot;, which seem to have broken the compatibility...&lt;/p&gt;

&lt;p&gt;Incidentally, what was the motivation for requiring the &amp;lt;NUM&amp;gt; token to have numbers only in every second segment and not in any segment?&lt;/p&gt;
</comment>
                    <comment id="12517483" author="stanislaw.osinski" created="Fri, 3 Aug 2007 09:19:20 +0100"  >&lt;p&gt;I&apos;ve attached another patch with:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;grammar translated &quot;dot for dot&quot; from JavaCC (no &quot;optimizations&quot; this time)&lt;/li&gt;
	&lt;li&gt;tests extended with Mark&apos;s latest compatibility examples&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I hope this time the patch correctly applies to the test class (previously I used Eclipse to create the patch which may not have been a good idea). All unit tests pass, so I hope this time I finally got it right.&lt;/p&gt;</comment>
                    <comment id="12517513" author="mikemccand" created="Fri, 3 Aug 2007 13:28:03 +0100"  >&lt;p&gt;The TestStandardAnalyzer.java patch still fails to apply &amp;#8211; looks like&lt;br/&gt;
the same thing as before (the unicode chars under &quot;Korean words&quot; were&lt;br/&gt;
replaced by ?&apos;s somewhere along the way).&lt;/p&gt;

&lt;p&gt;And, somehow, many of the files are dup&apos;d (appear twice) in the&lt;br/&gt;
patch (eg StandardTokenizerImpl.jflex, StandardFilter.java, etc.).&lt;br/&gt;
I&apos;m not sure whether first or 2nd one is the one to keep.&lt;/p&gt;</comment>
                    <comment id="12517514" author="mikemccand" created="Fri, 3 Aug 2007 13:33:45 +0100"  >&lt;p&gt;&amp;gt; The TestStandardAnalyzer.java patch still fails to apply &amp;#8211; looks like&lt;br/&gt;
&amp;gt; the same thing as before (the unicode chars under &quot;Korean words&quot; were&lt;br/&gt;
&amp;gt; replaced by ?&apos;s somewhere along the way). &lt;/p&gt;

&lt;p&gt;WOOPS!  This was my bad.  I was clicking on the patch and then&lt;br/&gt;
copy/pasting the text out of the browser into a local file, and this&lt;br/&gt;
step (ugh) introduces the ?&apos;s.  If I instead right-click on the link&lt;br/&gt;
and have browser directly save the file then it works perfectly!&lt;/p&gt;

&lt;p&gt;Sorry for the confusion.&lt;/p&gt;</comment>
                    <comment id="12517515" author="stanislaw.osinski" created="Fri, 3 Aug 2007 13:34:53 +0100"  >&lt;p&gt;This time I used Tortoise, but it made things worse &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; I&apos;ll create the patch the usual way and e-mail it directly to you to see if it&apos;s not JIRA&apos;s fault (I don&apos;t see the &apos;?&apos; characters on my local machine).&lt;/p&gt;</comment>
                    <comment id="12517518" author="stanislaw.osinski" created="Fri, 3 Aug 2007 13:37:51 +0100"  >&lt;p&gt;One more try &amp;#8211; this time without duplicated entries (no idea why Tortoise did this...).&lt;/p&gt;</comment>
                    <comment id="12517520" author="mikemccand" created="Fri, 3 Aug 2007 13:43:00 +0100"  >&lt;p&gt;Super, I will compare tokens on Wikipedia...&lt;/p&gt;</comment>
                    <comment id="12517542" author="mikemccand" created="Fri, 3 Aug 2007 15:12:39 +0100"  >&lt;p&gt;First 1000 documents in wikipedia show absolutely no difference &amp;#8211; I think this one is it!&lt;/p&gt;</comment>
                    <comment id="12517577" author="stanislaw.osinski" created="Fri, 3 Aug 2007 17:51:35 +0100"  >&lt;p&gt;Good news &amp;#8211; thanks for the test!&lt;/p&gt;</comment>
                    <comment id="12517581" author="mikemccand" created="Fri, 3 Aug 2007 17:55:41 +0100"  >&lt;p&gt;OK I can commit this.  Does anyone see any reason not to?  I will wait a few days then commit...&lt;/p&gt;

&lt;p&gt;Thank you Stanislaw!&lt;/p&gt;</comment>
                    <comment id="12518463" author="mikemccand" created="Wed, 8 Aug 2007 16:01:57 +0100"  >
&lt;p&gt;I was gearing up to commit this, but realized the copyright on top of&lt;br/&gt;
StandardTokenizer.java isn&apos;t the standard Apache header; it&apos;s this&lt;br/&gt;
one:&lt;/p&gt;

&lt;p&gt;/*&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Carrot2 project.&lt;br/&gt;
 *&lt;/li&gt;
	&lt;li&gt;Copyright (C) 2002-2007, Dawid Weiss, Stanis&#322;aw Osi&#324;ski.&lt;/li&gt;
	&lt;li&gt;Portions (C) Contributors listed in &quot;carrot2.CONTRIBUTORS&quot; file.&lt;/li&gt;
	&lt;li&gt;All rights reserved.&lt;br/&gt;
 *&lt;/li&gt;
	&lt;li&gt;Refer to the full license file &quot;carrot2.LICENSE&quot;&lt;/li&gt;
	&lt;li&gt;in the root folder of the repository checkout or at:&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;http://www.carrot2.org/carrot2.LICENSE&quot; class=&quot;external-link&quot;&gt;http://www.carrot2.org/carrot2.LICENSE&lt;/a&gt;&lt;br/&gt;
 */&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I believe (according to &lt;a href=&quot;http://www.apache.org/legal/src-headers.html&quot; class=&quot;external-link&quot;&gt;http://www.apache.org/legal/src-headers.html&lt;/a&gt;),&lt;br/&gt;
we need to replace the above with the standard Apache header and then&lt;br/&gt;
maybe move this one into the NOTICE.txt.  Is that right?  Stanislaw,&lt;br/&gt;
is that OK?&lt;/p&gt;

&lt;p&gt;I would also add the Apache header into StandardAnalyzerImpl.jflex.&lt;/p&gt;</comment>
                    <comment id="12518521" author="stanislaw.osinski" created="Wed, 8 Aug 2007 18:50:19 +0100"  >&lt;p&gt;Absolutely &amp;#8211; the header was there only because I used Carrot2&apos;s grammar to start with and forgot to remove it. You can put the Apache header on all the files, NOTICE.txt is not necessary either. Apologies for confusion &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="12518523" author="mikemccand" created="Wed, 8 Aug 2007 18:54:57 +0100"  >&lt;p&gt;Super, thanks!&lt;/p&gt;</comment>
                    <comment id="12518566" author="mikemccand" created="Wed, 8 Aug 2007 23:29:30 +0100"  >&lt;p&gt;OK I committed this!  Thank you Stanislaw!&lt;/p&gt;

&lt;p&gt;I ran a quick perf test on Wikipedia (first 50K docs only) and found&lt;br/&gt;
the new StandardTokenizer is ~6X faster &amp;#8211; awesome &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;I made these small additional changes over the final patch before&lt;br/&gt;
committing:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;I removed StandardAnalyzer.html &quot;grammar doc&quot; generation from&lt;br/&gt;
    build.xml since it was using jjdoc.  Stanislaw, is there something&lt;br/&gt;
    in jflex that can generated a BNF description of the grammar as&lt;br/&gt;
    HTML?&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;I removed the @author tag from StandardTokenizer.java: we are&lt;br/&gt;
    removing all such tags and instead giving credit in CHANGES.txt.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;I removed the whitespace-only diffs from common-build.xml &amp;amp;&lt;br/&gt;
    build.xml.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;I put back the big comment that describes this tokenizer in&lt;br/&gt;
    StandardTokenizer.java.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Put standard Apache copyright headers in all sources.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12518636" author="stanislaw.osinski" created="Thu, 9 Aug 2007 07:53:14 +0100"  >&lt;p&gt;&amp;gt;  * I removed StandardAnalyzer.html &quot;grammar doc&quot; generation from&lt;br/&gt;
&amp;gt;    build.xml since it was using jjdoc. Stanislaw, is there something&lt;br/&gt;
&amp;gt;    in jflex that can generated a BNF description of the grammar as&lt;br/&gt;
&amp;gt;    HTML? &lt;/p&gt;

&lt;p&gt;I&apos;ve had a look at the JFlex docs and there doesn&apos;t seem to be such a tool for JFlex, I&apos;m afraid.&lt;/p&gt;</comment>
                    <comment id="12518661" author="mikemccand" created="Thu, 9 Aug 2007 09:21:53 +0100"  >&lt;p&gt;&amp;gt; &amp;gt; * I removed StandardAnalyzer.html &quot;grammar doc&quot; generation from&lt;br/&gt;
&amp;gt; &amp;gt; build.xml since it was using jjdoc. Stanislaw, is there something&lt;br/&gt;
&amp;gt; &amp;gt; &amp;gt; in jflex that can generated a BNF description of the grammar as&lt;br/&gt;
&amp;gt; &amp;gt; &amp;gt; HTML?&lt;/p&gt;

&lt;p&gt;&amp;gt; I&apos;ve had a look at the JFlex docs and there doesn&apos;t seem to be such&lt;br/&gt;
&amp;gt; a tool for JFlex, I&apos;m afraid.&lt;/p&gt;

&lt;p&gt;OK, I think we can just live without this.  Thanks!&lt;/p&gt;</comment>
                </comments>
                    <attachments>
                    <attachment id="12362607" name="AnalyzerBenchmark.java" size="4124" author="stanislaw.osinski" created="Thu, 26 Jul 2007 14:15:55 +0100" />
                    <attachment id="12362606" name="jflex-analyzer-patch.txt" size="52981" author="stanislaw.osinski" created="Thu, 26 Jul 2007 14:12:46 +0100" />
                    <attachment id="12362672" name="jflex-analyzer-r560135-patch.txt" size="69054" author="stanislaw.osinski" created="Fri, 27 Jul 2007 09:05:43 +0100" />
                    <attachment id="12362865" name="jflex-analyzer-r561292-patch.txt" size="146414" author="stanislaw.osinski" created="Tue, 31 Jul 2007 11:05:19 +0100" />
                    <attachment id="12362954" name="jflex-analyzer-r561693-compatibility.txt" size="134964" author="stanislaw.osinski" created="Wed, 1 Aug 2007 09:33:18 +0100" />
                    <attachment id="12363116" name="jflex-analyzer-r562378-patch-nodup.txt" size="136424" author="stanislaw.osinski" created="Fri, 3 Aug 2007 13:37:51 +0100" />
                    <attachment id="12363108" name="jflex-analyzer-r562378-patch.txt" size="242125" author="stanislaw.osinski" created="Fri, 3 Aug 2007 09:19:20 +0100" />
                </attachments>
            <subtasks>
        </subtasks>
                <customfields>
                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                <customfieldname>Attachment count</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>7.0</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                <customfieldname>Date of First Response</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>Thu, 26 Jul 2007 15:05:37 +0000</customfieldvalue>

                </customfieldvalues>
            </customfield>
                                                                                                        <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Global Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>12777</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                <customfieldname>Lucene Fields</customfieldname>
                <customfieldvalues>
                        <customfieldvalue key="10121"><![CDATA[New]]></customfieldvalue>
    <customfieldvalue key="10120"><![CDATA[Patch Available]]></customfieldvalue>
    
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>26763</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                <customfieldname>Time in Status</customfieldname>
                <customfieldvalues>
                    
                </customfieldvalues>
            </customfield>
                            </customfields>
    </item>
</channel>
</rss>