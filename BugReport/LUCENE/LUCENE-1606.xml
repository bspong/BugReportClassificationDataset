<!-- 
RSS generated by JIRA (5.2.8#851-sha1:3262fdc28b4bc8b23784e13eadc26a22399f5d88) at Tue Jul 16 13:33:49 UTC 2013

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/LUCENE-1606/LUCENE-1606.xml?field=key&field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>5.2.8</version>
        <build-number>851</build-number>
        <build-date>26-02-2013</build-date>
    </build-info>

<item>
            <title>[LUCENE-1606] Automaton Query/Filter (scalable regex)</title>
                <link>https://issues.apache.org/jira/browse/LUCENE-1606</link>
                <project id="12310110" key="LUCENE">Lucene - Core</project>
                        <description>&lt;p&gt;Attached is a patch for an AutomatonQuery/Filter (name can change if its not suitable).&lt;/p&gt;

&lt;p&gt;Whereas the out-of-box contrib RegexQuery is nice, I have some very large indexes (100M+ unique tokens) where queries are quite slow, 2 minutes, etc. Additionally all of the existing RegexQuery implementations in Lucene are really slow if there is no constant prefix. This implementation does not depend upon constant prefix, and runs the same query in 640ms.&lt;/p&gt;

&lt;p&gt;Some use cases I envision:&lt;br/&gt;
 1. lexicography/etc on large text corpora&lt;br/&gt;
 2. looking for things such as urls where the prefix is not constant (http:// or &lt;a href=&quot;ftp://&quot; class=&quot;external-link&quot;&gt;ftp://&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;The Filter uses the BRICS package (&lt;a href=&quot;http://www.brics.dk/automaton/&quot; class=&quot;external-link&quot;&gt;http://www.brics.dk/automaton/&lt;/a&gt;) to convert regular expressions into a DFA. Then, the filter &quot;enumerates&quot; terms in a special way, by using the underlying state machine. Here is my short description from the comments:&lt;/p&gt;

&lt;p&gt;     The algorithm here is pretty basic. Enumerate terms but instead of a binary accept/reject do:&lt;/p&gt;

&lt;p&gt;     1. Look at the portion that is OK (did not enter a reject state in the DFA)&lt;br/&gt;
     2. Generate the next possible String and seek to that.&lt;/p&gt;

&lt;p&gt;the Query simply wraps the filter with ConstantScoreQuery.&lt;/p&gt;

&lt;p&gt;I did not include the automaton.jar inside the patch but it can be downloaded from &lt;a href=&quot;http://www.brics.dk/automaton/&quot; class=&quot;external-link&quot;&gt;http://www.brics.dk/automaton/&lt;/a&gt; and is BSD-licensed.&lt;/p&gt;</description>
                <environment></environment>
            <key id="12422990">LUCENE-1606</key>
            <summary>Automaton Query/Filter (scalable regex)</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/newfeature.png">New Feature</type>
                                <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                    <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png">Closed</status>
                    <resolution id="1">Fixed</resolution>
                                <assignee username="rcmuir">Robert Muir</assignee>
                                <reporter username="rcmuir">Robert Muir</reporter>
                        <labels>
                    </labels>
                <created>Thu, 16 Apr 2009 09:47:24 +0100</created>
                <updated>Fri, 10 May 2013 11:42:52 +0100</updated>
                    <resolved>Wed, 9 Dec 2009 17:46:34 +0000</resolved>
                                            <fixVersion>4.0-ALPHA</fixVersion>
                                <component>core/search</component>
                        <due></due>
                    <votes>0</votes>
                        <watches>3</watches>
                                                    <comments>
                    <comment id="12699584" author="rcmuir" created="Thu, 16 Apr 2009 09:48:08 +0100"  >&lt;p&gt;patch&lt;/p&gt;</comment>
                    <comment id="12699642" author="rcmuir" created="Thu, 16 Apr 2009 12:24:14 +0100"  >&lt;p&gt;Here is an updated patch with AutomatonWildCardQuery.&lt;/p&gt;

&lt;p&gt;This implements standard Lucene Wildcard query with AutomatonFilter.&lt;/p&gt;

&lt;p&gt;This accelerates quite a few wildcard situations, such as ??(a|b)?cd*ef&lt;br/&gt;
Sorry, provides no help for leading *, but definitely for leading ?.&lt;/p&gt;

&lt;p&gt;All wildcard tests pass.&lt;/p&gt;</comment>
                    <comment id="12699650" author="markrmiller@gmail.com" created="Thu, 16 Apr 2009 12:42:02 +0100"  >&lt;p&gt;Very nice Robert. This looks like it would make a very nice addition to our regex support.&lt;/p&gt;

&lt;p&gt;Found the benchmarks here quite interesting: &lt;a href=&quot;http://tusker.org/regex/regex_benchmark.html&quot; class=&quot;external-link&quot;&gt;http://tusker.org/regex/regex_benchmark.html&lt;/a&gt; (though it sounds like your &quot;special&quot; enumeration technique makes this regex imp even faster for our uses?)&lt;/p&gt;</comment>
                    <comment id="12699652" author="rcmuir" created="Thu, 16 Apr 2009 12:43:26 +0100"  >&lt;p&gt;oops I did say in javadocs score is constant / boost only so when Wildcard has no wildcards and rewrites to termquery, wrap it with ConstantScoreQuery(QueryWrapperFilter)) to ensure this.&lt;/p&gt;
</comment>
                    <comment id="12699657" author="rcmuir" created="Thu, 16 Apr 2009 12:46:14 +0100"  >&lt;p&gt;mark yeah, the enumeration helps a lot, it means a lot less comparisons, plus brics is &lt;b&gt;FAST&lt;/b&gt;.&lt;/p&gt;

&lt;p&gt;inside the AutomatonFilter i describe how it could possibly be done better, but I was afraid I would mess it up.&lt;br/&gt;
its affected somewhat by the size of the alphabet so if you were using it against lots of CJK text, it might be worth it to instead use the State/Transition objects in the package. Transitions are described by min and max character intervals and you can access intervals in sorted order...&lt;/p&gt;

&lt;p&gt;its all so nice but I figure this is a start.&lt;/p&gt;</comment>
                    <comment id="12699659" author="mikemccand" created="Thu, 16 Apr 2009 12:48:17 +0100"  >&lt;p&gt;Can this do everything that RegexQuery currently does?  (Ie we&apos;d deprecate RegexQuery)?&lt;/p&gt;</comment>
                    <comment id="12699662" author="rcmuir" created="Thu, 16 Apr 2009 12:56:44 +0100"  >&lt;p&gt;Mike the thing it cant do is stuff that cannot be determinized. However I think you only need an NFA for capturing group related things:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://oreilly.com/catalog/regex/chapter/ch04.html&quot; class=&quot;external-link&quot;&gt;http://oreilly.com/catalog/regex/chapter/ch04.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;One thing is that the brics syntax is a bit different. i.e. ^ and $ are implied and I think some things need to be escaped. &lt;br/&gt;
So I think it can do everything RegexQuery does, but maybe different syntax is required.&lt;/p&gt;</comment>
                    <comment id="12699672" author="thetaphi" created="Thu, 16 Apr 2009 13:26:11 +0100"  >&lt;p&gt;I looked into the patch, looks good. Maybe it would be good to make the new AutomatonRegExQuey als a subclass of MultiTermQuery. As you also seek/exchange the TermEnum, the needed FilteredTermEnum may be a little bit complicated. But you may do it in the same way like I commit soon for TrieRange (&lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1602&quot; title=&quot;Rewrite TrieRange to use MultiTermQuery&quot;&gt;&lt;del&gt;LUCENE-1602&lt;/del&gt;&lt;/a&gt;).&lt;br/&gt;
The latest changes from &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1603&quot; title=&quot;Changes for TrieRange in FilteredTermEnum and MultiTermQuery improvement&quot;&gt;&lt;del&gt;LUCENE-1603&lt;/del&gt;&lt;/a&gt; make it possible to write a FilteredTermEnum, that handles over to different positioned TermEnums like you do.&lt;br/&gt;
With MultiTermQuery you get all for free: ConstantScore, Boolean rewrite and optionally the Filter (which is not needed here, I think). And: You could also overwrite difference in FilteredTermEnum to rank the hits.&lt;br/&gt;
A note: The FilteredTermEnum created by TrieRange is not for sure really ordered correctly according Term.compareTo(), but this is not really needed for MultiTermQuery.&lt;/p&gt;</comment>
                    <comment id="12699673" author="rcmuir" created="Thu, 16 Apr 2009 13:30:00 +0100"  >&lt;p&gt;Uwe, I agree with you, with one caveat: for this functionality to work the Enum must be ordered correctly according to Term.compareTo().&lt;/p&gt;

&lt;p&gt;Otherwise it will not work correctly...&lt;/p&gt;</comment>
                    <comment id="12699676" author="thetaphi" created="Thu, 16 Apr 2009 13:38:46 +0100"  >&lt;p&gt;It will work, that was what I said. For MultiTermQuery, it must &lt;b&gt;not&lt;/b&gt; be ordered, the ordering is irrelevant for it, MultTermQuery only enumerates the terms. TrieRange is an example of that, the order of terms is not for sure ordered correctly (it is at the moment because of the internal implementation of splitLongRange(), but I tested it with the inverse order and it still worked). If you want to use the enum for something other, it will fail.&lt;br/&gt;
The filters inside MultiTermQuery and the BooleanQuery do not need to have the terms ordered.&lt;/p&gt;</comment>
                    <comment id="12699685" author="rcmuir" created="Thu, 16 Apr 2009 13:54:00 +0100"  >&lt;p&gt;Uwe, i&apos;ll look and see how you do it for TrieRange.&lt;/p&gt;

&lt;p&gt;if it can make the code for this simpler that will be fantastic. maybe by then I will have also figured out some way to cleanly and non-recursively use min/max character intervals in the state machine to decrease the amount of seeks and optimize a little bit.&lt;/p&gt;

</comment>
                    <comment id="12699690" author="thetaphi" created="Thu, 16 Apr 2009 14:01:50 +0100"  >&lt;p&gt;I committed TrieRange revision 765618. You can see the impl here:&lt;br/&gt;
&lt;a href=&quot;http://svn.apache.org/viewvc/lucene/java/trunk/contrib/queries/src/java/org/apache/lucene/search/trie/TrieRangeTermEnum.java?view=markup&quot; class=&quot;external-link&quot;&gt;http://svn.apache.org/viewvc/lucene/java/trunk/contrib/queries/src/java/org/apache/lucene/search/trie/TrieRangeTermEnum.java?view=markup&lt;/a&gt;&lt;/p&gt;</comment>
                    <comment id="12699693" author="rcmuir" created="Thu, 16 Apr 2009 14:19:14 +0100"  >&lt;p&gt;Uwe, thanks. I&apos;ll think on this and on other improvements. &lt;br/&gt;
I&apos;m not really confident in my ability to make the code much cleaner at the end of the day, but more efficient and get some things for free as you say.&lt;br/&gt;
For now it is working much better than a linear scan, and the improvements wont change the order, but might help a bit.&lt;/p&gt;

&lt;p&gt;Think i should try to correct this issue or create a separate issue?&lt;/p&gt;</comment>
                    <comment id="12699697" author="thetaphi" created="Thu, 16 Apr 2009 14:23:11 +0100"  >&lt;p&gt;Let&apos;s stay with this issue!&lt;/p&gt;</comment>
                    <comment id="12700390" author="rcmuir" created="Sat, 18 Apr 2009 01:24:27 +0100"  >&lt;p&gt;ok I refactored this to use FilteredTermEnum/MultiTermQuery as Uwe suggested.&lt;/p&gt;

&lt;p&gt;on my big index its actually faster without setting the constant score rewrite (maybe creating the huge bitset is expensive?)&lt;/p&gt;

&lt;p&gt;I also changed the term enumeration to be a bit smarter, so it will work well on a large alphabet like CJK now.&lt;/p&gt;</comment>
                    <comment id="12700393" author="markrmiller@gmail.com" created="Sat, 18 Apr 2009 01:31:44 +0100"  >&lt;blockquote&gt;&lt;p&gt;on my big index its actually faster without setting the constant score rewrite (maybe creating the huge bitset is expensive?)&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Thats surprising, because I have seen people state the opposite on a couple occasions. Perhaps it has to do with how many terms are being enumerated?&lt;/p&gt;</comment>
                    <comment id="12700397" author="rcmuir" created="Sat, 18 Apr 2009 01:42:10 +0100"  >&lt;p&gt;its ~700ms if i .setConstantScoreRewrite(true)&lt;br/&gt;
its ~150ms otherwise...&lt;/p&gt;
</comment>
                    <comment id="12700473" author="markrmiller@gmail.com" created="Sat, 18 Apr 2009 13:52:11 +0100"  >&lt;p&gt;How many terms are being enumerated for the test? My guess is that for queries that turn into very large BooleanQueries, it can be much faster to build the filter, but for a smaller BooleanQuery or TermQuery, filter construction dominates?&lt;/p&gt;</comment>
                    <comment id="12700477" author="rcmuir" created="Sat, 18 Apr 2009 14:03:58 +0100"  >&lt;p&gt;~ 116,000,000 terms.&lt;/p&gt;

&lt;p&gt;I&apos;ve seen the same behavior with other lucene queries on this index, where I do not care about score and thought filter would be best, but queries still have the edge.&lt;/p&gt;</comment>
                    <comment id="12700478" author="rcmuir" created="Sat, 18 Apr 2009 14:06:05 +0100"  >&lt;p&gt;my test queries are ones that match like 50-100 out of those 116,000,000... so maybe this helps paint the picture.&lt;/p&gt;

&lt;p&gt;i can profile each one if you are curious?&lt;/p&gt;</comment>
                    <comment id="12700480" author="rcmuir" created="Sat, 18 Apr 2009 14:30:17 +0100"  >&lt;p&gt;well here it is just for the record:&lt;/p&gt;

&lt;p&gt;in the query case (fast), time is dominated by AutomatonTermEnum.next(). This is what I expect.&lt;br/&gt;
in the filter case (slower), time is instead dominated by OpenBitSetIterator.next().&lt;/p&gt;

&lt;p&gt;I&apos;ve seen this with simpler (non-MultiTermQuery) queries before as well.&lt;/p&gt;

&lt;p&gt;For this functionality I still like the constant score rewrite option because there is no risk of hitting the boolean clause limit.&lt;/p&gt;
</comment>
                    <comment id="12700493" author="thetaphi" created="Sat, 18 Apr 2009 16:33:15 +0100"  >&lt;blockquote&gt;&lt;p&gt;For this functionality I still like the constant score rewrite option because there is no risk of hitting the boolean clause limit.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I thought about that, too. Maybe there will be a possibility to do an auto-switch in MultiTermQuery. If a TooManyBooleanClauses exception is catched during the rewrite() method, it could fall back to returning the ConstantScore variant. The problem: The time for iterating the terms until the Exception thrown is lost... Maybe we could store the iterated terms for reuse (if FilteredTermEnum or a wrapper like BufferedTermEnum has something like the known mark() option from BufferedInputStreams).&lt;/p&gt;

&lt;p&gt;This is just an idea, but has nothing to do with this query, it affects all MultiTermQueries.&lt;/p&gt;</comment>
                    <comment id="12700496" author="rcmuir" created="Sat, 18 Apr 2009 16:48:54 +0100"  >&lt;p&gt;Uwe: yes I tried to think of some heuristics for this query to guess which would be the best method.&lt;/p&gt;

&lt;p&gt;For example, if the language of the automaton is infinite (for example, built from a regular expression/wildcard with a * operator), it seems best to set constant score rewrite=true.&lt;/p&gt;

&lt;p&gt;I didn&apos;t do any of this because I wasn&apos;t sure if this constant score rewrite option is something that should be entirely left to the user, or not.&lt;/p&gt;</comment>
                    <comment id="12700497" author="rcmuir" created="Sat, 18 Apr 2009 17:08:14 +0100"  >&lt;p&gt;yes, I just verified and can easily and quickly detect if the FSM can accept more than BooleanQuery.getMaxClauseCount() Strings.&lt;/p&gt;

&lt;p&gt; !Automaton.isFinite() || Automaton.getFiniteStrings(BooleanQuery.getMaxClauseCount()) == null&lt;/p&gt;

&lt;p&gt;If you think its ok, I could set constant score rewrite=true in this case.&lt;/p&gt;</comment>
                    <comment id="12700500" author="thetaphi" created="Sat, 18 Apr 2009 17:09:43 +0100"  >&lt;blockquote&gt;&lt;p&gt;I didn&apos;t do any of this because I wasn&apos;t sure if this constant score rewrite option is something that should be entirely left to the user, or not.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes, it should be normally be left to the user. And the slower filter on large indexes with only sparingly filled bitsets is related to &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1536&quot; title=&quot;if a filter can support random access API, we should use it&quot;&gt;&lt;del&gt;LUCENE-1536&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;E.g. I did some comparisions for TrieRangeQuery on a 5 mio doc index, integer field, 8 bit precision step (so about 400 terms per query), the filter is about double as fast. But the ranges were random and hit about 1/3 of all documents in average per query, so the bitset is not so sparse.&lt;br/&gt;
TrieRangeQuery is a typical example of a MultiTermQuery, that also works well with Boolean rewrite, because the upper term count is limited by the precision step (for ints and 8 bit the theoretical, but never reached, maximum is about 1700 terms, for lower precisionSteps even less).&lt;/p&gt;</comment>
                    <comment id="12700503" author="rcmuir" created="Sat, 18 Apr 2009 17:26:10 +0100"  >&lt;p&gt;Uwe, ok based on your tests I tried some of my own... on my index when the query matches like less than 10-20% of the docs Query method is faster.&lt;/p&gt;

&lt;p&gt;when it matches something like over 20%, the Filter method starts to win.&lt;/p&gt;
</comment>
                    <comment id="12700511" author="markrmiller@gmail.com" created="Sat, 18 Apr 2009 18:29:49 +0100"  >&lt;p&gt;When refactoring multitermquery I tried just computing the bit set iterator on the fly. It did not appear to work out, but I wonder if there are cases where it would be a better option.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;For example, if the language of the automaton is infinite (for example, built from a regular expression/wildcard with a * operator), it seems best to set constant score rewrite=true.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Okay, that starts to make more sense then. I think the reports that it was faster on some large indexes was based on wildcard queries I think (hard to remember 100%).&lt;/p&gt;
</comment>
                    <comment id="12700516" author="markrmiller@gmail.com" created="Sat, 18 Apr 2009 18:50:35 +0100"  >&lt;blockquote&gt;&lt;p&gt;If you think its ok, I could set constant score rewrite=true in this case.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I agree that it should just be left up to the user. Its probably not a good idea to change the scoring for what to a user could appear to be arbitrary queries.&lt;/p&gt;</comment>
                    <comment id="12700551" author="rcmuir" created="Sun, 19 Apr 2009 06:43:54 +0100"  >&lt;p&gt;updated with smarter enumeration. I think this is mathematically the best you can get with a DFA.&lt;/p&gt;

&lt;p&gt;for example if the regexp is (a|b)cdefg it knows to position at acdefg, then bcdefg, etc&lt;br/&gt;
if the regexp is (a|b)cd*efg it can only position at acd, etc.&lt;/p&gt;

&lt;p&gt;nextString() is now cpu-friendly, and instead walks the state transition character intervals in sorted order instead of brute-forcing characters.&lt;/p&gt;</comment>
                    <comment id="12700608" author="rcmuir" created="Sun, 19 Apr 2009 22:36:43 +0100"  >&lt;p&gt;this includes an alternative for another slow linear query, fuzzy query.&lt;/p&gt;

&lt;p&gt;automatonfuzzyquery creates a DFA that accepts all strings within an edit distance of 1.&lt;/p&gt;

&lt;p&gt;on my 100M term index this works pretty well:&lt;br/&gt;
fuzzy: 251,219 ms&lt;br/&gt;
automatonfuzzy: 172 ms&lt;/p&gt;

&lt;p&gt;while its true its limited to edit distance of one, on the other hand it supports transposition and is fast.&lt;/p&gt;</comment>
                    <comment id="12701261" author="rcmuir" created="Tue, 21 Apr 2009 21:48:00 +0100"  >&lt;p&gt;found this interesting article applicable to this query: &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.16.652&quot; class=&quot;external-link&quot;&gt;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.16.652&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&quot;We show how to compute, for any fixed bound n and any input word W, a deterministic Levenshtein-automaton of degree n for W in time linear in the length of W.&quot;&lt;/p&gt;</comment>
                    <comment id="12701279" author="eksdev" created="Tue, 21 Apr 2009 22:42:59 +0100"  >&lt;p&gt;Robert, &lt;br/&gt;
in order for Lev. Automata to work, you need to have the complete dictionary as DFA. Once you have dictionary as DFA (or any sort of trie), computing simple regex-s or simple fixed or weighted Levenshtein distance becomes a snap. Levenshtein-Automata is particularity fast at it, much simpler and only slightly slower method (one pager code)   &quot;K.Oflazer&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.136.3862&lt;/p&gt;

&lt;p&gt;As said, you cannot really walk  current term dictionary as automata/trie (or you have an idea on how to do that?). I guess there is enough application where stoing complete Term dictionary into RAM-DFA is not a problem. Even making some smart (heavily cached) persistent trie/DFA  should not be all that complex.&lt;/p&gt;

&lt;p&gt;Or you intended just to iterate all terms, and compute distance faster  &quot;break LD Matrix computation as soon as you see you hit the boundary&quot;? But this requires iteration over all terms?  &lt;/p&gt;


&lt;p&gt;I have done something similar, in memory, but unfortunately someone else paid me for this and is not willing to share... &lt;/p&gt;</comment>
                    <comment id="12701285" author="rcmuir" created="Tue, 21 Apr 2009 23:00:59 +0100"  >&lt;p&gt;eks:&lt;/p&gt;

&lt;p&gt;the AutomatonTermEnumerator in this patch does walk the term dictionary according to the transitions present in the DFA. Thats what this JIRA issue is all about to me, not iterating all the terms! So you do not need the complete dictionary as a DFA.&lt;/p&gt;

&lt;p&gt;for example: a regexp query of (a|b)cdefg with this patch seeks to &apos;acdefg&apos;, then &apos;bcdefg&apos;, as opposed to the current regex support which exhaustively enumerates all terms.&lt;/p&gt;

&lt;p&gt;slightly more complex example, query of (a|b)cd*efg first seeks to &apos;acd&apos; (because of kleen star operator). suppose it then encounters term &apos;acda&apos;, it will next seek to &apos;acdd&apos;, etc. if it encounters &apos;acdf&apos;, then next it seeks to &apos;bcd&apos;.&lt;/p&gt;

&lt;p&gt;this patch implements regex, wildcard, and fuzzy with n=1 in terms of this enumeration. what it doesnt do is fuzzy with arbitrary n!. &lt;/p&gt;

&lt;p&gt;I used the simplistic quadratic method to compute a DFA for fuzzy with n=1 for the FuzzyAutomatonQuery present in this patch, the paper has a more complicate but linear method to compute the DFA.&lt;/p&gt;</comment>
                    <comment id="12701298" author="eksdev" created="Tue, 21 Apr 2009 23:39:19 +0100"  >&lt;p&gt;hmmm, sounds like good idea, but I am still not convinced it would work for Fuzzy&lt;/p&gt;

&lt;p&gt;take simple dictionary:&lt;br/&gt;
one&lt;br/&gt;
two&lt;br/&gt;
three&lt;br/&gt;
four &lt;/p&gt;

&lt;p&gt;query Term is, e.g. &quot;ana&quot;, right? and n=1, means your DFA would be: &lt;/p&gt;
{.na, a.a, an., an, na, ana, .ana, ana., a.na, an.a, ana.}
&lt;p&gt; where dot represents any character in you alphabet.&lt;/p&gt;

&lt;p&gt;For the first element in DFA (in expanded form) you need to visit all terms, no matter how you walk DFA... or am I missing something?&lt;/p&gt;

&lt;p&gt;Where you could save time is actual calculation of LD Matrix for terms that do not pass automata&lt;/p&gt;
</comment>
                    <comment id="12701303" author="rcmuir" created="Tue, 21 Apr 2009 23:48:50 +0100"  >&lt;p&gt;eks, well it does work well for fuzzy n=1 (I have tested against my huge&lt;br/&gt;
index).&lt;/p&gt;

&lt;p&gt;for your simple dictionary it will do 3 comparisons instead of 4.&lt;br/&gt;
this is because your simple dictionary is sorted in the index as such:&lt;br/&gt;
four&lt;br/&gt;
one&lt;br/&gt;
three&lt;br/&gt;
two&lt;/p&gt;

&lt;p&gt;when it encounters &apos;three&apos; it will next ask for a TermEnum(&quot;una&quot;) which will&lt;br/&gt;
return null.&lt;/p&gt;

&lt;p&gt;give it a try on a big dictionary, you might be surprised &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;





&lt;p&gt;&amp;#8211; &lt;br/&gt;
Robert Muir&lt;br/&gt;
rcmuir@gmail.com&lt;/p&gt;</comment>
                    <comment id="12701304" author="rcmuir" created="Tue, 21 Apr 2009 23:49:55 +0100"  >&lt;p&gt;eks in your example it does three comparisons instead of four (not much of a gain for this example, but a big gain on a real index)&lt;/p&gt;

&lt;p&gt;this is because it doesnt need to compare &apos;two&apos;, after encountering &apos;three&apos; it requests TermEnum(&quot;uana&quot;), which returns null.&lt;/p&gt;

&lt;p&gt;i hope you can see how this helps for a large index... (or i can try to construct a more realistic example)&lt;/p&gt;
</comment>
                    <comment id="12701310" author="rcmuir" created="Wed, 22 Apr 2009 00:13:33 +0100"  >&lt;p&gt;eks in case this makes it a little better explanation for your example, &lt;br/&gt;
assume a huge term dictionary where words start with a-zA-Z for simplicity.&lt;/p&gt;

&lt;p&gt;for each character in that alphabet it will look for &apos;Xana&apos; and &apos;Xna&apos; in the worst case.&lt;br/&gt;
thats 110 comparisons to check all the words that don&apos;t start with &apos;a&apos;.&lt;br/&gt;
(the enumeration thru all the words that start with &apos;a&apos; is a little more complex).&lt;/p&gt;

&lt;p&gt;if you have say, 1M unique terms you can see how doing something like 100-200 comparisons is a lot better than 1M.&lt;/p&gt;</comment>
                    <comment id="12703791" author="rcmuir" created="Tue, 28 Apr 2009 19:55:46 +0100"  >&lt;p&gt;removed use of multitermquery&apos;s getTerm()&lt;/p&gt;

&lt;p&gt;equals/hashcode are defined based upon the field and the language accepted by the FSM, i.e. regex query of AB.*C equals() wildcard query of AB*C because they are the same.&lt;/p&gt;</comment>
                    <comment id="12719560" author="markrmiller@gmail.com" created="Mon, 15 Jun 2009 14:52:31 +0100"  >&lt;p&gt;This is a cool issue, but it hasn&apos;t found an assignee yet. We may have to push it to 3.1.&lt;/p&gt;

&lt;p&gt;Any interest Uwe?&lt;/p&gt;</comment>
                    <comment id="12719570" author="thetaphi" created="Mon, 15 Jun 2009 15:09:41 +0100"  >&lt;p&gt;I take it, I think it is almost finished. The only problems at the moment are bundling the external library in contrib, which is BSD licensed, are there any problems?&lt;/p&gt;

&lt;p&gt;If not, I can manage the inclusion into the regex contrib.&lt;/p&gt;</comment>
                    <comment id="12719571" author="markrmiller@gmail.com" created="Mon, 15 Jun 2009 15:13:05 +0100"  >&lt;p&gt;I don&apos;t think there is a problem with BSD. I know Grant has committed a BSD licensed stop word list in the past.&lt;/p&gt;

&lt;p&gt;I&apos;ve asked explicitly about it before, but got no response.&lt;/p&gt;

&lt;p&gt;I&apos;ll try and dig a little, but Grant is the PMC head and he did it, so we wouldnt be following bad company...&lt;/p&gt;</comment>
                    <comment id="12719602" author="thetaphi" created="Mon, 15 Jun 2009 16:41:07 +0100"  >&lt;p&gt;Robert: I applied the patch locally, one test was still using @Override, fixed that. I did only download automaton.jar not the source package.&lt;/p&gt;

&lt;p&gt;Do you know, if automaton.jar is compiled using -source 1.4 -target 1.4  (it was compiled using ant 1.7 and Java 1.6). If not sure, I will try to build it again from source and use the correct compiler switches. The regex contrib module is Java 1.4 until now. If automaton only works with 1.5, we should wait until 3.0 to release it.&lt;/p&gt;</comment>
                    <comment id="12719605" author="rcmuir" created="Mon, 15 Jun 2009 16:47:30 +0100"  >&lt;p&gt;Uwe, you are correct, I just took a glance at the automaton source code and saw StringBuilder, so I think it is safe to say it only works with 1.5...&lt;/p&gt;</comment>
                    <comment id="12719606" author="thetaphi" created="Mon, 15 Jun 2009 16:47:37 +0100"  >&lt;p&gt;Doesn&apos;t seem to work, I will check the sources:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
compile-core:
    [javac] Compiling 12 source files to C:\Projects\lucene\trunk\build\contrib\regex\classes\java
    [javac] C:\Projects\lucene\trunk\contrib\regex\src\java\org\apache\lucene\search\regex\AutomatonFuzzyQuery.java:11: cannot access dk.brics.automaton.Automaton
    [javac] bad class file: C:\Projects\lucene\trunk\contrib\regex\lib\automaton
.jar(dk/brics/automaton/Automaton.class)
    [javac] class file has wrong version 49.0, should be 48.0
    [javac] Please remove or make sure it appears in the correct subdirectory of
 the classpath.
    [javac] &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; dk.brics.automaton.Automaton;
    [javac]                           ^
    [javac] 1 error
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                    <comment id="12719607" author="thetaphi" created="Mon, 15 Jun 2009 16:49:08 +0100"  >&lt;p&gt;So I tend to move this to 3.0 or 3.1, because of missing support in regex contrib.&lt;/p&gt;</comment>
                    <comment id="12719612" author="rcmuir" created="Mon, 15 Jun 2009 17:05:17 +0100"  >&lt;p&gt;Uwe, sorry about this.&lt;/p&gt;

&lt;p&gt;I did just verify automaton.jar can be compiled for Java 5 (at least it does not have java 1.6 dependencies), so perhaps this can be integrated for a later release.&lt;/p&gt;</comment>
                    <comment id="12719615" author="thetaphi" created="Mon, 15 Jun 2009 17:09:31 +0100"  >&lt;p&gt;I move this to 3.0 (and not 3.1), because it can be released together with 3.0 (contrib modules do not need to wait until 3.1).&lt;/p&gt;

&lt;p&gt;Robert: you could supply a patch with StringBuilder toString() variants and all those @Override uncommented-in. And it works correct with 1.5 (I am working with 1.5 here locally - I hate 1.6...).&lt;/p&gt;</comment>
                    <comment id="12719623" author="rcmuir" created="Mon, 15 Jun 2009 17:19:08 +0100"  >&lt;p&gt;Uwe, ok.&lt;/p&gt;

&lt;p&gt;Not to try to complicate things, but related to &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1689&quot; title=&quot;supplementary character handling&quot;&gt;&lt;del&gt;LUCENE-1689&lt;/del&gt;&lt;/a&gt; and java 1.5, I could easily modify the Wildcard functionality here to work correctly with suppl. characters&lt;/p&gt;

&lt;p&gt;This could be an alternative to fixing the WildcardQuery ? operator in core.&lt;/p&gt;</comment>
                    <comment id="12720483" author="otis" created="Wed, 17 Jun 2009 04:32:40 +0100"  >&lt;p&gt;Regarding the license - I think we already have BRICS in one of Nutch&apos;s plugins, so we should be OK with the BSD licensed jar in our repo.&lt;/p&gt;

&lt;p&gt;./urlfilter-automaton/lib/automaton.jar&lt;/p&gt;</comment>
                    <comment id="12761331" author="thetaphi" created="Thu, 1 Oct 2009 21:40:45 +0100"  >&lt;p&gt;Robert: Do you want to take this again? It&apos;s your&apos;s and contrib &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="12761333" author="rcmuir" created="Thu, 1 Oct 2009 21:50:10 +0100"  >&lt;p&gt;Uwe, sure. I will bring this patch up to speed (java 5, etc)&lt;/p&gt;</comment>
                    <comment id="12765176" author="rcmuir" created="Tue, 13 Oct 2009 19:17:17 +0100"  >&lt;p&gt;updated patch to trunk:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;add support for optional regex features&lt;/li&gt;
	&lt;li&gt;remove recursion&lt;/li&gt;
	&lt;li&gt;improve performance for worst-case regexp/wildcard/FSM&lt;/li&gt;
	&lt;li&gt;improved docs &amp;amp; test&lt;/li&gt;
	&lt;li&gt;remove the fuzzy impl, NFA-&amp;gt;DFA too slow for this, maybe a later addition.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12766396" author="rcmuir" created="Fri, 16 Oct 2009 04:56:43 +0100"  >&lt;p&gt;if anyone can spare a sec to take a glance/review before 3.0, i think its ok...&lt;/p&gt;</comment>
                    <comment id="12767961" author="rcmuir" created="Tue, 20 Oct 2009 22:57:53 +0100"  >&lt;p&gt;if no one objects, i&apos;d like to commit this in a few days. Can someone help out and commit the update to NOTICE?&lt;/p&gt;</comment>
                    <comment id="12767963" author="thetaphi" created="Tue, 20 Oct 2009 23:00:37 +0100"  >&lt;p&gt;No prob! I will help you, I am on heavy committing &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="12768700" author="gsingers" created="Thu, 22 Oct 2009 15:50:30 +0100"  >&lt;p&gt;Why are new features going into 3.0?  I was under the impression that 3.0 was just supposed to be cleanup plus Java 1.5&lt;/p&gt;</comment>
                    <comment id="12768705" author="rcmuir" created="Thu, 22 Oct 2009 16:01:06 +0100"  >&lt;p&gt;Grant, I thought it was ok from Uwe&apos;s comment:&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I move this to 3.0 (and not 3.1), because it can be released together with 3.0 (contrib modules do not need to wait until 3.1). &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I guess now I am a little confused about what should happen for 3.0 with contrib in general? &lt;br/&gt;
No problem moving this to 3.1, let me know!&lt;/p&gt;</comment>
                    <comment id="12768739" author="thetaphi" created="Thu, 22 Oct 2009 17:20:27 +0100"  >&lt;p&gt;3.0 is just the switch to 1.5 and generics. So this is a typical java 1.5 issue and can go into 3.0 even if it is a new feature. Contrib is not core and may have own rules.&lt;/p&gt;

&lt;p&gt;In my opinion, this would be a nice addition to the regex contrib and should also have been in 2.9, but the underlying library is Java 5 only, so we had to wait until 3.0.&lt;/p&gt;</comment>
                    <comment id="12780430" author="markrmiller@gmail.com" created="Fri, 20 Nov 2009 04:35:47 +0000"  >&lt;p&gt;So Robert - what do you think about paring down the automaton lib, and shoving all this in core? I want it, I want, I want it &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;You should also post the info about that Fuzzy possibility you were mentioning - perhaps a math head will come along and take care of that for us with the proper setup.&lt;/p&gt;</comment>
                    <comment id="12780432" author="rcmuir" created="Fri, 20 Nov 2009 04:51:28 +0000"  >&lt;blockquote&gt;&lt;p&gt;So Robert - what do you think about paring down the automaton lib, and shoving all this in core? I want it, I want, I want it &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Mark, some notes on size. jarring up the full source code (no paring) is 81KB.&lt;br/&gt;
in practice, the jar file is larger because it contains some &apos;precompiled DFAs&apos; for certain things like Unicode blocks, XML types... are these really needed?&lt;/p&gt;

&lt;p&gt;see here for a list of what I mean: &lt;a href=&quot;http://www.brics.dk/automaton/doc/dk/brics/automaton/Datatypes.html&quot; class=&quot;external-link&quot;&gt;http://www.brics.dk/automaton/doc/dk/brics/automaton/Datatypes.html&lt;/a&gt;&lt;br/&gt;
I enabled these in the patch (they could be easily disabled): an example of how they are used in a regexp is like this: &amp;lt;Arabic&amp;gt;* (match 0 or more arabic characters)&lt;/p&gt;

&lt;p&gt;if a user really wanted them, they can load them themselves, you can also create custom ones and use a DataTypesAutomatonProvider to register them for some name:&lt;br/&gt;
Example: your users want to be able to use &amp;lt;make&amp;gt; or &amp;lt;model&amp;gt; inside their regexps, you can register &amp;lt;make&amp;gt; and &amp;lt;model&amp;gt; to match to some DFA you make yourself.&lt;br/&gt;
its really a nice mechanism, but I don&apos;t think we need all the precompiled ones? &lt;/p&gt;</comment>
                    <comment id="12780433" author="rcmuir" created="Fri, 20 Nov 2009 04:55:16 +0000"  >&lt;blockquote&gt;&lt;p&gt;You should also post the info about that Fuzzy possibility you were mentioning - perhaps a math head will come along and take care of that for us with the proper setup.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Right, i created a FuzzyQuery that builds in the &apos;naive&apos; method. The problem is that for large strings this exponential-time naive mechanism creates a rather large NFA, and the NFA-&amp;gt;DFA conversion is very slow.&lt;br/&gt;
Once the DFA is built, actually running it on a term dictionary is fast &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
So the slow part has nothing to do with lucene at all.&lt;/p&gt;

&lt;p&gt;So we just need to build these DFAs in an efficient way:&lt;br/&gt;
We show how to compute, for any fixed bound n and any input word W , a deterministic Levenshtein-automaton of degree n for W in time linear in the length of W&lt;br/&gt;
&lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.16.652&quot; class=&quot;external-link&quot;&gt;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.16.652&lt;/a&gt;&lt;/p&gt;</comment>
                    <comment id="12780439" author="rcmuir" created="Fri, 20 Nov 2009 05:04:04 +0000"  >&lt;p&gt;By the way Mark, in case you are interested, the TermEnum here still has problems with &apos;kleene star&apos; as I have mentioned many times.&lt;br/&gt;
So wildcard of ?abacadaba is fast, wildcard of *abacadaba is still slow&lt;br/&gt;
in the same manner, regex of .abacadaba is fast, wildcard of .*abacadaba is still slow.&lt;/p&gt;

&lt;p&gt;but there are algorithms to reverse an entire dfa, so you could use ReverseStringFilter and support wildcards AND regexps with leading *&lt;br/&gt;
I didnt implement this here though yet.&lt;/p&gt;</comment>
                    <comment id="12780440" author="markrmiller@gmail.com" created="Fri, 20 Nov 2009 05:09:36 +0000"  >&lt;blockquote&gt;
&lt;p&gt;By the way Mark, in case you are interested, the TermEnum here still has problems with &apos;kleene star&apos; as I have mentioned many times.&lt;br/&gt;
So wildcard of ?abacadaba is fast, wildcard of *abacadaba is still slow&lt;br/&gt;
in the same manner, regex of .abacadaba is fast, wildcard of .*abacadaba is still slow.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;No problem in my mind - nothing the current WildcardQuery doesn&apos;t face. Any reason we wouldn&apos;t want to replace the current WCQ that with this?&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;but there are algorithms to reverse an entire dfa, so you could use ReverseStringFilter and support wildcards AND regexps with leading *&lt;br/&gt;
I didnt implement this here though yet.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Now that sounds interesting - now sure I fully understand you though - are you saying we can do a prefix match, but without having to index terms reversed in the index? That would be very cool.&lt;/p&gt;</comment>
                    <comment id="12780441" author="rcmuir" created="Fri, 20 Nov 2009 05:16:08 +0000"  >&lt;blockquote&gt;&lt;p&gt;No problem in my mind - nothing the current WildcardQuery doesn&apos;t face. Any reason we wouldn&apos;t want to replace the current WCQ that with this?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don&apos;t think there is any issue. by implementing WildcardQuery with the DFA, leading ? is no longer a problem, &lt;br/&gt;
i mean depending on your term dictionary if you do something stupid like ???????abacadaba it probably wont be that fast.&lt;/p&gt;

&lt;p&gt;I spent a lot of time with the worst-case regex, wildcards to ensure performance is at least as good as the other alternatives.&lt;br/&gt;
There is only one exception, the leading * wildcard is a bit slower with a DFA than if you ran it with actual WildcardQuery (less than 5% in my tests)&lt;br/&gt;
Because of this, currently this patch rewrites this very special case to a standard WildcardQuery.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Now that sounds interesting - now sure I fully understand you though - are you saying we can do a prefix match, but without having to index terms reversed in the index? That would be very cool.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;No, what I am saying is that you still have to index the terms in reversed order for the leading *  or .* case, except then this reversing buys you faster wildcard AND regex queries &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="12780445" author="markrmiller@gmail.com" created="Fri, 20 Nov 2009 05:20:41 +0000"  >&lt;p&gt;Okay - still not an issue I don&apos;t think - leading wildcards are already an issue - 5% is worth the other speedups I think - though you&apos;ve taken care of that anyway - so sounds like gold to me. I didn&apos;t expect this to solve leading wildcard issues, so no loss to me.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;No, what I am saying is that you still have to index the terms in reversed order for the leading * or .* case, except then this reversing buys you faster wildcard AND regex queries &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;bummer &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; Does it make sense to implement here though? Isn&apos;t the ReverseStringFilter enough if a user wants to go this route? Solr&apos;s support for this is fairly good, but I don&apos;t think it needs to be as &apos;built in&apos; for Lucene?&lt;/p&gt;</comment>
                    <comment id="12780447" author="rcmuir" created="Fri, 20 Nov 2009 05:23:51 +0000"  >&lt;blockquote&gt;&lt;p&gt;Does it make sense to implement here though?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I do not think so. I tested another solution where users wanted leading * wildcards on 100M+ term dictionary.&lt;br/&gt;
I found out what was acceptable (clarification: to these specific users/system) was for *  to actually match .&lt;/p&gt;
{0,3}
&lt;p&gt; (between 0 and 3 of anything), and rewrote it to an equivalent regex like this.&lt;br/&gt;
This performed very well, because it can still avoid comparing many terms.&lt;/p&gt;</comment>
                    <comment id="12780452" author="markrmiller@gmail.com" created="Fri, 20 Nov 2009 05:36:59 +0000"  >&lt;p&gt;That is a cool tradeoff to be able to make.&lt;/p&gt;</comment>
                    <comment id="12780471" author="rcmuir" created="Fri, 20 Nov 2009 06:43:41 +0000"  >&lt;blockquote&gt;&lt;p&gt;That is a cool tradeoff to be able to make. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Mark, yes. I guess someone could implement the DFA-reversing if they wanted to, to enable leading .* regex support with ReverseStringFilter.&lt;br/&gt;
you can still use this Wildcard impl with ReverseStringFilter just like the core Wildcard impl, because its just so easy to reverse a wildcard string.&lt;/p&gt;

&lt;p&gt;but you don&apos;t want to try to reverse a regular expression! that would be hairy. easier to reverse a DFA.&lt;/p&gt;

&lt;p&gt;but even without this, there are tons of workarounds, like the tradeoff i mentioned earlier.&lt;br/&gt;
also, another one that might not be apparent is that its only the leading .* that is a problem, depending on corpus of course.&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;a-z&amp;#93;&lt;/span&gt;.*abacadaba will avoid visiting terms that start with 1,2,3 or are in chinese, etc, which might be a nice improvement.&lt;br/&gt;
of course if all your terms start with a-z, then its gonna be the same as entering .*abacadaba, and be bad.&lt;/p&gt;

&lt;p&gt;all depends on how selective the regular expression is wrt your terms.&lt;/p&gt;</comment>
                    <comment id="12780575" author="rcmuir" created="Fri, 20 Nov 2009 14:44:41 +0000"  >&lt;blockquote&gt;&lt;p&gt;So Robert - what do you think about paring down the automaton lib, and shoving all this in core? I want it, I want, I want it &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think trying this out around in contrib (after 3.0 is released) would be best in the short term?&lt;/p&gt;

&lt;p&gt;Separately, my quickly &apos;pared&apos; automaton library is now 53KB jar (14 java files, some just simple POJO)&lt;br/&gt;
Do you have a target size I should shoot for?&lt;/p&gt;</comment>
                    <comment id="12780584" author="markrmiller@gmail.com" created="Fri, 20 Nov 2009 15:05:24 +0000"  >&lt;blockquote&gt;&lt;p&gt;I think trying this out around in contrib (after 3.0 is released) would be best in the short term?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;What are your concerns? If it passes the current wildcard tests and survives in trunk for a dev cycle, isn&apos;t that likely enough?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Do you have a target size I should shoot for?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;As small as possible &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; But I don&apos;t personally have any issue adding 53k to the core jar for this goodness. Guess we will have to see what others say - but its a low percentage of the current 1.1 MB, and pretty sweet functionality.&lt;/p&gt;</comment>
                    <comment id="12780589" author="rcmuir" created="Fri, 20 Nov 2009 15:15:35 +0000"  >&lt;blockquote&gt;&lt;p&gt;What are your concerns? If it passes the current wildcard tests and survives in trunk for a dev cycle, isn&apos;t that likely enough?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;i don&apos;t really have any, except that I don&apos;t necessarily trust the current wildcard tests. Shouldn&apos;t they have detected 2.9.0 scorer bug? &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;As small as possible &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;ok, i will work at this some more. obviously i could pare it down to just what we are using, but i am trying to preserve &apos;reasonable&apos; functionality that might be handy elsewhere.&lt;/p&gt;</comment>
                    <comment id="12780591" author="markrmiller@gmail.com" created="Fri, 20 Nov 2009 15:19:55 +0000"  >&lt;blockquote&gt;&lt;p&gt;i don&apos;t really have any, except that I don&apos;t necessarily trust the current wildcard tests. Shouldn&apos;t they have detected 2.9.0 scorer bug? &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;If they caught that, they wouldn&apos;t catch another &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; How do you want to improve them? I&apos;ll help test and write tests - we can make something much more intensive if you&apos;d like, and then just put a flag to tone it down for normal test running.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;ok, i will work at this some more. obviously i could pare it down to just what we are using, but i am trying to preserve &apos;reasonable&apos; functionality that might be handy elsewhere.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Right - don&apos;t go further than makes sense - even 53k -&amp;gt; 20k - I don&apos;t think it really matters that much. So really I meant, as small as makes reasonable sense.&lt;/p&gt;</comment>
                    <comment id="12780594" author="rcmuir" created="Fri, 20 Nov 2009 15:26:52 +0000"  >&lt;blockquote&gt;&lt;p&gt;How do you want to improve them?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;well for one, i test all the rewrite methods and boosts here.&lt;br/&gt;
ok these are also now fixed as of 3.0 in core wildcard tests also (&lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1951&quot; title=&quot;wildcardquery rewrite improvements&quot;&gt;&lt;del&gt;LUCENE-1951&lt;/del&gt;&lt;/a&gt;), but those were two &apos;buglets&apos;, just an example.&lt;/p&gt;</comment>
                    <comment id="12780599" author="markrmiller@gmail.com" created="Fri, 20 Nov 2009 15:34:33 +0000"  >&lt;p&gt;Point taken - the tests are not perfect. They never are. But it doesn&apos;t stop us chugging along &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; We can always write more tests and trunk tends to get quite a work out if you put changes in towards the beginning of a dev cycle. Bugs are inevitable, in trunk or contrib. But I don&apos;t think the wildcard impl will get much exposure in contrib anyway - its not wired into the queryparser, and it won&apos;t come with a sign saying check this out. Users will still use the standard wildcardquery - and I want to see it improved. We can work out the patch, work out the tests, and then decided its not good enough - or perhaps another committer will look and decided that. I&apos;d still love to put it in core myself.&lt;/p&gt;</comment>
                    <comment id="12780602" author="rcmuir" created="Fri, 20 Nov 2009 15:38:00 +0000"  >&lt;p&gt;Mark, ok. I will supply a new patch with no lib dependency, instead it includes the pared Automaton code in one pkg.&lt;br/&gt;
this compiles to about a 48KB jar right now. Reducing it more would involve sacrificing readability or useful stuff.&lt;/p&gt;

&lt;p&gt;Example: keeping the &quot;Matcher&quot; would be useful if you want to use this for a really fast &apos;PatternTokenizer&apos;, but not needed here.&lt;/p&gt;</comment>
                    <comment id="12780623" author="rcmuir" created="Fri, 20 Nov 2009 16:18:26 +0000"  >&lt;p&gt;attached is an alternate patch with no library dependency (&lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1606&quot; title=&quot;Automaton Query/Filter (scalable regex)&quot;&gt;&lt;del&gt;LUCENE-1606&lt;/del&gt;&lt;/a&gt;_nodep.patch)&lt;br/&gt;
instead it imports &apos;pared-down&apos; automaton source code (compiles to 48KB jar)&lt;br/&gt;
it is still setup in contrib regex because...&lt;/p&gt;

&lt;p&gt;Mark: some practical questions, I&apos;d like to create a patch that integrates it nicely into core, just so we can see what it would look like.&lt;br/&gt;
Thoughts on class names and pkg names?&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;I assume we should nuke the old WildcardQuery, rename AutomatonWildcardQuery to WildcardQuery?&lt;/li&gt;
	&lt;li&gt;but then what should AutomatonRegexQuery be called, we already have RegexQuery &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Thoughts on the automaton src code? Should I reformat to our style... (I did not do this).&lt;br/&gt;
should we rename the pkg? &lt;/p&gt;

&lt;p&gt;sorry the patch is monster, if it makes it any easier i could split the automaton library itself away from the lucene integration (queries, etc)?&lt;br/&gt;
also, i did not remove any tests, for example, TestWildcardQuery already exists, so the test here is just duplication, i just might add a test or 2 to the existing TestWildcardQuery&lt;/p&gt;</comment>
                    <comment id="12780629" author="markrmiller@gmail.com" created="Fri, 20 Nov 2009 16:28:27 +0000"  >&lt;blockquote&gt;&lt;p&gt;I assume we should nuke the old WildcardQuery, rename AutomatonWildcardQuery to WildcardQuery?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes - I think so - but how to handle the fact that you fall back to it? We might either rename it or incorporate it into the new WildcardQuery?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;but then what should AutomatonRegexQuery be called, we already have RegexQuery?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Shouldn&apos;t this one eventually make the old obsolete? I say we name it RegexQuery.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Thoughts on the automaton src code? Should I reformat to our style... (I did not do this).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yup - I think we should reformat and drop the author tags. We can mention that type of info in the NOTICE file.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;should we rename the pkg?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think so - perhaps util.brics?  No need for dk I don&apos;t think.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;sorry the patch is monster, if it makes it any easier i could split the automaton library itself away from the lucene integration (queries, etc)?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;One large patch is fine with me - my IDE will make short work of groking it &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="12780633" author="rcmuir" created="Fri, 20 Nov 2009 16:34:27 +0000"  >&lt;blockquote&gt;&lt;p&gt;Yes - I think so - but how to handle the fact that you fall back to it? We might either rename it or incorporate it into the new WildcardQuery?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;We could just remove the .rewrite(). it is only that very special case, for leading *, where the existing WildcardQuery logic is slightly faster (&amp;lt; 5%).&lt;br/&gt;
I was actually surprised the wildcardquery logic beats a DFA, i guess something to be said for that hairy logic &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Shouldn&apos;t this one eventually make the old obsolete? I say we name it RegexQuery.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I do not know, all regex is not created equal. This one has different syntax and stuff from the other impl&apos;s.&lt;br/&gt;
Any other ideas? Obviously the name RegexpQuery, with a p,  is available&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Yup - I think we should reformat and drop the author tags. We can mention that type of info in the NOTICE file.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;ok, this is easy, i already have NOTICE in the patch. i was sure all files from brics have their license header also.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I think so - perhaps util.brics? No need for dk I don&apos;t think.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;o.a.l.util.brics?&lt;/p&gt;</comment>
                    <comment id="12780643" author="markrmiller@gmail.com" created="Fri, 20 Nov 2009 16:50:33 +0000"  >&lt;blockquote&gt;&lt;p&gt;We could just remove the .rewrite(). it is only that very special case, for leading *, where the existing WildcardQuery logic is slightly faster (&amp;lt; 5%).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Agreed - not worth the extra code for speeding up such a horrible case by 5%.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Any other ideas?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;d rather change the contrib names and let core have the good name &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; We can start with RegexpQuery I think.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;o.a.l.util.brics?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Thats my best thought at the moment.&lt;/p&gt;</comment>
                    <comment id="12780654" author="rcmuir" created="Fri, 20 Nov 2009 17:03:36 +0000"  >&lt;p&gt;OK we have the start of a plan, only one final nit I am worried about.&lt;/p&gt;

&lt;p&gt;I pared away the &apos;built-in named automata&apos;:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;example &amp;lt;Lu&amp;gt; (uppercase letter, from Unicode)&lt;/li&gt;
	&lt;li&gt;example &amp;lt;QName&amp;gt; (from XML)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;if we keep the original pkg name, a user can have these just by adding brics.jar into their path.&lt;br/&gt;
They would just pass new DatatypesAutomatonProvider() to the constructor of RegexpQuery, done.&lt;/p&gt;

&lt;p&gt;if we rename the pkg, this will not work because the DataTypesAutomatonProvider from the jar file implements dk.brics.automaton.AutomatonProvider,&lt;br/&gt;
not o.a.l.util.brics.AutomatonProvider.&lt;/p&gt;

&lt;p&gt;alternatively, we could rename the pkg, but I could restore perhaps a subset of these datatypes, maybe without all the xml ones, just the basic unicode categories and stuff?&lt;br/&gt;
This would cost a little space though. Here is the list:&lt;br/&gt;
&lt;a href=&quot;http://www.brics.dk/automaton/doc/dk/brics/automaton/Datatypes.html#get%28java.lang.String%29&quot; class=&quot;external-link&quot;&gt;http://www.brics.dk/automaton/doc/dk/brics/automaton/Datatypes.html#get%28java.lang.String%29&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;i ask this question because personally i don&apos;t use any of these built-ins, but users might want them? what do you think?&lt;/p&gt;</comment>
                    <comment id="12780655" author="markrmiller@gmail.com" created="Fri, 20 Nov 2009 17:08:19 +0000"  >&lt;p&gt;On the way hand I&apos;d say, well lets not rename the package then - its not that important. But these things could get out of sync anyway, so I&apos;m not sure its worth it to try and maintain some sort of compatibility. If these features are useful enough, we could end up adding them later. Your call though. Personally, I&apos;d think we start just by adding the essentials and build from there as makes sense.&lt;/p&gt;</comment>
                    <comment id="12780659" author="rcmuir" created="Fri, 20 Nov 2009 17:13:03 +0000"  >&lt;p&gt;Mark, ok. In that case I will not include these, and rename the pkg as you suggest. &lt;br/&gt;
These default named automata are not enabled by default in the library anyway if you use the RegExp() default constructor.&lt;br/&gt;
the (renamed and pared) api is still extensible, if you want to create named automata to use in your regular expressions, you just implement the very simple interface DatatypesAutomatonProvider.&lt;br/&gt;
then you pass this to the constructor of RegexpQuery&lt;/p&gt;</comment>
                    <comment id="12780684" author="rcmuir" created="Fri, 20 Nov 2009 18:12:14 +0000"  >&lt;blockquote&gt;&lt;p&gt;Okay - still not an issue I don&apos;t think - leading wildcards are already an issue - 5% is worth the other speedups I think&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Mark, the old WildcardTermEnum is public, so we must keep it around for a while anyway.&lt;br/&gt;
I can use it for this case, so we don&apos;t lose this 5% in the special case &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;Might be worth deprecating this old WildcardTermEnum still though, just because its code to be maintained, hardly used except for this purpose.&lt;/p&gt;</comment>
                    <comment id="12780725" author="rcmuir" created="Fri, 20 Nov 2009 19:20:02 +0000"  >&lt;p&gt;Mark, I think this patch is ok, all tests pass etc.&lt;br/&gt;
Can you take a look and let me know your thoughts?&lt;/p&gt;</comment>
                    <comment id="12780738" author="markrmiller@gmail.com" created="Fri, 20 Nov 2009 19:59:28 +0000"  >&lt;p&gt;Nice! Resulting jar is still just 1.0 MB. Looks great on a quick look through. I&apos;ll go over more thoroughly when I get a chance.&lt;/p&gt;

&lt;p&gt;As far as testing, one of the simple things we can try is generating random wildcard strings against a large corpus and auto comparing the results of the old and the new.&lt;/p&gt;

&lt;p&gt;+1 on the automaton name for the util package.&lt;/p&gt;

&lt;p&gt;I&apos;d almost still prefer RegexQuery - its contrib vs core and different packages - I hate to lose out on the better name. Though thats a bit subjective &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="12780747" author="rcmuir" created="Fri, 20 Nov 2009 20:07:06 +0000"  >&lt;p&gt;Mark, thanks, let me know if you have the chance to look more thoroughly.&lt;/p&gt;

&lt;p&gt;I agree, lets consider some ideas for testing wildcards, yours sounds good.&lt;br/&gt;
One problem I had is trying to figure out: &quot;what is the average/common case&quot; for wildcards/regex &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
Its important also when considering some additional optimizations i havent yet implemented.&lt;/p&gt;

&lt;p&gt;also, I think i might have some additional wildcards tests from the contrib patch.&lt;br/&gt;
I left TestWildCard completely as-is for now tho, b/c i thought it would be nice to show it passes unchanged.&lt;/p&gt;</comment>
                    <comment id="12780748" author="thetaphi" created="Fri, 20 Nov 2009 20:09:14 +0000"  >&lt;p&gt;I like it, too, some thoughts:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Maybe make AutomatonTermEnum public instead package private (if it maybe extended and of usage for own sub classes like a future FuzzyQuery to return a difference())&lt;/li&gt;
	&lt;li&gt;The code in WildcardTermEnum is deprecated but still there and teherefor duplicated functionality. Maybe we could make this class subclass of AutomatonTermEnum, but it initializes to be a simple WildCard. The TermEnum has no longer a test (the deprecated one), so we maybe must add a test.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12780749" author="rcmuir" created="Fri, 20 Nov 2009 20:11:11 +0000"  >&lt;blockquote&gt;&lt;p&gt;As far as testing, one of the simple things we can try is generating random wildcard strings against a large corpus and auto comparing the results of the old and the new.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;An idea i have here is &lt;a href=&quot;https://issues.apache.org/jira/browse/ORP-2&quot; title=&quot;add support for hamshahri collection&quot;&gt;&lt;del&gt;ORP-2&lt;/del&gt;&lt;/a&gt; corpus, it has approx 417K unique terms and 160K docs.&lt;br/&gt;
and its open, so anyone could participate. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="12780750" author="rcmuir" created="Fri, 20 Nov 2009 20:12:29 +0000"  >&lt;p&gt;Uwe, both your ideas are great. thank you for looking.&lt;br/&gt;
I will take a stab at those.&lt;/p&gt;</comment>
                    <comment id="12780796" author="rcmuir" created="Fri, 20 Nov 2009 22:37:16 +0000"  >&lt;p&gt;Uwe, i looked at the WildcardTermEnum and it was easy to make it a subclass, with no logic, just a ctor.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; WildcardTermEnum(IndexReader reader, Term term) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
    &lt;span class=&quot;code-keyword&quot;&gt;super&lt;/span&gt;(WildcardQuery.toAutomaton(term), term, reader);
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The problem is that this hardly removes any duplicated code, because we must keep this available:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
 &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; wildcardEquals(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; pattern, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; patternIdx,
    &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; string, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; stringIdx)
  {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This is where all the logic really is anyway.&lt;br/&gt;
So I think i would rather leave this one alone? But I will add a test for it, to ensure it doesn&apos;t break since we are not using it.&lt;br/&gt;
What do you think?&lt;/p&gt;</comment>
                    <comment id="12780801" author="thetaphi" created="Fri, 20 Nov 2009 22:43:12 +0000"  >&lt;blockquote&gt;&lt;p&gt;Uwe, i looked at the WildcardTermEnum and it was easy to make it a subclass, with no logic, just a ctor. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That was my idea!&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;This is where all the logic really is anyway.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;We should simply add a test for this method and everything else is the WildCardEnum. The good thing of subclassing it is, that one has a more performat class if it uses common prefixes and so on than the version we currently have. The wildcardEquals method must stay, but it is not used, so explicitely mark it as &quot;dead code&quot;.&lt;/p&gt;

&lt;p&gt;The good thing: the method is final (this is what I see from yor fragment) - so nobody was able to override it to change the behaviour of the enum, so nothing can break.&lt;/p&gt;

&lt;p&gt;I would go this way.&lt;/p&gt;</comment>
                    <comment id="12780806" author="rcmuir" created="Fri, 20 Nov 2009 22:51:03 +0000"  >&lt;blockquote&gt;&lt;p&gt;We should simply add a test for this method and everything else is the WildCardEnum. The good thing of subclassing it is, that one has a more performat class if it uses common prefixes and so on than the version we currently have. The wildcardEquals method must stay, but it is not used, so explicitely mark it as &quot;dead code&quot;.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;if we do this, there are lots of cases where it will perform better, yes (virtually anything involving ? operator)&lt;br/&gt;
but if we do this, there are also some cases where it won&apos;t perform quite as well, really bad wildcards where it is better to just do linear scan than skip around many many times. &lt;br/&gt;
This is why i have detection for these cases, in the getEnum() instead I return &quot;DumbTermEnum&quot; aka LinearTermEnum in AutomatonQuery.&lt;br/&gt;
if you think this is no problem, we can subclass it anyway. excerpt below:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    /*
     * If the DFA has a leading kleene star, or something similar, it will
     * need to run against the entire term dictionary. In &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; its much
     * better to &lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt; just that than to use fancy enumeration.
     * 
     * &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; heuristic looks &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; an initial loop, with a range of at least 1/3
     * of the unicode BMP.
     */
    State state = automaton.getInitialState();
    &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (Transition transition : state.getTransitions())
      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (transition.getDest() == state
          &amp;amp;&amp;amp; (transition.getMax() - transition.getMin()) &amp;gt; (&lt;span class=&quot;code-object&quot;&gt;Character&lt;/span&gt;.MAX_VALUE / 3))
        &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; LinearTermEnum(reader);

    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; AutomatonTermEnum(automaton, term, reader);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                    <comment id="12780825" author="rcmuir" created="Fri, 20 Nov 2009 23:11:51 +0000"  >&lt;p&gt;by the way Uwe, I do not particularly like how this AutomatonQuery &quot;decides to use smart or dumb termenum&quot; in getEnum() works.&lt;br/&gt;
I wish instead the AutomatonTermEnum would always be fast, instead of relying on the query to decide.&lt;br/&gt;
I think this would be cleaner, and make subclassing easier.&lt;/p&gt;

&lt;p&gt;but on the other hand, having these two separate, it makes things easy to understand, as the two methods work in two completely different ways.&lt;br/&gt;
i wonder if you have any ideas on this.&lt;/p&gt;</comment>
                    <comment id="12780831" author="thetaphi" created="Fri, 20 Nov 2009 23:28:16 +0000"  >&lt;p&gt;see &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-2075&quot; title=&quot;Share the Term -&amp;gt; TermInfo cache across threads&quot;&gt;&lt;del&gt;LUCENE-2075&lt;/del&gt;&lt;/a&gt;, why it is not so fast (the setEnum calls use seeking and this is not optimized by the TermCache). Yonik has poited us to that.&lt;/p&gt;

&lt;p&gt;If the dumb enumeration would be included inside AutomatonTermEnum, one could use it without thinking. I would like to move your posted code into AutomatonTermEnum and have two modi dumb and intelligent. This would need an if switch on each next() call and a delegation to super.next(). That would make the enum ugly... But would work. So just fold the LinearTermEnum into it and make  a switch: if (linearMode) return super.next();&lt;br/&gt;
But you have to remove the assert inside endEnum() and change it. In the intelligent case, the endEnum method is never called (because super.next() is never called). So the assert must be assert linearMode;&lt;br/&gt;
termCompare looks identical in both enums, for the indelligent case the comonPrefix is &quot;&quot;.&lt;/p&gt;</comment>
                    <comment id="12780833" author="rcmuir" created="Fri, 20 Nov 2009 23:31:40 +0000"  >&lt;blockquote&gt;&lt;p&gt;That would make the enum ugly... But would work.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This is why i did not do it (i tried and it was ugly), i did not want to make a complicated enum ugly!&lt;br/&gt;
I&apos;ll try to think of how this can be done without it being so ugly.&lt;/p&gt;

&lt;p&gt;edit, by the way Uwe, if you are bored and want to take a stab at this &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; You know your way around multitermquery better than me.&lt;/p&gt;</comment>
                    <comment id="12780857" author="thetaphi" created="Sat, 21 Nov 2009 00:55:43 +0000"  >&lt;p&gt;Hi Robert,&lt;/p&gt;

&lt;p&gt;here is my patch. The WildCard and RegExp test querys still pass. I also added a test for the deprec TermEnum (just a simple MTQ that returns it is used and should produce same results as WildcardQuery).&lt;/p&gt;

&lt;p&gt;The AutomatonTermEnum now switches between smart(R) and non-smart mode using your detection algorithm. termCompare now handles both cases.&lt;br/&gt;
next() just calls super in the linear case (so it behaves like a normal FilteredTermEnum) and uses the smart(R) code in all other cases.&lt;/p&gt;

&lt;p&gt;I will go to bed now, tell me if you like it.&lt;/p&gt;</comment>
                    <comment id="12780858" author="rcmuir" created="Sat, 21 Nov 2009 01:07:06 +0000"  >&lt;p&gt;Uwe, thank you. This is much nicer!&lt;/p&gt;

&lt;p&gt;I think now it will be easier for some subclass to extend this enum, for example to override difference() or whatever for fuzzy.&lt;/p&gt;</comment>
                    <comment id="12780940" author="mikemccand" created="Sat, 21 Nov 2009 09:58:46 +0000"  >&lt;p&gt;I&apos;m not following this very closely, but, it looks really really cool!&lt;/p&gt;</comment>
                    <comment id="12780957" author="thetaphi" created="Sat, 21 Nov 2009 12:25:20 +0000"  >&lt;p&gt;Some cleanups and a more consistent endEnum handling. Also added Javadocs explaining smart and linear mode.&lt;/p&gt;</comment>
                    <comment id="12780964" author="thetaphi" created="Sat, 21 Nov 2009 12:38:41 +0000"  >&lt;p&gt;Again some updates, moved the &apos;*&apos; and &apos;?&apos; constants also to WildcardQuery and use them in switch. Also added better deprecation messeg to WildcardTermEnum.&lt;/p&gt;</comment>
                    <comment id="12780987" author="rcmuir" created="Sat, 21 Nov 2009 14:48:19 +0000"  >&lt;p&gt;Uwe, lookout for that &#248; in the NOTICE.txt... I will fix it, thanks for your cleanups &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="12780995" author="rcmuir" created="Sat, 21 Nov 2009 15:22:20 +0000"  >&lt;p&gt;fix the &#248; in NOTICE, cleanup some unused imports, etc.&lt;/p&gt;

&lt;p&gt;now that Uwe fixed a performance bug in the dumb enum (it would never set endEnum=true but instead false), &lt;br/&gt;
I will dig up my old performance tests and see how we are looking.&lt;/p&gt;</comment>
                    <comment id="12781000" author="rcmuir" created="Sat, 21 Nov 2009 16:05:47 +0000"  >&lt;p&gt;I reran my tests, Uwe&apos;s fix removes this &apos;5%&apos; problem I mentioned before for leading *.&lt;br/&gt;
Now wildcardquery is always faster than before (before it was comparing terms from another field due to the endEnum bug)&lt;/p&gt;

&lt;p&gt;This makes sense, because RunAutomaton.run() is just array access, instead of all the conditional/branching in the old wildcardEquals.&lt;br/&gt;
But i could not figure out before for the life of me, why this was slower before!&lt;/p&gt;

&lt;p&gt;I will create a better benchmark now that generates lots of random numeric wildcards with lots of patterns, and post the results and code.&lt;/p&gt;</comment>
                    <comment id="12781017" author="rcmuir" created="Sat, 21 Nov 2009 17:41:40 +0000"  >&lt;p&gt;this patch fixes a bug i introduced when i removed recursion.&lt;br/&gt;
the wildcard tests do not detect it... told you i didnt trust them &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;I will add a test for this, although it was an obvious mistake on my part.&lt;/p&gt;</comment>
                    <comment id="12781022" author="rcmuir" created="Sat, 21 Nov 2009 18:20:15 +0000"  >&lt;p&gt;attached is benchmark, which generates random wildcard queries.&lt;br/&gt;
it builds an index of 10million docs, each with a term from 0-10million.&lt;br/&gt;
it will fill a pattern such as N?N?N?N? with random digits, substituting a random digit for N.&lt;/p&gt;

&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Pattern&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Iter&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;AvgHits&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;AvgMS (old)&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;AvgMS (new)&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;N?N?N?N&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1000.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;288.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;38.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;?NNNNNN&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2453.1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;6.4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;??NNNNN&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;100.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2484.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;???NNNN&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1000.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2821.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;47.8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;????NNN&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10000.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2346.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;299.8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;NN??NNN&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;100.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;34.8&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;6.3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;NN?N*&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10000.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;26.5&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;9.4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;?NN*&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;100000.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2009.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;73.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;*N&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1000000.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;6837.4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;6087.9&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;NNNNN??&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;100.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2.3&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;


&lt;p&gt;i would like to incorporate part of this logic into the junit tests, on maybe a smaller index, because its how i found the recursion bug.&lt;/p&gt;</comment>
                    <comment id="12781028" author="mikemccand" created="Sat, 21 Nov 2009 19:00:21 +0000"  >&lt;p&gt;Those are impressive gains!&lt;/p&gt;</comment>
                    <comment id="12781031" author="rcmuir" created="Sat, 21 Nov 2009 19:13:08 +0000"  >&lt;p&gt;Thanks Mike, it is not that impressive really, until you look at regex performance &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;The current regexp implementations will scan entire term dictionary for an expression like &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;dl&amp;#93;&lt;/span&gt;og?&quot;, because there is no &apos;constant prefix&apos;&lt;br/&gt;
The idea here, is that lucene should be smart enough to look for do, dog, lo, and log.&lt;/p&gt;</comment>
                    <comment id="12781032" author="markrmiller@gmail.com" created="Sat, 21 Nov 2009 19:16:42 +0000"  >&lt;p&gt;You are the man Robert. This is going to be great.&lt;/p&gt;

&lt;p&gt;Next on my wish list is getting the scalable fuzzy done &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; We should start a new issue for that, seeding it with the info you have here. If you don&apos;t get to it, I&apos;ll be happy to.&lt;/p&gt;

&lt;p&gt;Still on my list to help with review on this patch too. Thanks Uwe as well! Love seeing this stuff make its way into core.&lt;/p&gt;</comment>
                    <comment id="12781035" author="rcmuir" created="Sat, 21 Nov 2009 19:28:30 +0000"  >&lt;p&gt;Mark, yeah lets create a separate issue for fuzzy. &lt;br/&gt;
I found someone implemented that algorithm in python or some other language, we should look/contact them to see what they did.&lt;/p&gt;

&lt;p&gt;currently, I am trying to check this &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-2075&quot; title=&quot;Share the Term -&amp;gt; TermInfo cache across threads&quot;&gt;&lt;del&gt;LUCENE-2075&lt;/del&gt;&lt;/a&gt; issue, to see if this caching will help cases where the enum must seek a lot, for example the pattern ????NNN&lt;br/&gt;
it is still better than the current wildcard case, but you see it gets a lot worse when you have a lot more seeks.&lt;/p&gt;

&lt;p&gt;i think though, this means i have to cut over to the new FilteredTermsEnum api for the flex branch... which looks interesting btw but this is a complicated enum.&lt;/p&gt;</comment>
                    <comment id="12781037" author="rcmuir" created="Sat, 21 Nov 2009 19:46:52 +0000"  >&lt;p&gt;Mark, one last comment. I want to mention this impl is largely unoptimized (from a code perspective, but the algorithm is better)&lt;br/&gt;
I think you see that from the NNNNN?? being 2.3ms on average versus 1.9, not that I am sure that isnt just a random hiccup.&lt;/p&gt;

&lt;p&gt;So I want to incorporate the logic of some of this benchmark into the tests, so that we can improve the actual code impl. to speed up cases like that.&lt;br/&gt;
While i focus on the scalability, i know a lot of people have small indexes and maybe lots of qps and I don&apos;t want to slow them down.&lt;/p&gt;

&lt;p&gt;Some of this is easy, for example we make State.getSortedTransitionArray public, so we don&apos;t have to convert from arrays to lists to arrays and such, for no good reason.&lt;/p&gt;</comment>
                    <comment id="12781134" author="mikemccand" created="Sun, 22 Nov 2009 14:54:09 +0000"  >&lt;p&gt;Are we going to deprecate contrib/regex with this?&lt;/p&gt;</comment>
                    <comment id="12781135" author="rcmuir" created="Sun, 22 Nov 2009 15:01:17 +0000"  >&lt;blockquote&gt;&lt;p&gt;Are we going to deprecate contrib/regex with this? &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I would argue against that, only because the other regex impl&apos;s have different features and syntax, even if they are slow.&lt;/p&gt;</comment>
                    <comment id="12781155" author="mikemccand" created="Sun, 22 Nov 2009 16:35:35 +0000"  >&lt;blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;Are we going to deprecate contrib/regex with this?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I would argue against that, only because the other regex impl&apos;s have different features and syntax, even if they are slow.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Ahh OK, I agree then.  I didn&apos;t realize this new query doesn&apos;t subsume contrib&apos;s.  Would be good to call out what&apos;s different in the javadocs somewhere...&lt;/p&gt;</comment>
                    <comment id="12781156" author="rcmuir" created="Sun, 22 Nov 2009 16:39:13 +0000"  >&lt;blockquote&gt;&lt;p&gt;Would be good to call out what&apos;s different in the javadocs somewhere...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;good idea, let me know if you have some suggested wording.&lt;br/&gt;
its really a general issue, the supported features and syntax of even the existing regex implementations in contrib are different I think?&lt;br/&gt;
(i.e. they are not compatible: you cannot just swap impls around, without testing that it supports the syntax and features you are using)&lt;/p&gt;</comment>
                    <comment id="12781160" author="mikemccand" created="Sun, 22 Nov 2009 16:43:50 +0000"  >&lt;p&gt;I don&apos;t have any wording &amp;#8211; I don&apos;t really know the differences &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;If it&apos;s &quot;only&quot; that the syntax is different, that&apos;s one thing... but if eg certain functionality isn&apos;t possible w/ new or old, that&apos;s another.&lt;/p&gt;</comment>
                    <comment id="12781162" author="rcmuir" created="Sun, 22 Nov 2009 16:49:20 +0000"  >&lt;blockquote&gt;&lt;p&gt;If it&apos;s &quot;only&quot; that the syntax is different, that&apos;s one thing... but if eg certain functionality isn&apos;t possible w/ new or old, that&apos;s another.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;from a glance, it appears to me that both the syntax and functionality of our two contrib impls (java.util and jakarta), are very different.&lt;/p&gt;

&lt;p&gt;here is one example. Java.util supports reluctant &lt;/p&gt;
{m,n} closures, jakarta does not, it says this right in the javadocs.&lt;br/&gt;
&lt;a href=&quot;http://jakarta.apache.org/regexp/apidocs/org/apache/regexp/RE.html&quot; class=&quot;external-link&quot;&gt;http://jakarta.apache.org/regexp/apidocs/org/apache/regexp/RE.html&lt;/a&gt;&lt;br/&gt;
&lt;br/&gt;
Should RE support reluctant {m,n}
&lt;p&gt; closures (does anyone care)?&lt;br/&gt;
But it supports reluctant versus greedy for other operators.&lt;/p&gt;

&lt;p&gt;in automaton, this concept of reluctance versus greedy, does not even exist, as spelled out on their page:&lt;br/&gt;
The * operator is mathematically the Kleene star operator (i.e. we don&apos;t have greedy/reluctant/possesive variants). &lt;br/&gt;
&lt;a href=&quot;http://www.brics.dk/automaton/faq.html&quot; class=&quot;external-link&quot;&gt;http://www.brics.dk/automaton/faq.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;this is an example, where all 3 are different... i guess i kinda assumed everyone was aware that all these regex packages are very different.&lt;/p&gt;</comment>
                    <comment id="12781168" author="rcmuir" created="Sun, 22 Nov 2009 17:28:10 +0000"  >&lt;p&gt;we call this out nicely in the current RegexQuery,&lt;br/&gt;
The expressions supported depend on the regular expression implementation used by way of the RegexCapabilities interface. &lt;/p&gt;

&lt;p&gt;what should I say for the automaton implementation? it already has a javadoc link to the precise syntax supported,&lt;br/&gt;
so in my opinion its actually less ambiguous than contrib RegexQuery.&lt;/p&gt;

&lt;p&gt;but maybe improve this, instead of&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
The supported syntax is documented in the {@link RegExp} class.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;maybe:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
The supported syntax is documented in the {@link RegExp} class.
warning: &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; might not be the syntax you are used to!
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                    <comment id="12781178" author="mikemccand" created="Sun, 22 Nov 2009 18:06:16 +0000"  >&lt;p&gt;OK that warning seems good.  Maybe also reference contrib/regex, as another alternative, nothing that syntax/capabilities are different?&lt;/p&gt;</comment>
                    <comment id="12781181" author="mikemccand" created="Sun, 22 Nov 2009 18:17:23 +0000"  >&lt;p&gt;First cut @ cutting over to flex API attached &amp;#8211; note that this&lt;br/&gt;
applies to the flex branch, not trunk!&lt;/p&gt;

&lt;p&gt;I made some small changes to the benchmarker: use constant score&lt;br/&gt;
filter mode, and print the min (not avg) time (less noise).&lt;/p&gt;

&lt;p&gt;Also, I ported the AutomatonTermEnum to the flex API, so this is now a&lt;br/&gt;
better measure (&quot;flex on flex&quot;) of what future perf will be.  It&apos;s&lt;br/&gt;
possible there&apos;s a bug here, though TestWildcard passes.&lt;/p&gt;

&lt;p&gt;I still need to investigate why &quot;non-flex on non-flex&quot; and &quot;non-flex&lt;br/&gt;
on flex&quot; perform worse.&lt;/p&gt;

&lt;p&gt;I ran like this:&lt;/p&gt;

&lt;p&gt;  java -server -Xmx1g -Xms1g BenchWildcard&lt;/p&gt;

&lt;p&gt;java is 1.6.0_14 64 bit, on OpenSolaris.&lt;/p&gt;

&lt;p&gt;Results (msec is min of 10 runs each);&lt;/p&gt;

&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Pattern&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;ITrunk (min msec)&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;(Flex (min msec)&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;N?N?N?N0.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;13&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;18&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;?NNNNNN&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;??NNNNN&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;???NNNN&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;23&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;28&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;????NNN&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;210&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;170&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;NN??NNN&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;NN?N*&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;?NN*&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;62&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;30&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;*N&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4332&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2576&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;NNNNN??&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;


&lt;p&gt;Looks like flex API is faster for the slow queries.  Once I fix caching on trunk we should retest...&lt;/p&gt;</comment>
                    <comment id="12781183" author="rcmuir" created="Sun, 22 Nov 2009 18:22:43 +0000"  >&lt;blockquote&gt;&lt;p&gt;Looks like flex API is faster for the slow queries. Once I fix caching on trunk we should retest...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Mike, this is cool. I like the results. it appears tentatively, that flex api is faster for both &quot;dumb&quot; (brute force linear reading) and &quot;fast&quot; (lots of seeking) modes.&lt;br/&gt;
at least looking at ????NNN, and *N, which are the worst cases of both here. So it would seem its faster in every case.&lt;/p&gt;

&lt;p&gt;I&apos;ll look at what you did to port this to the TermsEnum api!&lt;/p&gt;</comment>
                    <comment id="12781185" author="rcmuir" created="Sun, 22 Nov 2009 18:42:17 +0000"  >&lt;p&gt;Mike, I think your port to TermsEnum is correct, and its definitely faster here.&lt;/p&gt;

&lt;p&gt;One question, is it possible to speed this up further, by using UnicodeUtil/char[] conversion from TermRef instead of String?&lt;br/&gt;
Because its trivial to use char[] with the Automaton api (even tho that is not exposed, its no problem)&lt;/p&gt;

&lt;p&gt;I use only string because of the old TermEnum api.&lt;/p&gt;</comment>
                    <comment id="12781188" author="mikemccand" created="Sun, 22 Nov 2009 18:52:04 +0000"  >&lt;blockquote&gt;
&lt;p&gt;One question, is it possible to speed this up further, by using UnicodeUtil/char[] conversion from TermRef instead of String?&lt;br/&gt;
Because its trivial to use char[] with the Automaton api (even tho that is not exposed, its no problem)&lt;/p&gt;

&lt;p&gt;I use only string because of the old TermEnum api.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Oh, that&apos;d be great!  It would be faster.  I was bummed at how many new String()&apos;s I was doing...&lt;/p&gt;</comment>
                    <comment id="12781190" author="rcmuir" created="Sun, 22 Nov 2009 19:01:42 +0000"  >&lt;blockquote&gt;&lt;p&gt;Oh, that&apos;d be great! It would be faster. I was bummed at how many new String()&apos;s I was doing...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;it would be nice I think if TermRef provided a helper method to make the char[] available? &lt;br/&gt;
i.e. I don&apos;t think i should do unicode conversion in a multitermquery?&lt;/p&gt;</comment>
                    <comment id="12781213" author="mikemccand" created="Sun, 22 Nov 2009 20:52:36 +0000"  >&lt;blockquote&gt;&lt;p&gt;it would be nice I think if TermRef provided a helper method to make the char[] available? &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I agree... though, this requires state (UnicodeUtil.UTF16Result).  We could lazily set such state on the TermRef, but, that&apos;s making TermRef kinda heavy (it&apos;s nice and light weight now).  Hmmm.&lt;/p&gt;</comment>
                    <comment id="12781214" author="rcmuir" created="Sun, 22 Nov 2009 20:55:59 +0000"  >&lt;blockquote&gt;&lt;p&gt;I agree... though, this requires state (UnicodeUtil.UTF16Result). We could lazily set such state on the TermRef, but, that&apos;s making TermRef kinda heavy (it&apos;s nice and light weight now). Hmmm.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;i guess the state could be in the TermsEnum, but that doesnt make for general use of TermRef.&lt;br/&gt;
what else uses TermRef?&lt;/p&gt;</comment>
                    <comment id="12781219" author="mikemccand" created="Sun, 22 Nov 2009 21:23:32 +0000"  >&lt;p&gt;Besides TermsEnum.. TermRef is used by the terms dict, when doing the binary search + scan to find a term.  And also by TermsConsumer (implemented by the codec, and used when writing a segment to the index).&lt;/p&gt;

&lt;p&gt;Maybe MTQ holds the state, or FilteredTermsEnum?  Other consumers of TermsEnum don&apos;t need to convert to char[].&lt;/p&gt;

&lt;p&gt;We can discuss this under the new &lt;span class=&quot;error&quot;&gt;&amp;#91;separately&amp;#93;&lt;/span&gt; &quot;optimization&quot; issue for MTQs?&lt;/p&gt;

&lt;p&gt;Also, remember that the current API is doing not only new String() but also new Term() when it enums the terms, so having to do new String() for MTQs on flex API is OK for starters.&lt;/p&gt;</comment>
                    <comment id="12781220" author="rcmuir" created="Sun, 22 Nov 2009 21:25:26 +0000"  >&lt;blockquote&gt;&lt;p&gt;We can discuss this under the new &lt;span class=&quot;error&quot;&gt;&amp;#91;separately&amp;#93;&lt;/span&gt; &quot;optimization&quot; issue for MTQs?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;is there a jira issue for this??&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Also, remember that the current API is doing not only new String() but also new Term() when it enums the terms, so having to do new String() for MTQs on flex API is OK for starters.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;oh yeah, its clear the flex api is already better, from benchmarks.&lt;br/&gt;
I am just trying to think of ways to make it both faster, at the same time easy too.&lt;/p&gt;</comment>
                    <comment id="12781221" author="mikemccand" created="Sun, 22 Nov 2009 21:29:51 +0000"  >&lt;blockquote&gt;&lt;p&gt;is there a jira issue for this??&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I thought you were about to open one!&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I am just trying to think of ways to make it both faster, at the same time easy too.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Which is great: keep it up!&lt;/p&gt;

&lt;p&gt;Actually... wouldn&apos;t we need to convert to int[] (for Unicode 4) not char[], to be most convenient for &quot;higher up&quot; APIs like automaton?  If we did char[] you&apos;d still have to handle surrogates process (and then it&apos;s not unlike doing byte[]).&lt;/p&gt;</comment>
                    <comment id="12781223" author="rcmuir" created="Sun, 22 Nov 2009 21:35:23 +0000"  >&lt;blockquote&gt;&lt;p&gt;I thought you were about to open one!&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I opened one for Automaton specifically, should i change it to be all MTQ?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Actually... wouldn&apos;t we need to convert to int[] (for Unicode 4) not char[], to be most convenient for &quot;higher up&quot; APIs like automaton? If we did char[] you&apos;d still have to handle surrogates process (and then it&apos;s not unlike doing byte[]).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;nope. because unicode and java are optimized for UTF-16, not UTF-32. so we should use char[], but use the codePoint apis, which are designed such that you can process text in UTF-16 (char[]) efficiently, yet also handle the rare case of supp. characters.&lt;br/&gt;
char[] is correct, its just that we have to be careful to use the right apis for processing it.&lt;br/&gt;
With String() a lot of the apis such as String.toLowerCase do this automatically for you, so most applications have no issues.&lt;/p&gt;</comment>
                    <comment id="12781227" author="rcmuir" created="Sun, 22 Nov 2009 21:45:53 +0000"  >&lt;blockquote&gt;&lt;p&gt;Actually... wouldn&apos;t we need to convert to int[] (for Unicode 4) not char[], to be most convenient for &quot;higher up&quot; APIs like automaton? If we did char[] you&apos;d still have to handle surrogates process (and then it&apos;s not unlike doing byte[]).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I wanted to make another comment here, I agree that this somewhat like byte[].&lt;br/&gt;
But there are some major differences:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;the java API provides mechanisms in Character, etc for processing text this way.&lt;/li&gt;
	&lt;li&gt;lots of stuff is unaffected. for example .startsWith() is not broken for supp characters.&lt;br/&gt;
 it does not have to use codepoint anywhere, can just compare chars, which are surrogates, but this is ok.&lt;br/&gt;
 so lots of char[]-based processing is already compatible, and completely unaware of this issue. this is not true for byte[]&lt;/li&gt;
	&lt;li&gt;it will perform the best overall, its only needed in very few places and we can be very careful where we add these checks, so we don&apos;t slow anything down or increase RAM usage, etc.&lt;/li&gt;
&lt;/ol&gt;
</comment>
                    <comment id="12781229" author="mikemccand" created="Sun, 22 Nov 2009 21:47:49 +0000"  >&lt;blockquote&gt;&lt;p&gt;I opened one for Automaton specifically, should i change it to be all MTQ?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Oh, sorry no, just automaton.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;nope. because unicode and java are optimized for UTF-16, not UTF-32.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;OK char[] it is!&lt;/p&gt;</comment>
                    <comment id="12781252" author="rcmuir" created="Sun, 22 Nov 2009 23:37:46 +0000"  >&lt;p&gt;Mike, here is an update to your flex patch. I restored back two tests that disappeared (TestRegexp, etc)&lt;br/&gt;
Also, I converted the enum to use char[] as an experiment. i posted the results on &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-2090&quot; title=&quot;convert automaton to char[] based processing and TermRef / TermsEnum api&quot;&gt;&lt;del&gt;LUCENE-2090&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
this is just a hack, it stores the UTF16Result in AutomatonEnum&lt;br/&gt;
I figured i would pass it back in case, just in the case you wanted to play more.&lt;/p&gt;</comment>
                    <comment id="12781341" author="mikemccand" created="Mon, 23 Nov 2009 09:26:27 +0000"  >&lt;blockquote&gt;&lt;p&gt;Mike, here is an update to your flex patch. I restored back two tests that disappeared (TestRegexp, etc)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Woops, thanks!  Need svn patch, badly...&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Also, I converted the enum to use char[] as an experiment. i posted the results on &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-2090&quot; title=&quot;convert automaton to char[] based processing and TermRef / TermsEnum api&quot;&gt;&lt;del&gt;LUCENE-2090&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
this is just a hack, it stores the UTF16Result in AutomatonEnum&lt;br/&gt;
I figured i would pass it back in case, just in the case you wanted to play more.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Wow, not &quot;new String()&quot;ing all over gave a sizable gain on the full linear scan query...&lt;/p&gt;</comment>
                    <comment id="12781371" author="rcmuir" created="Mon, 23 Nov 2009 11:47:03 +0000"  >&lt;p&gt;Michael, the problem is this code (automaton itself), like many other code, is unaware of supplementary characters.&lt;br/&gt;
It uses a symbolic interval range of &apos;char&apos; for state transitions.&lt;br/&gt;
But this is ok! When matching an input string with suppl. characters, things work just fine.&lt;/p&gt;

&lt;p&gt;This is one reason why i am concerned about the change to byte[] in flex branch.&lt;br/&gt;
I would have to rewrite this DFA library for this enum to work!&lt;/p&gt;</comment>
                    <comment id="12781431" author="rcmuir" created="Mon, 23 Nov 2009 15:27:57 +0000"  >&lt;p&gt;Mike, just one comment here.&lt;/p&gt;

&lt;p&gt;I am definitely willing to do refactoring here to support this byte[] scheme if necessary, I don&apos;t want to give the wrong impression. I think i already have an issue here related to UTF-16 binary order vs UTF-8 binary order that I need to fix, although I think this is just writing a Comparator.&lt;/p&gt;

&lt;p&gt;edit: pretty sure this exists. If someone has say, both data from Arabic Presentation forms and Chinese text outside the BMP in the index, the &quot;smart&quot; enumerator will unknowningly skip right past the Arabic Presentation forms block, because it sorts after the lead surrogate in UTF-16 order, but before the entire codepoint in UTF-8/UTF-32 order. I have not experienced this in practice, because i normalize my text so i don&apos;t have stuff in Arabic Presentation forms block &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; I can fix this, but i would like to see what the approach is for the flex branch, as its sufficiently compex that I would rather not fix it twice.&lt;/p&gt;

&lt;p&gt;I am just concerned about other similar applications outside of lucene, or some already in lucene core itself!&lt;/p&gt;</comment>
                    <comment id="12781585" author="rcmuir" created="Mon, 23 Nov 2009 19:50:29 +0000"  >&lt;p&gt;I think i have a workaround for this enum that will not hurt performance as well.&lt;br/&gt;
There are two problems, one exists with the existing api, one will become a problem with the flex API if we move to byte[] TermRef, which, from performance numbers, it seems we almost certainly should.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;problem 1 is the fact that this enum depends upon &apos;sorted transitions&apos; where each transition is an interval of UTF-16 characters.&lt;br/&gt;
To fix this, two things are required:&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
	&lt;li&gt;splitting intervals that overlap between the BMP and surrogate range into separate intervals&lt;/li&gt;
	&lt;li&gt;sorting intervals in codepoint order, which means ordering the surrogate range intervals after any BMP intervals.&lt;/li&gt;
&lt;/ol&gt;


&lt;ul&gt;
	&lt;li&gt;problem 2 is the fact the enum works on UTF-16 characters again, and we can try to seek in the enumerator to a place ending with a lead surrogate.&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
	&lt;li&gt;In this case, we should just tack on U+DC00 (the lowest of trail surrogates), which is functionally equivalent.&lt;/li&gt;
	&lt;li&gt;for the &quot;common prefix&quot; we just remove any trail surrogates, although this common prefix is currently not even used at all, so we should get rid of it, if the first state is not a loop we are in smart mode anyway!&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;I&apos;ll fix these problems, by providing a new &quot;codepoint-order&quot; comparator for transitions behind the scenes in automaton, along with a getSortedTransitionsCodepointOrder() or something similar to make the whole thing work.&lt;/p&gt;

&lt;p&gt;it might seem at a glance that using &apos;int&apos; (UTF-32 intervals) instead is a better fix, but this is not true, because it would cause a RunAutomaton to use 1MB memory where it currently uses 64KB, only for these stupid rare cases.&lt;/p&gt;</comment>
                    <comment id="12781721" author="rcmuir" created="Tue, 24 Nov 2009 01:04:53 +0000"  >&lt;p&gt;I spent a while with this, thinking I would be slick and create a version of Automaton that works with both trunk and flex branch correctly.&lt;br/&gt;
Finally, i figured it out, this is not possible.&lt;/p&gt;

&lt;p&gt;There is no bug with the current version, because in trunk, IndexReader.terms() uses UTF-16 binary order.&lt;br/&gt;
In the flex branch, it uses UTF-8 binary order.&lt;/p&gt;

&lt;p&gt;I can emulate UTF-8 binary order in the enum, but then it won&apos;t work correctly on trunk, but will work on flex branch!&lt;/p&gt;

&lt;p&gt;This enum is sensitive to the order of terms coming in...&lt;/p&gt;

&lt;p&gt;doh!&lt;/p&gt;</comment>
                    <comment id="12781729" author="yseeley@gmail.com" created="Tue, 24 Nov 2009 01:16:45 +0000"  >&lt;p&gt;geeze... maybe we should have just stuck with CESU-8 &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="12781746" author="rcmuir" created="Tue, 24 Nov 2009 02:15:22 +0000"  >&lt;p&gt;Yonik, maybe we can use this trick?&lt;/p&gt;

&lt;p&gt;UTF-8 in UTF-16 Order&lt;br/&gt;
The following comparison function for UTF-8 yields the same results as UTF-16 binary&lt;br/&gt;
comparison. In the code, notice that it is necessary to do extra work only once per string,&lt;br/&gt;
not once per byte. That work can consist of simply remapping through a small array; there&lt;br/&gt;
are no extra conditional branches that could slow down the processing.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; strcmp8like16(unsigned &lt;span class=&quot;code-object&quot;&gt;char&lt;/span&gt;* a, unsigned &lt;span class=&quot;code-object&quot;&gt;char&lt;/span&gt;* b) {
  &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; (&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;) {
  &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; ac = *a++;
  &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; bc = *b++;
  &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (ac != bc) &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; rotate[ac] - rotate[bc];
  &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (ac == 0) &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; 0;
  }
}

&lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;char&lt;/span&gt; rotate[256] =
{0x00, ..., 0x0F,
0x10, ..., 0x1F,
. .
. .
. .
0xD0, ..., 0xDF,
0xE0, ..., 0xED, 0xF0, 0xF1,
0xF2, 0xF3, 0xF4, 0xEE, 0xEF, 0xF5, ..., 0xFF};
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The rotate array is formed by taking an array of 256 bytes from 0x00 to 0xFF, and rotating&lt;br/&gt;
0xEE and 0xEF to a position after the bytes 0xF0..0xF4. These rotated values are shown in&lt;br/&gt;
boldface. When this rotation is performed on the initial bytes of UTF-8, it has the effect of&lt;br/&gt;
making code points U+10000..U+10FFFF sort below U+E000..U+FFFF, thus mimicking&lt;br/&gt;
the ordering of UTF-16.&lt;/p&gt;</comment>
                    <comment id="12781888" author="rcmuir" created="Tue, 24 Nov 2009 12:22:06 +0000"  >&lt;p&gt;updated patch:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;don&apos;t seek to high surrogates, instead tack on \uDC00. this still works for trunk, but also with flex branch.&lt;/li&gt;
	&lt;li&gt;don&apos;t use a high surrogate prefix, instead truncate. this isn&apos;t being used at all, i would rather use &apos;constant suffix&apos;&lt;/li&gt;
	&lt;li&gt;add tests that will break if lucene&apos;s sort order is not UTF-16 (or if automaton is not adjusted to the new sort order)&lt;/li&gt;
	&lt;li&gt;add another enum constructor, where you can specify smart or dumb mode yourself&lt;/li&gt;
	&lt;li&gt;regexp javadoc note&lt;/li&gt;
	&lt;li&gt;add wordage to LICENSE, not just NOTICE&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12781890" author="rcmuir" created="Tue, 24 Nov 2009 12:26:47 +0000"  >&lt;p&gt;sorry, my ide added a @author tag. i need to look to see where to turn this @author generation off for eclipse.&lt;/p&gt;</comment>
                    <comment id="12781911" author="thetaphi" created="Tue, 24 Nov 2009 13:25:45 +0000"  >&lt;p&gt;what is UTF-38? &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; I think you mean UTF-32, if such exists.&lt;/p&gt;

&lt;p&gt;Else it looks good!&lt;/p&gt;</comment>
                    <comment id="12781914" author="rcmuir" created="Tue, 24 Nov 2009 13:28:55 +0000"  >&lt;p&gt;i think there is one last problem with this for flex branch, where you have abacadaba\uFFFC, abacadaba\uFFFD and abacadaba\uFFFE  in the term dictionary, but a regex the matches say abacadaba&lt;span class=&quot;error&quot;&gt;&amp;#91;\uFFFC\uFFFF&amp;#93;&lt;/span&gt;. in this case, the match on abacadaba\uFFFD will fail, it will try to seek to the &quot;next&quot; string, which is abacadaba\uFFFF, but the FFFF will get replaced by FFFD by the byte conversion, and we will loop.&lt;/p&gt;

&lt;p&gt;mike i don&apos;t think this should be any back compat concern, unlike the high surrogate case which i think many CJK applications are probably doing to...&lt;/p&gt;</comment>
                    <comment id="12781915" author="rcmuir" created="Tue, 24 Nov 2009 13:32:13 +0000"  >&lt;p&gt;Uwe, where do you see UTF-38 &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="12781922" author="thetaphi" created="Tue, 24 Nov 2009 13:35:52 +0000"  >&lt;blockquote&gt;&lt;p&gt;Uwe, where do you see UTF-38  &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Patch line 6025.&lt;/p&gt;</comment>
                    <comment id="12781924" author="thetaphi" created="Tue, 24 Nov 2009 13:40:11 +0000"  >&lt;p&gt;about the cleanupPrefix method: it is only used in the linear case to initially set the termenum. What happens if the nextString() method returs such a string ussed to seek the next enum?&lt;/p&gt;</comment>
                    <comment id="12781926" author="rcmuir" created="Tue, 24 Nov 2009 13:41:58 +0000"  >&lt;blockquote&gt;&lt;p&gt;about the cleanupPrefix method: it is only used in the linear case to initially set the termenum. What happens if the nextString() method returs such a string ussed to seek the next enum? &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;look at the code to nextString() itself. &lt;br/&gt;
it uses cleanupPosition() which works differently.&lt;/p&gt;

&lt;p&gt;when seeking, we can append \uDC00 to achieve the same thing as seeking to a high surrogate.&lt;br/&gt;
when using a prefix, we have to truncate the high surrogate, because we cannot use it with TermRef.startsWith() etc, it cannot be converted into UTF-8 bytes. (and we can&apos;t use the \uDC00 trick, obviously, or startsWith() will return false when it should not)&lt;/p&gt;</comment>
                    <comment id="12782024" author="rcmuir" created="Tue, 24 Nov 2009 16:57:02 +0000"  >&lt;blockquote&gt;&lt;p&gt;Patch line 6025.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Thanks for reviewing the patch and catching this. I&apos;m working on trying to finalize this.&lt;br/&gt;
It already works fine for trunk, but I don&apos;t want it to suddenly break with the flex branch, so I&apos;m adding a lot of tests and improvements in that regard.&lt;br/&gt;
The current wildcard tests aren&apos;t sufficient anyway to tell if its really working.&lt;br/&gt;
Also, when Mike ported it to the flex branch, he reorganized some code some in a way that I think is better, so I want to tie that in too.&lt;/p&gt;</comment>
                    <comment id="12782026" author="thetaphi" created="Tue, 24 Nov 2009 17:04:35 +0000"  >&lt;p&gt;Did he changed the FilteredTermEnum.next() loops? if yes, maybe the better approach also works for NRQ. I am just interested, but had no time to thoroughly look into the latest changes.&lt;/p&gt;

&lt;p&gt;I am still thinking about an extension of FilteredTermEnum that works with these repositioning out of the box. But I have no good idea. The work in FilteredTerm*s*Enum is a good start, but may be extended, to also support something like a return value &quot;JUMP_TO_NEXT_ENUM&quot; and a mabstract method &quot;nextEnum()&quot; that returns null per default (no further enum).&lt;/p&gt;</comment>
                    <comment id="12782029" author="rcmuir" created="Tue, 24 Nov 2009 17:10:20 +0000"  >&lt;p&gt;No, the main thing he did here that i like better, is that instead of caching the last comparison in termCompare(), he uses a boolean &apos;first&apos;&lt;/p&gt;

&lt;p&gt;This still gives the optimization of &apos;don&apos;t seek in the term dictionary unless you get a mismatch, as long as you have matches, read sequentially&apos;&lt;br/&gt;
But in my opinion, its cleaner.&lt;/p&gt;</comment>
                    <comment id="12782033" author="thetaphi" created="Tue, 24 Nov 2009 17:14:25 +0000"  >&lt;p&gt;OK, so doesn&apos;t affect NRQ, as it uses a different algo&lt;/p&gt;</comment>
                    <comment id="12782036" author="rcmuir" created="Tue, 24 Nov 2009 17:17:53 +0000"  >&lt;p&gt;Yeah, but in general I think I already agree that FilteredTerm*s*Enum is easier for stuff like this.&lt;/p&gt;

&lt;p&gt;Either way its still tricky to make enums like this, so I am glad you are looking into it.&lt;/p&gt;</comment>
                    <comment id="12782042" author="thetaphi" created="Tue, 24 Nov 2009 17:23:48 +0000"  >&lt;p&gt;I think the approach with nextEnum() would work for Automaton and NRQ, because both use this iteration approach. You have nextString() for repositioning, and I have a LinkedList (a stack) of pre-sorted range bounds.&lt;/p&gt;</comment>
                    <comment id="12782043" author="rcmuir" created="Tue, 24 Nov 2009 17:25:16 +0000"  >&lt;p&gt;And I could still use this with &quot;dumb mode&quot;?, just one enum, right?&lt;/p&gt;</comment>
                    <comment id="12782056" author="thetaphi" created="Tue, 24 Nov 2009 17:40:26 +0000"  >&lt;p&gt;yes.&lt;/p&gt;</comment>
                    <comment id="12782081" author="rcmuir" created="Tue, 24 Nov 2009 18:45:26 +0000"  >&lt;p&gt;this patch removes constant prefix, as its only used in dumb mode, and in dumb mode there is no constant prefix.&lt;br/&gt;
instead its replaced with constant suffix, which speeds up comparisons.&lt;/p&gt;

&lt;p&gt;constant suffix is implemented naively as reversing the DFA, taking its constant prefix, then reversing that.&lt;/p&gt;</comment>
                    <comment id="12782155" author="mikemccand" created="Tue, 24 Nov 2009 20:38:27 +0000"  >&lt;p&gt;Responding from &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-2075&quot; title=&quot;Share the Term -&amp;gt; TermInfo cache across threads&quot;&gt;&lt;del&gt;LUCENE-2075&lt;/del&gt;&lt;/a&gt;...&lt;/p&gt;

&lt;blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;So I guess if there&apos;s a non-empty common suffix you should just always seek?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;the suffix is just for quick comparison, not used at all in seeking.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think I&apos;m confused &amp;#8211; if the query is ???1234, the common suffix is&lt;br/&gt;
1234, and so shouldn&apos;t the DFA tell us the next XXX1234 term to try to&lt;br/&gt;
seek to (and we should never use next() on the enum)?&lt;/p&gt;</comment>
                    <comment id="12782159" author="rcmuir" created="Tue, 24 Nov 2009 20:56:32 +0000"  >&lt;blockquote&gt;
&lt;p&gt;I think I&apos;m confused - if the query is ???1234, the common suffix is&lt;br/&gt;
1234, and so shouldn&apos;t the DFA tell us the next XXX1234 term to try to&lt;br/&gt;
seek to (and we should never use next() on the enum)?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;not really the suffix, but more general, the structure of the dfa itself tells us that for ???1234, if you are evaluating 5551234, that the next term should really be 5561234&lt;br/&gt;
you can tell this by basically &apos;walking the graph&apos;&lt;/p&gt;

&lt;p&gt;but this knowledge is not always available, sometimes we only have &apos;partial&apos; knowledge of where to go next.&lt;br/&gt;
The culprit here is the * operator, because it eats up anything &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
So when you walk the graph, the * operator is this giant monster in your way. &lt;/p&gt;

&lt;p&gt;so sometimes, depending on the dfa (which depends on the wildcard or regex used to construct it), &lt;br/&gt;
automaton knows enough to seek to all the exact locations, if its finite (like ???1234)&lt;/p&gt;

&lt;p&gt;sometimes, it only knows partial information. when a loop is encountered walking the graph (the giant monster), it has to stop and only use the path information it knows so far.&lt;br/&gt;
for example a wildcard of abcd*1234, the best it can do is seek to abcd.&lt;/p&gt;

&lt;p&gt;your description of ping-pong is right, this is how these situations are handled.&lt;/p&gt;

&lt;p&gt;right now, the way the enum works, is i don&apos;t even bother seeking until i hit a mismatch.&lt;br/&gt;
you can see this in the comments &apos;as long as there is a match, keep reading. this is an optimization when many terms are matched sequentially like ab*&apos;&lt;/p&gt;

&lt;p&gt;i tested this along time ago, perhaps we should re-test to see if its appropriate?&lt;/p&gt;</comment>
                    <comment id="12782169" author="rcmuir" created="Tue, 24 Nov 2009 21:11:45 +0000"  >&lt;p&gt;mike, here is a more complex example of the ping-pong:&lt;/p&gt;

&lt;p&gt;a wildcard of abcd*12?4&lt;/p&gt;

&lt;p&gt;it has to seek to abcd first because of the * (the loop stops me)&lt;br/&gt;
the ping-pong from the term dictionary, returns say abcdk1000&lt;br/&gt;
it moves me past the giant monster.&lt;br/&gt;
now i know enough to seek to abcdk12\u00004&lt;/p&gt;

&lt;p&gt;in this case its nice, the TermEnum moved me past it in one seek.&lt;br/&gt;
sometimes its not so nice, if the TermEnum gave me abcda, i&apos;m not past the monster.&lt;/p&gt;

&lt;p&gt;all i can do is generate the next possible term that won&apos;t put me into a DFA reject state, which is abcda\u0000... forcing the enum to move me forwards.&lt;br/&gt;
maybe i seek to abcda\u0000, and it gives me abcdaa back, ill do the same thing again.&lt;/p&gt;

&lt;p&gt;the reason is, somewhere down the line there could be abcdaaaaaaaaaaaaaaaaaaaaaaaaaa1234 &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="12782170" author="mikemccand" created="Tue, 24 Nov 2009 21:12:18 +0000"  >&lt;p&gt;But, take the abcd*1234 case &amp;#8211; you first seek to abcd, the terms enum finds (say) abcdX1234 &amp;#8211; don&apos;t you (DFA) know at this point that next possible candidate is abcdY1234?  Ie, you should seek to that term?  (Doing next() at that point is most likely a waste, and anyway the enum will turn your seek into a next if it&apos;s &quot;close&quot;).&lt;/p&gt;

&lt;p&gt;That said, seeking on trunk is alot more costly than seeking on flex, because trunk has to make a new &lt;span class=&quot;error&quot;&gt;&amp;#91;cloned&amp;#93;&lt;/span&gt; SegmentTermEnum for each seek.&lt;/p&gt;</comment>
                    <comment id="12782173" author="rcmuir" created="Tue, 24 Nov 2009 21:18:38 +0000"  >&lt;blockquote&gt;&lt;p&gt;But, take the abcd*1234 case - you first seek to abcd, the terms enum finds (say) abcdX1234 - don&apos;t you (DFA) know at this point that next possible candidate is abcdY1234? Ie, you should seek to that term? (Doing next() at that point is most likely a waste, and anyway the enum will turn your seek into a next if it&apos;s &quot;close&quot;). &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;pretty sure I know this information, but in general i only seek on mismatches, I think for the reason that there can be a lot of seeks for AB* (say 1 million terms).&lt;br/&gt;
so instead i wait for a mismatch until i seek again, I think tests showed this due to what you mentioned below?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;That said, seeking on trunk is alot more costly than seeking on flex, because trunk has to make a new &lt;span class=&quot;error&quot;&gt;&amp;#91;cloned&amp;#93;&lt;/span&gt; SegmentTermEnum for each seek.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think that might be whats killing me, when i ran tests on lucene 2.9 or whatever.&lt;br/&gt;
We should retest performance on flex.&lt;/p&gt;

&lt;p&gt;This is why i said, significant rework of this maybe should take place in flex (although I still think this is an improvement for trunk already), to fully take advantage of it.&lt;/p&gt;</comment>
                    <comment id="12782180" author="rcmuir" created="Tue, 24 Nov 2009 21:27:11 +0000"  >&lt;p&gt;I guess here is the big question Mike, pretend ab* isn&apos;t rewritten to a prefixquery (it is, but there are more complex examples like this that cannot be)&lt;/p&gt;

&lt;p&gt;is it faster to seek 1M times and get the 1M terms, or just read them sequentially?&lt;br/&gt;
furthermore to &quot;seek&quot; is not just lucene seek, I have to walk the transitions and compute the next place to go... (and create a few objects along the way)&lt;/p&gt;</comment>
                    <comment id="12782184" author="mikemccand" created="Tue, 24 Nov 2009 21:32:22 +0000"  >&lt;blockquote&gt;
&lt;p&gt;pretend ab* isn&apos;t rewritten to a prefixquery (it is, but there are more complex examples like this that cannot be)&lt;br/&gt;
is it faster to seek 1M times and get the 1M terms, or just read them sequentially?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This case should definitely be done sequentially.&lt;/p&gt;

&lt;p&gt;But the fixed trailing prefix case I think should be all seeks.&lt;/p&gt;

&lt;blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;That said, seeking on trunk is alot more costly than seeking on flex, because trunk has to make a new &lt;span class=&quot;error&quot;&gt;&amp;#91;cloned&amp;#93;&lt;/span&gt; SegmentTermEnum for each seek.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think that might be whats killing me, when i ran tests on lucene 2.9 or whatever.&lt;br/&gt;
We should retest performance on flex.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Well, the seeks need to be done anyway... so you can&apos;t work around that.  The only question is if a wasted next() was done before each, I guess...&lt;/p&gt;</comment>
                    <comment id="12782188" author="rcmuir" created="Tue, 24 Nov 2009 21:40:21 +0000"  >&lt;blockquote&gt;&lt;p&gt;But the fixed trailing prefix case I think should be all seeks.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;ll use regular expressions here, just to elaborate on this.&lt;/p&gt;

&lt;p&gt;what if its ab.&lt;b&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;ab&amp;#93;&lt;/span&gt;? but the ab.&lt;/b&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;a-z&amp;#93;&lt;/span&gt;? ... where do you draw the line &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;its also worth mentioning that the automaton &quot;seek&quot;, nextString() is a lot more heavyweight right now than its &quot;compare&quot;, which is extremely fast. its the DFA in tableized (array) form, just as an array lookup.&lt;br/&gt;
This is why it beats even the hairy wildcard code we had before, after Uwe fixed my bug of course &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;I think there are heuristics like you say we can do, and there&apos;s a lot of knowledge in the DFA we can use to implement these for optimal behavior.&lt;br/&gt;
I think we can also improve the code itself, so that &quot;seek&quot;, the nextString() method itself, is more lightweight.&lt;/p&gt;

&lt;p&gt;on the other hand the big unknown is the distribution of the term dictionary itself.&lt;/p&gt;

&lt;p&gt;I did a very basic implementation here, I&apos;m hoping we can come up with better ideas that work well on average.&lt;br/&gt;
One problem is, what is an &quot;average&quot; regular expression or wildcard query &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="12782198" author="rcmuir" created="Tue, 24 Nov 2009 22:02:34 +0000"  >&lt;p&gt;benchmark results from mike&apos;s idea. I don&apos;t use any heuristic, just remove the extra &apos;next&apos; to show the tradeoffs.&lt;/p&gt;

&lt;p&gt;disclaimer: against trunk with &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-2075&quot; title=&quot;Share the Term -&amp;gt; TermInfo cache across threads&quot;&gt;&lt;del&gt;LUCENE-2075&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Pattern&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Iter&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;AvgHits&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;AvgMS&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;AvgMS (noNext)&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;N?N?N?N&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1000.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;37.5&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;28.4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;?NNNNNN&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;6.4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;6.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;??NNNNN&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;100.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;9.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;9.2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;???NNNN&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1000.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;52.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;40.9&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;????NNN&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10000.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;300.7&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;262.3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;NN??NNN&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;100.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4.9&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;NN?N*&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10000.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;9.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;28.9&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;?NN*&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;100000.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;80.4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;235.4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;*N&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1000000.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;3811.6&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;3747.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;*NNNNNN&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2098.3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2221.9&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;NNNNN??&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;100.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2.2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;2.4&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;


&lt;p&gt;Mike my gut feeling, which will require a lot more testing, is that if the automaton accepts a finite language (in the wildcard case, no *), we should not do the next() call.&lt;br/&gt;
but more benchmarking is needed, with more patterns, especially on flex branch to determine if this heuristic is best.&lt;/p&gt;</comment>
                    <comment id="12782204" author="rcmuir" created="Tue, 24 Nov 2009 22:19:17 +0000"  >&lt;p&gt;in this patch, if the automaton is finite, always seek.&lt;br/&gt;
if its infinite, keep reading terms sequentially until a term fails (then seek)&lt;/p&gt;

&lt;p&gt;it seems to be the best of both worlds, and makes perfect sense to me.&lt;/p&gt;

&lt;p&gt;only thing that has me nervous is that SpecialOperations.isFinite() is defined recursively... will have to look into maybe trying to write this method iteratively, in case someone builds some monster automaton from a 2 page regexp or something like that.&lt;/p&gt;</comment>
                    <comment id="12782205" author="rcmuir" created="Tue, 24 Nov 2009 22:20:28 +0000"  >&lt;p&gt;sorry, wrong file. getting lost in iterations of this patch.&lt;/p&gt;</comment>
                    <comment id="12782405" author="mikemccand" created="Wed, 25 Nov 2009 12:59:01 +0000"  >&lt;blockquote&gt;&lt;p&gt;(Doing next() at that point is most likely a waste, and anyway the enum will turn your seek into a next if it&apos;s &quot;close&quot;)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Actually &amp;#8211; I just remembered &amp;#8211; flex branch is failing to do this optimization (there&apos;s already a nocommit reminding us to do it).  Ie, it&apos;s always doing the binary search through the indexed terms... and not doing a scan when it determines the term you&apos;re seeking to is within the same index block.&lt;/p&gt;

&lt;p&gt;But I don&apos;t think this&apos;ll impact your tests with a large suffix since each seek will jump way ahead to a new index block.&lt;/p&gt;</comment>
                    <comment id="12782413" author="rcmuir" created="Wed, 25 Nov 2009 13:09:26 +0000"  >&lt;blockquote&gt;&lt;p&gt;But I don&apos;t think this&apos;ll impact your tests with a large suffix since each seek will jump way ahead to a new index block.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Mike, if you add that optimization, that takes care of lucene itself, its smart enough to turn a seek into a read when it should, so I you might say I should simplify my code and just always seek.&lt;br/&gt;
But if I were to do this, then that would kill the TermRef comparison speedup, because then no matter how much i optimize &quot;my seek&quot; nextString(), it needs to do the unicode conversion, which we have seen is expensive across many terms.&lt;/p&gt;
</comment>
                    <comment id="12782416" author="mikemccand" created="Wed, 25 Nov 2009 13:14:25 +0000"  >&lt;blockquote&gt;&lt;p&gt;But if I were to do this, then that would kill the TermRef comparison speedup, because then no matter how much i optimize &quot;my seek&quot; nextString(), it needs to do the unicode conversion, which we have seen is expensive across many terms.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Right, I think ATE must still pick &amp;amp; choose when to seek itself vs seek Lucene, based on how costly nextString() is...&lt;/p&gt;</comment>
                    <comment id="12782418" author="mikemccand" created="Wed, 25 Nov 2009 13:14:51 +0000"  >&lt;p&gt;Make that &quot;when to seek itself vs next() Lucene&quot;&lt;/p&gt;</comment>
                    <comment id="12782420" author="rcmuir" created="Wed, 25 Nov 2009 13:18:41 +0000"  >&lt;p&gt;Mike by the way, I profiled the seeking on trunk, right at the top with 20% in hprof is the SegmentTermEnum clone... this is why at least for now, and on flex for different reasons, I think we should keep this stupid heuristic.&lt;/p&gt;

&lt;p&gt;But its improved now, because at least its using some knowledge of the DFA (whether or not it contains loops) to make this determination, thanks for the idea!&lt;/p&gt;</comment>
                    <comment id="12782477" author="mikemccand" created="Wed, 25 Nov 2009 16:07:26 +0000"  >&lt;blockquote&gt;&lt;p&gt;Mike by the way, I profiled the seeking on trunk, right at the top with 20% in hprof is the SegmentTermEnum clone... this is why at least for now, and on flex for different reasons, I think we should keep this stupid heuristic.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;OK let&apos;s keep it for now?  But somehow we need to remember when this gets onto flex branch to put it back...&lt;/p&gt;</comment>
                    <comment id="12782485" author="rcmuir" created="Wed, 25 Nov 2009 16:16:19 +0000"  >&lt;blockquote&gt;&lt;p&gt;OK let&apos;s keep it for now? But somehow we need to remember when this gets onto flex branch to put it back...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I guess what I am saying is I think the latest patch, which uses the isFinite() property of the DFA to determine whether or not to seek itself versus trying next(), is the best for both trunk and flex, but for different reasons?&lt;/p&gt;

&lt;p&gt;edit:&lt;br/&gt;
the different reasons being: seek is expensive in trunk, because of the SegmentTermEnum clone()&lt;br/&gt;
seek is &quot;expensive&quot; in flex, because doing a seek when we are in a loop entails unicode conversion, but next() avoids this with TermRef comparison.&lt;/p&gt;

&lt;p&gt;It gives the best of all the scores from &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1606?focusedCommentId=12782198&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#action_12782198&quot; class=&quot;external-link&quot;&gt;https://issues.apache.org/jira/browse/LUCENE-1606?focusedCommentId=12782198&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#action_12782198&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In the future this could be refined, such that whether to try the extra next() or go ahead and seek() could instead be driven by whether or not we are &apos;ping-ponging against a loop&apos;, i.e. actually pingponging against a wildcard *, rather than computed up-front for the entire query. this can be determined from the state/transitions of the path being evaluated, but its not a one-liner!&lt;/p&gt;</comment>
                    <comment id="12783661" author="rcmuir" created="Mon, 30 Nov 2009 13:49:57 +0000"  >&lt;p&gt;Mike,&lt;/p&gt;

&lt;p&gt;This is ok for the trunk, but I have a question about \uFFFF in flex (I guess we do not need to figure it out now, just think about it).&lt;br/&gt;
My understanding is that now \uFFFF can be in the index, and I can seek to it (it won&apos;t get replaced with \uFFFD).&lt;br/&gt;
From your comment this seems undefined at the moment, but for this enum I need to know, otherwise it will either skip \uFFFF terms, or go into a loop.&lt;/p&gt;
</comment>
                    <comment id="12783697" author="mikemccand" created="Mon, 30 Nov 2009 15:36:29 +0000"  >&lt;blockquote&gt;&lt;p&gt;My understanding is that now \uFFFF can be in the index, and I can seek to it (it won&apos;t get replaced with \uFFFD).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes, \uFFFF should be untouched now (though I haven&apos;t verified  &amp;#8211; actually I&apos;ll go add it to the test we already have for \uFFFF).&lt;/p&gt;</comment>
                    <comment id="12783701" author="rcmuir" created="Mon, 30 Nov 2009 15:40:38 +0000"  >&lt;p&gt;Thanks Mike, I will change the enum to reflect this.&lt;br/&gt;
Currently I cheat and take advantage of this property (in trunk) to make the code simpler.&lt;/p&gt;</comment>
                    <comment id="12785027" author="rcmuir" created="Wed, 2 Dec 2009 22:20:28 +0000"  >&lt;p&gt;here is an updated patch. In my opinion all that is needed is to add the random testing, and code reorganization (but no algorithmic/feature changes), maybe better docs too.&lt;/p&gt;

&lt;p&gt;This patch has:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;more tests, especially surrogate handling&lt;/li&gt;
	&lt;li&gt;some more automaton paring&lt;/li&gt;
	&lt;li&gt;the seek positions and common suffix are always valid UTF-8 strings&lt;/li&gt;
	&lt;li&gt;backtracking is aware of U+FFFF, so terms can have it.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;This patch works correctly on both trunk and flex, although I don&apos;t have an included test for U+FFFF since I can&apos;t put it in a trunk index.&lt;/p&gt;

&lt;p&gt;I&apos;m not too terribly happy about the way the unicode handling works here, its correct but could be coded better.&lt;br/&gt;
The code I wrote is not the easiest to read and suggestions welcome &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
But it is all localized to one method, cleanupPosition(). This is defined as&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
* &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; the seek position cannot be converted to valid UTF-8,
* then &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; the next valid &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; (in UTF-16 sort order) that
* can be converted to valid UTF-8.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;if you have ideas on how to make this nicer I am happy to hear them.&lt;/p&gt;
</comment>
                    <comment id="12785034" author="rcmuir" created="Wed, 2 Dec 2009 22:43:50 +0000"  >&lt;p&gt;edit: edit out my chinese chars and replaced with &amp;lt;chineseCharOutsideBMP&amp;gt; as there are some problems indexing this comment.&lt;/p&gt;

&lt;p&gt;btw the unicode complexity i mention here is not just me being anal, its an impedence mismatch between the automaton library using UTF-16 code unit representation and the new flex api requiring valid UTF-8. &lt;/p&gt;

&lt;p&gt;I am not trying to introduce complexity for no reason, here is an example:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
RegExp re = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; RegExp(&lt;span class=&quot;code-quote&quot;&gt;&quot;(&amp;lt;chineseCharOutsideBMP&amp;gt;|&amp;lt;chineseCharOutsideBMP&amp;gt;)&quot;&lt;/span&gt;);
&lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.out.println(re.toAutomaton());
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;initial state: 0
state 0 [reject]:
  \ud866 -&amp;gt; 2
state 1 [accept]:
state 2 [reject]:
  \udf05-\udf06 -&amp;gt; 1
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;as you can see, the automaton library handles these characters correctly, but as code units.&lt;br/&gt;
so its important not to seek to invalid locations when walking thru the DFA, because these will be replaced by U+FFFD, &lt;br/&gt;
and terms could be skipped, or we go backwards, creating a loop.&lt;br/&gt;
Thats why i spent so much time on this.&lt;/p&gt;
</comment>
                    <comment id="12785951" author="rcmuir" created="Fri, 4 Dec 2009 14:51:33 +0000"  >&lt;p&gt;I added random testing for wildcards and regexps. &lt;br/&gt;
Don&apos;t know what else needs to be done here, please review if you can.&lt;/p&gt;</comment>
                    <comment id="12785962" author="markrmiller@gmail.com" created="Fri, 4 Dec 2009 15:16:35 +0000"  >&lt;p&gt;I&apos;ll play with it some for one. Fantastic commenting man - this whole patch is pretty darn thorough.&lt;/p&gt;</comment>
                    <comment id="12786049" author="rcmuir" created="Fri, 4 Dec 2009 18:12:00 +0000"  >&lt;p&gt;attached is a port of the latest trunk patch to flex branch, for experimenting or whatever.&lt;/p&gt;</comment>
                    <comment id="12786052" author="rcmuir" created="Fri, 4 Dec 2009 18:19:18 +0000"  >&lt;p&gt;btw this patch is a bit different than the last port to flex in one way.&lt;br/&gt;
Like the trunk patch the commonSuffix is only computed for &quot;linear mode&quot; aka slow queries.&lt;br/&gt;
but computing this for flex will be a win even for faster queries in &quot;smart mode&quot;, because it can dodge more unicode conversion with TermRef byte[] comparison.&lt;/p&gt;

&lt;p&gt;the problem is my implementation of getCommonSuffix() is a little crappy, reverse the entire automaton, redeterminize, take its common prefix, then reverse that.&lt;br/&gt;
instead, improving reverse() so that it keeps determinism when its already a DFA (DFA-&amp;gt;DFA) will allow this commonSuffix to be used in both modes without any concern that it will ever hurt performance.&lt;/p&gt;</comment>
                    <comment id="12786429" author="thetaphi" created="Sat, 5 Dec 2009 15:06:03 +0000"  >&lt;p&gt;Here a flex patch for automaton. It contains &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-2110&quot; title=&quot;Refactoring of FilteredTermsEnum and MultiTermQuery&quot;&gt;&lt;del&gt;LUCENE-2110&lt;/del&gt;&lt;/a&gt;, as soon as 2110 is committed I will upload a new patch. But its hard to differentiate between all modified files.&lt;/p&gt;

&lt;p&gt;Robert: Can you do performance tests with the old and new flex patch, I do not want to commit 2110 before.&lt;/p&gt;</comment>
                    <comment id="12786431" author="rcmuir" created="Sat, 5 Dec 2009 15:10:47 +0000"  >&lt;blockquote&gt;&lt;p&gt;Robert: Can you do performance tests with the old and new flex patch, I do not want to commit 2110 before.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Uwe I will run a benchmark on both versions!&lt;/p&gt;</comment>
                    <comment id="12786432" author="thetaphi" created="Sat, 5 Dec 2009 15:15:55 +0000"  >&lt;p&gt;New patch, there was a lost private field. Also changed the nextSeekTerm method to be more straigtForward.&lt;/p&gt;

&lt;p&gt;Robert: Sorry, it would be better to test this one &lt;b&gt;g&lt;/b&gt;&lt;/p&gt;</comment>
                    <comment id="12786438" author="rcmuir" created="Sat, 5 Dec 2009 15:44:21 +0000"  >&lt;p&gt;Hi Uwe, I ran my benchmarks, and with your patch the performance is the same.&lt;/p&gt;

&lt;p&gt;But the code is much simpler and easier to read... great work.&lt;/p&gt;</comment>
                    <comment id="12786472" author="thetaphi" created="Sat, 5 Dec 2009 19:52:02 +0000"  >&lt;p&gt;An update with the changed nextSeekTerm() semantics from &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-2110&quot; title=&quot;Refactoring of FilteredTermsEnum and MultiTermQuery&quot;&gt;&lt;del&gt;LUCENE-2110&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Robert: Can you test performance again and compare with old?&lt;/p&gt;</comment>
                    <comment id="12786476" author="thetaphi" created="Sat, 5 Dec 2009 20:02:34 +0000"  >&lt;p&gt;There was a bug in the patch before, sorry. I will finish work for today, I am exhausted like the enums.&lt;/p&gt;</comment>
                    <comment id="12786479" author="thetaphi" created="Sat, 5 Dec 2009 20:07:07 +0000"  >&lt;p&gt;Stop everything I get a collaps!!!!! Again wrong patch.&lt;/p&gt;</comment>
                    <comment id="12786483" author="thetaphi" created="Sat, 5 Dec 2009 20:19:52 +0000"  >&lt;p&gt;Now the final one.&lt;/p&gt;

&lt;p&gt;I somehow need a test enum which does very strange things like seeking forward and backwards and returning all strange stati.&lt;/p&gt;

&lt;p&gt;Will think about one tomorrow.&lt;/p&gt;</comment>
                    <comment id="12786489" author="markrmiller@gmail.com" created="Sat, 5 Dec 2009 20:39:40 +0000"  >&lt;p&gt;The new WildcardQuery is holding up very well under random testing -&lt;/p&gt;

&lt;p&gt;I&apos;m comparing the results of the old WildcardQuery impl with the new WildcardQuery impl.&lt;/p&gt;

&lt;p&gt;I&apos;m using a 2 million doc english and 2 million doc french index. (wikipedia dumps)&lt;/p&gt;

&lt;p&gt;Generating random queries - both random short strings built up from random unicode chars mixed with some random wildcards, and random english/french words from dictionaries, randomly chopped or not, with random wildcards injected. A whole lot of crazy randomness.&lt;/p&gt;

&lt;p&gt;They have always produced the same number of results so far (a few hours of running).&lt;/p&gt;

&lt;p&gt;The new impl is generally either a bit faster in these cases, or about the same - at worst (in general), I&apos;ve seen it about .01s  slower. When its faster, its offten &amp;gt; .1s faster (or more when a few &apos;?&apos; are involved).&lt;/p&gt;

&lt;p&gt;On avg, I&apos;d say the perf is about the same - where the new impl shines appears to be when &apos;?&apos; is used (as I think Robert has mentioned).&lt;/p&gt;

&lt;p&gt;So far I haven&apos;t seen any anomalies in time taken or anything of that nature.&lt;/p&gt;</comment>
                    <comment id="12786493" author="rcmuir" created="Sat, 5 Dec 2009 20:47:57 +0000"  >&lt;p&gt;Mark, thanks for testing!&lt;/p&gt;

&lt;p&gt;Yes, the new wildcard should really only help for ? with trunk (especially leading ?)&lt;br/&gt;
With flex it should help a lot more, even leading * gets the benefit of &quot;common suffix&quot; and byte[] comparison and things like that.&lt;br/&gt;
This code is in the trunk patch but does not really help yet because trunk enum works on String.&lt;/p&gt;

&lt;p&gt;btw how many uniq terms is the field you are testing... this is where it starts to help with ?, when you have a ton of unique terms.&lt;br/&gt;
But I am glad you are testing with hopefully a smaller # of uniq terms, this is probably more common.&lt;/p&gt;</comment>
                    <comment id="12786495" author="thetaphi" created="Sat, 5 Dec 2009 20:50:07 +0000"  >&lt;p&gt;Here is the patch with the getEnum/getTermsEnum changes instead of rewrite but with reverted &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-2110&quot; title=&quot;Refactoring of FilteredTermsEnum and MultiTermQuery&quot;&gt;&lt;del&gt;LUCENE-2110&lt;/del&gt;&lt;/a&gt;, which was stupid.&lt;/p&gt;</comment>
                    <comment id="12786498" author="markrmiller@gmail.com" created="Sat, 5 Dec 2009 20:55:32 +0000"  >&lt;blockquote&gt;&lt;p&gt;how many uniq terms is the field you are testing&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;m not sure at the moment - but its wikipedia dumps, so I&apos;d guess its rather high actually. It is hitting the standard analyzer going in (mainly because I didn&apos;t think about changing it on building the indexes). And the queries are getting hit with the lowercase filter (stole the code anyway).&lt;/p&gt;</comment>
                    <comment id="12786500" author="thetaphi" created="Sat, 5 Dec 2009 20:59:23 +0000"  >&lt;p&gt;again - krr to the hell with the AM/PM bug in JIRA! It is ****&lt;b&gt;xxx&lt;/b&gt;**&lt;/p&gt;</comment>
                    <comment id="12786502" author="rcmuir" created="Sat, 5 Dec 2009 21:10:14 +0000"  >&lt;blockquote&gt;&lt;p&gt;I&apos;m not sure at the moment - but its wikipedia dumps, so I&apos;d guess its rather high actually. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;See the description, I created this for working mainly regexp on indexes with 100M+ unique terms.&lt;br/&gt;
Wildcard doesn&apos;t get as much benefit, except ? operator and the comparisons being faster (array-based DFA)&lt;/p&gt;

&lt;p&gt;I&apos;m pleased to hear its doing so well on such a &quot;small&quot; index as wikipedia, as I would think automata overhead would make it slower (although this can probably be optimized away)&lt;/p&gt;</comment>
                    <comment id="12786528" author="rcmuir" created="Sat, 5 Dec 2009 22:58:55 +0000"  >&lt;blockquote&gt;&lt;p&gt;I&apos;m not sure at the moment - but its wikipedia dumps, so I&apos;d guess its rather high actually.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I looked at the wikipedia dump in benchmark (when indexed with standardanalyzer), body only has 65k terms... I think thats pretty small &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
I do not think automaton will help much with such a small number of terms, its definitely a worst case benchmark you are performing.&lt;br/&gt;
I think very little time is probably spent here in term enumeration so scalability does not matter for that corpus.&lt;/p&gt;

&lt;p&gt;More interesting to see the benefits would be something like indexing geonames data (lots of terms), or even that (much smaller) persian corpus i mentioned with nearly 500k terms... &lt;/p&gt;</comment>
                    <comment id="12786529" author="markrmiller@gmail.com" created="Sat, 5 Dec 2009 23:05:55 +0000"  >&lt;blockquote&gt;&lt;p&gt;I think thats pretty small&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Okay, fair enough &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; Guess it depends on your idea of small - though I would have guess (wrongly it appears), that it would be more. One diff is that I think the bechmark uses a 200mb (zipped) or so dump by default? I&apos;m using a 5 gig dump - though that prob doesn&apos;t add too many more in the scheme of things.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;More interesting to see the benefits...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Right, but I&apos;m not really testing for benefits - more for correctness and no loss of performance (on a fairly standard corpus). I think the benches you have already done are probably plenty good for benefits testing.&lt;/p&gt;</comment>
                    <comment id="12786531" author="rcmuir" created="Sat, 5 Dec 2009 23:10:37 +0000"  >&lt;blockquote&gt;&lt;p&gt;Right, but I&apos;m not really testing for benefits - more for correctness and no loss of performance (on a fairly standard corpus). I think the benches you have already done are probably plenty good for benefits testing.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;oh ok, I didnt know. Because my benchmark as Mike said, is definitely very &quot;contrived&quot;. &lt;/p&gt;

&lt;p&gt;But its kind of realistic, there are situations where the number of terms compared to the number of docs is much higher (maybe even 1-1 for unique product ids and things like that). &lt;/p&gt;

&lt;p&gt;I am glad you did this test, because I was concerned about the &quot;small index&quot; case too. And definitely correctness....&lt;/p&gt;

&lt;p&gt;I think you are right about the partial dump. I am indexing the full dump now (at least I think). I will look at it too, at least for curiousity sake.&lt;/p&gt;</comment>
                    <comment id="12786533" author="markrmiller@gmail.com" created="Sat, 5 Dec 2009 23:15:43 +0000"  >&lt;blockquote&gt;&lt;p&gt;And definitely correctness....&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Right - thats my main motivation - comparing the results of the old wildcardquery with the new - I actually put the timings in there as an after thought - just because I was curious.&lt;/p&gt;

&lt;p&gt;I really just wanted to make sure every random query acts the same with both impls and that no random input can somehow screw things up (Im using commons lang to pump in random unicode strings, along with turning the dict entires into wildcards that more likely to get many hits).&lt;/p&gt;

&lt;p&gt;Didn&apos;t expect to find anything, but it will make me feel better about +1ing the commit &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;Also going over the code, but thats going to take more time.&lt;/p&gt;</comment>
                    <comment id="12786536" author="rcmuir" created="Sat, 5 Dec 2009 23:25:04 +0000"  >&lt;p&gt;Mark oh ok, well thanks for spending so much time here testing and reviewing.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I really just wanted to make sure every random query acts the same with both impls and that no random input can somehow screw things up (Im using commons lang to pump in random unicode strings, along with turning the dict entires into wildcards that more likely to get many hits).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yeah I tried to do some of this in a very quick way if you look at the tests... I generate some random wildcard/regexp queries (mainly to prevent bugs from being introduced).&lt;/p&gt;

&lt;p&gt;The unicode tests (TestAutomatonUnicode) took me quite some time, they are definitely contrived but I think cover the bases for any unicode problems.&lt;br/&gt;
One problem is that none of this unicode stuff is ever a problem on trunk!&lt;/p&gt;

&lt;p&gt;If you save this test setup, maybe in the future I can trick you into running your tests on flex, where the unicode handling matters (as TermRef must be valid UTF-8 there).&lt;/p&gt;</comment>
                    <comment id="12786541" author="markrmiller@gmail.com" created="Sat, 5 Dec 2009 23:48:16 +0000"  >&lt;blockquote&gt;&lt;p&gt;Yeah I tried to do some of this in a very quick way if you look at the tests... I generate some random wildcard/regexp queries (mainly to prevent bugs from being introduced).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yeah, I think the tests are pretty solid (from the briefs looks I&apos;ve had thus far) - this is mainly just a precaution - so that we are not surprised by a more realistic corpus. And to have the opportunity to compare with the old WildcardQuery - I&apos;d rather not keep it around for tests - once we are confident its the same (and I am at this point), I&apos;m happy to see it fade into the night. Replacing such a core piece though, I want to be absolutely sure everything is on the level.&lt;/p&gt;

&lt;p&gt;bq, they are definitely contrived but I think cover the bases for any unicode problems.&lt;/p&gt;

&lt;p&gt;Right - in terms of unit tests, I think you&apos;ve done great based on what I&apos;ve seen. This is just throwing more variety at a larger more realistic corpus. More of a one time deal than something that should be incorporated into the tests. Ensures there are no surprises for me - since I didn&apos;t write any of this code (and I&apos;m not yet super familiar with it), it helps with my comfort level &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;One problem is that none of this unicode stuff is ever a problem on trunk!&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yeah - I assumed not. But as I&apos;m not that familiar with the automaton stuff yet, I wanted to be sure there wasn&apos;t going to be any input that somehow confused it. I realize that your familiarity level probably tells you thats not possible - but mine puts me in the position of testing anyway - else I&apos;ll look like a moron when I +1 this thing &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;If you save this test setup, &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;ll save it for sure.&lt;/p&gt;</comment>
                    <comment id="12786542" author="rcmuir" created="Sat, 5 Dec 2009 23:49:15 +0000"  >&lt;blockquote&gt;&lt;p&gt;Also going over the code, but thats going to take more time.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Btw, I will accept any criticism here. I am not happy with the complexity of the enum in the trunk patch, personally.&lt;br/&gt;
But here are the three main issues that I think make it complex: (not to try to place blame elsewhere)&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;This trie&amp;lt;-&amp;gt;DFA intersection is inherently something i would want to define recursively, but this would be obviously bad.&lt;/li&gt;
	&lt;li&gt;The DFA library uses UTF-16 whereas TermRef requires UTF-8. Changing automaton to use &apos;int&apos; would fix this, but then would destroy performance. The reason brics is the fastest java regex library is that it tableizes the DFA into a 64k UTF-16 char[]. See RunAutomaton for the impl. I think making this require 1MB for the corner cases is bad.&lt;/li&gt;
	&lt;li&gt;MultiTermQuerys that seek around are pretty complex in trunk. In my opinion this enum is a lot easier to understand with the improvements Uwe is working on for FilteredTermsEnum (see his branch patch, I think its easier there).&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;if you have ideas how we can simplify any of this in trunk for easier readability (instead of just adding absurd amounts of comments as I did), I&apos;d be very interested.&lt;/p&gt;</comment>
                    <comment id="12786551" author="markrmiller@gmail.com" created="Sun, 6 Dec 2009 00:58:27 +0000"  >&lt;p&gt;Sorry - haven&apos;t been paying a lot of attention to all of the Unicode issues/talk lately.&lt;/p&gt;

&lt;p&gt;Could you briefly explain cleanupPosition? Whats the case where a seek position cannot be converted to UTF-8?&lt;/p&gt;

&lt;p&gt;&lt;b&gt;edit&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;Because of next string guesses that might not be valid UTF-8?&lt;/p&gt;</comment>
                    <comment id="12786555" author="rcmuir" created="Sun, 6 Dec 2009 01:38:57 +0000"  >&lt;p&gt;yes, Mark you have it right. This is not an issue for trunk, only flex, but I fixed it ahead of time to prevent problems.&lt;/p&gt;

&lt;p&gt;so i have a chinese example here: &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1606?focusedCommentId=12785034&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#action_12785034&quot; class=&quot;external-link&quot;&gt;https://issues.apache.org/jira/browse/LUCENE-1606?focusedCommentId=12785034&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#action_12785034&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;but at the same time, this kind of thing can happen with a simple wildcard *, or ?&lt;br/&gt;
Because a wildcard ? will be converted into a UTF-16 DFA transition of \u0000-\uFFFF, when enumerating this transition (depending on your term dictionary), we cannot create a nextString for example that ends with say, \uD800, else it will get replaced with \uFFFD, and we will miss terms.&lt;/p&gt;

&lt;p&gt;The enumeration in nextString is greedy, so we can&apos;t just look for these in final position either. For example, if you have a regexp of &lt;span class=&quot;error&quot;&gt;&amp;#91;lm&amp;#93;&lt;/span&gt;ar&lt;span class=&quot;error&quot;&gt;&amp;#91;kl&amp;#93;&lt;/span&gt;, this enum first tries to seek to lark (it will continue to walk transitions until an accept state or a loop).&lt;/p&gt;</comment>
                    <comment id="12786557" author="rcmuir" created="Sun, 6 Dec 2009 01:58:40 +0000"  >&lt;p&gt;here is an explanation of the cleanupPosition, and the cases it handles&lt;/p&gt;

&lt;p&gt;Symbols:&lt;br/&gt;
A = \u0000 - \uD7FFF (lower BMP)&lt;br/&gt;
H = \uD800 - \uDBFFF (high/lead surrogates)&lt;br/&gt;
L = \uDC00 - \uDFFFF (low/trail surrogates)&lt;br/&gt;
Z = \uE000 - \uFFFF (upper BMP)&lt;/p&gt;

&lt;p&gt;case 1: &lt;br/&gt;
// an illegal combination, where we have not yet enumerated into the supp. plane&lt;br/&gt;
// so we increment to H + \uDC00 (the lowest possible trail surrogate)&lt;br/&gt;
HA -&amp;gt; H \uDC00&lt;br/&gt;
HH -&amp;gt; H \uDC00&lt;br/&gt;
case 2:&lt;br/&gt;
// an illegal combination where we have already enumerated the supp. plane&lt;br/&gt;
// we must replace both H and Z with \uE000 (the lowest possible &quot;upper BMP&quot;) &lt;br/&gt;
HZ -&amp;gt; \uE000&lt;br/&gt;
case 3:&lt;br/&gt;
// an illegal combination where we have a final lead surrogate.&lt;br/&gt;
// we have not yet enumerated the supp plane, so append \uDC00 (lowest possible trail surrogate)&lt;br/&gt;
// this is just like case 1, except in final position.&lt;br/&gt;
H$ -&amp;gt; H \uDC00&lt;br/&gt;
case 4:&lt;br/&gt;
// an unpaired trail surrogate. this is invalid when not preceded by lead surrogate&lt;br/&gt;
// (and if there was one, the above rules would have dealt with it already)&lt;br/&gt;
// in this case we have to bump to \uE000 (the lowest possible &quot;upper BMP&quot;)&lt;br/&gt;
unpaired L -&amp;gt; \uE000&lt;br/&gt;
case 5:&lt;br/&gt;
// this is just like case 4, its obviously illegal because the term starts with a trail surrogate.&lt;br/&gt;
// (because it is in initial position)&lt;br/&gt;
^L -&amp;gt; \uE000&lt;/p&gt;

&lt;p&gt;edit: sorry for the many edits &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="12786562" author="rcmuir" created="Sun, 6 Dec 2009 02:43:50 +0000"  >&lt;p&gt;in this patch, i take some commented out code in UnicodeUtil (validUTF16String), and pervert it slightly into nextValidUTF16String.&lt;/p&gt;

&lt;p&gt;all the tests pass using this on trunk and flex, and I think it reads much easier.&lt;/p&gt;</comment>
                    <comment id="12786564" author="rcmuir" created="Sun, 6 Dec 2009 03:02:32 +0000"  >&lt;p&gt;here is an update to the last one, using UnicodeUtil constants, etc.&lt;/p&gt;

&lt;p&gt;So I think I do not absolutely hate the unicode handling code in this enum anymore.&lt;/p&gt;</comment>
                    <comment id="12786566" author="rcmuir" created="Sun, 6 Dec 2009 03:22:35 +0000"  >&lt;p&gt;btw one thing we could do is put this nextValidUTF16String in UnicodeUtil and also use it in SegmentReader.LegacyTermEnum to replace the &quot;hack&quot;, just in case someone else wrote an enum like mine.&lt;/p&gt;

&lt;p&gt;this would provide better backwards compatibility, as they would receive the &apos;next Term&apos; in IndexReader.terms() just as they did before, even if the term is completely jacked...&lt;/p&gt;

&lt;p&gt;below is the existing hack:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
   &lt;span class=&quot;code-comment&quot;&gt;// &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; is a hack only &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; backwards compatibility.
&lt;/span&gt;   &lt;span class=&quot;code-comment&quot;&gt;// previously you could supply a term ending with a lead surrogate,
&lt;/span&gt;   &lt;span class=&quot;code-comment&quot;&gt;// and it would &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; the next Term.
&lt;/span&gt;   &lt;span class=&quot;code-comment&quot;&gt;// &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; someone does &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;, tack on the lowest possible trail surrogate.
&lt;/span&gt;   &lt;span class=&quot;code-comment&quot;&gt;// &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; emulates the old behavior, and forms &lt;span class=&quot;code-quote&quot;&gt;&quot;valid UTF-8&quot;&lt;/span&gt; unicode.
&lt;/span&gt;   &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (text.length() &amp;gt; 0 
      &amp;amp;&amp;amp; &lt;span class=&quot;code-object&quot;&gt;Character&lt;/span&gt;.isHighSurrogate(text.charAt(text.length() - 1)))
        tr = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; TermRef(t.text() + &lt;span class=&quot;code-quote&quot;&gt;&quot;\uDC00&quot;&lt;/span&gt;);
   &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt;
        tr = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; TermRef(t.text());
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;instead it could read something like tr = new TermRef(UnicodeUtil.nextValidUTF16String(t.text()));&lt;/p&gt;</comment>
                    <comment id="12786582" author="mikemccand" created="Sun, 6 Dec 2009 09:03:40 +0000"  >&lt;blockquote&gt;&lt;p&gt;one thing we could do is put this nextValidUTF16String in UnicodeUtil and also use it in SegmentReader.LegacyTermEnum to replace the &quot;hack&quot;, just in case someone else wrote an enum like mine.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;+1&lt;/p&gt;</comment>
                    <comment id="12786616" author="rcmuir" created="Sun, 6 Dec 2009 13:34:16 +0000"  >&lt;p&gt;Mike I created &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-2121&quot; title=&quot;add UnicodeUtil.nextValidUTF16String &quot;&gt;&lt;del&gt;LUCENE-2121&lt;/del&gt;&lt;/a&gt; for this.&lt;br/&gt;
If you get a chance to review it, I can create a new version of the flex branch patch for this issue... this would resolve one of my &quot;big 3 complaints&quot; about complexity of the code.&lt;/p&gt;</comment>
                    <comment id="12786652" author="rcmuir" created="Sun, 6 Dec 2009 17:17:38 +0000"  >&lt;p&gt;Setting this issue as depending on &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-2111&quot; title=&quot;Wrapup flexible indexing&quot;&gt;&lt;del&gt;LUCENE-2111&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This is because I do not feel comfortable committing this code in trunk, it is too complicated there.&lt;br/&gt;
Instead I would like simply work it against the flex branch where we can make it nice&lt;/p&gt;</comment>
                    <comment id="12786726" author="rcmuir" created="Sun, 6 Dec 2009 22:29:03 +0000"  >&lt;p&gt;latest flex patch, after &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-2110&quot; title=&quot;Refactoring of FilteredTermsEnum and MultiTermQuery&quot;&gt;&lt;del&gt;LUCENE-2110&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-2121&quot; title=&quot;add UnicodeUtil.nextValidUTF16String &quot;&gt;&lt;del&gt;LUCENE-2121&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                    <comment id="12786729" author="rcmuir" created="Sun, 6 Dec 2009 22:47:26 +0000"  >&lt;p&gt;the current wildcardquery has getTerm(), this is needed for bw compat. I added it.&lt;/p&gt;</comment>
                    <comment id="12786927" author="rcmuir" created="Mon, 7 Dec 2009 14:34:29 +0000"  >&lt;p&gt;this is an update to improve performance for lots of seeking (wildcards like ?????NN, crazy regular expressions, fuzzy)&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;expose State.getNumber() as an expert method. this returns the consecutive integer of the state in the automaton.&lt;/li&gt;
	&lt;li&gt;(re)use a bitset for tracking &apos;visited&apos; instead of creating a hashset for each seek&lt;/li&gt;
	&lt;li&gt;use an array indexed by state number for caching transitions, instead of a hashmap.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12787042" author="rcmuir" created="Mon, 7 Dec 2009 18:42:26 +0000"  >&lt;p&gt;this builds off the last improvement, and uses RunAutomaton (the tablelized DFA) for nextString.&lt;/p&gt;

&lt;p&gt;this means parts of nextString are now O&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/thumbs_down.gif&quot; height=&quot;19&quot; width=&quot;19&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; where n is number of states, instead of transitions.&lt;br/&gt;
doesn&apos;t mean much for wildcard as these DFAs typically do not have many transitions per state, but for more complex DFAs such as regexp/wildcard this helps... and it simplifies code.&lt;/p&gt;</comment>
                    <comment id="12787163" author="rcmuir" created="Mon, 7 Dec 2009 22:20:41 +0000"  >&lt;p&gt;here i removed the use of String in the enum.&lt;br/&gt;
this seems to help a bit when seeking.&lt;/p&gt;

&lt;p&gt;instead a char[] is reused, and nextString() etc returns boolean if more solutions exist.&lt;br/&gt;
I think its actually more readable in a way, need to reorganize a bit more but I need a break from this enum.&lt;/p&gt;</comment>
                    <comment id="12787405" author="thetaphi" created="Tue, 8 Dec 2009 10:50:51 +0000"  >&lt;p&gt;I updated the patch because of my last commit.&lt;br/&gt;
Your&apos;s looks good, my change was only adding the method param and removing the access to the noew private tenum.&lt;/p&gt;</comment>
                    <comment id="12787602" author="rcmuir" created="Tue, 8 Dec 2009 18:00:26 +0000"  >&lt;p&gt;So what do you guys think? I am pretty satisfied with how this enum looks in flex branch myself.&lt;/p&gt;

&lt;p&gt;I think it would be nice to start looking at committing this to flex so we do not have to work with huge patches?&lt;/p&gt;

&lt;p&gt;If there are reservations please speak up, I think the automaton code imported here is solid, and if you run clover you will see our testcases exercise the important bits (not .toString or .toDot &amp;lt;graphviz&amp;gt; or other things, but those work too).&lt;/p&gt;

&lt;p&gt;If you have concerns or think it is confusing, i will do my best to try to figure out ways to simplify or improve it from here.&lt;/p&gt;</comment>
                    <comment id="12787653" author="mikemccand" created="Tue, 8 Dec 2009 18:57:01 +0000"  >&lt;blockquote&gt;&lt;p&gt;I think it would be nice to start looking at committing this to flex so we do not have to work with huge patches?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;+1&lt;/p&gt;</comment>
                    <comment id="12787685" author="rcmuir" created="Tue, 8 Dec 2009 19:28:37 +0000"  >&lt;p&gt;Ok, if no one objects I will (heavy) commit this to the flex branch tomorrow.&lt;/p&gt;

&lt;p&gt;The only differences from Uwe&apos;s patch will be:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;ensure the barred-O (&#248;) is corrrect in Anders name for the NOTICE.txt&lt;/li&gt;
	&lt;li&gt;remove the unused instance variable in the enum, as it is unused and irrelevant for FilteredTermsEnum&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12788188" author="rcmuir" created="Wed, 9 Dec 2009 17:46:34 +0000"  >&lt;p&gt;Committed revision 888891.&lt;/p&gt;</comment>
                    <comment id="12788189" author="rcmuir" created="Wed, 9 Dec 2009 17:53:49 +0000"  >&lt;p&gt;btw, Thanks to Uwe, Mike, Mark for all the help here!&lt;/p&gt;</comment>
                </comments>
                <issuelinks>
                        <issuelinktype id="10030">
                <name>Reference</name>
                                                <inwardlinks description="is related to">
                            <issuelink>
            <issuekey id="12442399">LUCENE-2110</issuekey>
        </issuelink>
                    </inwardlinks>
                            </issuelinktype>
                        <issuelinktype id="10001">
                <name>dependent</name>
                                <outwardlinks description="depends upon">
                            <issuelink>
            <issuekey id="12442406">LUCENE-2111</issuekey>
        </issuelink>
                    </outwardlinks>
                                                <inwardlinks description="is depended upon by">
                            <issuelink>
            <issuekey id="12441407">LUCENE-2090</issuekey>
        </issuelink>
                    </inwardlinks>
                            </issuelinktype>
                    </issuelinks>
                <attachments>
                    <attachment id="12405882" name="automatonmultiqueryfuzzy.patch" size="47792" author="rcmuir" created="Sun, 19 Apr 2009 22:36:43 +0100" />
                    <attachment id="12405828" name="automatonMultiQuery.patch" size="34470" author="rcmuir" created="Sat, 18 Apr 2009 01:24:27 +0100" />
                    <attachment id="12405860" name="automatonMultiQuerySmart.patch" size="35919" author="rcmuir" created="Sun, 19 Apr 2009 06:43:54 +0100" />
                    <attachment id="12405633" name="automaton.patch" size="19348" author="rcmuir" created="Thu, 16 Apr 2009 09:48:07 +0100" />
                    <attachment id="12405641" name="automatonWithWildCard2.patch" size="36791" author="rcmuir" created="Thu, 16 Apr 2009 12:43:26 +0100" />
                    <attachment id="12405639" name="automatonWithWildCard.patch" size="36567" author="rcmuir" created="Thu, 16 Apr 2009 12:24:14 +0100" />
                    <attachment id="12425732" name="BenchWildcard.java" size="3839" author="rcmuir" created="Sat, 21 Nov 2009 18:20:15 +0000" />
                    <attachment id="12427323" name="LUCENE-1606-flex.patch" size="215833" author="thetaphi" created="Tue, 8 Dec 2009 10:50:51 +0000" />
                    <attachment id="12427245" name="LUCENE-1606-flex.patch" size="221055" author="rcmuir" created="Mon, 7 Dec 2009 22:20:41 +0000" />
                    <attachment id="12427210" name="LUCENE-1606-flex.patch" size="216997" author="rcmuir" created="Mon, 7 Dec 2009 18:42:26 +0000" />
                    <attachment id="12427180" name="LUCENE-1606-flex.patch" size="217349" author="rcmuir" created="Mon, 7 Dec 2009 14:34:29 +0000" />
                    <attachment id="12427115" name="LUCENE-1606-flex.patch" size="217716" author="rcmuir" created="Sun, 6 Dec 2009 22:47:26 +0000" />
                    <attachment id="12427114" name="LUCENE-1606-flex.patch" size="217731" author="rcmuir" created="Sun, 6 Dec 2009 22:29:03 +0000" />
                    <attachment id="12427068" name="LUCENE-1606-flex.patch" size="235497" author="thetaphi" created="Sat, 5 Dec 2009 20:59:23 +0000" />
                    <attachment id="12427063" name="LUCENE-1606-flex.patch" size="282371" author="thetaphi" created="Sat, 5 Dec 2009 20:19:52 +0000" />
                    <attachment id="12427051" name="LUCENE-1606-flex.patch" size="282246" author="thetaphi" created="Sat, 5 Dec 2009 15:15:55 +0000" />
                    <attachment id="12426928" name="LUCENE-1606-flex.patch" size="239163" author="rcmuir" created="Fri, 4 Dec 2009 18:12:00 +0000" />
                    <attachment id="12425783" name="LUCENE-1606-flex.patch" size="217568" author="rcmuir" created="Sun, 22 Nov 2009 23:37:46 +0000" />
                    <attachment id="12425764" name="LUCENE-1606-flex.patch" size="202033" author="mikemccand" created="Sun, 22 Nov 2009 18:17:23 +0000" />
                    <attachment id="12425621" name="LUCENE-1606_nodep.patch" size="199046" author="rcmuir" created="Fri, 20 Nov 2009 16:18:26 +0000" />
                    <attachment id="12427088" name="LUCENE-1606.patch" size="218494" author="rcmuir" created="Sun, 6 Dec 2009 03:02:31 +0000" />
                    <attachment id="12427087" name="LUCENE-1606.patch" size="218216" author="rcmuir" created="Sun, 6 Dec 2009 02:43:50 +0000" />
                    <attachment id="12426905" name="LUCENE-1606.patch" size="219249" author="rcmuir" created="Fri, 4 Dec 2009 14:51:33 +0000" />
                    <attachment id="12426707" name="LUCENE-1606.patch" size="208807" author="rcmuir" created="Wed, 2 Dec 2009 22:20:28 +0000" />
                    <attachment id="12426027" name="LUCENE-1606.patch" size="216553" author="rcmuir" created="Tue, 24 Nov 2009 22:20:28 +0000" />
                    <attachment id="12425994" name="LUCENE-1606.patch" size="216254" author="rcmuir" created="Tue, 24 Nov 2009 18:45:26 +0000" />
                    <attachment id="12425956" name="LUCENE-1606.patch" size="212801" author="rcmuir" created="Tue, 24 Nov 2009 12:26:47 +0000" />
                    <attachment id="12425729" name="LUCENE-1606.patch" size="203129" author="rcmuir" created="Sat, 21 Nov 2009 17:41:40 +0000" />
                    <attachment id="12425725" name="LUCENE-1606.patch" size="203115" author="rcmuir" created="Sat, 21 Nov 2009 15:22:20 +0000" />
                    <attachment id="12425718" name="LUCENE-1606.patch" size="204391" author="thetaphi" created="Sat, 21 Nov 2009 12:38:41 +0000" />
                    <attachment id="12425714" name="LUCENE-1606.patch" size="203732" author="thetaphi" created="Sat, 21 Nov 2009 12:25:20 +0000" />
                    <attachment id="12425690" name="LUCENE-1606.patch" size="202561" author="thetaphi" created="Sat, 21 Nov 2009 00:55:43 +0000" />
                    <attachment id="12425652" name="LUCENE-1606.patch" size="196988" author="rcmuir" created="Fri, 20 Nov 2009 19:20:02 +0000" />
                    <attachment id="12422004" name="LUCENE-1606.patch" size="59057" author="rcmuir" created="Tue, 13 Oct 2009 19:17:17 +0100" />
                    <attachment id="12406682" name="LUCENE-1606.patch" size="48446" author="rcmuir" created="Tue, 28 Apr 2009 19:55:46 +0100" />
                </attachments>
            <subtasks>
        </subtasks>
                <customfields>
                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                <customfieldname>Attachment count</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>35.0</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                <customfieldname>Date of First Response</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>Thu, 16 Apr 2009 11:42:02 +0000</customfieldvalue>

                </customfieldvalues>
            </customfield>
                                                                                                        <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Global Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>12149</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                <customfieldname>Lucene Fields</customfieldname>
                <customfieldvalues>
                        <customfieldvalue key="10121"><![CDATA[New]]></customfieldvalue>
    <customfieldvalue key="10120"><![CDATA[Patch Available]]></customfieldvalue>
    
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>26122</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                <customfieldname>Time in Status</customfieldname>
                <customfieldvalues>
                    
                </customfieldvalues>
            </customfield>
                            </customfields>
    </item>
</channel>
</rss>