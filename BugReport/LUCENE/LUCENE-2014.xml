<!-- 
RSS generated by JIRA (5.2.8#851-sha1:3262fdc28b4bc8b23784e13eadc26a22399f5d88) at Tue Jul 16 13:03:35 UTC 2013

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/LUCENE-2014/LUCENE-2014.xml?field=key&field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>5.2.8</version>
        <build-number>851</build-number>
        <build-date>26-02-2013</build-date>
    </build-info>

<item>
            <title>[LUCENE-2014] position increment bug: smartcn</title>
                <link>https://issues.apache.org/jira/browse/LUCENE-2014</link>
                <project id="12310110" key="LUCENE">Lucene - Core</project>
                        <description>&lt;p&gt;If i use LUCENE_VERSION &amp;gt;= 2.9 with smart chinese analyzer, it will crash indexwriter with any reasonable amount of chinese text.&lt;/p&gt;

&lt;p&gt;its especially annoying because it happens in 2.9.1 RC as well.&lt;/p&gt;

&lt;p&gt;this is because the position increments for tokens after stopwords are bogus:&lt;/p&gt;

&lt;p&gt;Here&apos;s an example (from test case), where the position increment should be 2, but is instead 91975314!&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void testChineseStopWords2() &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; Exception {
    Analyzer ca = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; SmartChineseAnalyzer(Version.LUCENE_CURRENT); /* will load stopwords */
    &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; sentence = &lt;span class=&quot;code-quote&quot;&gt;&quot;Title:San&quot;&lt;/span&gt;; &lt;span class=&quot;code-comment&quot;&gt;// : is a stopword
&lt;/span&gt;    &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; result[] = { &lt;span class=&quot;code-quote&quot;&gt;&quot;titl&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;san&quot;&lt;/span&gt;};
    &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; startOffsets[] = { 0, 6 };
    &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; endOffsets[] = { 5, 9 };
    &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; posIncr[] = { 1, 2 };
    assertAnalyzesTo(ca, sentence, result, startOffsets, endOffsets, posIncr);
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;junit.framework.AssertionFailedError: posIncrement 1 expected:&amp;lt;2&amp;gt; but was:&amp;lt;91975314&amp;gt;&lt;br/&gt;
	at junit.framework.Assert.fail(Assert.java:47)&lt;br/&gt;
	at junit.framework.Assert.failNotEquals(Assert.java:280)&lt;br/&gt;
	at junit.framework.Assert.assertEquals(Assert.java:64)&lt;br/&gt;
	at junit.framework.Assert.assertEquals(Assert.java:198)&lt;br/&gt;
	at org.apache.lucene.analysis.BaseTokenStreamTestCase.assertTokenStreamContents(BaseTokenStreamTestCase.java:83)&lt;br/&gt;
	...&lt;/p&gt;



</description>
                <environment></environment>
            <key id="12439379">LUCENE-2014</key>
            <summary>position increment bug: smartcn</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                    <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png">Closed</status>
                    <resolution id="1">Fixed</resolution>
                                <assignee username="rcmuir">Robert Muir</assignee>
                                <reporter username="rcmuir">Robert Muir</reporter>
                        <labels>
                    </labels>
                <created>Thu, 29 Oct 2009 08:03:43 +0000</created>
                <updated>Mon, 16 May 2011 19:15:34 +0100</updated>
                    <resolved>Thu, 29 Oct 2009 09:58:22 +0000</resolved>
                                            <fixVersion>3.0</fixVersion>
                                <component>modules/analysis</component>
                        <due></due>
                    <votes>0</votes>
                        <watches>0</watches>
                                                    <comments>
                    <comment id="12771321" author="rcmuir" created="Thu, 29 Oct 2009 08:04:56 +0000"  >&lt;p&gt;this patch only contains a testcase demonstrating the problem.&lt;/p&gt;</comment>
                    <comment id="12771322" author="thetaphi" created="Thu, 29 Oct 2009 08:08:58 +0000"  >&lt;p&gt;Maybe we should use now BaseTokenStreamTestcase (which now no longer uses old/new TS API) to now test all Version constants, which is easy in 3.0 (because it&apos;s enum now) and you can iterate using for(Version v : Version.values()).&lt;/p&gt;

&lt;p&gt;I proposed this already for Highlighter (see other issue).&lt;/p&gt;

&lt;p&gt;Is it a problem in StopWordFilter?&lt;/p&gt;</comment>
                    <comment id="12771323" author="rcmuir" created="Thu, 29 Oct 2009 08:10:35 +0000"  >&lt;blockquote&gt;
&lt;p&gt;Is it a problem in StopWordFilter?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don&apos;t really know where it is to tell you the truth... i spent a little time trying to create an english testcase for StopFilter, but couldn&apos;t reproduce it there.&lt;/p&gt;

&lt;p&gt;smartcn doesn&apos;t even touch position increment attributes, so its really wierd...&lt;/p&gt;</comment>
                    <comment id="12771327" author="thetaphi" created="Thu, 29 Oct 2009 08:21:36 +0000"  >&lt;p&gt;I do not see the problem, from StopFilter:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
@Override
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; incrementToken() &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
  &lt;span class=&quot;code-comment&quot;&gt;// &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; the first non-stop word found
&lt;/span&gt;  &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; skippedPositions = 0;
  &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; (input.incrementToken()) {
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (!stopWords.contains(termAtt.termBuffer(), 0, termAtt.termLength())) {
      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (enablePositionIncrements) {
        posIncrAtt.setPositionIncrement(posIncrAtt.getPositionIncrement() + skippedPositions);
      }
      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;;
    }
    skippedPositions += posIncrAtt.getPositionIncrement();
  }
  &lt;span class=&quot;code-comment&quot;&gt;// reached EOS -- &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
&lt;/span&gt;  &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;;
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The problem can only be that the input filter returned some big posIncr for the stop word. The code seems very clear to me. Let&apos;s debug &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="12771329" author="rcmuir" created="Thu, 29 Oct 2009 08:26:37 +0000"  >&lt;p&gt;Uwe, check this out.&lt;/p&gt;

&lt;p&gt;smartcn doesn&apos;t use PositionIncrementAttribute, but its tokenizer does call clearAttributes() as it should.&lt;/p&gt;

&lt;p&gt;but if I modify WordTokenFilter to set the positionincrement to 1:&lt;br/&gt;
posIncAtt = addAttribute(PositionIncrementAttribute.class);&lt;br/&gt;
...&lt;br/&gt;
posIncAtt.setPositionIncrement(1);&lt;/p&gt;

&lt;p&gt;then the test passes... basically uninitialized variable problem... but smartcn shouldnt have to do this, right?&lt;/p&gt;</comment>
                    <comment id="12771331" author="thetaphi" created="Thu, 29 Oct 2009 08:29:38 +0000"  >&lt;p&gt;Hm hm&lt;br/&gt;
But the StopFilter also adds the attribute and therefore the clearAttributes call should clear it.&lt;/p&gt;

&lt;p&gt;I&apos;ll look into it.&lt;/p&gt;</comment>
                    <comment id="12771332" author="rcmuir" created="Thu, 29 Oct 2009 08:30:00 +0000"  >&lt;p&gt;duh, this is the problem Uwe.&lt;/p&gt;

&lt;p&gt;WordTokenFilter is like a source of tokens, even though it is not a tokenizer.&lt;/p&gt;

&lt;p&gt;this is because smartcn&apos;s tokenizer just breaks out sentences.... WordTokenFilter breaks these into words.&lt;/p&gt;

&lt;p&gt; so i think WordTokenFilter must call clearAttributes()... ?&lt;/p&gt;</comment>
                    <comment id="12771334" author="rcmuir" created="Thu, 29 Oct 2009 08:33:35 +0000"  >&lt;p&gt;this patch adds clearAttributes to chinese WordTokenFilter, fixes the issue.&lt;/p&gt;</comment>
                    <comment id="12771335" author="thetaphi" created="Thu, 29 Oct 2009 08:37:45 +0000"  >&lt;p&gt;This is the problem, you are right. I thought about that, too.&lt;/p&gt;

&lt;p&gt;The question is, why does the PosIncr get such strange values even when the filter is source of tokens? Nobody else modifies it?&lt;/p&gt;</comment>
                    <comment id="12771336" author="rcmuir" created="Thu, 29 Oct 2009 08:42:46 +0000"  >&lt;p&gt;Uwe, yeah the only thing modifying it should be StopFilter... so I can see the values being &quot;kinda strange&quot; but not as wierd as what I see.&lt;/p&gt;

&lt;p&gt;i worry about this clearAttributes solution though, perhaps WordTokenFilter should use captureState/restoreState api, like the ThaiWordFilter does (very similar analyzer).&lt;br/&gt;
If i use capture/restoreState this should not be a problem right?&lt;/p&gt;

&lt;p&gt;And this way things like custom attributes would be preserved?&lt;/p&gt;</comment>
                    <comment id="12771338" author="thetaphi" created="Thu, 29 Oct 2009 08:57:27 +0000"  >&lt;p&gt;Hihi, I know where the strange values come from: It is the test in BaseTokenStreamTestCase itsself, that does it to check for missing clearAttributes, see assertTokenStreamContents.... It sets all Attributes to bogus values before calling incrementToken. If you do not clear the attributes, the bogus values stay there.&lt;/p&gt;

&lt;p&gt;But the question is, why does IndexWriter fail (how does it fail?). Normally it should not be affected, as the posIncr stays 1.&lt;/p&gt;</comment>
                    <comment id="12771339" author="rcmuir" created="Thu, 29 Oct 2009 08:57:50 +0000"  >&lt;blockquote&gt;&lt;p&gt;Maybe we should use now BaseTokenStreamTestcase (which now no longer uses old/new TS API) to now test all Version constants, which is easy in 3.0 (because it&apos;s enum now) and you can iterate using for(Version v : Version.values()). &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;this might be a good idea, although the behavior of the analyzer could change depending upon Version. Maybe best to actually test the different possibilities explicitly?&lt;/p&gt;

&lt;p&gt;I think after this one is resolved, i will open a task as a first step to improve the tests of these analyzers to test posInc as well, because I don&apos;t see it tested for similar cases like Thai. &lt;/p&gt;</comment>
                    <comment id="12771341" author="rcmuir" created="Thu, 29 Oct 2009 08:59:17 +0000"  >&lt;blockquote&gt;&lt;p&gt;But the question is, why does IndexWriter fail (how does it fail?). Normally it should not be affected, as the posIncr stays 1.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Oh, the IndexWriter fails because of integer overflow with any large document (lots of posIncr&apos;s get added up, overflow and create a negative posIncr)&lt;br/&gt;
so the negative posIncr creates an exception.&lt;/p&gt;

&lt;p&gt;&amp;lt;edit&amp;gt;&lt;/p&gt;

&lt;p&gt;Uwe I think this really happens especially because of the way smartcn works. &lt;br/&gt;
smartcn creates individual tokens for each piece of punctuation (including things like whitespace), and puts these in the stopword list.&lt;br/&gt;
so if you have a chinese document with lots of space ... you can imagine how it can add up and overflow.&lt;/p&gt;</comment>
                    <comment id="12771342" author="thetaphi" created="Thu, 29 Oct 2009 09:04:55 +0000"  >&lt;p&gt;Ah understand, because nobody resets the posinc to 1 back, it adds up in a 2^n manner. stop filter updates to 2, because stop word. After that nobody resets to 1 back, so it gets 2, 4, 8,... b&#228;ng if more stopwords occur.&lt;/p&gt;</comment>
                    <comment id="12771343" author="rcmuir" created="Thu, 29 Oct 2009 09:07:22 +0000"  >&lt;p&gt;Uwe exactly. so only remaining question is, do you think I should change this filter to use capture/restoreState api instead of using clearAttributes?&lt;/p&gt;

&lt;p&gt;I guess the only advantage would be that it would preserve any customAttributes or payloads that someone might add after the SentenceTokenizer, but before the WordTokenFilter propagating them downto the individual words.&lt;/p&gt;</comment>
                    <comment id="12771344" author="thetaphi" created="Thu, 29 Oct 2009 09:07:42 +0000"  >&lt;blockquote&gt;&lt;p&gt;i worry about this clearAttributes solution though, perhaps WordTokenFilter should use captureState/restoreState api, like the ThaiWordFilter does (very similar analyzer).&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;If i use capture/restoreState this should not be a problem right?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think the filter is fine how it is at the moment. The problem is only the missing clearAttributes when you produce more than one token out of one big one (the sentence). No need for captureState, because the tokens are new ones. If somebody adds custom attributes, they would have cleared, but would that be not correct?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I guess the only advantage would be that it would preserve any customAttributes or payloads that someone might add after the SentenceTokenizer, but before the WordTokenFilter propagating them downto the individual words.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Does this make sense to insert a filter between both? The transition from sentence tokens to word tokens creates totally different tokens, how should a payload or other custom att work correct here? Normally such payload filters should be inserted after the WordFilter. The problem of capture/restore state is addiional copy cost for nothing (the &lt;b&gt;long&lt;/b&gt; sentence token is copied again and again and always reset to the text word).&lt;/p&gt;</comment>
                    <comment id="12771345" author="rcmuir" created="Thu, 29 Oct 2009 09:09:16 +0000"  >&lt;blockquote&gt;&lt;p&gt;I think the filter is fine how it is at the moment. The problem is only the missing clearAttributes when you produce more than one token out of one big one (the sentence). No need for captureState, because the tokens are new ones. If somebody adds custom attributes, they would have cleared, but would that be not correct?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;not really sure, thats why I asked you &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;I guess for now, its good enough to fix it to not crash IndexWriter.&lt;/p&gt;

&lt;p&gt;I will commit soon.&lt;/p&gt;</comment>
                    <comment id="12771347" author="thetaphi" created="Thu, 29 Oct 2009 09:12:18 +0000"  >&lt;blockquote&gt;&lt;p&gt;I will commit soon.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;+1&lt;/p&gt;

&lt;p&gt;And how about 2.9.1?&lt;/p&gt;</comment>
                    <comment id="12771350" author="rcmuir" created="Thu, 29 Oct 2009 09:16:00 +0000"  >&lt;blockquote&gt;&lt;p&gt;And how about 2.9.1?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I will upload and test a patch against 2.9 branch (can you commit it for me?)&lt;/p&gt;</comment>
                    <comment id="12771351" author="thetaphi" created="Thu, 29 Oct 2009 09:17:27 +0000"  >&lt;p&gt;ok.&lt;/p&gt;</comment>
                    <comment id="12771353" author="rcmuir" created="Thu, 29 Oct 2009 09:23:18 +0000"  >&lt;p&gt;Committed revision 830871 to trunk.&lt;/p&gt;

&lt;p&gt;I will test this against 2.9 and upload a patch.&lt;/p&gt;

&lt;p&gt;Thanks for your help Uwe.&lt;/p&gt;</comment>
                    <comment id="12771355" author="thetaphi" created="Thu, 29 Oct 2009 09:24:49 +0000"  >&lt;p&gt;No prob. I also forgot about the bogus values set by BaseTokenStreamTestcase.... But there is no possibility to test/document this in a good way.&lt;/p&gt;</comment>
                    <comment id="12771359" author="rcmuir" created="Thu, 29 Oct 2009 09:36:11 +0000"  >&lt;p&gt;patch against 2.9 branch&lt;/p&gt;</comment>
                    <comment id="12771360" author="mikemccand" created="Thu, 29 Oct 2009 09:36:58 +0000"  >&lt;p&gt;Guys, how serious is this issue?  Should we respin 2.9.1?&lt;/p&gt;</comment>
                    <comment id="12771362" author="thetaphi" created="Thu, 29 Oct 2009 09:38:31 +0000"  >&lt;p&gt;I merged your changes into 2.9. I can commit, no need for a patch!&lt;/p&gt;</comment>
                    <comment id="12771363" author="rcmuir" created="Thu, 29 Oct 2009 09:38:31 +0000"  >&lt;p&gt;Mike, its up to you.&lt;/p&gt;

&lt;p&gt;I was just analyzing some not-ridiculously-large Chinese texts from Gutenberg, when I hit the issue.&lt;/p&gt;

&lt;p&gt;The problem is that smartcn indexes punctuation as individual tokens, but filters them out with StopFilter (its stopword list is all punctuation).&lt;br/&gt;
This means it makes heavy use of stopfilter, compared to other analyzers.&lt;/p&gt;</comment>
                    <comment id="12771364" author="thetaphi" created="Thu, 29 Oct 2009 09:43:37 +0000"  >&lt;p&gt;I also merged the BaseTokenStreamTestcase back, because the bogus values setter was missing in 2.9. Now the tests produce same results.&lt;/p&gt;

&lt;p&gt;Will commit soon.&lt;/p&gt;</comment>
                    <comment id="12771365" author="rcmuir" created="Thu, 29 Oct 2009 09:48:58 +0000"  >&lt;blockquote&gt;&lt;p&gt;I also merged the BaseTokenStreamTestcase back, because the bogus values setter was missing in 2.9. Now the tests produce same results. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;good deal... i didnt test the bug with the JUnit test against 2.9, but my IndexWriter threw the exception if i used Version.LUCENE_29 (with the RC2 jars), so i knew it was affected.&lt;/p&gt;</comment>
                    <comment id="12771367" author="thetaphi" created="Thu, 29 Oct 2009 09:56:01 +0000"  >&lt;p&gt;Committed in 2.9, revision: 830876&lt;/p&gt;

&lt;p&gt;I think you can close the issue. We should ask Mike, to create a new RC, then we also have the other bug fixed in 2.9 (I resolved yesterday). Mike then only have to move the CHANGES entries down to 2.9.1 in contrib/CHANGES.txt&lt;/p&gt;

&lt;p&gt;The other problem still in 2.9 is the default for posincr in StopFilter is version is &amp;lt;2.9, which is now always false for StandardAnalyzer-no-argctor and others.&lt;/p&gt;</comment>
                    <comment id="12771368" author="rcmuir" created="Thu, 29 Oct 2009 09:58:22 +0000"  >&lt;p&gt;thanks again Uwe&lt;/p&gt;</comment>
                    <comment id="12771473" author="rcmuir" created="Thu, 29 Oct 2009 16:50:13 +0000"  >&lt;blockquote&gt;
&lt;p&gt;Does this make sense to insert a filter between both? The transition from sentence tokens to word tokens creates totally different tokens, how should a payload or other custom att work correct here? Normally such payload filters should be inserted after the WordFilter. The problem of capture/restore state is addiional copy cost for nothing (the long sentence token is copied again and again and always reset to the text word).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I could imagine a use case where a person wants to keep the sentence information intact (perhaps to improve retrieval accuracy or maybe just restrict phrase queries to match within sentences).&lt;br/&gt;
But I guess to some extent, the chinese phrasequery works pretty intelligently already with &amp;gt;= Version.LUCENE_29 because punctuation is a stopword, and the position increments are adjusted.&lt;/p&gt;

&lt;p&gt;I agree about the expensive cost though... best to leave it for now. But this is the way the Thai analyzer works.&lt;/p&gt;</comment>
                </comments>
                    <attachments>
                    <attachment id="12423565" name="LUCENE-2014_branch.patch" size="3032" author="rcmuir" created="Thu, 29 Oct 2009 09:36:11 +0000" />
                    <attachment id="12423560" name="LUCENE-2014.patch" size="1824" author="rcmuir" created="Thu, 29 Oct 2009 08:33:35 +0000" />
                    <attachment id="12423556" name="LUCENE-2014.patch" size="1086" author="rcmuir" created="Thu, 29 Oct 2009 08:04:56 +0000" />
                </attachments>
            <subtasks>
        </subtasks>
                <customfields>
                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                <customfieldname>Attachment count</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>3.0</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                <customfieldname>Date of First Response</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>Thu, 29 Oct 2009 08:08:58 +0000</customfieldvalue>

                </customfieldvalues>
            </customfield>
                                                                                                        <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Global Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>11759</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                <customfieldname>Lucene Fields</customfieldname>
                <customfieldvalues>
                        <customfieldvalue key="10121"><![CDATA[New]]></customfieldvalue>
    <customfieldvalue key="10120"><![CDATA[Patch Available]]></customfieldvalue>
    
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>25711</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                <customfieldname>Time in Status</customfieldname>
                <customfieldvalues>
                    
                </customfieldvalues>
            </customfield>
                            </customfields>
    </item>
</channel>
</rss>