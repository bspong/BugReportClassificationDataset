<!-- 
RSS generated by JIRA (5.2.8#851-sha1:3262fdc28b4bc8b23784e13eadc26a22399f5d88) at Tue Jul 16 13:10:09 UTC 2013

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/LUCENE-436/LUCENE-436.xml?field=key&field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>5.2.8</version>
        <build-number>851</build-number>
        <build-date>26-02-2013</build-date>
    </build-info>

<item>
            <title>[LUCENE-436] [PATCH] TermInfosReader, SegmentTermEnum Out Of Memory Exception</title>
                <link>https://issues.apache.org/jira/browse/LUCENE-436</link>
                <project id="12310110" key="LUCENE">Lucene - Core</project>
                        <description>&lt;p&gt;We&apos;ve been experiencing terrible memory problems on our production search server, running lucene (1.4.3).&lt;/p&gt;

&lt;p&gt;Our live app regularly opens new indexes and, in doing so, releases old IndexReaders for garbage collection.&lt;/p&gt;

&lt;p&gt;But...there appears to be a memory leak in org.apache.lucene.index.TermInfosReader.java.&lt;br/&gt;
Under certain conditions (possibly related to JVM version, although I&apos;ve personally observed it under both linux JVM 1.4.2_06, and 1.5.0_03, and SUNOS JVM 1.4.1) the ThreadLocal member variable, &quot;enumerators&quot; doesn&apos;t get garbage-collected when the TermInfosReader object is gc-ed.&lt;/p&gt;

&lt;p&gt;Looking at the code in TermInfosReader.java, there&apos;s no reason why it &lt;em&gt;shouldn&apos;t&lt;/em&gt; be gc-ed, so I can only presume (and I&apos;ve seen this suggested elsewhere) that there could be a bug in the garbage collector of some JVMs.&lt;/p&gt;

&lt;p&gt;I&apos;ve seen this problem briefly discussed; in particular at the following URL:&lt;br/&gt;
  &lt;a href=&quot;http://java2.5341.com/msg/85821.html&quot; class=&quot;external-link&quot;&gt;http://java2.5341.com/msg/85821.html&lt;/a&gt;&lt;br/&gt;
The patch that Doug recommended, which is included in lucene-1.4.3 doesn&apos;t work in our particular circumstances. Doug&apos;s patch only clears the ThreadLocal variable for the thread running the finalizer (my knowledge of java breaks down here - I&apos;m not sure which thread actually runs the finalizer). In our situation, the TermInfosReader is (potentially) used by more than one thread, meaning that Doug&apos;s patch &lt;em&gt;doesn&apos;t&lt;/em&gt; allow the affected JVMs to correctly collect garbage.&lt;/p&gt;

&lt;p&gt;So...I&apos;ve devised a simple patch which, from my observations on linux JVMs 1.4.2_06, and 1.5.0_03, fixes this problem.&lt;/p&gt;

&lt;p&gt;Kieran&lt;br/&gt;
PS Thanks to daniel naber for pointing me to jira/lucene&lt;/p&gt;

&lt;p&gt;@@ -19,6 +19,7 @@&lt;br/&gt;
 import java.io.IOException;&lt;/p&gt;

&lt;p&gt; import org.apache.lucene.store.Directory;&lt;br/&gt;
+import java.util.Hashtable;&lt;/p&gt;

&lt;p&gt; /** This stores a monotonically increasing set of &amp;lt;Term, TermInfo&amp;gt; pairs in a&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Directory.  Pairs are accessed either by Term or by ordinal position the&lt;br/&gt;
@@ -29,7 +30,7 @@&lt;br/&gt;
   private String segment;&lt;br/&gt;
   private FieldInfos fieldInfos;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private ThreadLocal enumerators = new ThreadLocal();&lt;br/&gt;
+  private final Hashtable enumeratorsByThread = new Hashtable();&lt;br/&gt;
   private SegmentTermEnum origEnum;&lt;br/&gt;
   private long size;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -60,10 +61,10 @@&lt;br/&gt;
   }&lt;/p&gt;

&lt;p&gt;   private SegmentTermEnum getEnum() {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;SegmentTermEnum termEnum = (SegmentTermEnum)enumerators.get();&lt;br/&gt;
+    SegmentTermEnum termEnum = (SegmentTermEnum)enumeratorsByThread.get(Thread.currentThread());&lt;br/&gt;
     if (termEnum == null) 
{
       termEnum = terms();
-      enumerators.set(termEnum);
+      enumeratorsByThread.put(Thread.currentThread(), termEnum);
     }
&lt;p&gt;     return termEnum;&lt;br/&gt;
   }&lt;br/&gt;
@@ -195,5 +196,15 @@&lt;br/&gt;
   public SegmentTermEnum terms(Term term) throws IOException &lt;/p&gt;
{
     get(term);
     return (SegmentTermEnum)getEnum().clone();
+  }
&lt;p&gt;+&lt;br/&gt;
+  /* some jvms might have trouble gc-ing enumeratorsByThread */&lt;br/&gt;
+  protected void finalize() throws Throwable &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+    try {
+        // make sure gc can clear up.
+        enumeratorsByThread.clear();
+    } finally {
+        super.finalize();
+    }   }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt; }&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;




&lt;p&gt;TermInfosReader.java, full source:&lt;br/&gt;
======================================&lt;br/&gt;
package org.apache.lucene.index;&lt;/p&gt;

&lt;p&gt;/**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Copyright 2004 The Apache Software Foundation&lt;br/&gt;
 *&lt;/li&gt;
	&lt;li&gt;Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);&lt;/li&gt;
	&lt;li&gt;you may not use this file except in compliance with the License.&lt;/li&gt;
	&lt;li&gt;You may obtain a copy of the License at&lt;br/&gt;
 *&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
 *&lt;/li&gt;
	&lt;li&gt;Unless required by applicable law or agreed to in writing, software&lt;/li&gt;
	&lt;li&gt;distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;/li&gt;
	&lt;li&gt;WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;/li&gt;
	&lt;li&gt;See the License for the specific language governing permissions and&lt;/li&gt;
	&lt;li&gt;limitations under the License.&lt;br/&gt;
 */&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;import java.io.IOException;&lt;/p&gt;

&lt;p&gt;import org.apache.lucene.store.Directory;&lt;br/&gt;
import java.util.Hashtable;&lt;/p&gt;

&lt;p&gt;/** This stores a monotonically increasing set of &amp;lt;Term, TermInfo&amp;gt; pairs in a&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Directory.  Pairs are accessed either by Term or by ordinal position the&lt;/li&gt;
	&lt;li&gt;set.  */&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;final class TermInfosReader {&lt;br/&gt;
  private Directory directory;&lt;br/&gt;
  private String segment;&lt;br/&gt;
  private FieldInfos fieldInfos;&lt;/p&gt;

&lt;p&gt;  private final Hashtable enumeratorsByThread = new Hashtable();&lt;br/&gt;
  private SegmentTermEnum origEnum;&lt;br/&gt;
  private long size;&lt;/p&gt;

&lt;p&gt;  TermInfosReader(Directory dir, String seg, FieldInfos fis)&lt;br/&gt;
       throws IOException &lt;/p&gt;
{
    directory = dir;
    segment = seg;
    fieldInfos = fis;

    origEnum = new SegmentTermEnum(directory.openFile(segment + &quot;.tis&quot;),
                                   fieldInfos, false);
    size = origEnum.size;
    readIndex();
  }

&lt;p&gt;  public int getSkipInterval() &lt;/p&gt;
{
    return origEnum.skipInterval;
  }

&lt;p&gt;  final void close() throws IOException &lt;/p&gt;
{
    if (origEnum != null)
      origEnum.close();
  }

&lt;p&gt;  /** Returns the number of term/value pairs in the set. */&lt;br/&gt;
  final long size() &lt;/p&gt;
{
    return size;
  }

&lt;p&gt;  private SegmentTermEnum getEnum() {&lt;br/&gt;
    SegmentTermEnum termEnum = (SegmentTermEnum)enumeratorsByThread.get(Thread.currentThread());&lt;br/&gt;
    if (termEnum == null) &lt;/p&gt;
{
      termEnum = terms();
      enumeratorsByThread.put(Thread.currentThread(), termEnum);
    }
&lt;p&gt;    return termEnum;&lt;br/&gt;
  }&lt;/p&gt;

&lt;p&gt;  Term[] indexTerms = null;&lt;br/&gt;
  TermInfo[] indexInfos;&lt;br/&gt;
  long[] indexPointers;&lt;/p&gt;

&lt;p&gt;  private final void readIndex() throws IOException {&lt;br/&gt;
    SegmentTermEnum indexEnum =&lt;br/&gt;
      new SegmentTermEnum(directory.openFile(segment + &quot;.tii&quot;),&lt;br/&gt;
			  fieldInfos, true);&lt;br/&gt;
    try {&lt;br/&gt;
      int indexSize = (int)indexEnum.size;&lt;/p&gt;

&lt;p&gt;      indexTerms = new Term&lt;span class=&quot;error&quot;&gt;&amp;#91;indexSize&amp;#93;&lt;/span&gt;;&lt;br/&gt;
      indexInfos = new TermInfo&lt;span class=&quot;error&quot;&gt;&amp;#91;indexSize&amp;#93;&lt;/span&gt;;&lt;br/&gt;
      indexPointers = new long&lt;span class=&quot;error&quot;&gt;&amp;#91;indexSize&amp;#93;&lt;/span&gt;;&lt;/p&gt;

&lt;p&gt;      for (int i = 0; indexEnum.next(); i++) &lt;/p&gt;
{
	indexTerms[i] = indexEnum.term();
	indexInfos[i] = indexEnum.termInfo();
	indexPointers[i] = indexEnum.indexPointer;
      }
&lt;p&gt;    } finally &lt;/p&gt;
{
      indexEnum.close();
    }
&lt;p&gt;  }&lt;/p&gt;

&lt;p&gt;  /** Returns the offset of the greatest index entry which is less than or equal to term.*/&lt;br/&gt;
  private final int getIndexOffset(Term term) throws IOException {&lt;br/&gt;
    int lo = 0;					  // binary search indexTerms[]&lt;br/&gt;
    int hi = indexTerms.length - 1;&lt;/p&gt;

&lt;p&gt;    while (hi &amp;gt;= lo) &lt;/p&gt;
{
      int mid = (lo + hi) &amp;gt;&amp;gt; 1;
      int delta = term.compareTo(indexTerms[mid]);
      if (delta &amp;lt; 0)
	hi = mid - 1;
      else if (delta &amp;gt; 0)
	lo = mid + 1;
      else
	return mid;
    }
&lt;p&gt;    return hi;&lt;br/&gt;
  }&lt;/p&gt;

&lt;p&gt;  private final void seekEnum(int indexOffset) throws IOException &lt;/p&gt;
{
    getEnum().seek(indexPointers[indexOffset],
	      (indexOffset * getEnum().indexInterval) - 1,
	      indexTerms[indexOffset], indexInfos[indexOffset]);
  }

&lt;p&gt;  /** Returns the TermInfo for a Term in the set, or null. */&lt;br/&gt;
  TermInfo get(Term term) throws IOException {&lt;br/&gt;
    if (size == 0) return null;&lt;/p&gt;

&lt;p&gt;    // optimize sequential access: first try scanning cached enum w/o seeking&lt;br/&gt;
    SegmentTermEnum enumerator = getEnum();&lt;br/&gt;
    if (enumerator.term() != null                 // term is at or past current&lt;br/&gt;
	&amp;amp;&amp;amp; ((enumerator.prev != null &amp;amp;&amp;amp; term.compareTo(enumerator.prev) &amp;gt; 0)&lt;/p&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; term.compareTo(enumerator.term()) &amp;gt;= 0)) 
{
      int enumOffset = (int)(enumerator.position/enumerator.indexInterval)+1;
      if (indexTerms.length == enumOffset	  // but before end of block
	  || term.compareTo(indexTerms[enumOffset]) &amp;lt; 0)
	return scanEnum(term);			  // no need to seek
    }&lt;/th&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;


&lt;p&gt;    // random-access: must seek&lt;br/&gt;
    seekEnum(getIndexOffset(term));&lt;br/&gt;
    return scanEnum(term);&lt;br/&gt;
  }&lt;/p&gt;

&lt;p&gt;  /** Scans within block for matching term. */&lt;br/&gt;
  private final TermInfo scanEnum(Term term) throws IOException {&lt;br/&gt;
    SegmentTermEnum enumerator = getEnum();&lt;br/&gt;
    while (term.compareTo(enumerator.term()) &amp;gt; 0 &amp;amp;&amp;amp; enumerator.next()) {}&lt;br/&gt;
    if (enumerator.term() != null &amp;amp;&amp;amp; term.compareTo(enumerator.term()) == 0)&lt;br/&gt;
      return enumerator.termInfo();&lt;br/&gt;
    else&lt;br/&gt;
      return null;&lt;br/&gt;
  }&lt;/p&gt;

&lt;p&gt;  /** Returns the nth term in the set. */&lt;br/&gt;
  final Term get(int position) throws IOException &lt;/p&gt;
{
    if (size == 0) return null;

    SegmentTermEnum enumerator = getEnum();
    if (enumerator != null &amp;amp;&amp;amp; enumerator.term() != null &amp;amp;&amp;amp;
        position &amp;gt;= enumerator.position &amp;amp;&amp;amp;
	position &amp;lt; (enumerator.position + enumerator.indexInterval))
      return scanEnum(position);		  // can avoid seek

    seekEnum(position / enumerator.indexInterval); // must seek
    return scanEnum(position);
  }

&lt;p&gt;  private final Term scanEnum(int position) throws IOException &lt;/p&gt;
{
    SegmentTermEnum enumerator = getEnum();
    while(enumerator.position &amp;lt; position)
      if (!enumerator.next())
	return null;

    return enumerator.term();
  }

&lt;p&gt;  /** Returns the position of a Term in the set or -1. */&lt;br/&gt;
  final long getPosition(Term term) throws IOException {&lt;br/&gt;
    if (size == 0) return -1;&lt;/p&gt;

&lt;p&gt;    int indexOffset = getIndexOffset(term);&lt;br/&gt;
    seekEnum(indexOffset);&lt;/p&gt;

&lt;p&gt;    SegmentTermEnum enumerator = getEnum();&lt;br/&gt;
    while(term.compareTo(enumerator.term()) &amp;gt; 0 &amp;amp;&amp;amp; enumerator.next()) {}&lt;/p&gt;

&lt;p&gt;    if (term.compareTo(enumerator.term()) == 0)&lt;br/&gt;
      return enumerator.position;&lt;br/&gt;
    else&lt;br/&gt;
      return -1;&lt;br/&gt;
  }&lt;/p&gt;

&lt;p&gt;  /** Returns an enumeration of all the Terms and TermInfos in the set. */&lt;br/&gt;
  public SegmentTermEnum terms() &lt;/p&gt;
{
    return (SegmentTermEnum)origEnum.clone();
  }

&lt;p&gt;  /** Returns an enumeration of terms starting at or after the named term. */&lt;br/&gt;
  public SegmentTermEnum terms(Term term) throws IOException &lt;/p&gt;
{
    get(term);
    return (SegmentTermEnum)getEnum().clone();
  }

&lt;p&gt;  /* some jvms might have trouble gc-ing enumeratorsByThread */ &lt;br/&gt;
  protected void finalize() throws Throwable {&lt;br/&gt;
    try &lt;/p&gt;
{
        // make sure gc can clear up.
        enumeratorsByThread.clear();
    }
&lt;p&gt; finally &lt;/p&gt;
{
        super.finalize();
    }
&lt;p&gt;  }&lt;br/&gt;
}&lt;/p&gt;</description>
                <environment>&lt;p&gt;Solaris JVM 1.4.1&lt;br/&gt;
Linux JVM 1.4.2/1.5.0&lt;br/&gt;
Windows not tested&lt;/p&gt;</environment>
            <key id="12317174">LUCENE-436</key>
            <summary>[PATCH] TermInfosReader, SegmentTermEnum Out Of Memory Exception</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                    <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png">Resolved</status>
                    <resolution id="1">Fixed</resolution>
                                <assignee username="otis">Otis Gospodnetic</assignee>
                                <reporter username="ktopping">kieran</reporter>
                        <labels>
                    </labels>
                <created>Thu, 22 Sep 2005 01:40:29 +0100</created>
                <updated>Wed, 20 Dec 2006 20:28:16 +0000</updated>
                    <resolved>Wed, 20 Dec 2006 20:28:16 +0000</resolved>
                            <version>1.4</version>
                                                <component>core/index</component>
                        <due></due>
                    <votes>4</votes>
                        <watches>6</watches>
                                                    <comments>
                    <comment id="12362382" author="fmar" created="Wed, 11 Jan 2006 07:28:38 +0000"  >&lt;p&gt;I&apos;m also having memory leaking when doing simple Searches using lucene CVS checkout from 2006-01-10&lt;br/&gt;
I&apos;m using jrockit-jdk1.5.0_03.&lt;/p&gt;

&lt;p&gt;I&apos;ve tried with this patch, and my simple search test STOPPED leaking.&lt;br/&gt;
Maybe it does depend on the JVM version.&lt;br/&gt;
I&apos;ll try on our application this patch to see if it stops leaking.&lt;/p&gt;
</comment>
                    <comment id="12377238" author="nshupe" created="Tue, 2 May 2006 00:15:34 +0100"  >&lt;p&gt;I will be trying this patch on Lucene 1.9.1 to see if it fixes my production memory leak with Tomcat 5.5.15 / Redhat / Java 1.5.0_06.&lt;/p&gt;</comment>
                    <comment id="12377242" author="rengels@tylertechinc.com" created="Tue, 2 May 2006 00:37:29 +0100"  >&lt;p&gt;The bug is invalid, as was pointed out on the lucene-dev list.&lt;/p&gt;

&lt;p&gt;When the thread dies, all thread locals will be cleaned-up.&lt;/p&gt;

&lt;p&gt;If the thread does not die, the thread-locals are still cleaned-up PERIODICALLY. And the value is always cleaned up - since it is held in a WeakReference, the only things that &quot;hangs around&quot; is the key - which consumes VERYL LITTLE memory.&lt;/p&gt;

&lt;p&gt;The submitter should be able to provide a testcase that demonstrate the ThreadLocal bug. The one provided with bug 529 is invalid (as was pointed out on the dev email thread).&lt;/p&gt;

&lt;p&gt;IMHO, there is NO BUG HERE. The users are ding something else that is causing a OOM.&lt;/p&gt;

&lt;p&gt;This bug should be closed as invalid.&lt;/p&gt;</comment>
                    <comment id="12377243" author="rengels@tylertechinc.com" created="Tue, 2 May 2006 00:39:35 +0100"  >&lt;p&gt;The finalize() method should be removed from the Segment/Term readers.&lt;/p&gt;

&lt;p&gt;In most cases this will actually make things worse, as the objects will need to stay around until the finalizer thread can run.&lt;/p&gt;</comment>
                    <comment id="12377385" author="ktopping" created="Tue, 2 May 2006 19:55:53 +0100"  >&lt;p&gt;I have created a test that exhibits the above-discussed problem.&lt;br/&gt;
Please note, I don&apos;t think it should necessarily be called a &quot;Lucene&quot; bug, as the lucene source is written in a way that /should/ work. It&apos;s more likely to be a JVM bug, I think.&lt;br/&gt;
Please note, I have seen this bug in SUN Hotspot JVM 1.4.2 on Linux. I will shortly be trying some other JVMs and platforms, but - for the time being - this test should only be run against such an environment.&lt;br/&gt;
While developing this test, it also became apparent that the bug only exhibits itself when using a RAMDirectory as the source for an IndexSearcher.&lt;br/&gt;
I will shortly attach the test to this issue.&lt;/p&gt;</comment>
                    <comment id="12377386" author="ktopping" created="Tue, 2 May 2006 19:58:02 +0100"  >&lt;p&gt;test case for recreating this issue on (at least) sun jvm hotspot 1.4.2 on linux&lt;/p&gt;</comment>
                    <comment id="12377604" author="nshupe" created="Thu, 4 May 2006 02:24:17 +0100"  >&lt;p&gt;I agree with robert engels about the finalize method being taken out of the class.  In fact, the finalize method is run by the finalizer thread, and by setting the value to null in that thread, it effectively creates one more entry in the Thread threadLocals map.  This can only hurt the class and performance.  I&apos;m still investigating to why the memory leak occurs though.&lt;/p&gt;</comment>
                    <comment id="12377607" author="rengels@tylertechinc.com" created="Thu, 4 May 2006 02:34:03 +0100"  >&lt;p&gt;fwiw, we have done EXTENSIVE memory profiling of the low-level Lucene (and JVM) routines.&lt;/p&gt;

&lt;p&gt;It is my opinion that there are no memory leaks in either.&lt;/p&gt;

&lt;p&gt;In every case that we &quot;found&quot; a memory leak, it always ended up tied back to something we were doing wrong on our client code.&lt;/p&gt;</comment>
                    <comment id="12377623" author="nshupe" created="Thu, 4 May 2006 04:32:38 +0100"  >&lt;p&gt;robert engels is &lt;b&gt;incorrect&lt;/b&gt; in that there isn&apos;t a memory leak with Lucene.  The test case made by kieran demonstrates the memory leak quite well on my machine for the following setup:&lt;/p&gt;

&lt;p&gt;Lucene 1.9.1&lt;br/&gt;
Sun JDK 1.5.0_06&lt;br/&gt;
JVM Args: -Xmx4M (low memory to get the unit test to fail faster)&lt;br/&gt;
Windows XP Pro&lt;/p&gt;

&lt;p&gt;The test case will fail on my machine with i = 2006 and useRamDirectory set to true (as indicated by kieran, this point is important).&lt;/p&gt;

&lt;p&gt;Furthermore, by changing the enumerators declaration to:&lt;/p&gt;

&lt;p&gt;  private Map enumerators = Collections.synchronizedMap(new WeakHashMap());&lt;/p&gt;

&lt;p&gt;and the getEnum method to:&lt;/p&gt;

&lt;p&gt;  private SegmentTermEnum getEnum() {&lt;br/&gt;
    Thread currentThread = Thread.currentThread();&lt;br/&gt;
    SegmentTermEnum termEnum = (SegmentTermEnum)enumerators.get(currentThread);&lt;br/&gt;
    if (termEnum == null) &lt;/p&gt;
{
      termEnum = terms();
      enumerators.put(currentThread, termEnum);
    }
&lt;p&gt;    return termEnum;&lt;br/&gt;
  }&lt;/p&gt;

&lt;p&gt;(note that I&apos;m not suggesting that my changes be used for the official patch)&lt;/p&gt;

&lt;p&gt;The problem dissapears, and the unit test completes.  I vote that this bug be bumped to critical in priority and a fix be included for the Lucene 1.9.2 release and perhaps a patch be made for the 1.4.3 release for those who need it.&lt;/p&gt;

&lt;p&gt;For further reading on the perils of ThreadLocal I suggest the following reading:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.me.umn.edu/~shivane/blogs/cafefeed/2004/06/of-non-static-threadlocals-and-memory.html&quot; class=&quot;external-link&quot;&gt;http://www.me.umn.edu/~shivane/blogs/cafefeed/2004/06/of-non-static-threadlocals-and-memory.html&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;http://www.szegedi.org/articles/memleak.html&quot; class=&quot;external-link&quot;&gt;http://www.szegedi.org/articles/memleak.html&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;http://crazybob.org/2006/02/threadlocal-memory-leak.html&quot; class=&quot;external-link&quot;&gt;http://crazybob.org/2006/02/threadlocal-memory-leak.html&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;http://opensource.atlassian.com/confluence/spring/pages/viewpage.action?pageId=2669&quot; class=&quot;external-link&quot;&gt;http://opensource.atlassian.com/confluence/spring/pages/viewpage.action?pageId=2669&lt;/a&gt;&lt;/p&gt;</comment>
                    <comment id="12377628" author="rengels@tylertechinc.com" created="Thu, 4 May 2006 04:51:48 +0100"  >&lt;p&gt;I agree that the test case does fail, so I was wrong. There is &quot;something&quot; broken in Lucene or the JDK.&lt;/p&gt;

&lt;p&gt;What is the JDK bug that was fixed that allows it to work under 1.5? The proposed patch is nearly exactly the implementation of ThreadLocal, so I am not sure how it would fix the problem?&lt;/p&gt;

&lt;p&gt;When I ran it under the profiler, it seems to work correctly. I still it may have something to do with finalizers preventing GC when it needs it.&lt;/p&gt;</comment>
                    <comment id="12377631" author="nshupe" created="Thu, 4 May 2006 04:59:50 +0100"  >&lt;p&gt;The problem is apparent on my machine with JDK 1.5, so basically this bug shows up, regardless of JDK version.&lt;/p&gt;

&lt;p&gt;I&apos;ve looked at the source for ThreadLocal, and there&apos;s a custom implementation of a map being used which is a bit scarry.  However, you&apos;d figure they tested the hell out of it, including instance count verification with the garbage collector.&lt;/p&gt;

&lt;p&gt;If we assume the code for ThreadLocal is correct, then the only idea I have is that the value, a SegmentTermEnum has a reference chain back to the ThreadLocal in someway, which would prevent the ThreadLocal key in the inner map from being collected.  However, I can&apos;t seem to show that being true.  I&apos;ve even tried not using the .clone method thinking there might be something fishy with that, but nothing came out of that.&lt;/p&gt;</comment>
                    <comment id="12377636" author="nshupe" created="Thu, 4 May 2006 05:13:53 +0100"  >&lt;p&gt;This type of ThreadLocal (anti?)pattern also seems to be present in SegmentReader.&lt;/p&gt;</comment>
                    <comment id="12377642" author="rengels@tylertechinc.com" created="Thu, 4 May 2006 05:45:56 +0100"  >&lt;p&gt;It works fine for me under 1.5.0_06.&lt;/p&gt;

&lt;p&gt;I have determined the problem with the ThreadLocal code in 1.4.2. The entries in the ThreadLocalMap extend WeakReference (holding a weak ref to the key which is the ThreadLocal), but also contain a HARD reference to the value (the thread local value - which in this case can be quite large).&lt;/p&gt;

&lt;p&gt;In JDK 1.4.2, the entries are only cleaned-up if a hit occurs and the ThreadLocalMap determines that the entry is stale (the key has been reclaimed), and at this point the entry is reused for the new ThreadLocal. If no hits ever occur (or it keeps hiiting the same entry), the number of entries in the table will become unbounded.&lt;/p&gt;

&lt;p&gt;In JDK 1.5, the ThreadLocal code periodically clean-ups SOME stale ThreadLocals during each invocation - using cleanSomeSlots().&lt;/p&gt;

&lt;p&gt;This is why using the proposed patch works - it uses a standard WeakHashMap which expunges ALL stale entries on nearly every operation.&lt;/p&gt;

&lt;p&gt;I will look into creating a derived ThreadLocal that works properly. Or we can just package the proposed patch into a FixedThreadLocal. I don&apos;t know what the Lucene dev policies are on &quot;fixing&quot; JDK problems. Seems to me a FixedThreadLocal is the best solution.&lt;/p&gt;</comment>
                    <comment id="12377687" author="rengels@tylertechinc.com" created="Thu, 4 May 2006 11:27:21 +0100"  >&lt;p&gt;ThreadLocal replacement that avoids memory leak&lt;/p&gt;</comment>
                    <comment id="12377688" author="rengels@tylertechinc.com" created="Thu, 4 May 2006 11:40:21 +0100"  >&lt;p&gt;I posted FixedThreadLocal.java. Changed Lucene to use this class instead of ThreadLocal. Test case runs fine under 1.4.&lt;/p&gt;

&lt;p&gt;The performance difference appears almost non existent. I think this is because in typical Lucene usage the number of invocations is quite small.&lt;/p&gt;

&lt;p&gt;A better multi-threaded version is also possible, using a WeakHashMap for each thread, containing the FixedThreadLocals for that thread. This would minimize the length of the synchronization required.&lt;/p&gt;

&lt;p&gt;In either case, the finalize methods should be removed. This contributes greatly to the problems with the current code. In fact, it does nothing, since if the object was finalizable, then its reference would have already been reclaimed from the ThreadLocalMap, so having the finalize method actually slows this process. (I removed the finalized methods from Lucene - test case runs fine).&lt;/p&gt;

&lt;p&gt;BUT, this problem is not as severe as it appears.&lt;/p&gt;

&lt;p&gt;The main reason that this becomes an issue with JDK 1.4 and the testcase, is that the size of the objects being put into the ThreadLocal, since the RAMDirectory has a complete copy of the index. In most uses this will not be the case, and the objects will be reclaimed eventually, as the ThreadLocalMap size stabalizes. The bug in ThreadLocal allows a certain number of stale entries, once the index size gets to 300k, a max of 30 entries can be stale without running out of memory.&lt;/p&gt;</comment>
                    <comment id="12377694" author="rengels@tylertechinc.com" created="Thu, 4 May 2006 11:53:23 +0100"  >&lt;p&gt;demonstrate thread local memory leak&lt;/p&gt;</comment>
                    <comment id="12377697" author="rengels@tylertechinc.com" created="Thu, 4 May 2006 12:00:23 +0100"  >&lt;p&gt;I posted ThreadLocalTest.java that clearly demonstrates the &quot;problem&quot; with JDK 1.4.&lt;/p&gt;

&lt;p&gt;BUT, it also demonstrates the problem with the test case.&lt;/p&gt;

&lt;p&gt;If you run the test with -Xmx4m it will fail quickly under JDK 1.4.2.&lt;br/&gt;
If you run the test as is under JDK 1.5 with the same memory constraints it will run forever.&lt;/p&gt;

&lt;p&gt;With the same memory constraints, if you change the test to use FixedThreadLocal it will run forever.&lt;/p&gt;

&lt;p&gt;BUT, if you run the test with -Xmx64m under JDK 1.4.2 it will run forever! This is because the ThreadLocalMap size stablizes.&lt;/p&gt;

&lt;p&gt;Thus, unless you are creating and accessing large RAMDirectories you will never experience the problem.&lt;/p&gt;

&lt;p&gt;I think this bug should be closed as invalid. BUT, the finalizer() methods should be removed from the Lucene code since it does no good, and actually slows the system by delaying the GC.&lt;/p&gt;

&lt;p&gt;Hopefully this ends the issue, and we can move on to other things.&lt;/p&gt;</comment>
                    <comment id="12377701" author="rengels@tylertechinc.com" created="Thu, 4 May 2006 12:06:01 +0100"  >&lt;p&gt;Just for my own &quot;pat on the back&quot;, it goes back to what I said in the earliest comment.&lt;/p&gt;

&lt;p&gt;There is NOT a memory leak in Lucene or JDK 1.4.2 or Lucene.&lt;/p&gt;

&lt;p&gt;JDK 1.4.2 made a performance vs. memory size decision that works in most cases.&lt;/p&gt;

&lt;p&gt;In the submitters case their deisgn decision does not work so well (combination of size of ThreadLocal values and maximum heap size).&lt;/p&gt;

&lt;p&gt;With JDK 1.5, they chose an alternative implementation that is SLOWER, but the memory requirements in the general case are smaller, and deterministic.&lt;/p&gt;

&lt;p&gt;There will ALWAYS be design decisions like this in ALL software development.&lt;/p&gt;</comment>
                    <comment id="12377764" author="andyhind" created="Thu, 4 May 2006 18:40:28 +0100"  >&lt;p&gt;I agree this is not strictly an issue with lucene....but .....&lt;/p&gt;

&lt;p&gt;Lucene has an unusual use pattern for thread locals (instance vs static member variables).&lt;br/&gt;
There are issues with ThreadLocal, discussed here and elsewhere, including potential instability.&lt;br/&gt;
You should expect others to use thread locals - maybe in the same way.&lt;/p&gt;

&lt;p&gt;I fixed the issue reported in &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-529&quot; title=&quot;TermInfosReader and other + instance ThreadLocal =&amp;gt; transient/odd memory leaks =&amp;gt;  OutOfMemoryException&quot;&gt;&lt;del&gt;LUCENE-529&lt;/del&gt;&lt;/a&gt; with memory sensitive caching using SoftReferences to the values held as ThreadLocals.&lt;br/&gt;
Before an out of memory error, the values are cleared and hard refs to the soft reference wrapper class remain.&lt;br/&gt;
This pattern is used by some classes in the JVM.&lt;br/&gt;
This limits the memory overhead with thread local use. &lt;br/&gt;
There will always be some overhead.&lt;/p&gt;

&lt;p&gt;I am happy with the alternative fix using WeakHashMap&lt;br/&gt;
Note: stale entries are always scanned and removed (each call to put, get, size) in contrast to thread locals. &lt;br/&gt;
This is what I want - it must be stable!&lt;/p&gt;

&lt;p&gt;I spent as much time as I could trying to come up with a clear, simple test case that applied regardless of memory constraints.&lt;br/&gt;
A clear failure case must be possible, but I did not have time to investigate the criteria for ThreadLocal instability.&lt;br/&gt;
In any case, I would send this to Sun.&lt;/p&gt;

&lt;p&gt;A test case is one thing, knowning, understanding and fixing/working around an issue is another.&lt;br/&gt;
In all the simple cases I tried I got stability but with higher memory use and gc activity than with the &quot;fixed&quot; version.&lt;br/&gt;
However, I did also remove the pointless finalize() method, which could very well explain the growth of the thread local table.&lt;/p&gt;

&lt;p&gt;We have had problems with 1.5.0_06. The issue is caused by the pattern of thread local use and garbage collection producing instability in the size of the thread local table. Your single test case does not imply that the issue does not exist for other JVMs and use cases.  I have had the issue without using RAMDirectory - it seems it is just more likely with it.&lt;/p&gt;

&lt;p&gt;By the way, cause and effect is sufficient for me. I have a problem with using the 1.4.3 code, this change fixes it.&lt;/p&gt;

&lt;p&gt;Regards&lt;/p&gt;

&lt;p&gt;Andy&lt;/p&gt;</comment>
                    <comment id="12377815" author="rengels@tylertechinc.com" created="Thu, 4 May 2006 23:00:59 +0100"  >&lt;p&gt;To restate:&lt;/p&gt;

&lt;p&gt;It is NOT a bug. It is a design decision in the JDK between performance and memory use. This decisions changed a bit in 1.5. 1.5 still does not clear the entire ThreadLocal table - it uses hueristics to clear MOST of the entries - a balance between memory and speed. The WeakHashMap clears ALL entries on every invocation. It is slower than a ThreadLocal, BUT, it&apos;s memory use is more deterministic.&lt;/p&gt;

&lt;p&gt;Lucene will work FINE in all cases except when loading large directories into a RAMDirectory, and closing and reopening said directories multiple times.&lt;/p&gt;

&lt;p&gt;Since this may be a common use case for Lucene, I suggest using the FixedThreadLocal class - trading performance for deterministic memory use.&lt;/p&gt;

&lt;p&gt;In all cases, the current finalize() methods that &quot;clear the ThreadLocal value&quot; should be removed. It is incorrect, and causes performance problems. Since the finalize() is for the ThreadLocal value, it will never be finalized until the ThreadLocal has already cleared the entry - which is based on the key (the ThreadLocal), since the ThreadLocal entry maintains a hard ref to the value.&lt;/p&gt;</comment>
                    <comment id="12377826" author="rengels@tylertechinc.com" created="Thu, 4 May 2006 23:31:36 +0100"  >&lt;p&gt;Oops. Last comment was not quite correct.&lt;/p&gt;

&lt;p&gt;The reason the finalize() methods are worthless for clearing the ThreadLocal entries, is that they are clearing the ThreadLocal entry for the &quot;finalize&quot; thread !&lt;/p&gt;

&lt;p&gt;So they do nothing but slow down finalization/GC.&lt;/p&gt;</comment>
                    <comment id="12377829" author="rengels@tylertechinc.com" created="Thu, 4 May 2006 23:40:38 +0100"  >&lt;p&gt;The best solution is this,&lt;/p&gt;

&lt;p&gt;move the &lt;/p&gt;

&lt;p&gt;    enumerators.set(null);&lt;/p&gt;

&lt;p&gt;to the TermInfosReader close(), and remove the finalize().&lt;/p&gt;

&lt;p&gt;Everything will work fine.&lt;/p&gt;</comment>
                    <comment id="12377842" author="rengels@tylertechinc.com" created="Fri, 5 May 2006 00:56:52 +0100"  >&lt;p&gt;Actually, the last simple &quot;fix&quot; only works well for single threaded applications, so it is not much of a &quot;fix&quot;.&lt;/p&gt;

&lt;p&gt;Use FixedthreadLocal - works best.&lt;/p&gt;</comment>
                    <comment id="12377850" author="nshupe" created="Fri, 5 May 2006 01:40:23 +0100"  >&lt;p&gt;However, this problem is classified is eventually irrelevant to me.  Bug in the JDK, bug in Lucene, not a bug, it&apos;s all the same.  What is relevant is that I have a production app using Lucene 1.9.1 that will produce an OutOfMemoryError within 2 weeks of use with a huge 128MB of heap.  The configuration is Sun&apos;s JDK 1.5.0_06 on Linux / Tomcat 5.5.15.  With a patch, I am NOT getting the memory link, and my customers are NOT being denied service because of &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-436&quot; title=&quot;[PATCH] TermInfosReader, SegmentTermEnum Out Of Memory Exception&quot;&gt;&lt;del&gt;LUCENE-436&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;For what it&apos;s worth, the use case for my app is opening up one IndexReader and one IndexSearcher, and using the IndexSearcher in an multi-threaded environment.  If this isn&apos;t a primary use case for Lucene, it should be.&lt;/p&gt;</comment>
                    <comment id="12377855" author="rengels@tylertechinc.com" created="Fri, 5 May 2006 01:55:46 +0100"  >&lt;p&gt;Are you always loading your indexes using RAMDirectories?&lt;/p&gt;

&lt;p&gt;I use multi-hundred megabytes indexes, with 196 max heap, and it runs for months.&lt;/p&gt;

&lt;p&gt;I can guarentee that if your index grows to 100+ megabytes you will get an OOM no matter what you do (loading into a RAMDirectory with a 128 max heap), SO, THE ISSUE IS COMPLETELY DEPENDENT on YOUR configuration.&lt;/p&gt;

&lt;p&gt;You may find that using a 256 max heap allows your index to run forever with NO code CHANGES.&lt;/p&gt;

&lt;p&gt;I am not saying this issue should not be addressed, but it is not  BUG. It is a performance vs. memory consumption design tradeoff. If you knew anything about software, you would understand this.&lt;/p&gt;

&lt;p&gt;It may be the common case that Lucene should favor lower memory consumption vs. performance, but it is not a ABSOLUTE.&lt;/p&gt;

&lt;p&gt;There are conceivably many users of Lucene where the change does not make sense, the performance degradation is not worth it (because they have plenty of memory available based on index size, and/or do not load the indexes into memory).&lt;/p&gt;

</comment>
                    <comment id="12377856" author="rengels@tylertechinc.com" created="Fri, 5 May 2006 01:57:03 +0100"  >&lt;p&gt;better version of TermInfos reader that avoid multiple ThreadLocal.get() calls&lt;/p&gt;</comment>
                    <comment id="12377858" author="rengels@tylertechinc.com" created="Fri, 5 May 2006 02:01:02 +0100"  >&lt;p&gt;I attached a better version of TermInfosReader that avoids multiple ThreadLocal.get() during get(Term r) which can be expensive.&lt;/p&gt;

&lt;p&gt;This is especially important if ThreadLocal is changed to FixedThreadLocal due to the lower performance of get().&lt;/p&gt;

&lt;p&gt;I also removed some unused package level methods.&lt;/p&gt;</comment>
                    <comment id="12377863" author="nshupe" created="Fri, 5 May 2006 02:20:29 +0100"  >&lt;p&gt;I am not using a RAMDirectory.  I never indicated as such.  Here&apos;s the the way I load my index:&lt;/p&gt;

&lt;p&gt;reader = IndexReader.open(dictionaryIndexDirectory);&lt;/p&gt;

&lt;p&gt;dictionaryIndexDirectory is a java.io.File.&lt;/p&gt;

&lt;p&gt;My index is 30 megabytes.  This configuration should be perfectly fine in 128 MB of heap, even 64 sounds reasonable.  I can&apos;t simply add a 128 MB heap to my configuration without additional cost.  I can&apos;t just throw hardware at the problem.  Also, any performance arguments are irrelevant unless proven with real numbers.  If you knew anything about software, you would understand this as well.&lt;/p&gt;</comment>
                    <comment id="12377865" author="rengels@tylertechinc.com" created="Fri, 5 May 2006 02:33:04 +0100"  >&lt;p&gt;Then you have some other problem.&lt;/p&gt;

&lt;p&gt;The ONLY way the ThreadLocal issue is an ISSUE is if VERY LARGE objects are referenced by the ThreadLocal. Since your indexes are not being held in ram, there is some other problem. You even provided that test case that DEMONSTRATES the &quot;memory leak&quot; issue is not a problem unless a RAMDirectory is used.&lt;/p&gt;

&lt;p&gt;As for what is a valid heap size - this depends completely on the other code loaded into the JVM, and what memory it uses.&lt;/p&gt;

&lt;p&gt;I use a max heap of 196 with 400mb index and it works fine.&lt;/p&gt;
</comment>
                    <comment id="12377905" author="ktopping" created="Fri, 5 May 2006 06:29:39 +0100"  >&lt;p&gt;Robert Engels description of the ThreadLocal issue in JDK 1.4.2 provides a very plausible explanation for why this is not a bug, either in Lucene, or in the JDK.&lt;/p&gt;

&lt;p&gt;It&apos;s not a memory &quot;leak&quot;, in the traditional sense (i.e. an unbounded increase in heap memory usage); however, it can - in certain circumstances - lead to a lot more memory being assigned than is necessary, which (and this is pivotal) isn&apos;t necessarily considered for GC-ing once it&apos;s no longer (hard-)referenced.&lt;/p&gt;

&lt;p&gt;Personally, now this behaviour of ThreadLocal has been pointed out, I find it very difficult to envisage circumstances in which I&apos;ll even consider using it - until it is altered. (I won&apos;t say never, because, as Robert points out, there IS a performance gain to this behaviour).&lt;/p&gt;

&lt;p&gt;My personal experience is that this &quot;memory leak&quot; / &quot;larger than necessary memory footprint&quot; can cause extreme problems in production apps. We&apos;ve been running out of memory even with 700MB assigned to each JRE. My patch has resolved the issue, and so we will apply it to each future release of Lucene, before we use it. Maybe ours is an unusual setup: we periodically close our IndexSearcher, reload an index from the filesystem into a RAMDirectory, and create a new IndexSearcher from it. These indexes are only a few MB in size.&lt;/p&gt;

&lt;p&gt;The reason I posted this patch and test case was to help developers who might be in a similar situation to me, and save them from the having to perform the days of investigation that I did - not because I wanted to force an unwanted change into the Lucene source code. It would be very useful to me if a variant of this patch WAS incorporated into Lucene but I recognize that other users may well have different priorities vis-a-vis performance vs memory ueage.&lt;/p&gt;

&lt;p&gt;(btw, Robert, I think you might have mistakenly ascribed the test case to Nicholaus! It was me who suggested that it was dependent on using RAMDirectories.)&lt;/p&gt;

&lt;p&gt;Kind regards.&lt;/p&gt;</comment>
                    <comment id="12377933" author="ehatcher" created="Fri, 5 May 2006 09:46:59 +0100"  >&lt;p&gt;Please, everyone, let&apos;s keep this discussion technical and factual and avoid making degrading statements to one another.  It doesn&apos;t help the situation to have such negative tones being used. The discussion aspect of this should be moved to java-dev anyway, and leave JIRA comments for details on patches attached and other technical details related directly towards resolving this issue.&lt;/p&gt;</comment>
                    <comment id="12378997" author="fern" created="Thu, 11 May 2006 08:07:10 +0100"  >&lt;p&gt;Here are our facts.  It looks like this bug is also affecting us!!&lt;/p&gt;


&lt;p&gt;We are also running into memory issues on our production servers and running out of memory.&lt;/p&gt;

&lt;p&gt;Tomcat 5, Lucene1.9.1, JDK 1.5, RHEL, RAMDirectory&lt;/p&gt;

&lt;p&gt;We are constantly updating the index ( 2400 documents smoothly reindexed every 30 hour ).&lt;/p&gt;

&lt;p&gt;Index size of about 5M.&lt;/p&gt;

&lt;p&gt;We are doing ordered searches against the index.&lt;/p&gt;

&lt;p&gt;We are constantly creating new IndexReader/Writer/Searcher and closing as needed.&lt;/p&gt;

&lt;p&gt;In QA we have Xmx500M, in production we have Xmx1500M.&lt;/p&gt;</comment>
                    <comment id="12379151" author="fern" created="Fri, 12 May 2006 06:07:26 +0100"  >&lt;p&gt;So I went ahead and made our own version of lucene-1.9.1 from the sources along with the proposed patch.  And yes it does help our memory leak.  If you refer to the previous comment, you can see what our environment looks like.  I will go ahead and attach our version of the patch now.&lt;/p&gt;</comment>
                    <comment id="12379152" author="fern" created="Fri, 12 May 2006 06:08:13 +0100"  >&lt;p&gt;alright then.  Attached is the patch that I just created.  I couldn&apos;t resist modifying the FixedThreadLocal to suit my tastes. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;and it goes against the &quot;1.9.1&quot; src that I downloaded off of their website. (though it was marked as version &quot;1.9.2-dev&quot;, which then I re-christened &quot;1.9.2-protrade&quot; ).&lt;/p&gt;

&lt;p&gt;And yes it seems to have helped with the memory leak.&lt;/p&gt;

&lt;p&gt;thank you all.&lt;/p&gt;</comment>
                    <comment id="12429418" author="antonyscerri" created="Mon, 21 Aug 2006 14:45:19 +0100"  >&lt;p&gt;Would it not be easier to simply make the objects stored in the ThreadLocal a WeakReference. So in the case of TermInfosReader store the SegmentTermEnum within the WeakReference, and then place that into the enumerators varaible. This will maintain the cloned term enumerator object for the lifetime of the thread using it, but also allow the objects to be cleaned up by the GC when the index owning the TermInfosReader is no longer referenced (at which point no thread should be using the index). &lt;/p&gt;</comment>
                    <comment id="12429451" author="antonyscerri" created="Mon, 21 Aug 2006 17:46:16 +0100"  >&lt;p&gt;Lets forget that last comment I made, I was testing out a simple setup and forgot there wasn&apos;t going to be a hard reference to the cloned term enum object anywhere, so the weak reference would get cleared away immediately upon GC. A SoftReference could be used instead, but would be subject to GC if free memory was low, which under heavy load could mean it would again get cleared away by GC before the thread had finished.&lt;/p&gt;</comment>
                    <comment id="12458264" author="otis" created="Wed, 13 Dec 2006 21:17:08 +0000"  >&lt;p&gt;4 months later, I think I see the same problem here.&lt;br/&gt;
I&apos;m using JDK 1.6 (I saw the same problem under 1.5.0_0(8,9,10)) and Lucene from HEAD (2.1-dev).&lt;br/&gt;
I&apos;m running out of 2GB heap in under 1 day on a production system that searches tens of thousands of indexes, where a few hundred of them have IndexSearchers open to them at any one time, with unused IndexSearchers getting closed after some period of inactivity.&lt;/p&gt;

&lt;p&gt;I&apos;m periodically dumping the heap with jconsole and noticing the continuously increasing number of:&lt;/p&gt;

&lt;p&gt; org.apache.lucene.index.TermInfo&lt;br/&gt;
 org.apache.lucene.index.CompoundFileReader$CSIndexInput&lt;br/&gt;
 org.apache.lucene.index.Term&lt;br/&gt;
 org.apache.lucene.index.SegmentTermEnum&lt;br/&gt;
...&lt;/p&gt;

&lt;p&gt;There was a LOT of back and forth here.&lt;/p&gt;

&lt;p&gt;What is the final solution?  I see a complete new copy of TermInfosReader, but there are a lot of formatting changes in there, it&apos;s hard to tell what was actually changed, even with diff -bB --expand-tabs.&lt;/p&gt;

&lt;p&gt;I also see FixedThreadLocal, but I see no references to it from TermInfosReader...?&lt;/p&gt;</comment>
                    <comment id="12458292" author="rengels@tylertechinc.com" created="Wed, 13 Dec 2006 22:32:08 +0000"  >&lt;p&gt;I would doubt the ThreadLocal &quot;issue&quot; that was in 1.4, changed in 1.5, would be reintroduced in 1.6.&lt;/p&gt;

&lt;p&gt;I do not use Lucene 2.1 so I can&apos;t say for certain that a new memory bug hasn&apos;t been introduced.&lt;/p&gt;

&lt;p&gt;I suggest attaching a good profiler (like JProfiler) and figure our the cause of the memory leak (the root references).&lt;/p&gt;

&lt;p&gt;I use 1.9 based Lucene and can say unequivocally there are no inherent memory issues (especially when running under 1.5+).&lt;/p&gt;

&lt;p&gt;There may also be new issues introduced in JDK 6 - we have not tested with it, only 1.4 and 1.5.&lt;/p&gt;</comment>
                    <comment id="12459779" author="otis" created="Tue, 19 Dec 2006 22:33:49 +0000"  >&lt;p&gt;My leak ended up being caused by the patch in &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-651&quot; title=&quot;Poor performance race condition in FieldCacheImpl&quot;&gt;&lt;del&gt;LUCENE-651&lt;/del&gt;&lt;/a&gt; and is fixed by &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-754&quot; title=&quot;FieldCache keeps hard references to readers, doesn&amp;#39;t prevent multiple threads from creating same instance&quot;&gt;&lt;del&gt;LUCENE-754&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The only thing left to do in this case is:&lt;br/&gt;
1) remove finalize() calls in SegmentReader and TermInfosReader&lt;br/&gt;
2) call enumerators.remove() in TermInfosReader&apos;s close()&lt;/p&gt;

&lt;p&gt;I&apos;ll do that in the next few days.&lt;/p&gt;</comment>
                    <comment id="12459813" author="yseeley@gmail.com" created="Wed, 20 Dec 2006 03:27:09 +0000"  >&lt;p&gt;The more finalizers we can get rid of, the better.  They are too hard to use correctly and cause performance problems.&lt;br/&gt;
&lt;a href=&quot;http://devresource.hp.com/drc/resources/jmemmodel/index.jsp&quot; class=&quot;external-link&quot;&gt;http://devresource.hp.com/drc/resources/jmemmodel/index.jsp&lt;/a&gt;&lt;/p&gt;</comment>
                    <comment id="12459814" author="otis" created="Wed, 20 Dec 2006 03:43:41 +0000"  >&lt;p&gt;This patch removes finalize() in TermInfosReader and SegmentReader, and it adds the enumerators.remove() call in TermInfosReader close() method.&lt;/p&gt;</comment>
                    <comment id="12460040" author="otis" created="Wed, 20 Dec 2006 20:28:16 +0000"  >&lt;p&gt;Applied and committed the &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-436&quot; title=&quot;[PATCH] TermInfosReader, SegmentTermEnum Out Of Memory Exception&quot;&gt;&lt;del&gt;LUCENE-436&lt;/del&gt;&lt;/a&gt;.patch (is JIRA smart enough not to hyperlink this?) - all unit tests still pass.&lt;/p&gt;</comment>
                </comments>
                    <attachments>
                    <attachment id="12326231" name="FixedThreadLocal.java" size="774" author="rengels@tylertechinc.com" created="Thu, 4 May 2006 11:27:21 +0100" />
                    <attachment id="12326590" name="lucene-1.9.1.patch" size="59786" author="fern" created="Fri, 12 May 2006 06:08:13 +0100" />
                    <attachment id="12347533" name="LUCENE-436.patch" size="1482" author="otis" created="Wed, 20 Dec 2006 03:43:41 +0000" />
                    <attachment id="12326145" name="Lucene-436-TestCase.tar.gz" size="588679" author="ktopping" created="Tue, 2 May 2006 19:58:02 +0100" />
                    <attachment id="12326257" name="TermInfosReader.java" size="5175" author="rengels@tylertechinc.com" created="Fri, 5 May 2006 01:57:03 +0100" />
                    <attachment id="12326232" name="ThreadLocalTest.java" size="794" author="rengels@tylertechinc.com" created="Thu, 4 May 2006 11:53:23 +0100" />
                </attachments>
            <subtasks>
        </subtasks>
                <customfields>
                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                <customfieldname>Attachment count</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>6.0</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                <customfieldname>Date of First Response</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>Wed, 11 Jan 2006 07:28:38 +0000</customfieldvalue>

                </customfieldvalues>
            </customfield>
                                                                                                        <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Global Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>13313</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>27295</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                <customfieldname>Time in Status</customfieldname>
                <customfieldvalues>
                    
                </customfieldvalues>
            </customfield>
                            </customfields>
    </item>
</channel>
</rss>