<!-- 
RSS generated by JIRA (5.2.8#851-sha1:3262fdc28b4bc8b23784e13eadc26a22399f5d88) at Tue Jul 16 13:04:29 UTC 2013

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/LUCENE-1470/LUCENE-1470.xml?field=key&field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>5.2.8</version>
        <build-number>851</build-number>
        <build-date>26-02-2013</build-date>
    </build-info>

<item>
            <title>[LUCENE-1470] Add TrieRangeFilter to contrib</title>
                <link>https://issues.apache.org/jira/browse/LUCENE-1470</link>
                <project id="12310110" key="LUCENE">Lucene - Core</project>
                        <description>&lt;p&gt;According to the thread in java-dev (&lt;a href=&quot;http://www.gossamer-threads.com/lists/lucene/java-dev/67807&quot; class=&quot;external-link&quot;&gt;http://www.gossamer-threads.com/lists/lucene/java-dev/67807&lt;/a&gt; and &lt;a href=&quot;http://www.gossamer-threads.com/lists/lucene/java-dev/67839&quot; class=&quot;external-link&quot;&gt;http://www.gossamer-threads.com/lists/lucene/java-dev/67839&lt;/a&gt;), I want to include my fast numerical range query implementation into lucene contrib-queries.&lt;/p&gt;

&lt;p&gt;I implemented (based on RangeFilter) another approach for faster&lt;br/&gt;
RangeQueries, based on longs stored in index in a special format.&lt;/p&gt;

&lt;p&gt;The idea behind this is to store the longs in different precision in index&lt;br/&gt;
and partition the query range in such a way, that the outer boundaries are&lt;br/&gt;
search using terms from the highest precision, but the center of the search&lt;br/&gt;
Range with lower precision. The implementation stores the longs in 8&lt;br/&gt;
different precisions (using a class called TrieUtils). It also has support&lt;br/&gt;
for Doubles, using the IEEE 754 floating-point &quot;double format&quot; bit layout&lt;br/&gt;
with some bit mappings to make them binary sortable. The approach is used in&lt;br/&gt;
rather big indexes, query times are even on low performance desktop&lt;br/&gt;
computers &amp;lt;&amp;lt;100 ms &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/warning.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; for very big ranges on indexes with 500000 docs.&lt;/p&gt;

&lt;p&gt;I called this RangeQuery variant and format &quot;TrieRangeRange&quot; query because&lt;br/&gt;
the idea looks like the well-known Trie structures (but it is not identical&lt;br/&gt;
to real tries, but algorithms are related to it).&lt;/p&gt;
</description>
                <environment></environment>
            <key id="12409265">LUCENE-1470</key>
            <summary>Add TrieRangeFilter to contrib</summary>
                <type id="2" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/newfeature.png">New Feature</type>
                                <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                    <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png">Closed</status>
                    <resolution id="1">Fixed</resolution>
                                <assignee username="thetaphi">Uwe Schindler</assignee>
                                <reporter username="thetaphi">Uwe Schindler</reporter>
                        <labels>
                    </labels>
                <created>Wed, 26 Nov 2008 14:08:32 +0000</created>
                <updated>Sun, 1 Mar 2009 10:43:39 +0000</updated>
                    <resolved>Fri, 13 Feb 2009 18:29:15 +0000</resolved>
                            <version>2.4</version>
                                <fixVersion>2.9</fixVersion>
                                <component>modules/other</component>
                        <due></due>
                    <votes>0</votes>
                        <watches>0</watches>
                                                    <comments>
                    <comment id="12651005" author="thetaphi" created="Wed, 26 Nov 2008 14:12:06 +0000"  >&lt;p&gt;First version of a patch for contrib-queries. It includes my classes for package o.a.l.search.trie. The TrieRangeFilter was refactored to be a separate class (in contrast to my original implementation). The class is Java 1.4 compatible (like contrib-queries). JavaDocs were updated and a general information page for the package was given.&lt;/p&gt;

&lt;p&gt;A first test case to test the trie-encoded values was added. The filter and query tests must be written.&lt;/p&gt;</comment>
                    <comment id="12651007" author="thetaphi" created="Wed, 26 Nov 2008 14:16:16 +0000"  >&lt;p&gt;See also the discussion in &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1461&quot; title=&quot;Cached filter for a single term field&quot;&gt;&lt;del&gt;LUCENE-1461&lt;/del&gt;&lt;/a&gt;, as it inspired me to give my code to contrib.&lt;/p&gt;</comment>
                    <comment id="12651011" author="thetaphi" created="Wed, 26 Nov 2008 14:23:59 +0000"  >&lt;p&gt;fixed patch&lt;/p&gt;</comment>
                    <comment id="12651014" author="earwin" created="Wed, 26 Nov 2008 14:34:50 +0000"  >&lt;p&gt;Lucene (at least 2.3.2 version) cannot index Strings containing 0xFFFF characters, as it is used internally as EOS marker.&lt;br/&gt;
I&apos;ve implemented binary encoding similar to yours, but after hitting this issue with some converted Date, switched to base-2 &lt;sup&gt;15&lt;/sup&gt; encoding, leaving high bit always zero.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; toLucene(&lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt; n) {
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (n == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;
    }

    &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; u = n + &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt;.MAX_VALUE + 1;

    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;char&lt;/span&gt;[]{
        (&lt;span class=&quot;code-object&quot;&gt;char&lt;/span&gt;) ((u &amp;amp; 0xFFFE000000000000L) &amp;gt;&amp;gt; 49),
        (&lt;span class=&quot;code-object&quot;&gt;char&lt;/span&gt;) ((u &amp;amp; 0x0001FFFC00000000L) &amp;gt;&amp;gt; 34),
        (&lt;span class=&quot;code-object&quot;&gt;char&lt;/span&gt;) ((u &amp;amp; 0x00000003FFF80000L) &amp;gt;&amp;gt; 19),
        (&lt;span class=&quot;code-object&quot;&gt;char&lt;/span&gt;) ((u &amp;amp; 0x000000000007FFF0L) &amp;gt;&amp;gt; 4),
        (&lt;span class=&quot;code-object&quot;&gt;char&lt;/span&gt;) ((u &amp;amp; 0x000000000000000FL) &amp;lt;&amp;lt; 11),
    });
  }

  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt; fromLucene(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; string) {
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (string == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;
    }

    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; (((&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) string.charAt(0)) &amp;lt;&amp;lt; 49 |
            ((&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) string.charAt(1)) &amp;lt;&amp;lt; 34 |
            ((&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) string.charAt(2)) &amp;lt;&amp;lt; 19 |
            ((&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) string.charAt(3)) &amp;lt;&amp;lt; 4 |
            ((&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) string.charAt(4)) &amp;gt;&amp;gt; 11
    ) - &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt;.MAX_VALUE - 1;
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                    <comment id="12651024" author="earwin" created="Wed, 26 Nov 2008 15:02:33 +0000"  >&lt;p&gt;Read your code closer. Silly me, I assumed you went with base-2 &lt;sup&gt;16&lt;/sup&gt;.&lt;/p&gt;</comment>
                    <comment id="12651035" author="thetaphi" created="Wed, 26 Nov 2008 15:28:35 +0000"  >&lt;p&gt;No problem, I have choosen the two chars / byte approach for two reasons:&lt;/p&gt;

&lt;p&gt;a) it is simplier to generate lower precision terms (for 1-8 bytes precision) you just have to remove 2 chars per byte. in base 2^15, you only have 4 precisions and some more bits. The number of terms in my special TrieRangeFilter per precision would not be 256 values, it would be 32768, making it slower. Another posibility would be to cast each byte to one char (+offset), but see the next point:&lt;br/&gt;
b) Java sometimes has strange string comparisons, and I did not want to walk into incompatiblities with String.compareTo()&lt;/p&gt;

&lt;p&gt;But one other point you noted in the other JIRA issue is hurting me: I did not try to sort the results to my combined, prefixed field since long time, and you are right, it is not possible, if all different precisions are in the same field. A earlier version of TrieRangeQuery used a suffix after the field-name, automatically added by the TrieUtils.addXXXXTrieDocumentField. I reverted removed this about two years ago, but never tried to sort a numerical field since then. I think, I have to write a bug report for my own project &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; The question is, if this is included into contrib and I put a dependency in my project to this contrib pacakge, the index format of panFMP may change, which is not good.&lt;/p&gt;

&lt;p&gt;Just one question to other developers: Why is it not possible, to sort by a field with more than one term/doc, if you would restrict this to only use the &lt;b&gt;first&lt;/b&gt; added term to the document as sort key in FieldCache?&lt;/p&gt;</comment>
                    <comment id="12651056" author="earwin" created="Wed, 26 Nov 2008 16:48:29 +0000"  >&lt;blockquote&gt;&lt;p&gt;in base 2^15, you only have 4 precisions and some more bits&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;We have slightly different approaches. Yours is universal, and mine requires hand-tuning. I have an abstract FastRangeFilter, which I extend, specifying functions that lower precision before encoding, thus I have any required amount of type/field-dependent precision levels. For further ease of use that one is extended by FastDateRangeFilter, which accepts an array of date parts, like &lt;/p&gt;
{HOUR_OF_DAY, DAY_OF_MONTH}
&lt;p&gt;.&lt;br/&gt;
That allows me to exploit known statistical properties of my requests/data, for example most date ranges are rolling day/week/month/3 months windows, or salaries which tend to be attracted to certain values.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Java sometimes has strange string comparisons, and I did not want to walk into incompatiblities with String.compareTo()&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Fact that java strings are UCS-16 (UTF-16 minus special non-16bit characters) is written into java language specification, so you can trust String.compareTo() - anything that blows up there, is not Java(tm). Problems usually come from within libraries.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I did not try to sort the results to my combined, prefixed field since long time, and you are right, it is not possible, if all different precisions are in the same field.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Actually, right now I&apos;m &lt;del&gt;stealing&lt;/del&gt; borrowing your idea of storing various precisions in the same field. I have my own custom field cache, so broken sort can be fixed easily. Having everything in the same field allows you to do exactly one pass through TermEnum/TermDocs, and that is what I&apos;m going to exploit &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="12651061" author="thetaphi" created="Wed, 26 Nov 2008 17:05:16 +0000"  >&lt;p&gt;You are right, my intentation was to make it universal by casting everything to unsigned long. For the sorting problem:&lt;br/&gt;
With standard lucene, you can only sort when you have one term/field/doc. I am currently testing my code after modifying it to use a more compact version of the encoding:&lt;/p&gt;

&lt;p&gt;a) I do not encode half bytes, I encode full bytes per char. I still have 8 precisions after it, but code gets simplier and you have terms with length=8 chrs after encoding. After reading docs of String.compareTo() again, I understood the &quot;Java-Way&quot; of binary sort order and verified it with my test cases.&lt;/p&gt;

&lt;p&gt;b) the full precision is stored in the user-given document field name, all 7 lower precisions are prefixed (as before) and put into a &quot;helper&quot; field with suffix &quot;#trie&quot; after the name. This field is only indexed, not stored or anything else. This field is only used in TrieRangeFilter for the trie algorithm.&lt;/p&gt;

&lt;p&gt;For my project &lt;b&gt;panFMP&lt;/b&gt; it is not such a big problem, if you inform the &quot;few&quot; users using it (I know all of them) and ask them to do a index rebuild (for that a tool is available). But the encoding format of this contrib package should be fixed and discussed before it is released!&lt;/p&gt;</comment>
                    <comment id="12651070" author="earwin" created="Wed, 26 Nov 2008 17:26:37 +0000"  >&lt;blockquote&gt;&lt;p&gt;But the encoding format of this contrib package should be fixed and discussed before it is released!&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Make it pluggable? I have my encoding separate from range filters and precision loss, you can specify fields to use, etc-etc. Anyway, people can always copy your code and tweak it to their specific needs. For contribs, imho, the idea is much more valuable than actual implementation details.&lt;/p&gt;</comment>
                    <comment id="12651092" author="mikemccand" created="Wed, 26 Nov 2008 18:36:05 +0000"  >&lt;blockquote&gt;
&lt;p&gt;&amp;gt; Why is it not possible, to sort by a field with more than one&lt;br/&gt;
&amp;gt; term/doc, if you would restrict this to only use the first added term&lt;br/&gt;
&amp;gt; to the document as sort key in FieldCache?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This was discussed, but not resolved, in &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1372&quot; title=&quot;Proposal: introduce more sensible sorting when a doc has multiple values for a term&quot;&gt;&lt;del&gt;LUCENE-1372&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;If we wanted to allow &quot;use the first term&quot; as a policy, we&apos;d have to&lt;br/&gt;
fix how FieldCacheImpl computes the StringIndex: currently it gets a&lt;br/&gt;
TermEnum, walks through all terms, for each term walks through all&lt;br/&gt;
docs, and records docID-&amp;gt;termNumber as well as termNumber-&amp;gt;termText&lt;br/&gt;
arrays, un-inverting the field.  I guess we could get a TermPositions,&lt;br/&gt;
instead, and only pay attention to position=0 terms, and then only&lt;br/&gt;
increment t if there were any docs with position=0 occurrences of the&lt;br/&gt;
term.&lt;/p&gt;</comment>
                    <comment id="12651109" author="mikemccand" created="Wed, 26 Nov 2008 19:05:05 +0000"  >
&lt;p&gt;It seems like there are two things you might want to make &quot;pluggable&quot;:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Which hierarchical ranges to create &amp;amp; logic that creates them for&lt;br/&gt;
    a given value.  For certain types (dates) I think there&apos;s one&lt;br/&gt;
    obvious set of ranges (year, quarter, month, day, etc.).  For&lt;br/&gt;
    something like &quot;price&quot; it&apos;s probably more app dependent, eg if you&lt;br/&gt;
    present certain filters/facets to the user.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;What label is attached to each range, and the correspond decoder&lt;br/&gt;
    to map that label back into its upper/lower values.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;So we could provide good defaults for eg Date.  The labels would&lt;br/&gt;
ideally be things like 2007, 2008 and &quot;Jan 2008&quot;, &quot;Feb 2008&quot;, etc.  I&lt;br/&gt;
think?  Hmm &amp;#8211; except for the need to sort them &quot;properly&quot;.&lt;/p&gt;

&lt;p&gt;We really should change Lucene&apos;s terms so that they are opaque objects&lt;br/&gt;
(as KS/Lucy is doing).  This way you could store a Term like &quot;Feb&lt;br/&gt;
2008&quot; in the index, along with details like &quot;this is a generated&lt;br/&gt;
ranged datetime term&quot; and the numeric date details ie 02/2008, and&lt;br/&gt;
you&apos;d just have to export a compareTo to Lucene.&lt;/p&gt;</comment>
                    <comment id="12651160" author="thetaphi" created="Wed, 26 Nov 2008 22:19:04 +0000"  >&lt;p&gt;An updated version of the patch. The format of encoded terms is incompatible to the previous patch.&lt;/p&gt;

&lt;p&gt;Changed:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Each byte of the 8 byte longs is encoded as 1 char (see coments before) -&amp;gt; more compact&lt;/li&gt;
	&lt;li&gt;each byte is shifted by 0x30 when converted to char (e.g. value 0x05 is saved as char 0x35)&lt;/li&gt;
	&lt;li&gt;the lower precision terms are stored in a separate field (using the original fieldname+&quot;#trie&quot;). With that it is possible to sort the original field. The mentioned helper field is only index. The prefix for the lower precisions starts at char 0x20. By separating prefix and data ranges, later merging the separate and the original field is easily possible. Because of this lower precisions would be listed before higher precisions or the full precision in the ordered term list.&lt;/li&gt;
	&lt;li&gt;fix a small issue with checking a term two times (between two ranges)&lt;/li&gt;
	&lt;li&gt;added test for TrieRangeQuery with a full-bounded and half-open range.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I will say something about Mike&apos;s suggestions tomorrow, now it is to late!&lt;/p&gt;</comment>
                    <comment id="12651185" author="thetaphi" created="Wed, 26 Nov 2008 23:56:58 +0000"  >&lt;p&gt;I wanted to go to bed, but it is the same every time, cannot sleep &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;The discussions about TrieRangeQuery are the same like two years ago when I prepared the original paper cited in the documentation with my mentor/colleague Michael Diepenbroek (the second author on the paper) &amp;#8211; here my comments about the suggestions to Mike McCandless and Earwin, after looking into my notices, I can explain:&lt;/p&gt;

&lt;p&gt;When looking for the first time on the algorithm to split the range, the ideas of Mike and Earwin are very clear: You are both interested in Dates and both of you have the same idea, how to divide them into parts with different &quot;precisions&quot;. For dates it is rather simple: If you have a range between March 1999 and August 2006, the two precisions &quot;full years&quot; and &quot;months&quot; are very easy to understand when creating the ranges. You would have three range queries: Mar&apos;1999 ... Dec&apos;1999, 2000 ... 2005, Jan&apos;2006 ... Aug&apos;2006 very easy. You have to visit 10+6+8=24 terms. Simple. The maximum number of terms would be 12+12+numberOfTotalPossibleYears. This is easy to understand and very effective.&lt;/p&gt;

&lt;p&gt;My approach in principle does the same, but the values are simply devided into bytes. There is no problem with it to store the number of milliseconds since 1970-01-01 in different precisions. The total range of this long would be very very large (I do not want to calculate now how many years BC the value -2^-31ms would be). If you have a range like the one above you have e.g. longs like 0x0000323113422134 TO 0x0000325113422174. You see the frront is identical, the center of the range maybe only goes to the precision of 12 digits. I said the long ist divided into 8 bytes, so you would use only the end of the range in highest precsision, the center in lower. As the lowest precsison does not change (it would only change if you are thousands of years from start to end), my algorithm would not use it, it would only go downto the precision that exists. The if-clause &quot;(length==1 || minShort.compareTo(maxShort)&amp;gt;=0)&quot; is responsible for that. If the lower and upper end of the next lower precision range is zero or inverted, it is not further calculated.&lt;/p&gt;

&lt;p&gt;Because of this shortcut it does not make a difference if the term values are distributed in the index very far from each other or are all on one place (the algorithm works as good, if your index contains prices between 1$ and 100$ or if you have double that give ages of millions of years and you want to do a range select on them. Independent on the selected range the number of terms to be visited is limited by my algorithm to the number of 3825 = (a maximum of 255 terms in the lowermost range)&lt;ins&gt;(a maximum of 255 terms in the uppermost range)&lt;/ins&gt;(255)&lt;ins&gt;(255)&lt;/ins&gt;......+(255 in center of range). This is a hard limit, and this limit can only be reached if you would have an index with 2^64-2 documents, that have 2^64-2 different long values and you have a range that selects all of them (only in this case you have to visit 3825 terms!).&lt;/p&gt;

&lt;p&gt;You can test a little bit with the new test case in the latest patch (change some numbers) and uncomment the System.out.println() for the number of terms seen. You will see, even with large indexes, the number of terms in mostly about 400. Only very very seldom more terms were visited (I have seen in our 500,000 docs index only one case with 750 terms, which can happen if you have a non-homogenous dispersion of values that has a local maximum near one of the range bounds). Important: The TrieRangeQuery only makes sense if your index as a minimum of about 500 docs, if there are less, you mostly have to visit all terms. Just play with the test case and do some statistics!&lt;/p&gt;

&lt;p&gt;Because of all this, I see no real need for giving the user a customized way to convert the values into Terms and calculate lower precisions of it. The above code works performant (you have tested it yesterday with our index) even for doubles, that are very seldom homogenous distributed through the whole LONG range if stored as IEEE-754 bitmap. So TrieRangeQuery in the current version is effective for longs, doubles and Dates (as they are longs). The only problem would be fixed comma numbers with many digits (e.g. BigDecimals), they cannot simply casted to longs. For these type of numbers, TrieUtils could be extended to generate longer strings.&lt;/p&gt;

&lt;p&gt;To space usage: You are right, if you only want to have ranges on year/month, a long is too much. But keep in mind, the length of terms is not so important for index size, important is the number of different terms in the TermEnum. So I see no problem with storing integers and doubles and dates as a 64bit value in index - its only little bit extra term length with &quot;unused bits&quot;.&lt;/p&gt;</comment>
                    <comment id="12651279" author="paul.elschot@xs4all.nl" created="Thu, 27 Nov 2008 08:20:29 +0000"  >&lt;blockquote&gt;&lt;p&gt;Independent on the selected range the number of terms to be visited is limited by my algorithm to the number of 3825 = (a maximum of 255 terms in the lowermost range)(a maximum of 255 terms in the uppermost range)(255)(255)......+(255 in center of range).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The code uses a trie factor of 256, or 8 bits in a long of 64 bits.&lt;br/&gt;
Would it be possible to use lower values for this trie factor, like 16 (4 bits) or even 4 (2 bits)?&lt;br/&gt;
In such cases the (rough) maximum number of terms for a single ended range becomes smaller:&lt;br/&gt;
(256-1) * (64/8) = 255 * 8 = 2040&lt;br/&gt;
(16-1) * (64/4) = 15 * 16 = 240&lt;br/&gt;
(4-1) * (64/2) = 3 * 32 = 96&lt;br/&gt;
This reduction comes at the cost doubling or quadrupling the number of the indexed terms in the lower precision field.&lt;/p&gt;

&lt;p&gt;The number of characters in the lower precision terms is not really relevant in the term index, because terms are indexed with common prefixes. Therefore in these cases one could just use a character to encode the 4 bits or 2 bits.&lt;/p&gt;

&lt;p&gt;So the question is would it be possible to specify the trie factor when building and using the index?&lt;/p&gt;</comment>
                    <comment id="12651283" author="thetaphi" created="Thu, 27 Nov 2008 08:39:39 +0000"  >&lt;p&gt;I think, this would easyly be possible. Refactoring some code parts, special implementations of the encoder and incrementTrieCoded/decrementTrieCoded would be possible.&lt;br/&gt;
A possibility to make this configuraeable would be to use an instance of TrieUtils, that takes the trie factor as constructor argument. The user would then encode/decode all his values using the instance. TrieRangeFilter would also get an instance of the encoder and use it to calculate the prefix terms and so on.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The number of characters in the lower precision terms is not really relevant in the term index, because terms are indexed with common prefixes. Therefore in these cases one could just use a character to encode the 4 bits or 2 bits.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;So the question is would it be possible to specify the trie factor when building and using the index?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes thats good for jumping to the correct term to start in the range query. The problem with shorter trie factors would be, that for each precision (e.g. 4 bits, 2 bits) you need one full char in the encoded variant. As length is not a problem for terms, I think the common prefixed cannot be used so effective (a lot of terms with two low-cardinality chars at the beginning).&lt;/p&gt;</comment>
                    <comment id="12651288" author="thetaphi" created="Thu, 27 Nov 2008 08:45:50 +0000"  >&lt;blockquote&gt;&lt;p&gt;In such cases the (rough) maximum number of terms for a single ended range becomes smaller:&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Are you sure? My algorithm is more effective on single ended ranges (the number of terms is half the size of the terms of a two-ended range). When the lower bound is open, it is enough to use the lowest precision in the lower half of the range beginning (this special case is done in splitRange()). Higher precision terms only occur at bthe higher bound. This is why I use 255 and not 256 for my formula of the maximum number of terms (a range of all 256 terms in higher precision could easily reduced to the lower precision).&lt;/p&gt;</comment>
                    <comment id="12651291" author="paul.elschot@xs4all.nl" created="Thu, 27 Nov 2008 08:59:06 +0000"  >&lt;p&gt;I simply used the maximum number of terms at each level times the number of levels.&lt;br/&gt;
For a trie factor of 2**b (using b bits), and a long of 64 bits, that is:&lt;br/&gt;
(2**b - 1) * (64/b)&lt;br/&gt;
The actual values for b = 8, b = 4 and b = 2 are shown above.&lt;/p&gt;</comment>
                    <comment id="12651292" author="thetaphi" created="Thu, 27 Nov 2008 09:03:41 +0000"  >&lt;p&gt;You are right, thats correct! I misunderstood your answer. The number of terms for single ended ranges is about half of the terms for a two-ended range.&lt;/p&gt;</comment>
                    <comment id="12651293" author="paul.elschot@xs4all.nl" created="Thu, 27 Nov 2008 09:15:29 +0000"  >&lt;p&gt;So going from 8 bits to 4 bits will reduce the number of filter terms by a factor 8.5, for a cost of doubling the number of indexed terms. I&apos;d like to see actual performance figures, but on the face of it I&apos;d rather use 4 bits.&lt;/p&gt;</comment>
                    <comment id="12651310" author="thetaphi" created="Thu, 27 Nov 2008 10:19:54 +0000"  >&lt;p&gt;Just a update of the patch, before I want to implement Paul&apos;s suggestions on trie factor.&lt;/p&gt;

&lt;p&gt;The current patch has some performance improvements by avoid seeking back and forth in IndexReader&apos;s TermEnum. IndexReader&apos;s TermEnum may also better use caching. The parts of the range, that use Terms, that come earlier in the TermEnum are done first. The order is now:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Highest precision (because the field name of highest precision is not suffixed, and so the terms come earlier, &quot;fieldname&quot;&amp;lt;&quot;fieldname#trie&quot;)&lt;/li&gt;
	&lt;li&gt;Lower precision starting with the lowest one. The prefix of the lowest precision is the smallest (0x20) and goes up to 0x27&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;When looking into SegmentTermEnum&apos;s code, I realized that IndexReader.terms(Term t) is faster than only getting the complete TermEnum and then seekTo(Term). Why this difference? I first wanted to change my code to use only one instance (like with the TermDocs) of the TermEnum through the wohle range split prcess and seek the enum for each range, but I dropped that change.&lt;/p&gt;

&lt;p&gt;Further improvements of that patch are more comments and a cleaner (and more elegant) code in TrieUtils (without using a StringBuffer).&lt;/p&gt;</comment>
                    <comment id="12651315" author="mikemccand" created="Thu, 27 Nov 2008 10:33:59 +0000"  >&lt;p&gt;Sheesh, doesn&apos;t anyone sleep anymore?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;When looking into SegmentTermEnum&apos;s code, I realized that IndexReader.terms(Term t) is faster than only getting the complete TermEnum and then seekTo(Term).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Did you mean TermEnum.skipTo?  See &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1437&quot; title=&quot;Faster skipTo on SegmentTermEnum&quot;&gt;&lt;del&gt;LUCENE-1437&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                    <comment id="12651317" author="mikemccand" created="Thu, 27 Nov 2008 10:39:29 +0000"  >&lt;blockquote&gt;&lt;p&gt;My approach in principle does the same, but the values are simply devided into bytes.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I do very much like that your approach requires no &quot;application or type-specific knowledge&quot; on what might make good ranges.  Ie, it&apos;s generic, and so any type that can be cast into long and back w/o losing any information, can make use of this.&lt;/p&gt;</comment>
                    <comment id="12651318" author="thetaphi" created="Thu, 27 Nov 2008 10:44:38 +0000"  >&lt;blockquote&gt;&lt;p&gt;Did you mean TermEnum.skipTo? See &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1437&quot; title=&quot;Faster skipTo on SegmentTermEnum&quot;&gt;&lt;del&gt;LUCENE-1437&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes exactly that, I wrote seekTop(), but meant skipTo(). The patch in this issue is only a faster scanning approach, but the best would be to make skipTo() use the same logic like SegmentInfoReader.terms that uses seeking on disk and so on, but this comment would be  better for the above issue.&lt;/p&gt;

&lt;p&gt;I am fine with calling IndexReader.terms(Term) to use the cache and faster seeking. The cost of creating new instances of TermEnums is less than doing disk reads.&lt;/p&gt;</comment>
                    <comment id="12651339" author="paul.elschot@xs4all.nl" created="Thu, 27 Nov 2008 12:21:18 +0000"  >&lt;p&gt;When the trie factor can be chosen, it might make sense to encode it in the trie field name, something like:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;fieldName#trieNN&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;with NN the trie factor or its number of bits.&lt;/p&gt;</comment>
                    <comment id="12651367" author="thetaphi" created="Thu, 27 Nov 2008 15:08:11 +0000"  >&lt;p&gt;Here is a new version of the patch, supporting 8bit, 4bit and 2bit trie variant. The API is similar, but instead of using TrieUtils as static class, you can choose 3 singleton converters: e.g. TrieUtils.VARIANT_8BIT.convertSomething(). TrieRangeQuery and TrieRangeFilter both accept a parameter for choosing the variant. A default can be set with a static TrieRangeFilter.setDefaultTrieVariant(...) and the corresponding getter.&lt;/p&gt;

&lt;p&gt;To Paul&apos;s suggestion: You could put the trie variant into the filed name, but the main fieldname, where the full precision value is indexed/stored/whatever, has no suffix. This would make it inconsistent.&lt;/p&gt;

&lt;p&gt;In my opinion, one should choose the same trie variant when indexing values and doing range queries. It is the same like choosing another analyzer for indexing and searching. Maybe setting the default trie variant with this static method maybe better hosted in TrieUtils, but this is room for discussion.&lt;/p&gt;

&lt;p&gt;Now it is time to do some performance tests with really big indexes  comparing the trie variants &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; Does anybody has a synthetic benchmarker that can be easily used for this? The test case is not so interesting (uses RAMDirectory). I could reindex our PANGAEA index for performance testing in real world (doubles, dates).&lt;/p&gt;

&lt;p&gt;The testcase (if you uncomment the printout in TrieRangeFilter of number of terms) clearly shows the lower number of terms visited for 4bit or 2bit. Formulas are in the package description.&lt;/p&gt;

&lt;p&gt;In my opinion 4bit is a good alternative (about 3 times space requirement for about 8.5x less terms), but the impact of 2bit is to low for the about 6 times larger space.&lt;/p&gt;</comment>
                    <comment id="12651418" author="markh" created="Thu, 27 Nov 2008 21:19:06 +0000"  >&lt;p&gt;A note of caution - I noticed when moving from Lucene 2.3 to 2.4 that my similar scheme for encoding information meant that I couldn&apos;t encode information using byte arrays using bytes with values &amp;gt; 216.&lt;br/&gt;
The changes (I think in Lucene-510) introduced some code that modified the way the bytes were written/read and corrupted my encoding.&lt;/p&gt;

&lt;p&gt;Not sure if your proposed approach is prone to this or if anyone can cast further light on these encoding issues.&lt;/p&gt;

&lt;p&gt;Good to see this making its way into Lucene, Uwe.&lt;/p&gt;</comment>
                    <comment id="12651422" author="thetaphi" created="Thu, 27 Nov 2008 22:29:57 +0000"  >&lt;p&gt;I do not know what you had done in your code. Did you directly converted the byte[] arrays to a string, e.g. by using new String(byte[],charset) or without charset (in this case Java would use whats actual, but maybe its UTF-8)? Then, the character 216 (0xd8) would be interpreted by new String() as an UTF-8/16 sequence or whatever and map to some unknown char. UnicodeUtils, on the other hand, encodes the java chars to UTF-8 when storing in index, but does not like chars &amp;gt;0xd800 and replaces them by the replacement char for unknown chars. And this is a modification, as the char &amp;gt;0xd800 is not valid (see source of UnicodeUtils). and 0xd800 looks like 0xd8 (==216).&lt;/p&gt;

&lt;p&gt;My code does not transform a byte[] directly to a string, it creates a 16 bit standard java char of each byte with some offset. As the trie code only produces bytes between 0-255 and it adds a offset of 0x30 to it, the range of chars is 0x30..0x12f. This range is unicode safe and can be easily encoded to UTF-8. But I will make a explicit testcase for that tomorrow!&lt;/p&gt;

&lt;p&gt;Maybe your problem was the mentioned mis-use of directly generating strings from byte arrays using unknown/incorrect charset. Keep me informed!&lt;/p&gt;

&lt;p&gt;By the way Earwin Burrfoot: are you sure, your 15bit encoding works with the latest Lucene version, maybe this affects you, too?&lt;/p&gt;</comment>
                    <comment id="12651424" author="markh" created="Thu, 27 Nov 2008 22:44:51 +0000"  >&lt;p&gt;Yep, I was simply using new String(byte[]) &lt;/p&gt;</comment>
                    <comment id="12652002" author="nyh" created="Mon, 1 Dec 2008 13:52:09 +0000"  >&lt;p&gt;Hi, I just wanted to comment that a similar method was proposed in 2005 by several researchers in IBM (all of them have moved to Yahoo by now, actually). See &quot;Inverted Index Support for Numeric Search&quot;, by M Fontoura, R Lempel, R Qi, J Zien&lt;br/&gt;
&lt;a href=&quot;http://webcourse.cs.technion.ac.il/236620/Winter2006-2007/hw/WCFiles/paramsearch.pdf&quot; class=&quot;external-link&quot;&gt;http://webcourse.cs.technion.ac.il/236620/Winter2006-2007/hw/WCFiles/paramsearch.pdf&lt;/a&gt;&lt;br/&gt;
The paper contains some discussion on the tradeoffs between the number of layers, number of terms, index size, and so on, so it might contain some valuable ideas even if you don&apos;t use their scheme exactly.&lt;/p&gt;</comment>
                    <comment id="12652178" author="thetaphi" created="Mon, 1 Dec 2008 22:07:03 +0000"  >&lt;p&gt;Thank you, I did not know this paper. It is often rather complicated to find all papers about such subjects, very nice work!&lt;/p&gt;</comment>
                    <comment id="12652344" author="mikemccand" created="Tue, 2 Dec 2008 11:55:41 +0000"  >&lt;p&gt;Uwe, is this ready to be committed?  It looks good, and the tests pass.  Thanks!&lt;/p&gt;</comment>
                    <comment id="12652348" author="thetaphi" created="Tue, 2 Dec 2008 12:14:59 +0000"  >&lt;p&gt;It is almost complete. In my opinion the only change would be the setting of defaults. I wanted to move this into TrieUtils directly. Let me iterate one more patch and then we could commit. As I currently have no contributor status, it is simplier to first iterate the patch enough before committing. I was waiting for any additional comments before releasing a new patch version.&lt;/p&gt;

&lt;p&gt;I did not had time to do some benchmarks, so testing the three trie variants for speed/disk io/indexing speed is not yet done. My current benchmarks affect only the performance of my &quot;old&quot; trie code, not the new one using the more binary encoding. I asked for a good &quot;benchmarking framework&quot;, is contrib/benchmark useful for that? For benchmarking you need to create rather big indexes, maybe containing random numeric values. So the benchmark may also need much disk space (1 Gig?), ok you can leave out stored fields and additional full text fields, but the benchamrk should at last have also a normal tokenized field for performance with combining trie / ordinal term queries (like in the paper given by Nadav).&lt;/p&gt;

&lt;p&gt;Do you think, it is good to directly include it into contrib-search? In my opinion, it is, but maybe others think different.&lt;/p&gt;</comment>
                    <comment id="12652406" author="thetaphi" created="Tue, 2 Dec 2008 15:30:39 +0000"  >&lt;p&gt;New version of the patch:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;moved default trie variant handling to TrieUtils&lt;/li&gt;
	&lt;li&gt;method in TrieRangeFilter that returns the number of visited terms after execution of getDocIdSet()&lt;/li&gt;
	&lt;li&gt;tests print out the number of terms, other improvements to tests&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Just one question: is it ok to have a static initializer in the test to prevent the test from generating the rather large index for each test?&lt;/p&gt;</comment>
                    <comment id="12652413" author="thetaphi" created="Tue, 2 Dec 2008 16:03:17 +0000"  >&lt;p&gt;From my point of view: the patch is now ready to commit, all tests pass.&lt;/p&gt;

&lt;p&gt;The last patch also improved javadocs. Maybe some native speaker may please look into my javadocs, it is &quot;Denglish&quot; (as it is called in Germany)? &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="12652593" author="mikemccand" created="Tue, 2 Dec 2008 23:29:33 +0000"  >&lt;blockquote&gt;&lt;p&gt;I asked for a good &quot;benchmarking framework&quot;, is contrib/benchmark useful for that?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think it is good.  You should probably make your own DocMaker to create random number fields, or, make a big line file and use LineDocMaker.&lt;/p&gt;

&lt;p&gt;And then also create your own QueryMaker to create TrieRangeQuery&apos;s.&lt;/p&gt;

&lt;p&gt;One nice test to add, to assert correctness, would be to iterate N times, randomly picking lower/upper bounds, and compare the builtin RangeFilter vs the TrieRangeFilter, asserting that they pull the same docs?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;is it ok to have a static initializer in the test to prevent the test from generating the rather large index for each test?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think that&apos;s fine.&lt;/p&gt;</comment>
                    <comment id="12652780" author="thetaphi" created="Wed, 3 Dec 2008 13:27:35 +0000"  >&lt;p&gt;I have some first &quot;benchmarks&quot; on the three trie implementations. They were done using three indexes with same content, but encoded in 8bit, 4bit and 2bit, containing real-world data in 575,000 documents of the PANGAEA repository (see www.pangaea.de as mentioned before). The same range queries were executed after some warmup and time was measured until TopDocs returned the first 10 documents.&lt;/p&gt;

&lt;p&gt;The indexes each contain 13 numeric, tree encoded fields (doubles and Dates). Index size (including the &quot;normal&quot; fields) was:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;8bit: 4.8 GiB&lt;/li&gt;
	&lt;li&gt;4bit: 5.1 GiB&lt;/li&gt;
	&lt;li&gt;2bit: 5.7 GiB&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;So the addition 13*8*575,000 extra trie terms (with longer) size took 300 MB going from 8 to 4bit. Going from 4 to 2bit, the additional 13*16*575,000 extra terms took 600 MB (additional to the step from 8 to 4 bit, but its linear to the number of additional terms).&lt;/p&gt;

&lt;p&gt;The performance impact was neglectible (or better the standard deviation was bigger than the performance plus), so I think still, 8bit is a good idea and index size is the smallest.&lt;/p&gt;

&lt;p&gt;My idea, why this is so: Using fewer bits increases number of terms in index (I do not know how this decreases performance), needs more TermEnum seeks (for each trie precision, 2 seeking operations are needed). These term enum seeks are faster for 8bit trie varaint, because the 2 chars prefix can be used extensively (first prefix=precision, second char = first byte of numeric value). With 4bit and 2bit you get only 4bit or 2bits in addition to precision marker. So seeks in term enum are slower.&lt;/p&gt;

&lt;p&gt;In comparison a ConstantScoreRangeQuery on the full precision trie-coded values took about 10-20 times longer. Here the numbers:&lt;br/&gt;
For PANGAEA, all queries are half open (we have the problem, that data sets have ittself bounding boxes - minlatitude, maxlatitude, minlongitude, maxlongitude) and the user searches for bounding boxes, hits are datasets that &lt;b&gt;intersect&lt;/b&gt;  the search bounding box. So for a complete lat/lon constraint you have 4 half open ranges (with the current Trie implementation, this is not a problem, because two ANDed filters just withit half of the number of terms needed for a full range. The only performance impact is ANDing the two OpenBitSets). So 4 such half-open ranges ANDed together take the following times on the given index after some warmup, inkl fetching the first 10 documents:&lt;/p&gt;

&lt;p&gt;ConstantScoreRange: 1500-4000 ms&lt;br/&gt;
TrieRangeQuery 8bit: 40ms-100ms&lt;br/&gt;
TrieRangeQuery 4bit: 30ms-80ms&lt;br/&gt;
TrieRangeQuery 2bit: 20ms-80ms&lt;/p&gt;

&lt;p&gt;The old RangeQuery was not tested, but that hits the MaxClauseCount constraint, and if this is raised to Integer.MAX_VALUE, it tooks approx 1 minute to finish). The numbers are pure rnage queries, if you additionally add some search terms, time goes up a little bit. Used was only TrieRangeQuery (so rewrite to constant score), no docs were filtered in the classical way: termqueries + filtering of results.&lt;/p&gt;

&lt;p&gt;More benchmark results follow, when I finish the benchmarker. But these are real world examples. The search engine machine was a Sun X4600 machine with 16 opteron cores, 64bit Java 1.5, Sun Java System Web Server, -Xmx 8192M (our current configuration). On lower cost machnies like desktop pcs, the ConstantScoreRangeQuery takes much more time, but TrieRangeQuery is approx the same time, as disk io seeks is more the limiting factor. Processor speed and number of processors is not the limiting factor (if only one query is run in parallel).&lt;/p&gt;</comment>
                    <comment id="12652791" author="thetaphi" created="Wed, 3 Dec 2008 14:06:18 +0000"  >&lt;p&gt;Just one note: The queries in the comment before were taken on the same index with typical &quot;user queries&quot;, the hit count and ranges were rather large (e.g. queries with about 120,000 total hits, so the typical case water around Africa, like Mike McCandless did in his first tests). They were not synthetic, done on the real running productive system (I only have two X4600 sun machines..., so tests are most time done on the life system, e.g. like a open-heart surgery).&lt;/p&gt;</comment>
                    <comment id="12652865" author="paul.elschot@xs4all.nl" created="Wed, 3 Dec 2008 17:26:04 +0000"  >&lt;p&gt;Uwe, thanks very much for the size and performance info. The space/time tradeoff between 8 and 4 bits is clear, and it&apos;s great to have that fexibility.&lt;/p&gt;</comment>
                    <comment id="12652893" author="thetaphi" created="Wed, 3 Dec 2008 18:50:06 +0000"  >&lt;p&gt;New Patch, I think this is really ready to commit. Includes Mike&apos;s suggestion to compare the result count of RangeQuery with TrieRangeQuery with random values. Also contains a further test on result count of ranges with an index containing values with distance=1. This is to detect errors, when the code generating the splitted range may fail to correctly attach the range parts to each other.&lt;/p&gt;

&lt;p&gt;During changing my own project panFMP to use the new contrib package, I needed a function to read stored, trie-encoded values for re-indexing with another trie variant. The new static methods in TrieUtils choose the variant for decoding using the encoded string length. These static methods can be used for easy decoding of stored fields that use the trie encoding without knowing the encoding. For range queries, the encoding cannot be autodetected (which is clear).&lt;/p&gt;

&lt;p&gt;Further work maybe a optimized sort algorith for the trie encoded fields. Current FieldCache cannot handle them as longs, only as Strings which is memory intensive. Having a FieldCache implementation for longs that support this encoding would be good. I do not want to do this with the current unflexible FieldCache implementation, so I wait for &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-831&quot; title=&quot;Complete overhaul of FieldCache API/Implementation&quot;&gt;LUCENE-831&lt;/a&gt;. Has anybody an idea, how to plugin the correct FieldCache impl for this encoding in current Lucene, respecting the TrieUtils variant?&lt;/p&gt;</comment>
                    <comment id="12652897" author="mikemccand" created="Wed, 3 Dec 2008 18:54:42 +0000"  >&lt;p&gt;Those results are nice, thanks Uwe!  The open-heart surgery part was spooky though &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Index size (including the &quot;normal&quot; fields) was:&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;As a baseline, how large is an index with just the normal fields?&lt;/p&gt;

&lt;p&gt;I&apos;ll commit shortly.  This is a great addition!&lt;/p&gt;</comment>
                    <comment id="12652902" author="thetaphi" created="Wed, 3 Dec 2008 19:08:09 +0000"  >&lt;p&gt;I am sorry, one JavaDoc bug in the new static method, has a @link too much after @throws&lt;/p&gt;</comment>
                    <comment id="12652906" author="thetaphi" created="Wed, 3 Dec 2008 19:20:26 +0000"  >&lt;blockquote&gt;&lt;p&gt;As a baseline, how large is an index with just the normal fields?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This is not so simply to check out, I do not have such an index available and it takes long time to reindex &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; The 3 variants were generated last night on the X4600 monster machine, which took 2 hours there (in parallel).&lt;/p&gt;

&lt;p&gt;But as the step from 8 to 4 bits was about 300 MBytes space more and the step doubled the number of terms, the index without the numeric fields (if its still linear) should be about &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/warning.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; 4.5 GiB.&lt;/p&gt;

&lt;p&gt;Sometimes, when changing program code of &quot;live&quot; systems where users are working on (sometimes you cannot avoid it), I feel really like doing a open-heart surgery &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="12652917" author="mikemccand" created="Wed, 3 Dec 2008 19:30:29 +0000"  >&lt;blockquote&gt;&lt;p&gt;But as the step from 8 to 4 bits was about 300 MBytes space more and the step doubled the number of terms, the index without the numeric fields (if its still linear) should be about  4.5 GiB&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;OK thanks!&lt;/p&gt;</comment>
                    <comment id="12652924" author="mikemccand" created="Wed, 3 Dec 2008 19:39:26 +0000"  >&lt;p&gt;Committed revision 723031.&lt;/p&gt;

&lt;p&gt;Thanks Uwe!&lt;/p&gt;</comment>
                    <comment id="12653038" author="mikemccand" created="Wed, 3 Dec 2008 23:11:27 +0000"  >&lt;p&gt;Uwe, can&apos;t you use ExtendedFieldCache.getLongs, passing in your own LongParser?&lt;/p&gt;</comment>
                    <comment id="12653066" author="thetaphi" created="Wed, 3 Dec 2008 23:57:55 +0000"  >&lt;p&gt;The question is, how to plugin the whole FieldCache code from contrib? I see there is only one default ExtendedFieldCache named ExtendedFieldCacheImpl, but how do I implement a custom field cache and tell the searchers to use it whenever they see a Trie encoded field (e.g. when Sort.AUTO is used).? This is one thing, that I do not understand how to do.&lt;/p&gt;

&lt;p&gt;A very simple LongParser may be:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;  &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; LongParser() {
      &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; parseLong(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; value) {
        &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; TrieUtils.VARIANT_8BIT.trieCodedToLong(value);
      }
  };
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;But what to do with it for sorting search results...&lt;/p&gt;</comment>
                    <comment id="12653078" author="mikemccand" created="Thu, 4 Dec 2008 00:14:30 +0000"  >&lt;p&gt;I think if you call ExtendedFieldCache.EXT_DEFAULT.getLongs, first, with your parser, and then sort by that field as a long, it will just use what&apos;s already populated into the cache?  (It is sort of messy though; ideally there would be some way to record the LongParser you&apos;d like used for a given field).&lt;/p&gt;</comment>
                    <comment id="12653087" author="thetaphi" created="Thu, 4 Dec 2008 00:44:08 +0000"  >&lt;p&gt;This is messy and not easy to understand for a beginner. I was thinking of a possibility to supply a class in the contrib package o.a.l.search.trie that extends SortField or Sort or whatever else to mark a field explicitely as &quot;trie-encoded&quot; (which could also use the automatic trie variant detection in TrieUtils.trieCodedToLongAuto()), that can be used for calling Searcher.search(). And if TrieUtils would not be in Contrib, the AUTO parser could be extended to also try TrieUtils for deconding the field value (as it also throws NumberFormatException, it would fit in wonderful).&lt;/p&gt;

&lt;p&gt;Another idea was to overwrite ExtendedFieldCacheImpl and set it in the (non-final) static member ExtendedFieldCache.EXT_DEFAULT (which would be possible), but ExtendedFieldCacheImpl is package-protected. The whole sort thing is a bit messy, this is why I was hoping that &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-831&quot; title=&quot;Complete overhaul of FieldCache API/Implementation&quot;&gt;LUCENE-831&lt;/a&gt; may fix this problem in future, maybe we move this discussion to this issue.&lt;/p&gt;

&lt;p&gt;For the beginning, I could simply supply a static field parser instance in TrieUtils, e.g. LongParser named TrieUtils.TRIE_FIELD_CACHE_PARSER, that uses autodetection or the concrete trie variant.&lt;/p&gt;</comment>
                    <comment id="12653098" author="thetaphi" created="Thu, 4 Dec 2008 01:08:36 +0000"  >&lt;blockquote&gt;&lt;p&gt;I think if you call ExtendedFieldCache.EXT_DEFAULT.getLongs, first, with your parser, and then sort by that field as a long, it will just use what&apos;s already populated into the cache?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think, this cannot work. The Cache is keyed by FieldCacheImpl.Entry containing the parser to use. If search code would later call getLongs() with the default parser, it would get a new array of longs, not the one previously parsed with the specific parser, as there is no cache hit (because Entry is not equal). Do I miss something here?&lt;/p&gt;</comment>
                    <comment id="12653214" author="thetaphi" created="Thu, 4 Dec 2008 07:45:17 +0000"  >&lt;p&gt;Hi Mike,&lt;br/&gt;
the last Hudson build failed. It seems it did not like that I used &quot;LuceneTestCase&quot; instead of standard JUnit TestCase in one of the tests. I copied the source of this test from some other class. Maybe I cannot use LuceneTestCase in Contrib. But this is not a problem, it works identical with the JUNIT default class.&lt;/p&gt;</comment>
                    <comment id="12653218" author="thetaphi" created="Thu, 4 Dec 2008 08:30:28 +0000"  >&lt;p&gt;Sorry for again a new patch: When again looking into the test, I missed a test for the automatic encoding detection by string length (TrieUtils.trieCodedToXxxAuto()).&lt;br/&gt;
The appended patch fixes the hudson build and adds this test.&lt;/p&gt;</comment>
                    <comment id="12653257" author="mikemccand" created="Thu, 4 Dec 2008 11:02:15 +0000"  >&lt;p&gt;Hmm &amp;#8211; I would prefer that contrib tests subclass LiaTestCase.  We must be missing a dependency in the ant build files.&lt;/p&gt;

&lt;p&gt;OK this seems to fix it:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;Index: contrib/contrib-build.xml
===================================================================
--- contrib/contrib-build.xml	(revision 723145)
+++ contrib/contrib-build.xml	(working copy)
@@ -61,7 +61,7 @@
   &amp;lt;/target&amp;gt;
 
   
-  &amp;lt;target name=&lt;span class=&quot;code-quote&quot;&gt;&quot;init&quot;&lt;/span&gt; depends=&lt;span class=&quot;code-quote&quot;&gt;&quot;common.init,build-lucene&quot;&lt;/span&gt;/&amp;gt;
+  &amp;lt;target name=&lt;span class=&quot;code-quote&quot;&gt;&quot;init&quot;&lt;/span&gt; depends=&lt;span class=&quot;code-quote&quot;&gt;&quot;common.init,build-lucene,build-lucene-tests&quot;&lt;/span&gt;/&amp;gt;
   &amp;lt;target name=&lt;span class=&quot;code-quote&quot;&gt;&quot;compile-test&quot;&lt;/span&gt; depends=&lt;span class=&quot;code-quote&quot;&gt;&quot;init&quot;&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt;=&lt;span class=&quot;code-quote&quot;&gt;&quot;contrib.has.tests&quot;&lt;/span&gt;&amp;gt;
     &amp;lt;antcall target=&lt;span class=&quot;code-quote&quot;&gt;&quot;common.compile-test&quot;&lt;/span&gt; inheritRefs=&lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;&quot;&lt;/span&gt; /&amp;gt;
   &amp;lt;/target&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I&apos;ll commit that, and the fix to the test case.  Thanks Uwe!&lt;/p&gt;</comment>
                    <comment id="12653258" author="mikemccand" created="Thu, 4 Dec 2008 11:04:02 +0000"  >&lt;blockquote&gt;&lt;p&gt;Hmm - I would prefer that contrib tests subclass LiaTestCase&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Woops, I meant LuceneTestCase &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  Time sharing not working very well in my brain this morning...&lt;/p&gt;</comment>
                    <comment id="12653259" author="mikemccand" created="Thu, 4 Dec 2008 11:07:43 +0000"  >&lt;p&gt;Committed revision 723287.&lt;/p&gt;</comment>
                    <comment id="12653268" author="mikemccand" created="Thu, 4 Dec 2008 11:55:03 +0000"  >&lt;blockquote&gt;&lt;p&gt;I think, this cannot work. The Cache is keyed by FieldCacheImpl.Entry containing the parser to use.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Sigh, you are correct.  How would you fix FieldCache?&lt;/p&gt;

&lt;p&gt;I guess the workaround is to also index the original value (unencoded by TrieUtils) as an additional field, for sorting.&lt;/p&gt;</comment>
                    <comment id="12653270" author="thetaphi" created="Thu, 4 Dec 2008 12:02:20 +0000"  >&lt;p&gt;Thanks, then I would also change TestTrieRangeQuery to also use LuceneTestCase, just for completeness.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Sigh, you are correct. How would you fix FieldCache?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I would fix FieldCache by giving in SortField the possibility to supply a parser instance. So you create a SortField using a new constructor SortField(String field, int type, Object parser, boolean reverse). The parser is &quot;object&quot; bcause all parsers have no super-interface. The ideal solution would be to have:&lt;/p&gt;

&lt;p&gt;SortField(String field, int type, FieldCache.Parser parser, boolean reverse)&lt;/p&gt;

&lt;p&gt;and FieldCache.Parser is a super-interface (just empty, more like a marker-interface) of all other parsers (like LongParser...)&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I guess the workaround is to also index the original value (unencoded by TrieUtils) as an additional field, for sorting.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The problem with the extra field would be, that it works good for longs or doubles (with some extra work), but Dates still keep as String, or you use Date.getTime() as long. But this is not very elegant and needs more fields and terms. I prefer a clean solution.&lt;/p&gt;</comment>
                    <comment id="12653295" author="mikemccand" created="Thu, 4 Dec 2008 13:23:21 +0000"  >&lt;blockquote&gt;&lt;p&gt;Thanks, then I would also change TestTrieRangeQuery to also use LuceneTestCase, just for completeness. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;OK done.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;would fix FieldCache by giving in SortField the possibility to supply a parser instance. So you create a SortField using a new constructor SortField(String field, int type, Object parser, boolean reverse). The parser is &quot;object&quot; bcause all parsers have no super-interface.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This seems OK for now?  Can you open an issue?  Retro-fitting a super-interface would break back-compat for (admittedly very advanced) existing Parser instances external to Lucene, right?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;but Dates still keep as String, or you use Date.getTime() as long&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yeah.  But if we open the new issue (to allow external FieldCache parsers to be used when sorting) then one could parse to long directly from a TrieUtil encoded Date field, right?&lt;/p&gt;</comment>
                    <comment id="12653298" author="thetaphi" created="Thu, 4 Dec 2008 13:48:39 +0000"  >&lt;p&gt;Yes, I will open an issue! Maybe I maybe create a first patch after looking into the problem.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;This seems OK for now? Can you open an issue? Retro-fitting a super-interface would break back-compat for (admittedly very advanced) existing Parser instances external to Lucene, right?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I am not sure, but I think its better to leave it as now. On the other hand, if we just have a &quot;marker&quot; super-interface, it should be backwards compatible, because the new super-interface is new and existing code would only use the existing interfaces. New methods are not added by the super interface, so code would be source and binary compatible (as it only references the existing interfaces). I think we had this discussion some time in the past in another issue (Fieldable???), but this was another problem.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Yeah. But if we open the new issue (to allow external FieldCache parsers to be used when sorting) then one could parse to long directly from a TrieUtil encoded Date field, right?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Correct. As soon as this works, I would simply add as &quot;extra bonus&quot; o.a.l.search.trie.TrieSortField, that automatically supplys a correct parser for easy usage. Date, Double and Long trie fields can always be sorted as longs without knowing the correct meaning (because the trie format was designed like so).&lt;/p&gt;

&lt;p&gt;Currently my code would just sort the trie encoded fields using SortField.STRING, but this resource expensive (butI have no example currently running, as it was not needed for panFMP/PANGAEA and other projects).&lt;/p&gt;</comment>
                    <comment id="12653544" author="thetaphi" created="Thu, 4 Dec 2008 23:19:25 +0000"  >&lt;p&gt;Hi Mike,&lt;/p&gt;

&lt;p&gt;I opened issue &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1478&quot; title=&quot;Missing possibility to supply custom FieldParser when sorting search results&quot;&gt;&lt;del&gt;LUCENE-1478&lt;/del&gt;&lt;/a&gt; and attached a first patch.&lt;/p&gt;

&lt;p&gt;About the current issue: I have seen that TrieRangeQuery is missing in /lucene/java/trunk/contrib/queries/README.txt. Can you add it there or should I write a small patch? I think it should at least be mentioned there for what it is for, but the JavaDocs are much more informative and the corresponding paper / code credits are cited there.&lt;/p&gt;

&lt;p&gt;Thank you very much for helping to get this into Lucene!&lt;/p&gt;</comment>
                    <comment id="12653569" author="mikemccand" created="Fri, 5 Dec 2008 00:50:09 +0000"  >&lt;blockquote&gt;&lt;p&gt;Thank you very much for helping to get this into Lucene!&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;You&apos;re welcome!  But, that was the easy part &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  Thank you for creating it &amp;amp; getting it into Lucene!&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;About the current issue: I have seen that TrieRangeQuery is missing in /lucene/java/trunk/contrib/queries/README.txt.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I agree &amp;#8211; can you create a patch?  Thanks.&lt;/p&gt;</comment>
                    <comment id="12653719" author="thetaphi" created="Fri, 5 Dec 2008 09:48:07 +0000"  >&lt;p&gt;Here the readme changes.&lt;/p&gt;</comment>
                    <comment id="12653731" author="mikemccand" created="Fri, 5 Dec 2008 10:17:18 +0000"  >&lt;p&gt;Committed revision 723701.&lt;/p&gt;

&lt;p&gt;Thanks Uwe!&lt;/p&gt;</comment>
                    <comment id="12671495" author="yseeley@gmail.com" created="Sat, 7 Feb 2009 17:25:50 +0000"  >&lt;p&gt;Attaching completely untested prototype TrueUtils.java&lt;/p&gt;

&lt;p&gt;some discussion:&lt;br/&gt;
&lt;a href=&quot;http://www.lucidimagination.com/search/document/d62c0fd21d88f880&quot; class=&quot;external-link&quot;&gt;http://www.lucidimagination.com/search/document/d62c0fd21d88f880&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Features:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;same encode/decode code works for any variant... no 2,4,8 bit specific instances&lt;/li&gt;
	&lt;li&gt;decouples &quot;slicing&quot; of the value into different precisions and encoding of the slice to a String, allowing for the most efficient String encoding to be used for every prevision variant.&lt;/li&gt;
	&lt;li&gt;7 bit char encoding to optimize for UTF8 index storage&lt;/li&gt;
	&lt;li&gt;right justified to allow lucene to prefix compress efficiently&lt;/li&gt;
	&lt;li&gt;separates creation of sortableBits from trie encoding of those bits to avoid so many methods&lt;/li&gt;
	&lt;li&gt;allows indexing into multiple fields, or all in the same field&lt;/li&gt;
	&lt;li&gt;much smaller code should be much easier to understand&lt;/li&gt;
	&lt;li&gt;left out &quot;Date&quot; support - the average Java developer understands how to go from a Date to a long (unlike double, etc).&lt;/li&gt;
	&lt;li&gt;relatively trivial to add 32 bit (int/float) support and reuse code like addIndexedFields (which is just an agnostic helper method).&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="12671501" author="thetaphi" created="Sat, 7 Feb 2009 18:19:48 +0000"  >&lt;p&gt;Thanks for the code fragments, I can take this as basis and will implement the TrieRangeFilter counterpart. I have some more ideas (e.g. for the beginners API there is missing the possibility to &lt;b&gt;store&lt;/b&gt; the full-precision value). And norms should be disabled per default (in beginners API). 32bit support is also simple, as you noted.&lt;/p&gt;

&lt;p&gt;The problem is now, how to make TrieRangeFilter so generic, to support all posible encodings and field names possible (with your code, it would also be possible to put each precision in a separate field). I work on that, I want to have clean API on the TrieRangeFilter!&lt;/p&gt;

&lt;p&gt;I would name both addIndexedFields() and addField with the same name (just overload), but different options. I prepare that!&lt;/p&gt;

&lt;p&gt;I agree, date support is not needed. And if I would again add Date support, Calendars should also be possible etc. No need for that - Date should be deprecated by Sun!&lt;/p&gt;

&lt;p&gt;One question: The encoding is now different from NumberUtils again - NumberUtils tries to get the most out of each char vs. this tries to not affect UTF-8 encoding and use ASCII only? Would Solr use this encoding in future (7bit chars) for numeric values or should be both separate? These TrieUtils now also make it possible to not use trie coding, but encode doubles/longs for other use (and use the currently missing LongParser/SortField generators).&lt;/p&gt;</comment>
                    <comment id="12671502" author="thetaphi" created="Sat, 7 Feb 2009 18:29:09 +0000"  >&lt;p&gt;Adding that as comment:&lt;/p&gt;

&lt;p&gt;&amp;gt; On Sat, Feb 7, 2009 at 12:29 PM, Uwe Schindler &amp;lt;uwe@thetaphi.de&amp;gt; wrote:&lt;br/&gt;
&amp;gt; &amp;gt; This is only a minimal optimization, suitable for very large indexes.&lt;br/&gt;
&amp;gt; The&lt;br/&gt;
&amp;gt; &amp;gt; problem is: if you have many terms in highest precission (a lot of&lt;br/&gt;
&amp;gt; different&lt;br/&gt;
&amp;gt; &amp;gt; double values), seeking is more costly if you jump from higher to lower&lt;br/&gt;
&amp;gt; &amp;gt; precisions.&lt;br/&gt;
&amp;gt; &lt;br/&gt;
&amp;gt; That&apos;s my point... in very large indexes this should not result in any&lt;br/&gt;
&amp;gt; difference at all on average because the terms would be no where near&lt;br/&gt;
&amp;gt; each other.&lt;/p&gt;

&lt;p&gt;OK.&lt;/p&gt;

&lt;p&gt;I prepare a new TrieRangeFilter implementation, just taking the String[] fieldnames and the sortableLong and the precisionStep.&lt;/p&gt;

&lt;p&gt;And I think, you are right. We could completely remove the &quot;storing&quot; API. If one wants to add stored fields, he could use NumberUtils and do this separately (add stored, not indexed fields). For TrieRangeFilter it is not neded.&lt;/p&gt;

&lt;p&gt;&amp;gt; As an example: in a very big index, one wants to independently collect&lt;br/&gt;
&amp;gt; all documents that match &quot;apple&quot; and all documents that match &quot;zebra&quot;,&lt;br/&gt;
&amp;gt; which term you seek to first should not matter.&lt;/p&gt;

&lt;p&gt;OK, I agree &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="12671503" author="thetaphi" created="Sat, 7 Feb 2009 18:35:02 +0000"  >&lt;p&gt;Reopening this issue. I will later prepare a patch (have no time now, its now Saturday evening here in Germany), completely changing the current API and encoding, thanks Yonik! I think, the TrieRangeFilter will get smaller, too (ok, the c&apos;tors may stay for beginners). The Javadocs need to be updated too.&lt;/p&gt;

&lt;p&gt;I will also add missing methods for LongParser and SortField, as the encoded fields can be stored in ExtendedFieldCache (but there as real Longs, not sortableLongs) - as before.&lt;/p&gt;

&lt;p&gt;I will also add 32 bit API.&lt;/p&gt;

&lt;p&gt;Thanks, Yonik!&lt;/p&gt;</comment>
                    <comment id="12671504" author="yseeley@gmail.com" created="Sat, 7 Feb 2009 18:44:23 +0000"  >&lt;blockquote&gt;&lt;p&gt;for the beginners API there is missing the possibility to store the full-precision value&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;They could simply store it in a different field, in whatever format they desire, right?  It seems like TrieRange should be about range matching, not the format of stored fields.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;NumberUtils tries to get the most out of each char vs. this tries to not affect UTF-8 encoding and use ASCII only?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;NumberUtils in Solr was developed a &lt;b&gt;long&lt;/b&gt; time ago, before Parser support in the FieldCache, etc (Lucene 1.4).  I chose 14 bit numbers to minimize size in FieldCache using a StringIndex, and because I didn&apos;t understand Lucene prefix compression at the time &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;If there are to be many in-memory representations, then using 14 bit chars might be better.  Otherwise it seems like 7 bit might be preferable (better prefix compression, more predictable branches in the UTF8 encoder/decoder).  Of course it&apos;s a trivial switch, so perhaps we should just try and benchmark it when everything else is done.&lt;/p&gt;

&lt;p&gt;As for TrieRangeFilter, I guess the most generic constructor would look like:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;TrieRangeFilter(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; precisionStep, &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;[] fields, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; lowerSortableBits, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; upperSortableBits, &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; includeLower, &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; includeUpper)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

</comment>
                    <comment id="12671507" author="thetaphi" created="Sat, 7 Feb 2009 18:52:08 +0000"  >&lt;blockquote&gt;&lt;p&gt;NumberUtils in Solr was developed a long time ago, before Parser support in the FieldCache, etc (Lucene 1.4). I chose 14 bit numbers to minimize size in FieldCache using a StringIndex, and because I didn&apos;t understand Lucene prefix compression at the time &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The same here &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;. By the way, the new SortField constructors taking a LongParser (&lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1478&quot; title=&quot;Missing possibility to supply custom FieldParser when sorting search results&quot;&gt;&lt;del&gt;LUCENE-1478&lt;/del&gt;&lt;/a&gt;) as parameter make this very simple. You could so sort by the trie encoded field (and do not need to index them separately). Just use the LongParser supplied by TrieUtils to sort. No String sorting needed. I only wanted to supply static parsers based on TrieUtils for that.&lt;/p&gt;</comment>
                    <comment id="12671508" author="thetaphi" created="Sat, 7 Feb 2009 18:57:07 +0000"  >&lt;p&gt;For TrieRangeFilter I now also need something similar to the current increment/decrementTrieCoded, that adds 1 to a prefix coded value (in principle, just add 1&amp;lt;&amp;lt;shift to the long an use it, something like that) This is needed for the matching of the parts of the range. More later.&lt;/p&gt;</comment>
                    <comment id="12671539" author="thetaphi" created="Sat, 7 Feb 2009 23:32:18 +0000"  >&lt;p&gt;I modified the proposal TrieUtils a little bit. Maybe this class could get the new NumberUtils with the extra option to trie encode the values.&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Added 32bit support&lt;/li&gt;
	&lt;li&gt;Merged the unsigned int/long handling into prefixCode methods. For TrieRangeFilter the raw bits will not be needed (I need compareable signed ints/longs).&lt;/li&gt;
	&lt;li&gt;The conversion from doubles and floats was renamed and returns the standard signed long/int: doubleToSortableLong and floatToSortableInt, Date is removed (as just Date.getTime() can be used, as everybody knows).&lt;/li&gt;
	&lt;li&gt;Still missing are Long/IntParser for FieldCache and a SortField factory.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;It&apos;s still untested!&lt;/p&gt;

&lt;p&gt;I will implement tomorrow (now its time to go to bed) the TrieRangeFilter in two variants (one for 32 bit ints another for 64 bit longs). The min/max values are the ints/longs. The trie coding is also done using the shift value and bit magic. The results of the range split are then encoded using TrieUtils.xxxToPrefixCode().&lt;/p&gt;</comment>
                    <comment id="12671591" author="yseeley@gmail.com" created="Sun, 8 Feb 2009 14:30:08 +0000"  >&lt;blockquote&gt;&lt;p&gt;Merged the unsigned int/long handling into prefixCode methods. For TrieRangeFilter the raw bits will not be needed (I need compareable signed ints/longs).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Nice Uwe... we&apos;re really on the same wavelength now -  I came to the exact same conclusion and made the exact same changes!  It&apos;s much nicer having ints and longs as the exposed &quot;interface&quot;  so if a&amp;lt;b in java then a will come before b in the term index.&lt;/p&gt;</comment>
                    <comment id="12671593" author="thetaphi" created="Sun, 8 Feb 2009 14:35:59 +0000"  >&lt;p&gt;A fixed TrieUtils (a small bug in the encoding routine caused endless loop), the increment in array was missing &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    <comment id="12671594" author="thetaphi" created="Sun, 8 Feb 2009 14:39:56 +0000"  >&lt;p&gt;A first test version of TrieRangeFilter. Much of the functionality iss missing (no hashCode, some dead parts,....). But: it works. I modified the tests and get it running. Both variants (old and new) visit the same number of terms and get exact results.&lt;/p&gt;

&lt;p&gt;To do further testing it is now important, to generate Ranges with negative long. It seems to work, but I need more tests. It was a hell to get it running, I hate Sun for not having unsigned ints/longs in Java &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;TrieRangeQuery is obsolete now. You can wrap the Filter using a ConstantScore query or user TrieRangeFilter.asQuery() [which will return a nicer toString() output).&lt;/p&gt;

&lt;p&gt;I will now clean up everything and create a patch!&lt;/p&gt;</comment>
                    <comment id="12671624" author="thetaphi" created="Sun, 8 Feb 2009 14:48:15 +0000"  >&lt;p&gt;I forget to mention:&lt;br/&gt;
I modified the TrieUtils to have another SHIFT_START for ints and longs. By this you can earlier throw a NumberFormatException of you try to decode long using the int method or vice versa. I added these checks, to fail early, when old indexes using the different encoding are used or sorting may use the wrong encoding. TrieUtils still needs the FieldCache parser, but this is a trivial addition.&lt;/p&gt;</comment>
                    <comment id="12671625" author="thetaphi" created="Sun, 8 Feb 2009 14:52:31 +0000"  >&lt;p&gt;Yonik:&lt;br/&gt;
How would you hande a TrieRangeFilter for int&apos;s? I could create a separate class that looks identical (but uses the other TrieUtils methods and int instead of longs), or combine both in one class (which is hard). The problem is, you cannot have the same codebase, because masks, shifts, 31 vs. 63 is everywhere. And the other datatype.&lt;br/&gt;
If I do it, I will have two classes: TrieRangeFilter32, TrieRangeFilter64, alternatively TrieRangeFilterInt, TrieRangeFilterLong. Whats your opinion?&lt;/p&gt;</comment>
                    <comment id="12671627" author="thetaphi" created="Sun, 8 Feb 2009 15:15:30 +0000"  >&lt;p&gt;Now the next step: A corrected TrieUtils again.&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;contains the FieldCache parsers for easy usage and sort field factories.&lt;/li&gt;
	&lt;li&gt;changes the SHIFT for ints (0x80 was too much, UTF-8 optimization needs chars &amp;lt;0x80)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Sorting tests now also work.&lt;/p&gt;</comment>
                    <comment id="12671628" author="yseeley@gmail.com" created="Sun, 8 Feb 2009 15:37:24 +0000"  >&lt;p&gt;Uploading a new version of TrieUtils.&lt;/p&gt;

&lt;p&gt;I&apos;ve implemented my own range splitting logic (it will be interesting to see how it compares to yours, and if mine actually works!  so many edge cases...)&lt;/p&gt;

&lt;p&gt;It separates the range splitting logic from the execution of anything, so we can use the same logic to generate queries that match the same range (no building an OpenBitSet first), or other things like printable queries for debugging.&lt;/p&gt;

&lt;p&gt;After reflection, the RangeBuilder interface could be simplified to just have a single addRange() method... with the implicit assumption that all ranges are ORd together.&lt;/p&gt;</comment>
                    <comment id="12671629" author="yseeley@gmail.com" created="Sun, 8 Feb 2009 15:41:55 +0000"  >&lt;p&gt;Since filters are a symbolic representation (like Query), it makes sense to have separate TrieRangeFilter32 and TrieRangeFilter64 classes.&lt;br/&gt;
Hopefully most of the logic that is in common can be shared somehow.&lt;/p&gt;</comment>
                    <comment id="12671630" author="yseeley@gmail.com" created="Sun, 8 Feb 2009 15:46:06 +0000"  >&lt;p&gt;I &lt;b&gt;think&lt;/b&gt; the range splitting code I wrote is generic enough to also automatically handle 32 bits too.&lt;br/&gt;
I think it&apos;s just a matter of starting with a different shift?&lt;/p&gt;

&lt;p&gt;So for longs we have:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; buildRange(RangeBuilder builder, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; ll, &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; uu, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; precisionStep) {
    &lt;span class=&quot;code-comment&quot;&gt;// figure out where to start shift at
&lt;/span&gt;    &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; shift = ((64-1)/precisionStep) * precisionStep;
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; buildRange(builder, ll, uu, shift, precisionStep);
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And for ints, it would simply (hopefully) be:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; buildRange(RangeBuilder builder, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; ll, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; uu, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; precisionStep) {
    &lt;span class=&quot;code-comment&quot;&gt;// figure out where to start shift at
&lt;/span&gt;    &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; shift = ((32-1)/precisionStep) * precisionStep;
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; buildRange(builder, (&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;)ll, (&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;)uu, shift, precisionStep);
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Does that sound right?&lt;/p&gt;</comment>
                    <comment id="12671634" author="thetaphi" created="Sun, 8 Feb 2009 16:04:33 +0000"  >&lt;p&gt;I am still &quot;reading&quot; your code, but the main parts look identical (also the break condition, if no inner range available -&amp;gt; this condition is very important and must be min&amp;gt;=max). There are only differences between both are the generation of the inner range bounds. I just rewrote my old code, did you do it completely from scratch?&lt;/p&gt;

&lt;p&gt;I would change RangeBuilder to be only a interface/abstract class with no Object return code that has a addRange method. The range will always be or&apos;ed (anding makes no sense). The same idea came me, when I tried to unify the 32bit and 64 bit variant in my TrieRangeFilter code.&lt;/p&gt;

&lt;p&gt;For performance reasons, it is better to use the same TermEnum and TermDocs and only one OpenBitSet when executing the range. But this can be easily handled using the interface (RangeBuilder initializes the Openbitset, TermDocs and TermEnums, like in my code. When the range was built, the OpenBitset is retrieved).&lt;/p&gt;</comment>
                    <comment id="12671637" author="yseeley@gmail.com" created="Sun, 8 Feb 2009 16:17:31 +0000"  >&lt;blockquote&gt;&lt;p&gt;did you do it completely from scratch? &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yep, took me a while...  An interesting exercise and good news if it&apos;s so similar to yours.  Hard code like this is actually fun too &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I would change RangeBuilder to be only a interface/abstract class with no Object return code that has a addRange method.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Sounds fine - that means that RangeBuilder instances will always need to be stateful, but that seems flexible enough and simpler to understand than passing around Objects and casting.&lt;/p&gt;
</comment>
                    <comment id="12671638" author="thetaphi" created="Sun, 8 Feb 2009 16:19:55 +0000"  >&lt;p&gt;I like your idea, I will also use a generic Range splitter (as described before), but use my algorithm for it. But I am really interested how both compare. You can test this, if you use mine and enable the System.out in setBits (which is identical to your addRange()), that returns hexadecimals for each range.&lt;/p&gt;

&lt;p&gt;For nicer code, I would supply two interface to build ranges (int, long), because the TrieUtils always to correctly use int/long and the user may be confused if he gets longs (even if the api is very special for experts). But it can e.g. be used to create a BooleanQuery using classic RangeQueries or&apos;ed.&lt;/p&gt;</comment>
                    <comment id="12671639" author="thetaphi" created="Sun, 8 Feb 2009 16:27:17 +0000"  >&lt;p&gt;There may be one issue with signedness in your&apos;s and mine code for the special case of a precisionStep of 1. In this case the outermost/innermost calculation of the range bounds can fail, but I am not sure. I wanted to write a test for it.&lt;/p&gt;

&lt;p&gt;I am currently testing only 8, 4, 2 - as the results for that &lt;b&gt;must&lt;/b&gt; be identical to my old code (I also printed a lot of System.outs in my old code to generate a exact match of everything). There are some special cases in range splitting that are very sensitive. It took me also very long time to reimplement it. But the usage of longs/ints is really nicer and cleaner than incrementing/decrementing string values, as I did before.&lt;/p&gt;

&lt;p&gt;It is now also possible to use a completely other encoding, without changing the range splitting (e.g. to compare 7bit chars to 13/14 bit chars from NumberUtils).&lt;/p&gt;</comment>
                    <comment id="12671650" author="thetaphi" created="Sun, 8 Feb 2009 17:19:36 +0000"  >&lt;p&gt;Hi Yonik,&lt;/p&gt;

&lt;p&gt;I implemented the generic interface. I changed it a little bit (it throws now Exception, because without that the building of a range then needs wrapping the IOExceptions of IndexReader with a RuntimeException, not so nice). There are now 2 times the same implementation for 32 and 64 bit and two interfaces (long, int).&lt;/p&gt;

&lt;p&gt;The TrieRangeFilter is now a implementation using the LongRangeBuilder. The test, I used, is also there (just replace the files in contrib). The TrieUtilsTest is currently not working, TrieRangeQuery is obsolete.&lt;/p&gt;

&lt;p&gt;I think I will create a helper, that does the TermEnum/TermDocs iteration and reuse it in both LongTrieRangeFilter and IntTrieRangeFilter (maybe they get both the same superclass containing important methods useable for both).&lt;/p&gt;</comment>
                    <comment id="12671887" author="yseeley@gmail.com" created="Mon, 9 Feb 2009 15:09:26 +0000"  >&lt;p&gt;Oh I see.... one difference between our code is that you start at the lowest shift and I start at the highest.  Counting up has a nice effect of getting rid of the calculation of what shift to start at... I just had a harder time thinking about the recursion in that direction.&lt;/p&gt;

&lt;p&gt;Anyway, it&apos;s all looking great!&lt;/p&gt;

&lt;p&gt;Do we have test code that tests that the most efficient precision is used (as opposed to just the right bits matching?  i.e. for a precisionStep of 4&lt;br/&gt;
0x300-0x4ff could be matched with 3-4 with a shift of 8, or 30-4f with a shift of 4, or 300-4ff with a shift of 0.&lt;/p&gt;</comment>
                    <comment id="12671907" author="thetaphi" created="Mon, 9 Feb 2009 16:14:40 +0000"  >&lt;p&gt;I was preparing the whole day the final version, including all javadoc, but then i overwrote the wron file and the whole work of today (according trie) is away. Give me one more day, and I will redo everything. I changed since yesterday a lot in the trie code. Your code was a little bit better when the range bound of one precision was exact on the range&apos;s start or end (in this case the precision could be left out, in your code the boolean needUpper and needLower). I implemented this similar.&lt;/p&gt;

&lt;p&gt;I also extended the interface a little bit, but this is work I have to redo. So it takes now longer. Most work is writing documentation and javadocs. If everything had worked ok (and I did not overwrite/update svn in the wrong way, I would be finished now &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Do we have test code that tests that the most efficient precision is used (as opposed to just the right bits matching? i.e. for a precisionStep of 4&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;0x300-0x4ff could be matched with 3-4 with a shift of 8, or 30-4f with a shift of 4, or 300-4ff with a shift of 0.&lt;/p&gt;

&lt;p&gt;The most efficent precision is sometimes hard, but the optimization above with needUpper/needLower is really good sometimes (depends on the range). I think about it.&lt;/p&gt;

&lt;p&gt;Uwe&lt;/p&gt;</comment>
                    <comment id="12671990" author="thetaphi" created="Mon, 9 Feb 2009 20:05:50 +0000"  >&lt;blockquote&gt;
&lt;p&gt;Do we have test code that tests that the most efficient precision is used (as opposed to just the right bits matching? i.e. for a precisionStep of 4&lt;br/&gt;
0x300-0x4ff could be matched with 3-4 with a shift of 8, or 30-4f with a shift of 4, or 300-4ff with a shift of 0.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I misunderstood your note. My last optimizations (now they are again restored in my svn) exactly handle this. There are two cases:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if the left range of a precision has ((min &amp;amp; mask) == 0L) &lt;span class=&quot;error&quot;&gt;&amp;#91;starts exactly at the beginning of the next more unprecise range&amp;#93;&lt;/span&gt;, I leave out the left range for the actual precision and directly use the next lower prec&lt;/li&gt;
	&lt;li&gt;if the right range of a precision has ((max &amp;amp; mask) == mask) &lt;span class=&quot;error&quot;&gt;&amp;#91;ends exactly at the end of the next more unprecise range&amp;#93;&lt;/span&gt;, I do the same for the right one.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;My new code is now cleaner and easier to understand (there were some other unneeded extra shifts/ands in it). I also merged the 64 bit and 32 bit range splitting and wrap the RangeBuilder classes accordingly (now abstract with two different range collecting possibilities).&lt;/p&gt;

&lt;p&gt;The old code was not aware of this, leading to sometimes left/right precisions that are not needed. I will add test code in TestTrieUtils, that tests the range split (without an index). The problem here is, how to test this effectively. I could generate some examples and test for the resulting range bounds using a custom XxxRangeBuilder in the test, that collects the ranges into a List and compares this list). Do you have another prossibility to test this without a lot of manually checks example ranges?&lt;/p&gt;

&lt;p&gt;I have now restored all my changes (and did an extra backup). I will now write again the new Javadocs of TrieUtils and package.html. After that I will post a patch with the final API. The extra and new tests will be added later. First I want to fixate and document  the API.&lt;/p&gt;</comment>
                    <comment id="12672016" author="yseeley@gmail.com" created="Mon, 9 Feb 2009 21:28:23 +0000"  >&lt;blockquote&gt;&lt;p&gt;I could generate some examples and test for the resulting range bounds using a custom XxxRangeBuilder in the test, that collects the ranges into a List and compares this list).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;+1&lt;/p&gt;

&lt;p&gt;I think that, in conjunction with some random testing should be sufficient.&lt;/p&gt;</comment>
                    <comment id="12672027" author="thetaphi" created="Mon, 9 Feb 2009 21:47:26 +0000"  >&lt;p&gt;One of the trie filter test also checks, that the range is completely matched (when using a index with incrementing values). An additional test in TestTrieUtils can test for not having overlapping ranges. This can easily be tested using a OpenBitSet in which a RangeBuilder sets the bits. If it hits a bit two times, fails the test. I wrote this down here, to not forget it later, when writing this test.&lt;/p&gt;</comment>
                    <comment id="12672062" author="thetaphi" created="Mon, 9 Feb 2009 23:49:50 +0000"  >&lt;p&gt;This is the first patch for the revamp of TrieRange. It contains the complete API, a complete API documentation and some tests.&lt;/p&gt;

&lt;p&gt;Still missing is:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;TestIntTrieRangeFilter&lt;/li&gt;
	&lt;li&gt;TestTrieUtils (the old one is still there but commented out)&lt;/li&gt;
	&lt;li&gt;Tests as described in previous comments (in TestTrieUtils): No range overlap, most optimized rangeSplit&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Yonik: Can you look over it and say, if this is, what you would like to have for full flexibility and Solr (which needs this full flexibility)?&lt;/p&gt;

&lt;p&gt;All others: Is something missing in the API (like shortcuts), any comments?&lt;/p&gt;

&lt;p&gt;If everything is OK, I will commit the patch after adding the important tests.&lt;/p&gt;</comment>
                    <comment id="12672065" author="thetaphi" created="Mon, 9 Feb 2009 23:54:00 +0000"  >&lt;p&gt;Typos and wrong english in the docs can be fixed after the commit, merging of additional patches is simplier without all those small changes. The important things are API and functionality.&lt;/p&gt;

&lt;p&gt;Uwe&lt;/p&gt;</comment>
                    <comment id="12672459" author="thetaphi" created="Wed, 11 Feb 2009 00:05:43 +0000"  >&lt;p&gt;This is (hopefully) my last patch. It contains all tests and the final API (with some modifications).&lt;/p&gt;

&lt;p&gt;The split range test is a bit ugly, but it just test, if the algorithm works exactly like it should (but currently accepts no other order of addRange() calls when splitting the range) - and it tests only one &quot;reference&quot; range.&lt;/p&gt;

&lt;p&gt;Please give some comments, Yonik!&lt;/p&gt;</comment>
                    <comment id="12672623" author="yseeley@gmail.com" created="Wed, 11 Feb 2009 13:14:43 +0000"  >&lt;p&gt;Looking forward to the latest incarnation Uwe,  but I&apos;m traveling through the rest of the week... I&apos;ll definitely check it out at some point, but I liked the previous ones so you should go ahead and commit if you feel it&apos;s ready.&lt;/p&gt;</comment>
                    <comment id="12672630" author="thetaphi" created="Wed, 11 Feb 2009 13:34:34 +0000"  >&lt;p&gt;Thanks for the answer,&lt;/p&gt;

&lt;p&gt;My time is limited at the moment, too. I will commit Friday or the weekend!&lt;/p&gt;

&lt;p&gt;Uwe&lt;/p&gt;</comment>
                    <comment id="12673308" author="thetaphi" created="Fri, 13 Feb 2009 17:15:40 +0000"  >&lt;p&gt;New patch with:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;some optimizations in the splitRange (now it works even better) and more understandable again&lt;/li&gt;
	&lt;li&gt;split range now also works correct for precisionStep=1&lt;/li&gt;
	&lt;li&gt;new tests for splitRange (special cases are also tested, e.g. Long.MIN_VALUE..Long.MAX_VALUE can easily be done with only one range on the lowest precision)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I will commit soon.&lt;/p&gt;</comment>
                    <comment id="12673340" author="thetaphi" created="Fri, 13 Feb 2009 18:29:15 +0000"  >&lt;p&gt;Committed revision #744207&lt;/p&gt;</comment>
                    <comment id="12673405" author="thetaphi" created="Fri, 13 Feb 2009 22:40:58 +0000"  >&lt;p&gt;I forgot: Thanks Yonik for the good ideas and discussions about API and help with coding this new trie implementation!&lt;/p&gt;</comment>
                    <comment id="12673696" author="yseeley@gmail.com" created="Sun, 15 Feb 2009 19:17:09 +0000"  >&lt;p&gt;OK, I got a chance to further check things out and do some manual testing to ensure that the most efficient forms are always used.  Everything looks good!&lt;/p&gt;</comment>
                    <comment id="12673752" author="thetaphi" created="Sun, 15 Feb 2009 21:42:46 +0000"  >&lt;p&gt;Cool. So you like the new code? Are you happy with the API and how it works, is it good to use in Solr? If yes, it would be great and I am happy, that it is of use &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;There seem to be no problems, I converted my own code to use the new TrieRange API and I like it. No problems. 8bit precisionStep works good for me, my index with 13 numeric trie fields and 600,000 docs works fine, no performance differences, queries run amazingly fast. Index size is almost identical.&lt;/p&gt;

&lt;p&gt;I hope I will get some synthetic performance the next days, do you have some code for the performance contrib to check performance (I am not so familar with the performance code, I will check it out).&lt;/p&gt;

&lt;p&gt;Uwe&lt;/p&gt;</comment>
                    <comment id="12673912" author="ningli" created="Mon, 16 Feb 2009 16:06:04 +0000"  >&lt;p&gt;Good stuff!&lt;/p&gt;

&lt;p&gt;Is it worth to also have an option to specify the number of precisions to index a value?&lt;/p&gt;

&lt;p&gt;With a large precision step (say 8), a value is indexed in fewer terms (8) but the number of terms for a range can be large. With a small precision step (say 2), the number of terms for a range is smaller but a value is indexed in more terms (32). With precision step 2 and number of precisions set to 24, the number of terms for a range is still quite small but a value is indexed in 24 terms instead of 32. For applications usually query small ranges, the number of precisions can be further reduced.&lt;/p&gt;

&lt;p&gt;We can provide more options to make things more flexible. But we probably want a balance of flexibility vs. the complexity of user options. Does this number of precisions look like a good one?&lt;/p&gt;</comment>
                    <comment id="12673931" author="thetaphi" created="Mon, 16 Feb 2009 16:44:21 +0000"  >&lt;p&gt;Hi Ning,&lt;br/&gt;
thanks for suggesting. I was thinking abou that, too. In general an idea, would be to use 32 bit integers or floats, if you do not need  that much accuracy. In this case, the number of terms is reduced, too.&lt;br/&gt;
But it may be a good option, to specify a option, that values are indexed with the most possible precision and additionally indexed with lower precision values, too. But The precision step may be dynamic, like:&lt;br/&gt;
a) precision step gets bigger for lower precisions&lt;br/&gt;
b) after a precision of XXbits no mor lower precisions are generated and queried. This may be possible to implement by e.g. an array of precision step values that give the splitting of the whole long/int into different precisions (like 2-2-2-2-8-8-8-8-8-16, so precisie values use 2 bit precision step, e.g. from shift 0 to 2, but from shift 48 to 64 a step value of 16 is used).&lt;/p&gt;

&lt;p&gt;Uwe&lt;/p&gt;</comment>
                    <comment id="12674051" author="ningli" created="Mon, 16 Feb 2009 20:12:48 +0000"  >&lt;p&gt;Hi Uwe,&lt;/p&gt;

&lt;p&gt;I had something similar in mind when I said we can &quot;make things more flexible&quot;. Do you think it&apos;ll be too complex for users to specify? On the other hand, this is for experts so let experts have all the flexibility. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; We can open a different JIRA issue if we decide to go for it.&lt;/p&gt;</comment>
                    <comment id="12674066" author="thetaphi" created="Mon, 16 Feb 2009 21:15:39 +0000"  >&lt;p&gt;In principle it could be in the same way like the field names in the API: An array of precision step values as parameter where now only a single precisionStep is used. A shortcut would be the current API, that internally passes a one-item-array with the only precisionStep (if the array is shorter, the same logic with Math.min like on the field array). The simple-user API has only (like the current), one fieldname and one precision step, the full feaured api has an array of field names for each step and an array of precision step values.&lt;br/&gt;
But the problem with all this is, that the api gets complexer and complexer, so the simple shortcuts should also be provided and should be recommended.&lt;/p&gt;</comment>
                    <comment id="12674248" author="ningli" created="Tue, 17 Feb 2009 15:55:46 +0000"  >&lt;p&gt;Agree. Do you want to open a new issue? If you want, I can take a crack at it, but probably sometime next week.&lt;/p&gt;</comment>
                    <comment id="12674285" author="thetaphi" created="Tue, 17 Feb 2009 18:10:18 +0000"  >&lt;p&gt;A new issue would be good, can you open one? The idea for the patch is almost finished, I can attach a patch shortly. There are some minor things to solve and think about, but its not a big thing.&lt;/p&gt;</comment>
                    <comment id="12674648" author="thetaphi" created="Wed, 18 Feb 2009 15:15:04 +0000"  >&lt;p&gt;Removed the splitRange recursion and replaced by a simple loop. Committed rev #745533&lt;/p&gt;</comment>
                    <comment id="12675683" author="thetaphi" created="Sun, 22 Feb 2009 18:15:49 +0000"  >&lt;p&gt;A change for a more universal RangeBuilder API (as preparation for &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1541&quot; title=&quot;Trie range - make trie range indexing more flexible&quot;&gt;&lt;del&gt;LUCENE-1541&lt;/del&gt;&lt;/a&gt;). This patch also included the last commit that removes the recursion (for completeness).&lt;/p&gt;</comment>
                    <comment id="12675684" author="thetaphi" created="Sun, 22 Feb 2009 18:18:42 +0000"  >&lt;p&gt;Committed revision 746790.&lt;/p&gt;</comment>
                </comments>
                <issuelinks>
                        <issuelinktype id="10030">
                <name>Reference</name>
                                <outwardlinks description="relates to">
                            <issuelink>
            <issuekey id="12411367">SOLR-940</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12403462">LUCENE-1372</issuekey>
        </issuelink>
                    </outwardlinks>
                                                <inwardlinks description="is related to">
                            <issuelink>
            <issuekey id="12408791">LUCENE-1461</issuekey>
        </issuelink>
                    </inwardlinks>
                            </issuelinktype>
                    </issuelinks>
                <attachments>
                    <attachment id="12395271" name="fixbuild-LUCENE-1470.patch" size="2023" author="thetaphi" created="Thu, 4 Dec 2008 08:30:28 +0000" />
                    <attachment id="12395266" name="fixbuild-LUCENE-1470.patch" size="688" author="thetaphi" created="Thu, 4 Dec 2008 07:45:17 +0000" />
                    <attachment id="12400706" name="LUCENE-1470-apichange.patch" size="8147" author="thetaphi" created="Sun, 22 Feb 2009 18:15:49 +0000" />
                    <attachment id="12395203" name="LUCENE-1470.patch" size="57213" author="thetaphi" created="Wed, 3 Dec 2008 19:08:09 +0000" />
                    <attachment id="12395202" name="LUCENE-1470.patch" size="57221" author="thetaphi" created="Wed, 3 Dec 2008 18:50:06 +0000" />
                    <attachment id="12395097" name="LUCENE-1470.patch" size="52656" author="thetaphi" created="Tue, 2 Dec 2008 15:30:39 +0000" />
                    <attachment id="12394852" name="LUCENE-1470.patch" size="48979" author="thetaphi" created="Thu, 27 Nov 2008 15:08:11 +0000" />
                    <attachment id="12394833" name="LUCENE-1470.patch" size="40765" author="thetaphi" created="Thu, 27 Nov 2008 10:19:53 +0000" />
                    <attachment id="12394783" name="LUCENE-1470.patch" size="40000" author="thetaphi" created="Wed, 26 Nov 2008 22:19:04 +0000" />
                    <attachment id="12394742" name="LUCENE-1470.patch" size="32903" author="thetaphi" created="Wed, 26 Nov 2008 14:23:59 +0000" />
                    <attachment id="12395388" name="LUCENE-1470-readme.patch" size="2468" author="thetaphi" created="Fri, 5 Dec 2008 09:48:07 +0000" />
                    <attachment id="12400191" name="LUCENE-1470-revamp.patch" size="156737" author="thetaphi" created="Fri, 13 Feb 2009 17:15:40 +0000" />
                    <attachment id="12399956" name="LUCENE-1470-revamp.patch" size="152958" author="thetaphi" created="Wed, 11 Feb 2009 00:05:43 +0000" />
                    <attachment id="12399865" name="LUCENE-1470-revamp.patch" size="117299" author="thetaphi" created="Mon, 9 Feb 2009 23:49:50 +0000" />
                    <attachment id="12399768" name="TrieRangeFilter.java" size="11485" author="thetaphi" created="Sun, 8 Feb 2009 14:39:56 +0000" />
                    <attachment id="12399770" name="TrieUtils.java" size="13391" author="yseeley@gmail.com" created="Sun, 8 Feb 2009 15:37:24 +0000" />
                    <attachment id="12399769" name="TrieUtils.java" size="10875" author="thetaphi" created="Sun, 8 Feb 2009 15:15:30 +0000" />
                    <attachment id="12399767" name="TrieUtils.java" size="9046" author="thetaphi" created="Sun, 8 Feb 2009 14:35:59 +0000" />
                    <attachment id="12399742" name="TrieUtils.java" size="8668" author="thetaphi" created="Sat, 7 Feb 2009 23:32:18 +0000" />
                    <attachment id="12399728" name="TrieUtils.java" size="3475" author="yseeley@gmail.com" created="Sat, 7 Feb 2009 17:25:50 +0000" />
                    <attachment id="12399775" name="trie.zip" size="9165" author="thetaphi" created="Sun, 8 Feb 2009 17:19:36 +0000" />
                </attachments>
            <subtasks>
        </subtasks>
                <customfields>
                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                <customfieldname>Attachment count</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>21.0</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                <customfieldname>Date of First Response</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>Wed, 26 Nov 2008 14:34:50 +0000</customfieldvalue>

                </customfieldvalues>
            </customfield>
                                                                                                        <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Global Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>12281</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                <customfieldname>Lucene Fields</customfieldname>
                <customfieldvalues>
                        <customfieldvalue key="10121"><![CDATA[New]]></customfieldvalue>
    <customfieldvalue key="10120"><![CDATA[Patch Available]]></customfieldvalue>
    
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>26257</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                <customfieldname>Time in Status</customfieldname>
                <customfieldvalues>
                    
                </customfieldvalues>
            </customfield>
                            </customfields>
    </item>
</channel>
</rss>