<!-- 
RSS generated by JIRA (5.2.8#851-sha1:3262fdc28b4bc8b23784e13eadc26a22399f5d88) at Tue Jul 16 13:34:35 UTC 2013

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/LUCENE-2295/LUCENE-2295.xml?field=key&field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>5.2.8</version>
        <build-number>851</build-number>
        <build-date>26-02-2013</build-date>
    </build-info>

<item>
            <title>[LUCENE-2295] Create a MaxFieldLengthAnalyzer to wrap any other Analyzer and provide the same functionality as MaxFieldLength provided on IndexWriter</title>
                <link>https://issues.apache.org/jira/browse/LUCENE-2295</link>
                <project id="12310110" key="LUCENE">Lucene - Core</project>
                        <description>&lt;p&gt;A spinoff from &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-2294&quot; title=&quot;Create IndexWriterConfiguration and store all of IW configuration there&quot;&gt;&lt;del&gt;LUCENE-2294&lt;/del&gt;&lt;/a&gt;. Instead of asking the user to specify on IndexWriter his requested MFL limit, we can get rid of this setting entirely by providing an Analyzer which will wrap any other Analyzer and its TokenStream with a TokenFilter that keeps track of the number of tokens produced and stop when the limit has reached.&lt;/p&gt;

&lt;p&gt;This will remove any count tracking in IW&apos;s indexing, which is done even if I specified UNLIMITED for MFL.&lt;/p&gt;

&lt;p&gt;Let&apos;s try to do it for 3.1.&lt;/p&gt;</description>
                <environment></environment>
            <key id="12458229">LUCENE-2295</key>
            <summary>Create a MaxFieldLengthAnalyzer to wrap any other Analyzer and provide the same functionality as MaxFieldLength provided on IndexWriter</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                    <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png">Closed</status>
                    <resolution id="1">Fixed</resolution>
                                <assignee username="thetaphi">Uwe Schindler</assignee>
                                <reporter username="shaie">Shai Erera</reporter>
                        <labels>
                    </labels>
                <created>Fri, 5 Mar 2010 11:26:10 +0000</created>
                <updated>Mon, 16 May 2011 19:15:50 +0100</updated>
                    <resolved>Tue, 18 Jan 2011 12:03:35 +0000</resolved>
                                            <fixVersion>3.1</fixVersion>
                <fixVersion>4.0-ALPHA</fixVersion>
                                <component>modules/analysis</component>
                        <due></due>
                    <votes>0</votes>
                        <watches>0</watches>
                                                    <comments>
                    <comment id="12841822" author="shaie" created="Fri, 5 Mar 2010 11:40:15 +0000"  >&lt;p&gt;This will open the door for more extensible field-length limit - today MFL dictates the field length for all fields, while this Analyzer (TokenFilter actually) someone could wrap the TokenStream only for specific fields, and/or have fields with different limits. Just a thought.&lt;/p&gt;</comment>
                    <comment id="12841872" author="thetaphi" created="Fri, 5 Mar 2010 14:10:47 +0000"  >&lt;p&gt;The TokenFilter is quite easy, only few lines of code:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;no attributes to be registered&lt;/li&gt;
	&lt;li&gt;use a counter which is 0&lt;/li&gt;
	&lt;li&gt;override incrementToken() to update counter on true, return false when counter reaches limit or input exhausted&lt;/li&gt;
	&lt;li&gt;reset() resets counter&lt;/li&gt;
	&lt;li&gt;no other methods need to be overridden (this emulates the original behaviour of MaxFieldLength)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The Analyzer is more complicated as it should respect reusable streams. It should work like QueryAutoStopWordAnalyzer and maintain a Map of field names to chached streams. To detect if reusableTokenStream has reused a stream compare with cache. If new stream wrap.&lt;/p&gt;</comment>
                    <comment id="12841877" author="thetaphi" created="Fri, 5 Mar 2010 14:17:06 +0000"  >&lt;p&gt;&lt;del&gt;In the indexer, the backwards code is hairy: If a max limit is set, the indexer just plugs our Filter around the TokenStream. This would limit nr. of tokens for all cases:&lt;/del&gt;&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;&lt;del&gt;An ANALYZED field (wrapping the TokenStream got from Analyzer)&lt;/del&gt;&lt;/li&gt;
	&lt;li&gt;&lt;del&gt;A Field with ctor taking TokenStream: wrap the Field&apos;s TokenStream&lt;/del&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&lt;del&gt;We need some cache here, too &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &amp;#8211; The analyzer cannot be used because of (2).&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;For backwards we leave the code as it is and just remove the limiting code in 4.0. We just add coments, what needs to be removed.&lt;/p&gt;</comment>
                    <comment id="12841959" author="thetaphi" created="Fri, 5 Mar 2010 18:02:55 +0000"  >&lt;p&gt;After some discussion with rmuir, we realized, that an explicit reuse of the filter does not make sense. The maintenance of the Map&amp;lt;String,ReuseableStream&amp;gt; is more resource and maintenance than simply creating a class instance without any initialization cost.&lt;br/&gt;
The simple implementation of the Analyzer would be:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;override reusableTokenStream that delegates to the inner analyzer and wrap it with the filter. The cost of creating the filter is neglectible, as the filter has no initialization cost (it uses no attributes, does not create attribute maps,...)&lt;/li&gt;
	&lt;li&gt;override tokenStream that does the same, but instead delegates to inner analyzers tokenStream method.&lt;/li&gt;
	&lt;li&gt;Make this analyzer final, else we need VirtualMethod (also the TokenFilter, of course)&lt;/li&gt;
	&lt;li&gt;Override the rest of the methods in Analyzer and simply delegate. Don&apos;t forget the posIncr Gap methods and so on!&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I will supply a patch with filter and analyzer later.&lt;/p&gt;</comment>
                    <comment id="12842262" author="thetaphi" created="Sat, 6 Mar 2010 14:01:05 +0000"  >&lt;p&gt;Here is a first patch.&lt;/p&gt;

&lt;p&gt;Robert &amp;amp; me found a bug in CharTokenizer that it not correctly sets the endOffset when the underlying reader is not exhausted. This is fixed in the patch, too. The bug in CharTokenizer was also there when sombody used the MaxFieldLength with IW &amp;#8211; possible highlighting problems &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;Nevertheless, CharTokenizer should be rewritten, the code is not easy understandable. Too many states and branches and possibly uninitialized variables (i fixed by two asserts).&lt;/p&gt;

&lt;p&gt;Deprecating IW.MaxFieldLength is not yet added, this is just the new Filter/Analyzer.&lt;/p&gt;</comment>
                    <comment id="12842263" author="rcmuir" created="Sat, 6 Mar 2010 14:14:51 +0000"  >&lt;p&gt;Add this to the list of potential future checks in BaseTokenStreamTestcase.&lt;/p&gt;

&lt;p&gt;Perhaps we can use this new limiting analyzerwrapper in assertAnalyzesToReuse&lt;br/&gt;
to help determine if tokenstreams implement reset() correctly, versus just assuming&lt;br/&gt;
the entire stream will be consumed completely.&lt;/p&gt;</comment>
                    <comment id="12842384" author="thetaphi" created="Sun, 7 Mar 2010 09:49:51 +0000"  >&lt;p&gt;Further investigantions showed, that there is some difference between using this filter/analyzer and the current setting in IndexWriter. IndexWriter uses the given MaxFieldLength as maximum value for all instances of the same field name. So if you add 100 fields &quot;foo&quot; (with each 1,000 terms) and have the default of 10,000 tokens, DocInverter will index 10 of these field instances (10,000 terms in total) and the rest will be supressed.&lt;/p&gt;

&lt;p&gt;If you use the Filter, the limit is per TokenStream, so the above example will index all field instances and produce 100,000 terms.&lt;/p&gt;

&lt;p&gt;But the current IndexWriter code has a bug, too: The check for too many terms is done after the first token of each input stream is indexed, so in the abovce example, IW will index 10,089 terms, because once the limit is reached, each stream left will index one term. This could be fixed (if really needed, as the MaxFieldLength in IW should be deprecated) by moving the check up and dont even try to index the field and create the TokenStream.&lt;/p&gt;

&lt;p&gt;I just wanted to add this difference here for further discussing.&lt;/p&gt;</comment>
                    <comment id="12872205" author="thetaphi" created="Thu, 27 May 2010 13:51:01 +0100"  >&lt;p&gt;Updated patch for trunk.&lt;/p&gt;</comment>
                    <comment id="12873341" author="thetaphi" created="Sun, 30 May 2010 00:20:11 +0100"  >&lt;p&gt;Committed revision: 949445 (trunk), 949446 (3.x)&lt;/p&gt;</comment>
                    <comment id="12873397" author="mikemccand" created="Sun, 30 May 2010 11:06:14 +0100"  >&lt;blockquote&gt;&lt;p&gt;Further investigantions showed, that there is some difference between using this filter/analyzer and the current setting in IndexWriter. IndexWriter uses the given MaxFieldLength as maximum value for all instances of the same field name. So if you add 100 fields &quot;foo&quot; (with each 1,000 terms) and have the default of 10,000 tokens, DocInverter will index 10 of these field instances (10,000 terms in total) and the rest will be supressed.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;In &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-2450&quot; title=&quot;Explore write-once attr bindings in the analysis chain&quot;&gt;LUCENE-2450&lt;/a&gt; I&apos;m experimenting with having multi-valued fields be handled entirely by an analyzer stage, ie, the logical concatenation of tokens (with gaps) would &quot;hidden&quot; to IW, and IW would think its dealing with a single token stream.  In this model, if you then appended the new LimitTokenCountFilter to the end, I think it&apos;d result in the same behavior as maxFieldLength today.&lt;/p&gt;

&lt;p&gt;But, even before we eventually switch to that model... can&apos;t we still deprecate (on 3x) IW&apos;s maxFieldLength (remove from trunk) now?  I realize the limiting is different (applying the limit pre vs post concatenation), but I think the javadocs can explain this difference?  I think it&apos;s unlikely apps are relying on this specific interaction of truncation and multi-valued fields...&lt;/p&gt;</comment>
                    <comment id="12903135" author="rcmuir" created="Fri, 27 Aug 2010 00:10:03 +0100"  >&lt;p&gt;I&apos;m reopening this for discussion (both because it came up on the mailing list and Mike&apos;s question was never answered).&lt;/p&gt;

&lt;p&gt;I think the functionality added here is more flexible than the IW setting and we should consider deprecating/removing.&lt;/p&gt;</comment>
                    <comment id="12903279" author="thetaphi" created="Fri, 27 Aug 2010 08:44:43 +0100"  >&lt;p&gt;+1, I missed Mike&apos;s comment after resolving this issue!&lt;/p&gt;</comment>
                    <comment id="12982529" author="shaie" created="Mon, 17 Jan 2011 08:58:22 +0000"  >&lt;p&gt;I think the changes to 3x are less complicated than they seem - we don&apos;t need to deprecate anything, more than we already did. IndexWriterConfig is introduced in 3.1 and all IW ctors are already deprecated. So we can just remove the get/setMaxFieldLength from IWC and be done with it + some jdocs.&lt;/p&gt;

&lt;p&gt;Is that the intention behind the reopening of the issue?&lt;/p&gt;</comment>
                    <comment id="12982594" author="rcmuir" created="Mon, 17 Jan 2011 11:10:59 +0000"  >&lt;p&gt;Hi Shai, that sounds like the right solution to me!&lt;/p&gt;</comment>
                    <comment id="12983103" author="shaie" created="Tue, 18 Jan 2011 09:52:54 +0000"  >&lt;p&gt;Patch against 3x. Removed the get/set from IWC and changed code which used it. I also added some clarifying notes to the deprecation note in IW.setMaxFieldLength.&lt;/p&gt;

&lt;p&gt;I will post a separate patch for trunk where this setting will be removed altogether.&lt;/p&gt;</comment>
                    <comment id="12983144" author="shaie" created="Tue, 18 Jan 2011 11:15:13 +0000"  >&lt;p&gt;Patch against trunk - removes maxFieldLength handling from all the code.&lt;/p&gt;</comment>
                    <comment id="12983149" author="rcmuir" created="Tue, 18 Jan 2011 11:21:21 +0000"  >&lt;p&gt;Shai, the patch looks good to me. &lt;/p&gt;

&lt;p&gt;I would also say that with your trunk patch we can resolve &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-2086&quot; title=&quot;analysis.jsp should honor maxFieldLength setting&quot;&gt;SOLR-2086&lt;/a&gt;,&lt;br/&gt;
because then the maxFieldLength is totally implemented in the analyzer,&lt;br/&gt;
so tools like analysis.jsp will automatically work with it.&lt;/p&gt;</comment>
                    <comment id="12983164" author="shaie" created="Tue, 18 Jan 2011 12:03:35 +0000"  >&lt;p&gt;Committed revision 1060340 (trunk).&lt;br/&gt;
Committed revision 1060342 (3x).&lt;/p&gt;</comment>
                    <comment id="13013396" author="gsingers" created="Wed, 30 Mar 2011 16:50:12 +0100"  >&lt;p&gt;Bulk close for 3.1&lt;/p&gt;</comment>
                </comments>
                    <attachments>
                    <attachment id="12468631" name="LUCENE-2295-2-3x.patch" size="23192" author="shaie" created="Tue, 18 Jan 2011 09:52:54 +0000" />
                    <attachment id="12468639" name="LUCENE-2295-2-trunk.patch" size="24699" author="shaie" created="Tue, 18 Jan 2011 11:15:13 +0000" />
                    <attachment id="12438099" name="LUCENE-2295.patch" size="11197" author="thetaphi" created="Sat, 6 Mar 2010 14:01:05 +0000" />
                    <attachment id="12445651" name="LUCENE-2295-trunk.patch" size="13431" author="thetaphi" created="Thu, 27 May 2010 13:51:01 +0100" />
                </attachments>
            <subtasks>
        </subtasks>
                <customfields>
                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                <customfieldname>Attachment count</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>4.0</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                <customfieldname>Date of First Response</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>Fri, 5 Mar 2010 14:10:47 +0000</customfieldvalue>

                </customfieldvalues>
            </customfield>
                                                                                                        <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Global Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>11498</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                <customfieldname>Lucene Fields</customfieldname>
                <customfieldvalues>
                        <customfieldvalue key="10121"><![CDATA[New]]></customfieldvalue>
    <customfieldvalue key="10120"><![CDATA[Patch Available]]></customfieldvalue>
    
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>25430</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                <customfieldname>Time in Status</customfieldname>
                <customfieldvalues>
                    
                </customfieldvalues>
            </customfield>
                            </customfields>
    </item>
</channel>
</rss>