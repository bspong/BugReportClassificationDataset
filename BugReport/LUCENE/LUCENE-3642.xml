<!-- 
RSS generated by JIRA (5.2.8#851-sha1:3262fdc28b4bc8b23784e13eadc26a22399f5d88) at Tue Jul 16 13:07:27 UTC 2013

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/LUCENE-3642/LUCENE-3642.xml?field=key&field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>5.2.8</version>
        <build-number>851</build-number>
        <build-date>26-02-2013</build-date>
    </build-info>

<item>
            <title>[LUCENE-3642] EdgeNgrams creates invalid offsets</title>
                <link>https://issues.apache.org/jira/browse/LUCENE-3642</link>
                <project id="12310110" key="LUCENE">Lucene - Core</project>
                        <description>&lt;p&gt;A user reported this because it was causing his highlighting to throw an error.&lt;/p&gt;</description>
                <environment></environment>
            <key id="12534777">LUCENE-3642</key>
            <summary>EdgeNgrams creates invalid offsets</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                    <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png">Closed</status>
                    <resolution id="1">Fixed</resolution>
                                <assignee username="rcmuir">Robert Muir</assignee>
                                <reporter username="rcmuir">Robert Muir</reporter>
                        <labels>
                    </labels>
                <created>Mon, 12 Dec 2011 12:24:31 +0000</created>
                <updated>Fri, 10 May 2013 11:43:10 +0100</updated>
                    <resolved>Mon, 12 Dec 2011 18:59:30 +0000</resolved>
                            <version>3.5</version>
                                <fixVersion>3.6</fixVersion>
                <fixVersion>4.0-ALPHA</fixVersion>
                                        <due></due>
                    <votes>5</votes>
                        <watches>4</watches>
                                                    <comments>
                    <comment id="13167472" author="rcmuir" created="Mon, 12 Dec 2011 12:25:02 +0000"  >&lt;p&gt;screenshot from the user&lt;/p&gt;</comment>
                    <comment id="13167476" author="rcmuir" created="Mon, 12 Dec 2011 12:37:05 +0000"  >&lt;p&gt;I thought up a hackish way we can test for these invalid offsets for all filters... I&apos;ll see if it works.&lt;/p&gt;</comment>
                    <comment id="13167486" author="rcmuir" created="Mon, 12 Dec 2011 13:19:09 +0000"  >&lt;p&gt;here&apos;s a test.&lt;/p&gt;

&lt;p&gt;the problem is a previous filter &apos;lengthens&apos; this term by folding &#230; -&amp;gt; ae, but EdgeNGramFilter computes the offsets &quot;additively&quot;: offsetAtt.setOffset(tokStart + start, tokStart + end);&lt;/p&gt;

&lt;p&gt;Because of this if a word has been &apos;lengthened&apos; by a previous filter, edgengram will produce offsets that are longer than the original text. (and probably bogus ones if its been shortened).&lt;/p&gt;

&lt;p&gt;I think we should what WDF does here, if the original offsets have already been changed (startOffset + termLength != endOffset), then we should simply preserve them for the new subwords.&lt;/p&gt;

&lt;p&gt;I added a check for this to basetokenstreamtestcase... now to see if anything else fails... &lt;/p&gt;</comment>
                    <comment id="13167491" author="rcmuir" created="Mon, 12 Dec 2011 13:37:27 +0000"  >&lt;p&gt;so my assert trips for shit like whitespacespacetokenizer + lowercase... how horrible is that?&lt;/p&gt;

&lt;p&gt;There must be offset bugs in CharTokenizer... i&apos;ll dig into it.&lt;/p&gt;</comment>
                    <comment id="13167500" author="rcmuir" created="Mon, 12 Dec 2011 14:16:06 +0000"  >&lt;p&gt;Here&apos;s a patch fixing the (edge)ngrams filters, using the same logic as wdf (its well-defined, i think its the only thing we can do here).&lt;/p&gt;

&lt;p&gt;Still need to fix the chartokenizer bug, and also add some tests for any other &quot;filters that are actually tokenizers&quot; we might have.&lt;/p&gt;</comment>
                    <comment id="13167516" author="maxbeutel" created="Mon, 12 Dec 2011 14:58:40 +0000"  >&lt;p&gt;Robert, that patch for the EdgeNGramTokenFilter worked. If there occur any problems I let you know. Thanks!&lt;/p&gt;</comment>
                    <comment id="13167544" author="rcmuir" created="Mon, 12 Dec 2011 15:25:56 +0000"  >&lt;p&gt;Thanks Max, I am currently adding more tests/fixes for other broken tokenizers/filters with offset bugs.&lt;/p&gt;

&lt;p&gt;I&apos;ll update the patch when these are passing, but i think the ngrams stuff is ok.&lt;/p&gt;</comment>
                    <comment id="13167578" author="rcmuir" created="Mon, 12 Dec 2011 16:27:50 +0000"  >&lt;p&gt;updated patch with a test+fix for smartchinese, and with a test for CharTokenizer... it currently fails with an off by one (incorrect startOffset) which is in turn jacking up the endOffsets too. &lt;/p&gt;</comment>
                    <comment id="13167580" author="rcmuir" created="Mon, 12 Dec 2011 16:35:12 +0000"  >&lt;p&gt;here&apos;s the fix for CharTokenizer.&lt;/p&gt;

&lt;p&gt;Tests are passing, I will commit soon.&lt;/p&gt;</comment>
                    <comment id="13167585" author="rcmuir" created="Mon, 12 Dec 2011 16:41:40 +0000"  >&lt;p&gt;Just looking i see another bug in CharTOkenizer... i&apos;ll add another test.&lt;/p&gt;</comment>
                    <comment id="13167607" author="rcmuir" created="Mon, 12 Dec 2011 17:22:36 +0000"  >&lt;p&gt;patch with tests and fix for the additional bug in CharTokenizer.&lt;/p&gt;</comment>
                </comments>
                    <attachments>
                    <attachment id="12506995" name="6B2Uh.png" size="146659" author="rcmuir" created="Mon, 12 Dec 2011 12:25:01 +0000" />
                    <attachment id="12506999" name="LUCENE-3642_ngrams.patch" size="9442" author="rcmuir" created="Mon, 12 Dec 2011 14:16:06 +0000" />
                    <attachment id="12507018" name="LUCENE-3642.patch" size="25881" author="rcmuir" created="Mon, 12 Dec 2011 17:22:36 +0000" />
                    <attachment id="12507014" name="LUCENE-3642.patch" size="20918" author="rcmuir" created="Mon, 12 Dec 2011 16:35:12 +0000" />
                    <attachment id="12507012" name="LUCENE-3642.patch" size="19724" author="rcmuir" created="Mon, 12 Dec 2011 16:27:50 +0000" />
                    <attachment id="12506998" name="LUCENE-3642_test.patch" size="3478" author="rcmuir" created="Mon, 12 Dec 2011 13:19:08 +0000" />
                </attachments>
            <subtasks>
        </subtasks>
                <customfields>
                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                <customfieldname>Attachment count</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>6.0</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                <customfieldname>Date of First Response</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>Mon, 12 Dec 2011 14:58:40 +0000</customfieldvalue>

                </customfieldvalues>
            </customfield>
                                                                                                        <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Global Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>220462</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                <customfieldname>Lucene Fields</customfieldname>
                <customfieldvalues>
                        <customfieldvalue key="10121"><![CDATA[New]]></customfieldvalue>
    
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>24056</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                <customfieldname>Time in Status</customfieldname>
                <customfieldvalues>
                    
                </customfieldvalues>
            </customfield>
                            </customfields>
    </item>
</channel>
</rss>