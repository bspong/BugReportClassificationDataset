<!-- 
RSS generated by JIRA (5.2.8#851-sha1:3262fdc28b4bc8b23784e13eadc26a22399f5d88) at Tue Jul 16 13:29:24 UTC 2013

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/LUCENE-3653/LUCENE-3653.xml?field=key&field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>5.2.8</version>
        <build-number>851</build-number>
        <build-date>26-02-2013</build-date>
    </build-info>

<item>
            <title>[LUCENE-3653] Lucene Search not scalling</title>
                <link>https://issues.apache.org/jira/browse/LUCENE-3653</link>
                <project id="12310110" key="LUCENE">Lucene - Core</project>
                        <description>&lt;p&gt;I&apos;ve noticed that when doing thousands of searches in a single thread the average time is quite low i.e. a few milliseconds. When adding more concurrent searches doing exactly the same search the average time increases drastically. &lt;br/&gt;
I&apos;ve profiled the search classes and found that the whole of lucene blocks on &lt;/p&gt;

&lt;p&gt;org.apache.lucene.index.SegmentCoreReaders.getTermsReader&lt;br/&gt;
org.apache.lucene.util.VirtualMethod&lt;br/&gt;
  public synchronized int getImplementationDistance &lt;br/&gt;
org.apache.lucene.util.AttributeSourcew.getAttributeInterfaces&lt;/p&gt;

&lt;p&gt;These cause search times to increase from a few milliseconds to up to 2 seconds when doing 500 concurrent searches on the same in memory index. Note: That the index is not being updates at all, so not refresh methods are called at any stage.&lt;/p&gt;


&lt;p&gt;Some questions:&lt;br/&gt;
  Why do we need synchronization here?&lt;br/&gt;
  There must be a non-lockable solution for these, they basically cause lucene to be ok for single thread applications but disastrous for any concurrent implementation.&lt;/p&gt;

&lt;p&gt;I&apos;ll do some experiments by removing the synchronization from the methods of these classes.&lt;/p&gt;</description>
                <environment></environment>
            <key id="12535526">LUCENE-3653</key>
            <summary>Lucene Search not scalling</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                    <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png">Closed</status>
                    <resolution id="1">Fixed</resolution>
                                <assignee username="simonw">Simon Willnauer</assignee>
                                <reporter username="gerritjvv">Gerrit Jansen van Vuuren</reporter>
                        <labels>
                    </labels>
                <created>Fri, 16 Dec 2011 22:52:05 +0000</created>
                <updated>Fri, 10 May 2013 11:43:08 +0100</updated>
                    <resolved>Thu, 22 Dec 2011 12:37:58 +0000</resolved>
                                            <fixVersion>3.6</fixVersion>
                <fixVersion>4.0-ALPHA</fixVersion>
                                        <due></due>
                    <votes>0</votes>
                        <watches>0</watches>
                                                    <comments>
                    <comment id="13171367" author="thetaphi" created="Sat, 17 Dec 2011 00:30:18 +0000"  >&lt;p&gt;The problems you are mentioning are no issues at all:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;VirtualMethod is only used during class instantiations and class loading and must be synchronized. There is unlikely contention at all, just because its synchronized it does not mean its slow.&lt;/li&gt;
	&lt;li&gt;getAttributeInterfaces must be synchronized, too, as it has a reflection cache and is also only used during TokenStream instantiation. Analyzers should reuse TokenStreams so its not an issue at all. Fix your analyzers to resuse TokenStreams.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;On concurency the average time increases because of eventual contention in your file system directory implementation, not because methods may be synchronized.&lt;/p&gt;</comment>
                    <comment id="13171645" author="gerritjvv" created="Sat, 17 Dec 2011 19:27:38 +0000"  >&lt;p&gt;profile_1_&lt;span class=&quot;error&quot;&gt;&amp;#91;x&amp;#93;&lt;/span&gt;.png images shows lucene 3.4 used in the sample application App.java profiled using YourKit.&lt;/p&gt;

&lt;p&gt;1_a : shows the threads Blocking.&lt;br/&gt;
1_b : shows where the threads block. I went through all of the methods and almost all were blocking on SegmentCoreReaders&lt;br/&gt;
1_c : Shows the monitors on which the threads are blocking.&lt;/p&gt;


</comment>
                    <comment id="13171647" author="gerritjvv" created="Sat, 17 Dec 2011 19:30:08 +0000"  >&lt;p&gt;profile_2_&lt;span class=&quot;error&quot;&gt;&amp;#91;X&amp;#93;&lt;/span&gt;.png shows have lucene performs after having removed all synchronized methods from SegmentCoreReaders and some other areas which I&apos;m still investigating if they had effect or not.&lt;/p&gt;


&lt;p&gt;2_a : shows the thread view. Threads are not blocking any more but there is some thread sleep going on.&lt;/p&gt;
</comment>
                    <comment id="13171649" author="gerritjvv" created="Sat, 17 Dec 2011 19:37:49 +0000"  >&lt;p&gt;Hi Uwe,&lt;/p&gt;

&lt;p&gt;Thanks for the fast response. Maybe it would help you to understand my use case:&lt;/p&gt;

&lt;p&gt;-------------- Start ------------------------&lt;br/&gt;
I receive a customer request.&lt;br/&gt;
The create a Query based on the customer data.&lt;br/&gt;
Search a Lucene index in memory, not disk activity is done. i.e. I use RAMDirectory.&lt;br/&gt;
Then return the response to the customer.&lt;/p&gt;

&lt;p&gt;With a single request I get on average 3ms response times.&lt;br/&gt;
If I ramp it up to 200 requests I start getting 200-500ms response times.&lt;br/&gt;
------------ End ------------------------&lt;br/&gt;
For my application every millisecond counts, just does and out of my control.&lt;/p&gt;

&lt;p&gt;Assumptions:&lt;br/&gt;
 (1)  I create a new Instance of Query on each Request. The Query object is not shared ever. So, no locking is needed and no thread blocking should ever happen.&lt;br/&gt;
 (2)  The index is read only, and in memory so no OS file locking is applicable or will ever occur.&lt;br/&gt;
 (3) No index refresh happens and no writing, this is purely read only.&lt;/p&gt;

&lt;p&gt;Point is no need for locking anywhere.&lt;/p&gt;









</comment>
                    <comment id="13171652" author="gerritjvv" created="Sat, 17 Dec 2011 19:42:12 +0000"  >&lt;p&gt;Just to explain App.java:&lt;/p&gt;

&lt;p&gt;I&apos;ve created this app to show the problem.&lt;br/&gt;
Basically I create 500 threads.&lt;br/&gt;
 Each thread do:&lt;br/&gt;
        Create a Single Query.&lt;br/&gt;
        Does 10000 search requests against the lucene index.&lt;br/&gt;
        Calculate max,min,average&lt;br/&gt;
 Wait for threads to complete.&lt;br/&gt;
 Print out max,min,average&lt;/p&gt;


&lt;p&gt;The images attached are taken from profiling while running this class.&lt;/p&gt;
</comment>
                    <comment id="13171677" author="thetaphi" created="Sat, 17 Dec 2011 21:10:19 +0000"  >&lt;p&gt;Hi,&lt;/p&gt;

&lt;p&gt;short comment about your code and how to remove parts of the sync:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;The SegmentCoreReaders sync cannot be removed in Lucene 3.x, as segments are read/write. You can remove the synchronization partly in &lt;b&gt;your&lt;/b&gt; Lucene instance by patching it, the risk is on your side! This is not a bug in Lucene. In Lucene trunk, most of this sync is removed as IndexReaders will be pure read-only. We are currently working on removing contention in SegmentReader&apos;s SegmentCore.&lt;/li&gt;
	&lt;li&gt;You are not resusing the Analyzer. Create &lt;b&gt;one&lt;/b&gt; analyzer instance and reuse it for indexing and for QueryParser! When you do this, you will see no contention on TokenStream creation (VirtualMethod.getImplementationDistance, AttributeSource.getAttributeInterfaces). TokenStream creation by Analyzers is a heavy operation (not only the reflection cache contention), so use only one Analyzer per app and pass it to all you QueryParsers. Removing sync from AttributeSource/VirtualMethod caches will corrupt the cache and cause bugs - but thats unneeded if you reuse as already said.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    <comment id="13171691" author="simonw" created="Sat, 17 Dec 2011 22:10:50 +0000"  >&lt;blockquote&gt;&lt;p&gt;The SegmentCoreReaders sync cannot be removed in Lucene 3.x, as segments are read/write. You can remove the synchronization partly in your Lucene instance by patching it, the risk is on your side! This is not a bug in Lucene. In Lucene trunk, most of this sync is removed as IndexReaders will be pure read-only. We are currently working on removing contention in SegmentReader&apos;s SegmentCore.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Uwe, I had a quick look at it and I think we can remove this. We set the tis in the ctor or if we load a NRT reader. So basically we can assign the tisNoIndex reader to the tis instead of leaving it will a null ref and use a second boolean to actually signal if it was loaded or not. for read access this is not necessarily required to be synced since if you pull a NRT reader you can rely on the IW sync / mem barrier to see the latest reference. I will take a closer look at this next week.&lt;/p&gt;</comment>
                    <comment id="13171697" author="thetaphi" created="Sat, 17 Dec 2011 22:26:55 +0000"  >&lt;p&gt;Thanks Simon, Mike is currently working on that in Trunk (SegmentReader is getting so simple now...). For 3.x your solution might work.&lt;/p&gt;</comment>
                    <comment id="13171726" author="thetaphi" created="Sun, 18 Dec 2011 00:58:34 +0000"  >&lt;p&gt;Based on my work for another issue I added removal of synchronization for the caches in VirtualMethod and AttributeSource. As those caches are generally read (should be without synchronization) and seldom populated, ConcurrentHashMap is the best choice, as gets are without locks.&lt;br/&gt;
The problem is that those reflection caches need a WeakHashMap, but there is no ConcurrentWeakHashMap. Based on the work on issue &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-3531&quot; title=&quot;Improve CachingWrapperFilter to optionally also cache acceptDocs, if identical to liveDocs&quot;&gt;&lt;del&gt;LUCENE-3531&lt;/del&gt;&lt;/a&gt;, I reactivated my WeakIdentityMap and made the backing map exchangeable (there are 2 static factory methods allowing ConcurrentHashMap or simple HashMaps as backing map). For the reflection caches, identity is also fine (Class.equals/hashcode is based on class identity). The reflection caches also have no problem doing the heavy reflection work twice if two threads are requesting the same class at the same time - work is done twice and stored twice in map, but who cares?&lt;/p&gt;

&lt;p&gt;This patch improves concurrency on creation of TokenStreams and instantiation of all classes using VirtualMethod for backwards compatibility.&lt;/p&gt;</comment>
                    <comment id="13171739" author="thetaphi" created="Sun, 18 Dec 2011 01:23:52 +0000"  >&lt;p&gt;Updated patch (code cleanup, javadocs)&lt;/p&gt;</comment>
                    <comment id="13171742" author="gerritjvv" created="Sun, 18 Dec 2011 01:24:42 +0000"  >&lt;p&gt;Thanks, I&apos;ll keep an eye on the things happening in the trunk.&lt;/p&gt;

&lt;p&gt;Creating a Single Tokenizer does help, but the thread blocking still happens because of the synchronization used in several classes.&lt;/p&gt;

&lt;p&gt;I&apos;ve made some quick changes during the last few days on lucene-3.5, and have included the diff. (this is not an svn diff sorry).&lt;/p&gt;

&lt;p&gt;I agree, if anybody has to decide between, concurrency or storing things twice then concurrency wins, eventually all the cache data will be available to all threads, and the overhead goes away. But with synchronization the overhead never goes away.&lt;/p&gt;

&lt;p&gt;Some other points of contention are:&lt;br/&gt;
 RAMFile : all methods are synchronized.&lt;br/&gt;
 RAMInputStream: clone() &lt;br/&gt;
             This method came up during the profiling allot. I changed it from calling clone to: just create an new instance directly.&lt;/p&gt;



&lt;p&gt;I&apos;ll try to cleanup some of the code and add a better diff.&lt;/p&gt;
</comment>
                    <comment id="13171754" author="thetaphi" created="Sun, 18 Dec 2011 02:03:55 +0000"  >&lt;blockquote&gt;&lt;p&gt;Creating a Single -Tokenizer-Analyzer does help, but the thread blocking still happens because of the synchronization used in several classes.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Not reusing is stupid because of heavy construction cost (not contention)&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I agree, if anybody has to decide between, concurrency or storing things twice then concurrency wins, eventually all the cache data will be available to all threads, and the overhead goes away. But with synchronization the overhead never goes away.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;There are places where we cannot remove synchronization - and those places are no issue at all. Just because there is synchronization, there is not necessarily a bottleneck. Not everything you mention is an issue.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;RAMFile : all methods are synchronized.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;There is contention, but will not slowdown your search. Please keep synchronization there. every RAMFile is only opened once and then contention is gone. Not everything what your profiler shows as contention is one, only the first query will have some minor contention.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;RAMInputStream: clone() This method came up during the profiling allot. I changed it from calling clone to: just create an new instance directly.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Thats fine, but same applies here. You only have contention on first few queries.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I&apos;ll try to cleanup some of the code and add a better diff.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The VirtualMethod and AttributeSource is already fixed in my patch.&lt;/p&gt;

&lt;p&gt;On the time-line of your profiler output I see no improvement in speed. How much faster does your code get?&lt;/p&gt;</comment>
                    <comment id="13171760" author="gerritjvv" created="Sun, 18 Dec 2011 02:42:18 +0000"  >&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;There is contention, but will not slowdown your search. Please keep synchronization there. every RAMFile is&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;only opened once and then contention is gone.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;


&lt;p&gt;I&apos;m not clear on this one, you mean every RAMFile is opened once per search? or Will be reused across all searches? If the later all threads will block on RAMFile always, this is not minor but major, especially taking into account that I want to move from 200 concurrent requests to 8000.&lt;/p&gt;

&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;Not everything what your profiler shows as contention is one,only the first query will have some minor contention.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;


&lt;p&gt;&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  yes indeed. Thats why I&apos;ve run several tests with warmups and try to fish out based on call frequency, total time spent and total time a Thread  was blocking on a certain monitor.&lt;/p&gt;

&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;On the time-line of your profiler output I see no improvement in speed. How much faster does your code get?&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;


&lt;p&gt;I&apos;ve not profiled for individual search speed, but rather for contention, doing the tests on my laptop first and will move these changes to a production system during next week to test total search time with loading.&lt;/p&gt;

&lt;p&gt;With the current version i.e. with the synchronization in there the search times go up drastically, as I&apos;ve mentioned above. On our production deploy and indexes search times go from 3ms on single requests to 200-500ms and more on average when 200 concurrent requests are made. &lt;/p&gt;

</comment>
                    <comment id="13171800" author="thetaphi" created="Sun, 18 Dec 2011 08:47:55 +0000"  >&lt;blockquote&gt;&lt;p&gt;I&apos;m not clear on this one, you mean every RAMFile is opened once per search? or Will be reused across all searches? If the later all threads will block on RAMFile always, this is not minor but major, especially taking into account that I want to move from 200 concurrent requests to 8000.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Once per opening IndexReader, during searches there is no file open/closing done at all. Synchronization on the directory of files is only done when writing the files, and only when opening files during IndexReader openm, but not on every access. When files are deleted there are other contention points, but not during searches, as IndexReader is opened R/O.&lt;/p&gt;</comment>
                    <comment id="13171858" author="gerritjvv" created="Sun, 18 Dec 2011 13:01:37 +0000"  >&lt;p&gt;OK, so for searching (after loading) the RAMFile synced methods would not be called, now bare with me for a moment:&lt;/p&gt;

&lt;p&gt;This does not seem to be the case when you retrieve the Document, which is probably to be expected.&lt;br/&gt;
In my code I do:&lt;/p&gt;

&lt;p&gt;searcher.doc(matched&lt;span class=&quot;error&quot;&gt;&amp;#91;i&amp;#93;&lt;/span&gt;.doc) //searcher == IndexSearcer and matched[] == ScoreDoc[] &lt;/p&gt;

&lt;p&gt;In my code I see the following call trace (Top to Bottom):&lt;/p&gt;


&lt;p&gt;IndexSearcher.doc&lt;br/&gt;
IndexReader.document&lt;br/&gt;
DirectoryReader.document&lt;br/&gt;
SegementReader.document&lt;br/&gt;
FieldsReader.doc&lt;br/&gt;
RAMInputStream.seek&lt;br/&gt;
RAMInputStream.switchCurrentBuffer&lt;br/&gt;
RAMFile.getBuffer&lt;/p&gt;


&lt;p&gt;Which means I can search concurrently but as soon as I try to retrieve something again I hit contention. &lt;br/&gt;
Now I appreciate that with File IO this is required but a fully in memory index should not have these problems. I&apos;m trying to change the RAMFile usage so that it does not require synchronization.&lt;/p&gt;


</comment>
                    <comment id="13171899" author="thetaphi" created="Sun, 18 Dec 2011 17:01:48 +0000"  >&lt;p&gt;Updated patch with test for the concurrent weak hash map. I will commit this to 3.x and trunk as it improves the sophisticated&#8482; backwards layers and creation cost of AttributeSource (because ConcurrentHashMap has lockless get).&lt;/p&gt;

&lt;p&gt;I will keep this issue open for Simon to check the SegmentCoreReaders.&lt;/p&gt;</comment>
                    <comment id="13171905" author="thetaphi" created="Sun, 18 Dec 2011 17:36:35 +0000"  >&lt;p&gt;Committed VirtualMethod/AttributeSource improvements in trunk revision: 1220458, 3.x revision: 1220464&lt;/p&gt;</comment>
                    <comment id="13171949" author="thetaphi" created="Sun, 18 Dec 2011 22:35:35 +0000"  >&lt;p&gt;Committed improvement for WeakIndentityMap to not use ReferenceQueue on get/contains/remove operations, only put (trunk: 1220555, 3.x:  r1220557)&lt;/p&gt;</comment>
                    <comment id="13172111" author="simonw" created="Mon, 19 Dec 2011 08:51:28 +0000"  >&lt;p&gt;Gerrit, before I spend time on fixing this single IMO likely uncontented lock in org.apache.lucene.index.SegmentCoreReaders.getTermsReader() can I ask you to run your tests / benchmarks with -XX:BiasedLockingStartupDelay=0 as far as I can see you are running micro benchmarks which start up very quickly. Locks accessed right after startup behave differently in the JVM than other locks ie. sync blocks. Can you retest and report back?&lt;/p&gt;

&lt;p&gt;simon&lt;/p&gt;</comment>
                    <comment id="13172114" author="simonw" created="Mon, 19 Dec 2011 08:59:14 +0000"  >&lt;p&gt;here is a patch that removes the sync on SegmentCoreReaders#getTermsReader() - since this method is access on basically every search we should try to prevent any sync even if they are cheap in the uncontended case.&lt;/p&gt;</comment>
                    <comment id="13172167" author="gerritjvv" created="Mon, 19 Dec 2011 10:10:09 +0000"  >&lt;p&gt;Hi Simon,&lt;br/&gt;
Thanks, I&apos;ll try these on our production systems.&lt;br/&gt;
One other change I&apos;ve made, which I&apos;ll submit a patch for (pending testing) is introducing a ReadonlyRAMFile.&lt;/p&gt;

&lt;p&gt;Search for my use case is split into two:&lt;br/&gt;
             (1) Search &lt;br/&gt;
             (2) Get Stored data from index.&lt;br/&gt;
Now in an in memory index almost zero locking can be achieved.&lt;br/&gt;
   All the patches will do great for (1), the ReadonlyRAMFile seems to solve item (2).&lt;/p&gt;
</comment>
                    <comment id="13172190" author="gerritjvv" created="Mon, 19 Dec 2011 11:05:13 +0000"  >&lt;p&gt;These are the results from profiling with the Latest trunk checkout as from 2011-12-19 11:03.&lt;/p&gt;

&lt;p&gt;The Thread-LUCENE_3653.patch.png is without BiasedLockingStartupDelay.&lt;/p&gt;

&lt;p&gt;The others are with this option added to java + the patch.&lt;/p&gt;

&lt;p&gt;I&apos;ve included 3 images of the later so show that contention has improved but still other areas of contention exist that are probably related to the RAMFile itself being fully synchronized.&lt;/p&gt;</comment>
                    <comment id="13172210" author="rcmuir" created="Mon, 19 Dec 2011 11:47:44 +0000"  >&lt;p&gt;I think this is all profiler ghosts.&lt;/p&gt;

&lt;p&gt;Guys lets be careful not to introduce bugs over what isn&apos;t a performance problem at all.&lt;/p&gt;</comment>
                    <comment id="13172214" author="mikemccand" created="Mon, 19 Dec 2011 12:01:40 +0000"  >&lt;p&gt;Why are we using ConcurrentHashMap when we know there&apos;s a JVM deadlock bug, on certain 1.5.x&apos;s and certain CPUs...?  (&lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-3235&quot; title=&quot;TestDoubleBarrelLRUCache hangs under Java 1.5, 3.x and trunk, likely JVM bug&quot;&gt;LUCENE-3235&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;Shouldn&apos;t we move in the other direction here (don&apos;t use CHM unless it cannot be avoided)?&lt;/p&gt;

&lt;p&gt;For example it&apos;s crazy to use this class to back the core/reader closed listeners.... and I don&apos;t think we should back the AttrSource with it...?&lt;/p&gt;</comment>
                    <comment id="13172217" author="thetaphi" created="Mon, 19 Dec 2011 12:12:50 +0000"  >&lt;blockquote&gt;&lt;p&gt;For example it&apos;s crazy to use this class to back the core/reader closed listeners.... and I don&apos;t think we should back the AttrSource with it...?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;CHM is only risky on contention. Contention here is unlikely as once all classes are &quot;inspected&quot; there are only read accesses.&lt;/p&gt;

&lt;p&gt;On my tests, creating lots of AttributeSources and IndexSearchers are improved. The problem is that both VirtualMethod and AttributeSource block on construction on these cache locks.&lt;/p&gt;</comment>
                    <comment id="13172218" author="simonw" created="Mon, 19 Dec 2011 12:13:00 +0000"  >&lt;p&gt;Gerrit, I looked at your test and what you are seeing with soo many threads is certainly profiler ghosts. 500 threads is a lot even on a highly concurrent system. the blocking you see might not be due to a monitor.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I think this is all profiler ghosts.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I disagree I ran Gerrits simple test with 100 threads and its 2x faster without the locking on SegmentCoreReaders#getTermsReader() I agree this is not the part which takes time on a big index but this locking is certainly unnecessary and it takes up CPU resources. We should make the path down the IR as efficient as possible. &lt;/p&gt;

&lt;p&gt;I will attache my profiling session with and without the patch and you will see the differences.&lt;/p&gt;</comment>
                    <comment id="13172219" author="simonw" created="Mon, 19 Dec 2011 12:14:12 +0000"  >&lt;p&gt;here are two runs with 100 threads and 100000 iterations per thread. I think this is definitly something we can prevent with the &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-3653&quot; title=&quot;Lucene Search not scalling&quot;&gt;&lt;del&gt;LUCENE-3653&lt;/del&gt;&lt;/a&gt;.patch&lt;/p&gt;</comment>
                    <comment id="13172224" author="rcmuir" created="Mon, 19 Dec 2011 12:22:02 +0000"  >&lt;blockquote&gt;
&lt;p&gt;I disagree I ran Gerrits simple test with 100 threads and its 2x faster without the locking on SegmentCoreReaders#getTermsReader() &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Wait, if this stuff is a big problem, surely we can just use luceneutil with lots of threads right?&lt;/p&gt;

&lt;p&gt;I want to see the QPS change, I don&apos;t trust the benchmarks or the various fancy jvm tools being used on this issue. I think its all ghosts.&lt;/p&gt;</comment>
                    <comment id="13172229" author="simonw" created="Mon, 19 Dec 2011 12:32:51 +0000"  >&lt;blockquote&gt;&lt;p&gt;Wait, if this stuff is a big problem, surely we can just use luceneutil with lots of threads right?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;as I said, the index is tiny so just measuring the overhead of the lock on SegmentCoreReaders#getTermsReader() - this is a low hanging fruit IMO which we should pick even  if there is no real change in QPS. Its unnecessary and the patch is simple, any objections?&lt;/p&gt;</comment>
                    <comment id="13172234" author="thetaphi" created="Mon, 19 Dec 2011 12:37:26 +0000"  >&lt;p&gt;I general if we can remove contention anywhere we should do it. As I said, contention on thing that generally only reads but very seldom writes is horrible. Just write a test that creates 200 threads and creates TokenStreams or IndexSearchers (around a single IndexReader). They will all lock on the cache (ok, without reflection cache it would even be slower...)&lt;/p&gt;</comment>
                    <comment id="13172242" author="rcmuir" created="Mon, 19 Dec 2011 12:50:32 +0000"  >&lt;blockquote&gt;
&lt;p&gt;Just write a test that creates 200 threads and creates TokenStreams or IndexSearchers (around a single IndexReader). They will all lock on the cache (ok, without reflection cache it would even be slower...)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don&apos;t care. They should be reusing tokenstreams in their application.&lt;/p&gt;

&lt;p&gt;We don&apos;t need to make lucene more complicated to (possibly) speed up someones broken code.&lt;/p&gt;

&lt;p&gt;Lots of commits here, a title that says &apos;lucene doesn&apos;t scale, lots of arguing that there are locking problems, but not one luceneutil benchmark run?&lt;/p&gt;

&lt;p&gt;Seriously?&lt;/p&gt;</comment>
                    <comment id="13172258" author="thetaphi" created="Mon, 19 Dec 2011 13:22:24 +0000"  >&lt;p&gt;The code for the commit was standing here more than 24 hours and was tested extensively to remove contention on creation on all classes using VirtualMethod (IndexSearcher and TokenStream are only example). What&apos;s your problem with it? The latest commit 1 hr ago was only a fix in the tests and had nothing to do with ConcurrentHashMap.&lt;/p&gt;

&lt;p&gt;As I said, CHM is used for read-access only, but the guard is needed, if two ctors are running at same time and need to add a new entry to cache. All other cases are read-only, so lockless is better. It is just stupid to wait on a ctor, just because there is a lock on a map thats never be updated once your code is running an no new classes using VirtualMethod are loaded. We can also use Google Guava to use their MapMaker or wait until Java 8, where Doug Lea&apos;s ConcurrentWeakHashMap is maybe added (JSR-166).&lt;/p&gt;

&lt;p&gt;In fact the code of AttributeSource got simplier because we have no sync blocks.&lt;/p&gt;</comment>
                    <comment id="13172274" author="thetaphi" created="Mon, 19 Dec 2011 13:48:16 +0000"  >&lt;blockquote&gt;&lt;p&gt;For example it&apos;s crazy to use this class &lt;span class=&quot;error&quot;&gt;&amp;#91;ConcurrentHashMap&amp;#93;&lt;/span&gt; to back the core/reader closed listeners&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This is indeed totally crazy, as this is the wrong use-case for this map. This map should be used when you have lot&apos;s of reads and less writes to the map. For this case, you have only one thread reading (on close only, LOL), but maybe mayn adding listeners. So this is in general a bug to use CHM here. Should be a simple sycnrhonized HashMap (which performs better on writes, as it has less complexity inside).&lt;/p&gt;

&lt;p&gt;=&amp;gt; We should open issue for that!&lt;/p&gt;</comment>
                    <comment id="13172289" author="gerritjvv" created="Mon, 19 Dec 2011 14:08:13 +0000"  >&lt;p&gt;Just to clear up on some comments:&lt;/p&gt;

&lt;p&gt;Guys I&apos;m testing this on a production deploy and the use case is simple. Parser Query, Search, Get Doc fields. Contention was seen without profiling and profiling was used to find where the contention in the application.&lt;/p&gt;

&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;I don&apos;t care. They should be reusing tokenstreams in their application.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;


&lt;p&gt;Token streams is not the only place of contention discussed here. Please look at the test attached (App.java). It does not recreate the token streams on each search, only (by mistake) for each thread. But still this only has a very small impact. Searches are repeated from each thread reusing the same token stream.&lt;/p&gt;

&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;We don&apos;t need to make lucene more complicated to (possibly) speed up someones broken code.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;


&lt;p&gt;Please write an example and show me your findings. I&apos;ve done the same already. Have a look at App.java&lt;/p&gt;

&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;I want to see the QPS change, I don&apos;t trust the benchmarks or the various fancy jvm tools being used on this issue. &lt;br/&gt;
I think its all ghosts.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;


&lt;p&gt;Yourkit is a standard Profiling tool. I didn&apos;t just wake up and say hey I&apos;ll profile lucene. I only started after I noticed the contention on a production application where we are trying to use lucene in memory.&lt;/p&gt;

&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;Lots of commits here, a title that says &apos;lucene doesn&apos;t scale, lots of arguing that there are locking problems, but not one luceneutil benchmark run&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;


&lt;p&gt;??, You don&apos;t need to be a scientist nor use a profiling tool to see that all threads will block on a synchronized block or method on each request if that method is called during each search request, from that it doesn&apos;t take much to know that this does not scale. &lt;/p&gt;


&lt;p&gt;Again, this is not a go at lucene, the heading &apos;Lucene Search not scalling&apos; is causing toooo much problems here I see, I could have chosen a better heading and if we can change it to something else please do so. I think lucene is really great, thats why I&apos;m trying to use it. Thanks for the support, ideas and patches so far. &lt;/p&gt;


</comment>
                    <comment id="13172297" author="rcmuir" created="Mon, 19 Dec 2011 14:16:22 +0000"  >&lt;p&gt;Sorry, I don&apos;t care what Yourkit says: its wrong.&lt;/p&gt;

&lt;p&gt;a synchronized method that is just a &lt;b&gt;getter&lt;/b&gt; only called once per-segment is &lt;b&gt;NOT&lt;/b&gt; locking up your search.&lt;/p&gt;</comment>
                    <comment id="13172302" author="simonw" created="Mon, 19 Dec 2011 14:24:43 +0000"  >&lt;p&gt;Gerrit, what robert is saying is that if your index has a reasonable size the cost of a search is not dominated by calling the getter nor by the lock its using. You App is using 1k documents with a tiny number of terms. you are also using 500 threads where scheduling actually dominates the cost. A reasonable benchmark will not see a significant impact due to this synchronization in SegmentCoreReaders#getTermsReader() it will be dominated by retrieving the documents etc. What you are measuring is literally the impact of the lock in a case where your search is super super cheap. I still think we can and should get rid of the SegmentCoreReaders#getTermsReader() sync but in general saving a couple of cpu cycles but paying the price for more complicated code is not worth it IMO. so I agree with robert there will likely be no contention there.&lt;/p&gt;</comment>
                    <comment id="13172303" author="gerritjvv" created="Mon, 19 Dec 2011 14:25:03 +0000"  >
&lt;p&gt;this is not a problem if your ok with 200 or less requests on a server and your search time can be 0.5 or more seconds. But if your whole execution window is measured in milliseconds and you get 7000-10000 requests per second on a server then yes it does matter.&lt;/p&gt;

&lt;p&gt;If that method is called in each thread that is trying to search on the index then it becomes a point of contention, if there are several synchronized separately synchronized methods it only becomes worse. Your basically saying its ok for all threads to wait sequentially in several areas of the code during an in memory readonly index search. &lt;/p&gt;</comment>
                    <comment id="13172308" author="gerritjvv" created="Mon, 19 Dec 2011 14:29:08 +0000"  >&lt;p&gt;Just to clarify, my index is 2 gigs (may grow to 10 gigs, I&apos;ve got 72gigs of RAM to work with), with thousands of documents, documents are not big. The total processing time in my app without the index searches is on average 2-3 milliseconds (after warmup), this includes searching through a treemap with 11million entries.&lt;/p&gt;

&lt;p&gt;Contention was not only seen on the single method in SegmentCoreReaders#getTermsReader() but also on all methods in RAMFile and SegmentNorms etc. Its not just about a single method, that&apos;s what I&apos;ve been trying to make clear in my comments from the start.  &lt;/p&gt;</comment>
                    <comment id="13172312" author="rcmuir" created="Mon, 19 Dec 2011 14:35:08 +0000"  >&lt;blockquote&gt;
&lt;p&gt;Contention was not only seen on the single method in SegmentCoreReaders#getTermsReader() but also on all methods in RAMFile and SegmentNorms etc.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Not actually seen, just spit out by a profiling tool. I really don&apos;t think you should interpret what Yourkit is telling you as gospel truth.&lt;/p&gt;</comment>
                    <comment id="13172322" author="gerritjvv" created="Mon, 19 Dec 2011 14:47:54 +0000"  >&lt;p&gt;IndexSearch.doc calls RAMFile indirectly through RAMInputStream, once search is complete you need to know what&apos;s been found so IndexSearch.doc needs to be called.&lt;br/&gt;
i.e. RAMInputStream calls RAMFile.numBuffers and getBuffer on the switchCurrentBuffer which happens allot during my searches. &lt;/p&gt;

&lt;p&gt;IndexSearcher calls TermQuery$TermWeightScorer.scorer which calls SegmentReader.norms, which calls SegmentNorms.bytes on each search.&lt;br/&gt;
SegmentNorms has almost all methods synchronized.&lt;/p&gt;





</comment>
                    <comment id="13172332" author="thetaphi" created="Mon, 19 Dec 2011 15:08:35 +0000"  >&lt;blockquote&gt;&lt;p&gt;IndexSearcher calls TermQuery$TermWeightScorer.scorer which calls SegmentReader.norms, which calls SegmentNorms.bytes on each search. SegmentNorms has almost all methods synchronized.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Thats the idea behind this class, it caches norms, as they are heavy to load. Even accidently loading them two times because of double-checked-locking is too expensive. Hotspot does the removal of sync later!&lt;/p&gt;

&lt;p&gt;Have you thought about yourkit effectively disabling hotspot, so your analysis is bogus here?&lt;/p&gt;</comment>
                    <comment id="13172337" author="gerritjvv" created="Mon, 19 Dec 2011 15:17:34 +0000"  >&lt;p&gt;OK got you. Just keep in mind that I&apos;m still profiling this and will post my findings as I go along. &lt;/p&gt;
</comment>
                    <comment id="13172338" author="thetaphi" created="Mon, 19 Dec 2011 15:23:13 +0000"  >&lt;blockquote&gt;&lt;p&gt;IndexSearch.doc calls RAMFile indirectly through RAMInputStream, once search is complete you need to know what&apos;s been found so IndexSearch.doc needs to be called. i.e. RAMInputStream calls RAMFile.numBuffers and getBuffer on the switchCurrentBuffer which happens allot during my searches.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;If you use RAMDirectory on a large index its slowing down things as it drives the garbage collector crazy. Use an on-disk index with MMapDirectory, which has no locking at all (only on sometimes called IndexInput.clone, but if you remove that your JVM will SIGSEGV if you use Lucene incorrectly with multiple threads).&lt;/p&gt;

&lt;p&gt;RAMDirectory is written for tests, not for production use. There are already plans to remove it from Lucene trunk and move to tests only. Have you seen that it allocates buffers in 8 Kilobytes blocks? Calculate how many byte[] you have on a 50 Gigabytes index... GC will drive crazy when it starts to cleanup. And then it stops your whole application, not because it locks inside RAMFile, because it does a stop-the world GC.&lt;/p&gt;

&lt;p&gt;We are working on a RAM-Dir like approach storing the files outside Java heap using a large DirectByteBuffer (which is the same code as MMapDirctory). The problem is writing to such a directory, but reading is as fast (or even faster) than RAMDirectory without locks.&lt;/p&gt;</comment>
                    <comment id="13172343" author="gerritjvv" created="Mon, 19 Dec 2011 15:29:56 +0000"  >&lt;p&gt;Oh, ok I thought RAMDirectory would make things faster, good to know. I will try with MMapDirectory then post back.&lt;/p&gt;</comment>
                    <comment id="13172348" author="thetaphi" created="Mon, 19 Dec 2011 15:38:02 +0000"  >&lt;blockquote&gt;&lt;p&gt;Oh, ok I thought RAMDirectory would make things faster, good to know. I will try with MMapDirectory then post back.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Thats a hard to eliminate misbelief - same like &quot;optimizing indexes is good&quot;.&lt;/p&gt;

&lt;p&gt;Just remember that MMapDirectory will use memory outside the JVM heap. If the whole index is in file system cache, Lucene can directly access the cache using MMapDirectory (thats like a swap file, loaded on demand). So reduce JVM heap and supply lots of space for the OS kernel to cache file contents, as those are mapped by MMAP into Java&apos;s process space.&lt;/p&gt;</comment>
                    <comment id="13172446" author="dmsmith" created="Mon, 19 Dec 2011 17:50:54 +0000"  >&lt;blockquote&gt;&lt;p&gt;Thats a hard to eliminate misbelief - same like &quot;optimizing indexes is good&quot;.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Not sure why it is a misbelief? On Win98 and XP with Lucene 1.4.x, when creating an index, with Symantec AV and Windows Fast indexing both on, indexing of 64K small documents, took 40+ minutes. With them off, it took about 4 minutes. Going with a RAM dir took &amp;gt;40 seconds.&lt;/p&gt;

&lt;p&gt;From what I could tell (and remember), Lucene was writing and deleting tens of thousands of documents. It appeared, that the OS was updating its fast search index for each file change hitting the disk. And Symantec, seemed to be scanning every on file creation.&lt;/p&gt;

&lt;p&gt;As this was a desktop application, we couldn&apos;t ask end users to turn off those features or to tune them.&lt;/p&gt;

&lt;p&gt;Does MMapDirectory avoid this too many transient files problem?&lt;/p&gt;</comment>
                    <comment id="13172453" author="thetaphi" created="Mon, 19 Dec 2011 17:58:55 +0000"  >&lt;p&gt;DM: At lucene 1.4 times the indexer was working different and really created lots of files. With new merging this is no longer the case.&lt;/p&gt;

&lt;p&gt;In fact we were talking here about searching not indexing. It makes no sense to clone a huge RAM directory from disk to heap and run searches on it.&lt;/p&gt;</comment>
                    <comment id="13172484" author="mikemccand" created="Mon, 19 Dec 2011 18:40:42 +0000"  >&lt;blockquote&gt;&lt;p&gt;I still think we can and should get rid of the SegmentCoreReaders#getTermsReader() sync&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;+1, I think Simon&apos;s patch is a good improvement, even if in practice this sync&apos;d getter should be a tiny cost.&lt;/p&gt;</comment>
                    <comment id="13172578" author="dmsmith" created="Mon, 19 Dec 2011 20:22:57 +0000"  >&lt;blockquote&gt;&lt;p&gt;In fact we were talking here about searching not indexing. It makes no sense to clone a huge RAM directory from disk to heap and run searches on it.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I saw that this issue is on searching not indexing. I didn&apos;t mean to try to hijack it. I was responding to the statement that RAMDirectory going away (BTW, the statement on optimize does not regard a search feature but an index one). I&apos;ll have to test to see if the same index problem still is around.&lt;/p&gt;

&lt;p&gt;Regarding MMap, there is an open issue with it on Windows: Lucene-1669.&lt;/p&gt;</comment>
                    <comment id="13172637" author="thetaphi" created="Mon, 19 Dec 2011 21:34:10 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-1669&quot; title=&quot;MMapDirectory on Windows silently fails to write to a file if also open for read&quot;&gt;&lt;del&gt;LUCENE-1669&lt;/del&gt;&lt;/a&gt; seems to be relict and should already be solved since Lucene 2.9 in newer Windows versions? And BTW, MMap is only useful for reading indexes, written are they by NIO/SimpleFS.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;BTW, the statement on optimize does not regard a search feature but an index one&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This statement was just a comparison, to underline that both statements &quot;RAMDir is fast&quot; and &quot;Optimize is needed&quot; are myths.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I was responding to the statement that RAMDirectory going away &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;See my previous comment:&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;We are working on a RAM-Dir like approach storing the files outside Java heap using a large DirectByteBuffer (which is the same code as MMapDirctory). The problem is writing to such a directory, but reading is as fast (or even faster) than RAMDirectory without locks.&lt;/p&gt;&lt;/blockquote&gt;</comment>
                    <comment id="13173284" author="gerritjvv" created="Tue, 20 Dec 2011 16:27:03 +0000"  >&lt;p&gt;Hi,&lt;/p&gt;

&lt;p&gt;I&apos;ve tested my application using &lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Using a single Tokenizer&lt;/li&gt;
	&lt;li&gt;MMapDirectory,&lt;/li&gt;
	&lt;li&gt;the latest trunk build that contains the patches committed here.&lt;/li&gt;
	&lt;li&gt;with the &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-3653&quot; title=&quot;Lucene Search not scalling&quot;&gt;&lt;del&gt;LUCENE-3653&lt;/del&gt;&lt;/a&gt;.patch applied.&lt;/li&gt;
	&lt;li&gt;plus using the XX:BiasedLockingStartupDelay=0 option.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;My app request time has gone down from a terrible 400 ms to 120-140ms on average and is constant over 10-200-500 threads (after a 3 hour warmup). (Running java 1.6.0_29 64 bit centos 5.4).&lt;/p&gt;

&lt;p&gt;Still strange that I can do a single threaded request 10000 times and get 3-5 ms on average response time.&lt;/p&gt;

&lt;p&gt;Thanks, Uwe, Simon, your input, comments, and patches have helped allot.&lt;/p&gt;




</comment>
                    <comment id="13174693" author="simonw" created="Thu, 22 Dec 2011 08:45:46 +0000"  >&lt;blockquote&gt;&lt;p&gt;+1, I think Simon&apos;s patch is a good improvement, even if in practice this sync&apos;d getter should be a tiny cost.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I agree. However, I don&apos;t think we can get entirely rid of a mem-barrier here. Even if this is synced by the IW a thread could reopen the reader and another search thread gets the new instance without yet another barrier. This means that search thread would not use the dictionary resulting in a possibly slow search. I removed the sync and made the tis member volatile. That seems the safest option to me.&lt;/p&gt;</comment>
                    <comment id="13174741" author="thetaphi" created="Thu, 22 Dec 2011 10:23:33 +0000"  >&lt;p&gt;Hi Simon, for 3.x I agree. In trunk we already have no synchronization at all (committed 2 days ago; improved yesterday: &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-3631&quot; title=&quot;Remove write access from SegmentReader and possibly move to separate class or IndexWriter/BufferedDeletes/...&quot;&gt;&lt;del&gt;LUCENE-3631&lt;/del&gt;&lt;/a&gt;), so there is no need to change anything.&lt;/p&gt;</comment>
                    <comment id="13174753" author="simonw" created="Thu, 22 Dec 2011 10:36:13 +0000"  >&lt;blockquote&gt;&lt;p&gt;Hi Simon, for 3.x I agree. In trunk we already have no synchronization at all (committed 2 days ago; improved yesterday: &lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-3631&quot; title=&quot;Remove write access from SegmentReader and possibly move to separate class or IndexWriter/BufferedDeletes/...&quot;&gt;&lt;del&gt;LUCENE-3631&lt;/del&gt;&lt;/a&gt;), so there is no need to change anything.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;uwe that patch is against 3.x - I didn&apos;t intend to apply this to 4.0 since we do totally different things there. I will commit this if nobody objects in a bit.&lt;/p&gt;</comment>
                    <comment id="13174767" author="thetaphi" created="Thu, 22 Dec 2011 11:57:33 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                </comments>
                    <attachments>
                    <attachment id="12507796" name="App.java" size="3486" author="gerritjvv" created="Sat, 17 Dec 2011 19:39:27 +0000" />
                    <attachment id="12507898" name="LUCENE-3653-no-sync.png" size="33972" author="simonw" created="Mon, 19 Dec 2011 12:14:12 +0000" />
                    <attachment id="12508358" name="LUCENE-3653.patch" size="935" author="simonw" created="Thu, 22 Dec 2011 08:45:46 +0000" />
                    <attachment id="12507882" name="LUCENE-3653.patch" size="2344" author="simonw" created="Mon, 19 Dec 2011 08:59:13 +0000" />
                    <attachment id="12507893" name="LUCENE-3653.patch-BiasedLockingStartupDelay_1.png" size="132812" author="gerritjvv" created="Mon, 19 Dec 2011 11:05:13 +0000" />
                    <attachment id="12507892" name="LUCENE-3653.patch-BiasedLockingStartupDelay_2.png" size="131977" author="gerritjvv" created="Mon, 19 Dec 2011 11:05:13 +0000" />
                    <attachment id="12507891" name="LUCENE-3653.patch-BiasedLockingStartupDelay_3.png" size="132073" author="gerritjvv" created="Mon, 19 Dec 2011 11:05:13 +0000" />
                    <attachment id="12507899" name="LUCENE-3653-sync-.png" size="33271" author="simonw" created="Mon, 19 Dec 2011 12:14:12 +0000" />
                    <attachment id="12507840" name="LUCENE-3653-VirtualMethod+AttributeSource.patch" size="21922" author="thetaphi" created="Sun, 18 Dec 2011 17:01:48 +0000" />
                    <attachment id="12507821" name="LUCENE-3653-VirtualMethod+AttributeSource.patch" size="17631" author="thetaphi" created="Sun, 18 Dec 2011 01:23:52 +0000" />
                    <attachment id="12507818" name="LUCENE-3653-VirtualMethod+AttributeSource.patch" size="17506" author="thetaphi" created="Sun, 18 Dec 2011 00:58:34 +0000" />
                    <attachment id="12507822" name="lucene-unsync.diff" size="17516" author="gerritjvv" created="Sun, 18 Dec 2011 01:25:20 +0000" />
                    <attachment id="12507788" name="profile_1_a.png" size="136699" author="gerritjvv" created="Sat, 17 Dec 2011 19:27:37 +0000" />
                    <attachment id="12507789" name="profile_1_b.png" size="146943" author="gerritjvv" created="Sat, 17 Dec 2011 19:27:38 +0000" />
                    <attachment id="12507790" name="profile_1_c.png" size="165571" author="gerritjvv" created="Sat, 17 Dec 2011 19:27:38 +0000" />
                    <attachment id="12507791" name="profile_1_d.png" size="175103" author="gerritjvv" created="Sat, 17 Dec 2011 19:27:38 +0000" />
                    <attachment id="12507793" name="profile_2_a.png" size="131550" author="gerritjvv" created="Sat, 17 Dec 2011 19:30:08 +0000" />
                    <attachment id="12507794" name="profile_2_b.png" size="163812" author="gerritjvv" created="Sat, 17 Dec 2011 19:30:08 +0000" />
                    <attachment id="12507795" name="profile_2_c.png" size="138134" author="gerritjvv" created="Sat, 17 Dec 2011 19:30:08 +0000" />
                    <attachment id="12507894" name="Threads-LUCENE-3653.patch.png" size="130716" author="gerritjvv" created="Mon, 19 Dec 2011 11:05:13 +0000" />
                </attachments>
            <subtasks>
        </subtasks>
                <customfields>
                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                <customfieldname>Attachment count</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>20.0</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                <customfieldname>Date of First Response</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>Sat, 17 Dec 2011 00:30:18 +0000</customfieldvalue>

                </customfieldvalues>
            </customfield>
                                                                                                        <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Global Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>221211</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                <customfieldname>Lucene Fields</customfieldname>
                <customfieldvalues>
                        <customfieldvalue key="10121"><![CDATA[New]]></customfieldvalue>
    <customfieldvalue key="10120"><![CDATA[Patch Available]]></customfieldvalue>
    
                </customfieldvalues>
            </customfield>
                                            <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>24045</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                <customfieldname>Time in Status</customfieldname>
                <customfieldvalues>
                    
                </customfieldvalues>
            </customfield>
                            </customfields>
    </item>
</channel>
</rss>