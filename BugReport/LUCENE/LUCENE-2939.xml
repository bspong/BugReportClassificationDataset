<!-- 
RSS generated by JIRA (5.2.8#851-sha1:3262fdc28b4bc8b23784e13eadc26a22399f5d88) at Tue Jul 16 13:22:03 UTC 2013

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/LUCENE-2939/LUCENE-2939.xml?field=key&field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>5.2.8</version>
        <build-number>851</build-number>
        <build-date>26-02-2013</build-date>
    </build-info>

<item>
            <title>[LUCENE-2939] Highlighter should try and use maxDocCharsToAnalyze in WeightedSpanTermExtractor when adding a new field to MemoryIndex as well as when using CachingTokenStream</title>
                <link>https://issues.apache.org/jira/browse/LUCENE-2939</link>
                <project id="12310110" key="LUCENE">Lucene - Core</project>
                        <description>&lt;p&gt;huge documents can be drastically slower than need be because the entire field is added to the memory index&lt;br/&gt;
this cost can be greatly reduced in many cases if we try and respect maxDocCharsToAnalyze&lt;/p&gt;

&lt;p&gt;things can be improved even further by respecting this setting with CachingTokenStream&lt;/p&gt;
</description>
                <environment></environment>
            <key id="12499839">LUCENE-2939</key>
            <summary>Highlighter should try and use maxDocCharsToAnalyze in WeightedSpanTermExtractor when adding a new field to MemoryIndex as well as when using CachingTokenStream</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
                                <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.png">Minor</priority>
                    <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png">Closed</status>
                    <resolution id="1">Fixed</resolution>
                                <assignee username="markrmiller@gmail.com">Mark Miller</assignee>
                                <reporter username="markrmiller@gmail.com">Mark Miller</reporter>
                        <labels>
                    </labels>
                <created>Sun, 27 Feb 2011 01:14:41 +0000</created>
                <updated>Fri, 3 Jun 2011 17:37:16 +0100</updated>
                    <resolved>Wed, 20 Apr 2011 15:44:26 +0100</resolved>
                                            <fixVersion>3.2</fixVersion>
                <fixVersion>4.0-ALPHA</fixVersion>
                                <component>modules/highlighter</component>
                        <due></due>
                    <votes>0</votes>
                        <watches>2</watches>
                                                    <comments>
                    <comment id="12999859" author="markrmiller@gmail.com" created="Sun, 27 Feb 2011 01:18:58 +0000"  >&lt;p&gt;I&apos;m a little rusty on the new tokenstream api, but here is a little test patch I popped out real quick&lt;/p&gt;</comment>
                    <comment id="12999863" author="markrmiller@gmail.com" created="Sun, 27 Feb 2011 01:42:15 +0000"  >&lt;p&gt;hmmm...didn&apos;t quite get it right yet I think...&lt;/p&gt;

&lt;p&gt;q=java man news th*&lt;/p&gt;


&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
java.lang.NullPointerException
	at org.apache.lucene.util.CharacterUtils$Java5CharacterUtils.fill(CharacterUtils.java:181)
	at org.apache.lucene.analysis.CharTokenizer.incrementToken(CharTokenizer.java:150)
	at org.apache.lucene.analysis.miscellaneous.WordDelimiterFilter.incrementToken(WordDelimiterFilter.java:224)
	at org.apache.lucene.analysis.core.LowerCaseFilter.incrementToken(LowerCaseFilter.java:54)
	at org.apache.lucene.analysis.miscellaneous.ASCIIFoldingFilter.incrementToken(ASCIIFoldingFilter.java:71)
	at com.ACME.analysis.ACMEPluralStemFilter.incrementToken(ACMEPluralStemFilter.java:56)
	at org.apache.solr.highlight.TokenOrderingFilter.incrementToken(DefaultSolrHighlighter.java:575)
	at org.apache.lucene.analysis.CachingTokenFilter.fillCache(CachingTokenFilter.java:78)
	at org.apache.lucene.analysis.CachingTokenFilter.incrementToken(CachingTokenFilter.java:50)
	at org.apache.lucene.search.highlight.Highlighter.getBestTextFragments(Highlighter.java:220)

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                    <comment id="12999866" author="markrmiller@gmail.com" created="Sun, 27 Feb 2011 02:10:21 +0000"  >&lt;p&gt;only seems to happen when maxDocCharsToAnalyze is absurdly low - like 5&lt;/p&gt;</comment>
                    <comment id="12999880" author="rcmuir" created="Sun, 27 Feb 2011 04:44:04 +0000"  >&lt;p&gt;i don&apos;t know why you get this null pointer exception (maybe you triggered a bug), but...&lt;/p&gt;

&lt;p&gt;just a quick glance:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;why use offsets for this calculation? This seems a bit dangerous versus other approaches.&lt;/li&gt;
	&lt;li&gt;either way, the reset() method should clear any state such as counters in the tokenstream.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;As far as what i meant above... the whole maxDocCharsToAnalyze seems like the wrong measure.&lt;br/&gt;
Why not specify this just as max tokens, and use LimitTokenCountAnalyzer, which is already implemented.&lt;/p&gt;

&lt;p&gt;using arbitrary chars and offsets is going to create fake tokens (e.g. truncate words) and other problems.&lt;br/&gt;
besides, its not unicode safe since a codepoint might span multiple chars.&lt;/p&gt;</comment>
                    <comment id="12999882" author="markrmiller@gmail.com" created="Sun, 27 Feb 2011 05:06:09 +0000"  >&lt;p&gt;Because this is already a setting on the Highlighter that appears to work by offset?&lt;/p&gt;</comment>
                    <comment id="12999883" author="rcmuir" created="Sun, 27 Feb 2011 05:13:39 +0000"  >&lt;p&gt;Maybe the setting is already there, but I think we should remove it: I don&apos;t think its the best measure.&lt;/p&gt;

&lt;p&gt;We can instead replace it with a max # tokens setting, which is more intuitive, easier to implement,&lt;br/&gt;
and consistent with how other things are limited (e.g. the old IW setting and the new&lt;br/&gt;
LimitTokenCountFilter).&lt;/p&gt;</comment>
                    <comment id="12999884" author="markrmiller@gmail.com" created="Sun, 27 Feb 2011 05:17:26 +0000"  >&lt;p&gt;Fair enough (this setting is well before my time AFAIK) - but not my intent with this issue - which is just to fix this little perf bug.&lt;/p&gt;</comment>
                    <comment id="13000010" author="markrmiller@gmail.com" created="Sun, 27 Feb 2011 17:42:56 +0000"  >&lt;p&gt;The other problem was that CachingTokenFilter was exhausting the entire stream eagerly - which could be a spin through a very large TokenStream - uselessly if a user has set the maxDocCharOffset setting.&lt;/p&gt;

&lt;p&gt;This and adding the whole stream to the MemoryIndex was a very large performance bug in the span highlighter for some time now.&lt;/p&gt;

&lt;p&gt;In my test case, using Solr&apos;s DEFAULT_MAX_CHARS_TO_ANALYZE = 50*1024, highlighting 10 very large PDF docs I have dropped from 20 some seconds to 300ms.&lt;/p&gt;

&lt;p&gt;New patch with some fixes and cleanup. I don&apos;t see the above error with a more correct TokenFilter impl.&lt;/p&gt;</comment>
                    <comment id="13002334" author="markrmiller@gmail.com" created="Thu, 3 Mar 2011 23:51:14 +0000"  >&lt;p&gt;My last patch is missing a couple required test compile changes - I excluded that class cause I had some test code in it.&lt;/p&gt;

&lt;p&gt;I&apos;ll put up a new patch as soon as I get a chance with the test class changes (Scorer init method gets a new param and there are a couple anonymous impls in test)&lt;/p&gt;</comment>
                    <comment id="13002335" author="markrmiller@gmail.com" created="Thu, 3 Mar 2011 23:54:00 +0000"  >&lt;p&gt;Honestly, if I was not so busy, I&apos;d say we should really get this in for 3.1.&lt;/p&gt;

&lt;p&gt;If you are doing something like desktop search, this can be a really cruel highlighter perf problem.&lt;/p&gt;</comment>
                    <comment id="13002340" author="markrmiller@gmail.com" created="Thu, 3 Mar 2011 23:58:41 +0000"  >&lt;p&gt;P.S. One that is really a bad bug in my mind - we switched this to be the default and the old Highlighter did not suffer like this in these situations.&lt;/p&gt;

&lt;p&gt;Looking back over the email archives, it bit more than a few people. I&apos;m pretty sure this bug was the impetus of the Fast Vector Highlighter (which is still valuable if you &lt;b&gt;really&lt;/b&gt; do want to highlight over every token in your 3 billion word PDF file &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.gif&quot; height=&quot;20&quot; width=&quot;20&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; ).&lt;/p&gt;

&lt;p&gt;You pay this huge perf penalty for no gain and no reason. If you are talking wikipedia size docs, it won&apos;t affect you - but for long documents, doing 10 snippets can be prohibitive, with no workaround. That is not a friendly neighborhood highlighter.&lt;/p&gt;</comment>
                    <comment id="13002377" author="rcmuir" created="Fri, 4 Mar 2011 00:57:58 +0000"  >&lt;p&gt;i think the offsetLength calculation needs to be inside the incrementToken?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Honestly, if I was not so busy, I&apos;d say we should really get this in for 3.1.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;yeah, performance bugs are bugs too.&lt;/p&gt;</comment>
                    <comment id="13002394" author="gsingers" created="Fri, 4 Mar 2011 01:47:17 +0000"  >&lt;p&gt;I can backport if you want.&lt;/p&gt;</comment>
                    <comment id="13002400" author="markrmiller@gmail.com" created="Fri, 4 Mar 2011 02:07:26 +0000"  >&lt;blockquote&gt;&lt;p&gt;i think the offsetLength calculation needs to be inside the incrementToken?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I do not follow ... incrementToken is:&lt;/p&gt;

&lt;p&gt;+  @Override&lt;br/&gt;
+  public boolean incrementToken() throws IOException {&lt;br/&gt;
+    int offsetLength = offsetAttrib.endOffset() - offsetAttrib.startOffset();&lt;br/&gt;
+    if (offsetCount &amp;lt; offsetLimit &amp;amp;&amp;amp; input.incrementToken()) &lt;/p&gt;
{
+      offsetCount += offsetLength;
+      return true;
+    }
&lt;p&gt;+    return false;&lt;br/&gt;
+  }&lt;/p&gt;</comment>
                    <comment id="13002402" author="rcmuir" created="Fri, 4 Mar 2011 02:11:48 +0000"  >&lt;p&gt;Exactly, so what is the attributes values before calling input.incrementToken() ?&lt;/p&gt;

&lt;p&gt;I don&apos;t think this is good practice to work with the uninitialized values.&lt;/p&gt;</comment>
                    <comment id="13002406" author="markrmiller@gmail.com" created="Fri, 4 Mar 2011 02:19:51 +0000"  >&lt;p&gt;This includes the change to the test to make it compile.&lt;/p&gt;

&lt;p&gt;Still no Changes entry.&lt;/p&gt;

&lt;p&gt;The compile change to the test is a back compat break. The Scorer needs to know the maxCharsToAnalyze setting.&lt;/p&gt;

&lt;p&gt;Have not had time to consider further yet.&lt;/p&gt;</comment>
                    <comment id="13002407" author="markrmiller@gmail.com" created="Fri, 4 Mar 2011 02:25:53 +0000"  >&lt;blockquote&gt;&lt;p&gt;I can backport if you want.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;+1&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I don&apos;t think this is good practice to work with the uninitialized values.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I see what you mean now - though I still don&apos;t understand your previous comment.&lt;br/&gt;
I assume that it&apos;s just defaulting to 0 - 0 now?&lt;/p&gt;

&lt;p&gt;Yeah, that could be changed.&lt;/p&gt;</comment>
                    <comment id="13002433" author="rcmuir" created="Fri, 4 Mar 2011 03:29:29 +0000"  >&lt;blockquote&gt;
&lt;p&gt;I see what you mean now - though I still don&apos;t understand your previous comment.&lt;br/&gt;
I assume that it&apos;s just defaulting to 0 - 0 now?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Only the first time.&lt;/p&gt;

&lt;p&gt;But imagine you try to reuse this tokenstream (maybe its not being reused now, but in the future)... the values for the last token of the previous doc are say 10 - 5... the consumer calls reset(Reader) with new document and reset(), which clears your accumulator, but this attribute is still 10 - 5 until input.incrementToken()... only then does the tokenizer update the values.&lt;/p&gt;</comment>
                    <comment id="13002562" author="rcmuir" created="Fri, 4 Mar 2011 12:20:50 +0000"  >&lt;p&gt;Given the back compat breaks in the API, are we sure we should try to shove this into 3.1?&lt;/p&gt;

&lt;p&gt;I am sympathetic to performance bugs, BUT it seems that one could use TermVectors and FastVectorHighlighter for these large documents, the user is hardly left without options.&lt;/p&gt;

&lt;p&gt;As a safer alternative we can document the issue in CHANGES.txt and recommend that users take that approach for large documents, and take our time and fix for 3.2&lt;/p&gt;</comment>
                    <comment id="13002576" author="markrmiller@gmail.com" created="Fri, 4 Mar 2011 12:54:45 +0000"  >&lt;blockquote&gt;&lt;p&gt;Given the back compat breaks in the API, are we sure we should try to shove this into 3.1?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I won&apos;t do the work, so whatever form my perspective...&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;the user is hardly left without options.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Depends on what you mean by options - FastVectorHighlighter cannot highlight half our queries (multi-term last I knew, or Span) - trade one bug for anther.&lt;/p&gt;</comment>
                    <comment id="13002579" author="gsingers" created="Fri, 4 Mar 2011 12:58:59 +0000"  >&lt;p&gt;I&apos;m OK either way, but it does seem like a pretty big performance bug.&lt;/p&gt;</comment>
                    <comment id="13002580" author="rcmuir" created="Fri, 4 Mar 2011 12:59:59 +0000"  >&lt;blockquote&gt;
&lt;p&gt;Depends on what you mean by options - FastVectorHighlighter cannot highlight half our queries (multi-term last I knew, or Span) - trade one bug for anther.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Right, but you can use term vectors with this highlighter too right?&lt;br/&gt;
This issue only seems to refer to the case where you have no term vectors and analyze the text at runtime...&lt;/p&gt;

&lt;p&gt;I don&apos;t think its too much to say &apos;index your content according to what you are going to need&apos;&lt;/p&gt;</comment>
                    <comment id="13002582" author="markrmiller@gmail.com" created="Fri, 4 Mar 2011 13:02:31 +0000"  >&lt;p&gt;Grant: in terms of the back compat issue - I&apos;m not really worried about it myself since this is contrib and we have changed these interfaces before with no complaint -&lt;/p&gt;

&lt;p&gt;but another tmp option is to special case and do an instanceOf check on the Scorer - and if its our QueryScorer, cast and set the max chars to analyze.&lt;/p&gt;

&lt;p&gt;It&apos;s not as pretty, but it avoids the method sig change.&lt;/p&gt;</comment>
                    <comment id="13002583" author="markrmiller@gmail.com" created="Fri, 4 Mar 2011 13:03:18 +0000"  >&lt;blockquote&gt;&lt;p&gt; Right, but you can use term vectors with this highlighter too right?&lt;br/&gt;
This issue only seems to refer to the case where you have no term vectors and analyze the text at runtime...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Nope, that&apos;s not true. If you turn on term vectors, that does &lt;b&gt;NOT&lt;/b&gt; solve this bug.&lt;/p&gt;</comment>
                    <comment id="13002585" author="markrmiller@gmail.com" created="Fri, 4 Mar 2011 13:06:47 +0000"  >&lt;p&gt;Anyhow, all I have time for on this today.&lt;/p&gt;

&lt;p&gt;I&apos;ll leave it up to you guys...err, I mean robert, to decide what to do here.&lt;/p&gt;</comment>
                    <comment id="13002588" author="rcmuir" created="Fri, 4 Mar 2011 13:08:06 +0000"  >&lt;blockquote&gt;
&lt;p&gt;I&apos;ll leave it up to you guys...err, I mean robert, to decide what to do here.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Sorry you feel this way... everyone says they want faster releases but doesn&apos;t want to take the appropriate steps to move towards a model that supports that.&lt;/p&gt;

&lt;p&gt;In order to release more often we have to stop this cycle of shoving things in at the last minute.&lt;/p&gt;</comment>
                    <comment id="13002594" author="markrmiller@gmail.com" created="Fri, 4 Mar 2011 13:13:21 +0000"  >&lt;blockquote&gt;&lt;p&gt;In order to release more often we have to stop this cycle of shoving things in at the last minute.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;As always in Lucene land, these things should be taken case by case depending on the facts - the severity of the bug and its affect on the release. Tese things can often be discussed by more than a single person.&lt;/p&gt;

&lt;p&gt;Not ramrodded by someone being a bit of an asshole.&lt;/p&gt;</comment>
                    <comment id="13002600" author="rcmuir" created="Fri, 4 Mar 2011 13:18:44 +0000"  >&lt;blockquote&gt;&lt;p&gt;Not ramrodded by someone being a bit of an asshole.&lt;/p&gt;&lt;/blockquote&gt;

&lt;blockquote&gt;&lt;p&gt;Tese things can often be discussed by more than a single person.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes, anyone can can produce a release candidate of Lucene. But if its going to be me doing it, i&apos;ve already set aside time (and coordinated with others) to make RC builds. So I&apos;m going to push back on shoving in last minute changes.&lt;/p&gt;

&lt;p&gt;Well you can call it that, or someone trying to be a release manager that will actually get out a release in the next year.&lt;/p&gt;

&lt;p&gt;Bottom line: if you feel this change is really important, I respect your decision on that. But you should set the issue to blocker and be aware that the tradeoff likely means delaying the RC for a few weeks (unless someone else steps up to volunteer to produce an RC, which is fine!)&lt;/p&gt;

</comment>
                    <comment id="13002601" author="markrmiller@gmail.com" created="Fri, 4 Mar 2011 13:26:01 +0000"  >&lt;p&gt;What you don&apos;t seem to get is that I don&apos;t mind if you push back. I don&apos;t mind your position.&lt;/p&gt;

&lt;p&gt;I mind your attitude. Changing the issue target 2 seconds after Grant with no discussion. Declaring on your own that it won&apos;t get in. Not trying to get to a real conversation about the issue (which you clearly don&apos;t fully understand if you think storing term vectors will help). These things are my issue, not any so called push back.&lt;/p&gt;

&lt;p&gt;Well man, you need us on your team too. Performance bug is a technical valid reason for a -1 on a release. I&apos;m not threatening that - but I&apos;m pointing out that everyone needs to be on board - not just the RM. Taking the time for fair discussion is not a waste of time.&lt;/p&gt;</comment>
                    <comment id="13002602" author="rcmuir" created="Fri, 4 Mar 2011 13:33:20 +0000"  >&lt;blockquote&gt;
&lt;p&gt;I mind your attitude. Changing the issue target 2 seconds after Grant with no discussion. Declaring on your own that it won&apos;t get in. Not trying to get to a real conversation about the issue (which you clearly don&apos;t fully understand if you think storing term vectors will help). These things are my issue, not any so called push back.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Its not an attitude, and its not personal. Its trying to stop last minute stuff from being shoved into the release right before the RC, especially if its not fully-formed patches ready to be committed.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Well man, you need us on your team too. Performance bug is a technical valid reason for a -1 on a release. I&apos;m not threatening that - but I&apos;m pointing out that everyone needs to be on board - not just the RM. Taking the time for fair discussion is not a waste of time.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I totally agree with you here. But some people might say, if the bug has been aroudn since say 2.4 or 2.9 that its not critical that it be fixed in 3.1 at the last minute, and still +1 the release.&lt;/p&gt;

&lt;p&gt;As i stated earlier on this issue, I&apos;m sympathetic to performance bugs: performance bugs are bugs too. But we need to evaluate risk-reward here.&lt;/p&gt;

&lt;p&gt;Just don&apos;t forget that there are other performance problems with large documents in lucene (some have been around a while) and we aren&apos;t trying to shove any last minute fixes for those in.&lt;/p&gt;

&lt;p&gt;So, here are my questions:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;What version of Lucene was this performance bug introduced in? Is it something we introduced in version 3.1? If this is the case its more serious than if its something thats been around since 2.9.&lt;/li&gt;
	&lt;li&gt;Why is fast-vector highlighter with TVs &quot;ok&quot;, but highlighter with TVs slow?&lt;/li&gt;
&lt;/ol&gt;
</comment>
                    <comment id="13002604" author="gsingers" created="Fri, 4 Mar 2011 13:39:18 +0000"  >&lt;p&gt;I think Robert&apos;s right, we should not have shoved this in at the last minute, even though it is a pretty big issue for those doing highlighting of larger documents.  I&apos;d say we just mark it as 3.1.1 or 3.2.&lt;/p&gt;</comment>
                    <comment id="13002607" author="rcmuir" created="Fri, 4 Mar 2011 13:51:03 +0000"  >&lt;p&gt;I think 3.2 is a good tradeoff, unless we introduced this slowdown in 3.1 (my earlier question).&lt;/p&gt;

&lt;p&gt;If we are introducing this slowdown in the 3.1 release, then I think its much more serious, and I would instead suggest we set the issue to blocker.&lt;/p&gt;

&lt;p&gt;Regardless I think there are some technical steps that can be taken to easy my mind about the patch, for example the TokenFilter here can be tested independently with BaseTokenStreamTestCase (this is good at catching reuse bugs like the one I hinted at).&lt;/p&gt;</comment>
                    <comment id="13002609" author="markrmiller@gmail.com" created="Fri, 4 Mar 2011 13:57:27 +0000"  >&lt;blockquote&gt;&lt;p&gt;we should not have shoved this in at the last minute,&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;We didn&apos;t? Marking something as 3.1 is the best way to get it considered for last minute inclusion, blocker or not. It certainly doesn&apos;t mean its not going to be pushed back out after discussion.&lt;/p&gt;

&lt;p&gt;In any case, if you are not for it, that decides it - I&apos;m not willing to do the work right now.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;So, here are my questions:&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;1. I don&apos;t remember 2.9 probably.&lt;br/&gt;
2. Because it&apos;s a completely different approach.&lt;/p&gt;

&lt;p&gt;It&apos;s been around for a while. I saw one guy that stayed on Solr 1.3 over 1.4 because of it. Most people will try fast vector and say oh nice, it&apos;s fast - but it doesn&apos;t highlight wildcard queries or these queries, etc. They either accept one bug over the other, or stick with an older version. Honestly, if that continues for another release, it&apos;s no skin off my nose. But neither are most bugs.&lt;/p&gt;
</comment>
                    <comment id="13002716" author="mikemccand" created="Fri, 4 Mar 2011 17:03:17 +0000"  >&lt;blockquote&gt;&lt;p&gt;In order to release more often we have to stop this cycle of shoving things in at the last minute&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;+1&lt;/p&gt;

&lt;p&gt;Dev is a constant thing around here and we keep holding back a release&lt;br/&gt;
for the one-more-issue to get in we will never release. &lt;/p&gt;

&lt;p&gt;Our lack-of-release reflects badly on Lucene/Solr &amp;#8211; the outside world&lt;br/&gt;
uses this as the proxy for our health and we know we get bad marks.&lt;/p&gt;

&lt;p&gt;Worse, this whole situation (people getting angry at the RM for doing&lt;br/&gt;
&lt;b&gt;precisely&lt;/b&gt; what the RM is supposed to do) is a disincentive for&lt;br/&gt;
future RMs to volunteer doing releases, thus causing even less&lt;br/&gt;
frequent releases.  It&apos;s already hard enough for us to get a release&lt;br/&gt;
out as it is.&lt;/p&gt;

&lt;p&gt;The RM is &lt;b&gt;supposed&lt;/b&gt; to be an asshole (not that Robert has acted like&lt;br/&gt;
one, here, imho).  S/he has full authority to draw the line, crack the&lt;br/&gt;
whip, do whatever it takes to get the release out.  We all cannot&lt;br/&gt;
question that, unless we want to step up and be the RM because it is&lt;br/&gt;
NOT an easy job.&lt;/p&gt;

&lt;p&gt;I think this issue should wait for 3.2.&lt;/p&gt;</comment>
                    <comment id="13002730" author="markrmiller@gmail.com" created="Fri, 4 Mar 2011 17:29:13 +0000"  >&lt;blockquote&gt;
&lt;p&gt;Worse, this whole situation (people getting angry at the RM for doing&lt;br/&gt;
precisely what the RM is supposed to do) is a disincentive for&lt;br/&gt;
future RMs to volunteer doing releases, thus causing even less&lt;br/&gt;
frequent releases. It&apos;s already hard enough for us to get a release&lt;br/&gt;
out as it is.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;m not sure I agree. Declaring that this will not get in is beyond the scope of an RM in my opinion. Putting pressure is fine, but just because being an RM is hard is not a King for a day pass IMO. It&apos;s up to the RM to build the release candidate from whatever issues he wants - does that mean he needs to man handle JIRA?&lt;/p&gt;


&lt;blockquote&gt;
&lt;p&gt;The RM is supposed to be an asshole (not that Robert has acted like&lt;br/&gt;
one, here, imho).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don&apos;t think he is? Too strong a word. I didn&apos;t even use it full to refer to the 2 actions I was commenting on. First, I said a acting like a bit of an asshole and I separated it a distance as theoretical. It was weak sauce commentary on the two actions I&apos;ve pointed out:&lt;/p&gt;

&lt;p&gt;1. Just reverting a change another respected committer made immediately and without discussion - without too much investigation - because that issue was subsumed by another issue that had already been moved for 3.1 consideration and we where still discussing.&lt;/p&gt;

&lt;p&gt;2. Declaring that this will not make it in over ongoing discussion.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;S/he has full authority to draw the line, crack the&lt;br/&gt;
whip, do whatever it takes to get the release out.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Do whatever it takes? Come on...&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;We all cannot question that, unless we want to step up and be the RM because it is NOT an easy job.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I do question it. I have stepped up to be the RM, I know it&apos;s not an easy job, and I&apos;ll volunteer to do it again sometime.&lt;/p&gt;

&lt;p&gt;Robert is great at it - in general he has all my support in the world. I certainly understand the difficulties hes facing trying to point this release and he has my sympathies - and I wish he had more of my help. But that doesn&apos;t change my reaction to his actions. I feel the same way and I have the same responses to it. Meanwhile, I still like and respect Robert.&lt;/p&gt;</comment>
                    <comment id="13002838" author="mikemccand" created="Fri, 4 Mar 2011 22:02:01 +0000"  >
&lt;blockquote&gt;&lt;p&gt;Putting pressure is fine, but just because being an RM is hard is not a King for a day pass IMO&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Putting pressure is precisely what Robert has done here (and on&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-2390&quot; title=&quot;Performance of usePhraseHighlighter is terrible on very large Documents, regardless of hl.maxDocCharsToAnalyze&quot;&gt;&lt;del&gt;SOLR-2390&lt;/del&gt;&lt;/a&gt;)?&lt;/p&gt;

&lt;p&gt;He&apos;s acting just like an RM should act, as far as I can tell.  Moving&lt;br/&gt;
an issue out, stating that an issue won&apos;t make the RC,&lt;br/&gt;
is fair game.  These are the normal &quot;tools&quot; of the RM...&lt;/p&gt;

&lt;p&gt;My point is, we all must expect/allow/not-get-upset-about this&lt;br/&gt;
&quot;pressure&quot; from the RM &amp;#8211; it comes with the territory, and it&apos;s the&lt;br/&gt;
RM&apos;s right to be very aggressive in order to get the release done.&lt;/p&gt;

&lt;p&gt;Else releases will not get done, and we&apos;ll all keep one-more-thing&apos;ing&lt;br/&gt;
the release, and that&apos;s bad for all of us.&lt;/p&gt;

&lt;p&gt;We gotta remove the barriers to doing releases around here, not add to&lt;br/&gt;
them.  In fact, we should scrutinize our scary ReleaseTodo and pare it&lt;br/&gt;
back to the bare minimum... it&apos;s gotta become a push button process.&lt;/p&gt;</comment>
                    <comment id="13002877" author="markrmiller@gmail.com" created="Sat, 5 Mar 2011 00:01:02 +0000"  >&lt;blockquote&gt;&lt;p&gt;Moving&lt;br/&gt;
an issue out, stating that an issue won&apos;t make the RC,&lt;br/&gt;
is fair game. These are the normal &quot;tools&quot; of the RM...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Not in my experience. &lt;/p&gt;

&lt;p&gt;Regardless, I&apos;m not sure this is the same as changing a JIRA issue right after someone else changes it with no discussion and apparent lack of understanding of the issue. That&apos;s a statement if you ask me. If you look at how the culture of Lucene has worked, this is unusual - and I&apos;ll push to make it remain so.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Putting pressure is precisely what Robert has done here (and onSOLR-2390)?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-2390&quot; title=&quot;Performance of usePhraseHighlighter is terrible on very large Documents, regardless of hl.maxDocCharsToAnalyze&quot;&gt;&lt;del&gt;SOLR-2390&lt;/del&gt;&lt;/a&gt; was this issue - this patch spans lucene and solr and covers both of them. This issue was still marked 3.1 and we where discussing it when this happened with &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-2390&quot; title=&quot;Performance of usePhraseHighlighter is terrible on very large Documents, regardless of hl.maxDocCharsToAnalyze&quot;&gt;&lt;del&gt;SOLR-2390&lt;/del&gt;&lt;/a&gt; - this is how I know little thought went into shoving it out - &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-2390&quot; title=&quot;Performance of usePhraseHighlighter is terrible on very large Documents, regardless of hl.maxDocCharsToAnalyze&quot;&gt;&lt;del&gt;SOLR-2390&lt;/del&gt;&lt;/a&gt; should be in lock step with this issue. It&apos;s not a new or another issue. It&apos;s just where I am tracking this from a Solr user bug perspective - it&apos;s easier to have one patch.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;My point is, we all must expect/allow/not-get-upset-about this&lt;br/&gt;
&quot;pressure&quot; from the RM &#8211; it comes with the territory, and it&apos;s the&lt;br/&gt;
RM&apos;s right to be very aggressive in order to get the release done.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Depends - I&apos;ve seen a lot of RM&apos;s before - and I have been one. Personally I&apos;ve never seen things done this way. Nor do I think it was necessary. We would have come to the same conclusion in either case. The history and culture of Lucene has been to not be forceful in JIRA - that&apos;s something I&apos;ll argue to maintain.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;We gotta remove the barriers to doing releases around here, not add to&lt;br/&gt;
them.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Release at all costs is just not an excuse IMO. We release as often as someone is willing to put in the somewhat massive effort really. &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;In fact, we should scrutinize our scary ReleaseTodo and pare it&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;back to the bare minimum... it&apos;s gotta become a push button process.&lt;/p&gt;

&lt;p&gt;I think we all agree with that. I&apos;m still not aboard with the scary RM theory.&lt;/p&gt;</comment>
                    <comment id="13002879" author="markrmiller@gmail.com" created="Sat, 5 Mar 2011 00:07:13 +0000"  >&lt;p&gt;I will also note, there was never any strong argument to include this issue.&lt;/p&gt;

&lt;p&gt;There was never any danger of this needing to be strong armed out of 3.1.&lt;/p&gt;

&lt;p&gt;I&apos;ve already said I wouldn&apos;t do it - and Grant had volunteered, but never argued for it either.&lt;/p&gt;</comment>
                    <comment id="13002883" author="treyhyde" created="Sat, 5 Mar 2011 00:41:46 +0000"  >&lt;p&gt;Sorry if I missed it in this thread, which branch was this patch made against?  It doesn&apos;t apply cleanly against branch_3x.&lt;/p&gt;</comment>
                    <comment id="13002893" author="markrmiller@gmail.com" created="Sat, 5 Mar 2011 00:54:44 +0000"  >&lt;blockquote&gt;&lt;p&gt;Sorry if I missed it in this thread, which branch was this patch made against? It doesn&apos;t apply cleanly against branch_3x.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This patch is against trunk - still needs a fairly simple back port to 3x.&lt;/p&gt;</comment>
                    <comment id="13002910" author="rcmuir" created="Sat, 5 Mar 2011 02:34:24 +0000"  >&lt;p&gt;The patch needs more than a simple back port.&lt;/p&gt;

&lt;p&gt;The patch needs to be fixed. It has tokenstream reuse bugs that cause offsets from last token of the previous document to be applied to the calculations of the next document, because it reads dirty attributes.&lt;/p&gt;

&lt;p&gt;Its not just release manager being an asshole here, there are technical problems that need to be fixed.&lt;/p&gt;</comment>
                    <comment id="13002917" author="markrmiller@gmail.com" created="Sat, 5 Mar 2011 03:15:34 +0000"  >&lt;blockquote&gt;&lt;p&gt;The patch needs more than a simple back port. The patch needs to be fixed.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;And that is simple too if you follow the above comments.&lt;/p&gt;

&lt;p&gt;You should pop the offset calculation into the if statement - &lt;/p&gt;

&lt;p&gt;I&apos;m not convinced it&apos;s a problem in this situation (especially for someone wanting to try a patch), because this works one document at a time.&lt;/p&gt;

&lt;p&gt;Its also simple not to break the api as I mention above.&lt;/p&gt;

&lt;p&gt;I have done all of these things in my own work earlier (and added a test for the new filter) - took about 2 minutes.&lt;/p&gt;

&lt;p&gt;Eventually I will post another trunk patch.&lt;/p&gt;

&lt;p&gt;Doing a solid review and back port of this patch would not take long - it&apos;s fairly simple. I won&apos;t likely get to it for 3.X for a while though.&lt;/p&gt;</comment>
                    <comment id="13002946" author="markrmiller@gmail.com" created="Sat, 5 Mar 2011 07:36:25 +0000"  >&lt;p&gt;here is a more up to date version of the patch for trunk - good for testing performance difference of this issue&lt;/p&gt;</comment>
                    <comment id="13018319" author="gsingers" created="Mon, 11 Apr 2011 13:29:16 +0100"  >&lt;p&gt;Mark,&lt;/p&gt;

&lt;p&gt;Seems like we can move forward with this now that the release is out.  Do you have time or do you want me to take it?&lt;/p&gt;</comment>
                    <comment id="13019421" author="markrmiller@gmail.com" created="Wed, 13 Apr 2011 17:31:14 +0100"  >&lt;p&gt;Okay - I&apos;m going to commit to trunk shortly.&lt;/p&gt;</comment>
                    <comment id="13043498" author="rcmuir" created="Fri, 3 Jun 2011 17:37:16 +0100"  >&lt;p&gt;Bulk closing for 3.2&lt;/p&gt;</comment>
                </comments>
                <issuelinks>
                        <issuelinktype id="12310010">
                <name>Incorporates</name>
                                                <inwardlinks description="is part of">
                            <issuelink>
            <issuekey id="12499872">SOLR-2390</issuekey>
        </issuelink>
                    </inwardlinks>
                            </issuelinktype>
                    </issuelinks>
                <attachments>
                    <attachment id="12472742" name="LUCENE-2939.patch" size="10799" author="markrmiller@gmail.com" created="Sat, 5 Mar 2011 07:36:24 +0000" />
                    <attachment id="12472641" name="LUCENE-2939.patch" size="10224" author="markrmiller@gmail.com" created="Fri, 4 Mar 2011 02:19:51 +0000" />
                    <attachment id="12472120" name="LUCENE-2939.patch" size="9569" author="markrmiller@gmail.com" created="Sun, 27 Feb 2011 17:42:56 +0000" />
                    <attachment id="12472081" name="LUCENE-2939.patch" size="7086" author="markrmiller@gmail.com" created="Sun, 27 Feb 2011 01:18:58 +0000" />
                </attachments>
            <subtasks>
        </subtasks>
                <customfields>
                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                <customfieldname>Attachment count</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>4.0</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                <customfieldname>Date of First Response</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>Sun, 27 Feb 2011 04:44:04 +0000</customfieldvalue>

                </customfieldvalues>
            </customfield>
                                                                                                        <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Global Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>10933</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                <customfieldname>Rank</customfieldname>
                <customfieldvalues>
                    <customfieldvalue>24753</customfieldvalue>
                </customfieldvalues>
            </customfield>
                                                                                    <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                <customfieldname>Time in Status</customfieldname>
                <customfieldvalues>
                    
                </customfieldvalues>
            </customfield>
                            </customfields>
    </item>
</channel>
</rss>