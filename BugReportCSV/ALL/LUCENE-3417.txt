DictionaryCompoundWordTokenFilter does not properly add tokens from the end compound word.
Due to an off-by-one error a subword placed at the end of a compound word will not get a token added to the token stream. For example from the unit test in the attached patch Dictionary ab cd ef Input abcdef Created tokens abcdef ab cd Expected tokens abcdef ab cd ef Additionally it could produce tokens that were shorter than the minSubwordSize due to another off-by-one error. For example again from the attached patch Dictionary abc d efg Minimum subword length 2 Input abcdefg Created tokens abcdef abc d efg Expected tokens abcdef abc efg Adds two unit tests one showing each behavior and a fix for both issues. The above patch is trivial to backport for 3.3 3.4. It is similar to LUCENE-3038 but is not duplicated by LUCENE-3022 which deals with issues surrounding the interpretation of onlyLongestMatch. thanks for the patch all tests pass here with it and I think the added tests are clear. Thanks Njal Bulk close after release of 3.5
