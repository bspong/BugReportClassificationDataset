Add tokenize documents only task to contrib benchmark
I ve been looking at performance improvements to tokenization by re-using Tokens and to help benchmark my changes I ve added a new task called ReadTokens that just steps through all fields in a document gets a TokenStream and reads all the tokens out of it. EG this alg just reads all Tokens for all docs in Reuters collection doc.maker org.apache.lucene.benchmark.byTask.feeds.ReutersDocMaker doc.maker.forever false ReadTokens Attached patch that adds ReadTokensTask.java. I also added change to print net elapsed time of the algorithm. New rev of this patch. Only real change is to reduce overhead slightly of benchmark framework by pre-building array of PerfTasks instead of creating new iterator for each document. I plan to commit this soon... I m reviewing it now... Applies cleanly and all test pass running from contrib benchmark. I like the efficiency changes. A few suggestions 1 in ReadTokensTask change doLogic to return the number of tokens processed in that specific call to doLogic differs from tokensCount which aggregates all calls . 2 in TestPerfTaskLogic the comment in testReadTokens seems copy pasted from testLineDocFile and should be changed. Also I am not sure if it is worth your time but to really test it you could open a reader against the created index and verify the number of docs and also the index sum-of-DF comparing to the total tokens counts numbers in ReadTokensTask. Also I think the addition of printing of elapsed time is redundant because you get it anyhow as the elapsed time reported for the outermost task sequence. For instance if you add to tokenize.alg this line RepSumByName You get this output Operation round runCnt recsPerRun rec s elapsedSec avgUsedMem avgTotalMem Seq Exhaust 0 1 21578 638.2 33.81 15 694 368 20 447 232 Net elapsed time 33.809 sec So the total elapsed time is actually printed twice now - do we need this Also I think the addition of printing of elapsed time is redundant because you get it anyhow as the elapsed time reported for the outermost task sequence. Duh right I will remove that. 1 in ReadTokensTask change doLogic to return the number of tokens processed in that specific call to doLogic differs from tokensCount which aggregates all calls . Ahh good idea 2 in TestPerfTaskLogic the comment in testReadTokens seems copy pasted from testLineDocFile and should be changed. Woops will fix. - Also I am not sure if it is worth your time but to really test it you could open a reader against the created index and verify the number of docs and also the index sum-of-DF comparing to the total tokens counts numbers in ReadTokensTask. OK I added this too. Will submit new patch shortly. Thanks for fixing this Michael looks perfect to me now. Thank you for reviewing I will commit shortly.
