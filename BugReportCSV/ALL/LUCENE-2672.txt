speed up automaton seeking in nextString
While testing i found there are some queries e.g. wildcard that do quite a lot of backtracking. nextString doesn t handle this particularly well when it walks the DFA if it hits a dead-end and needs to backtrack it increments the bytes and starts over completely. alternatively it could save the path information in an int and backtrack could return a position to restart from instead of just a boolean. here is a prototype patch needs more testing and benchmarking. here s another iteration now that we have saved state turns a run into a single step ok heres a committable patch. i put a safety in here to address my own concerns. so the optimization doesnt apply to infinite dfas but these typically dont backtrack anyway i found a little perf problem with Standard s terms dict cache we should avoid clone on these deep hierarchies if theres a chance it will get called a lot. since the class in question is private static i changed how clone was impled. and i turned off terms dict cache for automaton it doesnt seem to help in any query i test and for some worst-case ones it slows things down even with the cloning fix ... and queries like this trash the cache anyway. Committed revision 1001781. I left out the terms dict cache clone thing its something we can revisit if we ever need to... not sure its a big deal especially if we can use it smarter such as LUCENE-2674 
