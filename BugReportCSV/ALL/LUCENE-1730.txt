TrecContentSource should use a fixed encoding rather than system dependent
TrecContentSource opens InputStreamReader w o a fixed encoding. On Windows this means CP1252 at least on my machine which is ok. However when I opened it on a Linux machine w a default of UTF-8 it failed to read the files. The patch changes it to use ISO-8859-1 which seems to be the right one and http mg4j.dsi.unimi.it man manual ch01s04.html mentions this encoding in its example of a script which reads the data . Patch to follow shortly. All tests pass. nice catch Thanks. Took me a while to think in that direction I was sure UTF-8 is what s used in the code . I think that it makes sense to make the default the encoding the one that trec typically always uses but we should probably make this configurable from the alg file. We don t want to be locked down to one input encoding. Could be done in another issue though. Should allow that for the other contentsources as well. I don t understand - the change is in TrecContentSource only which reads the TREC collection which is encoded in ISO-8859-1. Why should it be configurable Only if someone will read it and write it back in say UTF-8 it would make sense to make it configurable right Or am I missing something The trec data you are using is ISO-8859-1. Wouldn t it be conceivable that they might change the encoding to UTF-8 at some point Or that someone else has created trec compatible data in another encoding Or trec has data in different encodings If something reads a source of files and the files could technically be in any encoding I would expect things to be configurable so that I can specify what encoding the files are in. It just seems like a good standard feature with something that reads what are essentially pluggable files. The format is going to be consistent but why would the encoding necessarily be consistent You re right I didn t think in that direction. I ll make it configurable shouldn t be a problem. And if it makes sense and I think it is I ll put the config parameter on ContentSource. Will post a second patch soon. I d like this to be configurable. I used this package to test LUCENE-1628. For this I actually ran it with -Dfile.encoding UTF-8 to prevent this problem so its configurable already...but not obvious. Added content..source.encoding to ContentSource default null and set it to ISO-8859-1 in TrecContentSource and UTF-8 in LineDocSource in case someone wants to use a line file that wasn t created w WriteLineDocTask unless a different encoding is specified. Updated CHANGES and Javadocs. All tests pass. Any volunteers to help me get it in I think it s ready for commit. I havn t patched the code in but looking at the patch it looks like you are setting the default after specifying the encoding to the InputStream GZIPInputStream zis new GZIPInputStream new FileInputStream f BUFFER SIZE reader new BufferedReader new InputStreamReader zis encoding BUFFER SIZE ... if encoding null encoding ISO-8859-1 if encoding null happens in setConfig and the other one in openNextFile forgot the exact method name . The patch includes just the changes w o the method names so it may not be obvious just by looking at it. Okay cool. I ll patch it in run the tests and commit later today. Thanks Shai.
