NPE Thrown when two Cluster Nodes are hitting the same underlying database.
I ve created a test that creates two repositories with clustering enabled that are backed by the same database. Using the following workflow causes a NullPointerException to be thrown. The workflow I m using is The root node is versioned. ClusterNode1 creates a versioned child node named foo . The test waits to make sure the syncDelay has passed so ClusterNode2 will notice the newly created node. ClusterNode2 retrieves the foo child node and removes it. The test waits for the change ClusterNode1 to sync with that change. ClusterNode1 tries to create another new node however a NullPointerException is thrown when the it tries to checkout the rootNode. java.lang.NullPointerException null values not allowed at org.apache.commons.collections.map.AbstractReferenceMap.put AbstractReferenceMap.java 251 at org.apache.jackrabbit.core.version.VersionManagerImpl.getItem VersionManagerImpl.java 280 at org.apache.jackrabbit.core.version.XAVersionManager.getItem XAVersionManager.java 334 at org.apache.jackrabbit.core.version.AbstractVersionManager.getVersion AbstractVersionManager.java 87 at org.apache.jackrabbit.core.NodeImpl.getBaseVersion NodeImpl.java 3198 at org.apache.jackrabbit.core.NodeImpl.checkout NodeImpl.java 2991 at com.cerner.system.configuration.repository.jcr.SimpleJackrabbitConflictTest.testNullPointerExceptionThrown SimpleJackrabbitConflictTest.java 96 The test I used to create this exception and the two repository configuration files I used to configure the two nodes.Clustering in jackrabbit requires persistence managers that connect to a shared datasource. I noticed that the persistence managers in your repository.xml use the embedded Derby JDBC driver which will not work in a clustered setup. Did you try switching to Derby in standalone mode I changed PMs and the Clustering to use the org.apache.derby.jdbc.Driver30 and I still get the same exception. You mentioned that the PMs needed to use a shared datasource. What additional configuration is needed for me to be able to do that Do I need to configure a DataSource 1 at the top of the Repository configuration I ve been using the Clustering 2 wiki page as my guide and it doesn t show any special configuration for using the OraclePersistenceManager. I m actually seeing this issue when hitting an Oracle database. I just used an embedded derby database for this example tests. 1 - http wiki.apache.org jackrabbit DataStore 2 - http wiki.apache.org jackrabbit ClusteringI ve played around with my configuration a bit more and am still not able to get rid of the NPE. In this attachment I modified the repository1.xml file to use the bundle.PersistenceManager and configured a DbDataStore. For the testing purposes repository2.xml is an exact duplicate of the attachment with a different cluster id . This change in configuration does not fix the NPE. This still seems like an Jackrabbit issue instead of an error in my configuration.I have been playing around with the test a bit and have found that if I don t wait for the clusters to synchronize after deleting the node foo that I will get the following stack trace when trying to check out the root node of he first session again. Not completely related to this bug but thought I d post what I was finding. javax.jcr.InvalidItemStateException cafebabe-cafe-babe-cafe-babecafebabe http www.jcp.org jcr 1.0 isCheckedOut has been modified externally at org.apache.jackrabbit.core.ItemImpl.save ItemImpl.java 1248 at org.apache.jackrabbit.core.SessionImpl.save SessionImpl.java 896 at org.apache.jackrabbit.core.NodeImpl.checkout NodeImpl.java 3001 at com.cerner.system.configuration.repository.jcr.SimpleJackrabbitConflictTest.testNullPointerExceptionThrown SimpleJackrabbitConflictTest.java 99 I m still trying to find a workaround or solution to this issue. Looking at the code the issues comes from the fact that the map versionItems of VersionManagerImpl class is never updated syncrhonized between the two cluster nodes. The only time this method is changed is on calls to itemsUpdated Collection which is never called during the synchronization process. So that map becomes stale pretty quickly when multiple nodes are interacting with it.It should also be noted that this is not purely related to removing nodes. I ve changed the test around so the two nodes are adding independent child nodes to the root and it causes the same NPE exception to be thrown when trying to find the item at the item for the given id.I ran into this issue in a similar situation. Debugging in jackrabbit-core-1.4.2 I found that the InternalVersionHistoryImpl contains caches that were not aware of this update made by another node in the cluster. It s not clear to me how these caches are or should be synchronized but I was able to work around the problem by adding the following logic to InternalVersionHistoryImpl getVersion NodeId Run the existing logic to find the version in cache. If the cached version is found return it. If it is not found invoke InternalVersionHistoryImpl reload to ensure newer changes to the repository are visible to the cache Attempt to get the item from cache again now that we ve loaded the latest state I don t know if this is an appropriate fix or if there is some other workaround we might use. However this might shed some light on what is happening here. I imagine the reload operation can be expensive but it shouldn t be called during a normal flow. I m also trying to better understand the threading model in Jackrabbit to ensure this mutation doesn t cause any race condition. Ryan s patch fixes the issue I was seeing. I agree it isn t necessarily the most elegant solution. Can someone review his patch and commit it to trunk or perhaps propose a better solution Thanks.While coding against the 1.5-SNAPSHOT I started seeing a different exception being logged 1 . The attachment includes the same test that was previously attached but modified to run on linux and it will reliably produce the stack trace. The two repository.xml files were updated to support the newer security configuration needed as well. I have not tried applying Ryan s patch yet to see if it fixes this issue. Could someone look at comment on the patch It would be nice if this fix could make it into an upcoming release like 1.4.6 but if not maybe the 1.5. Thanks. 1 java.lang.NullPointerException at org.apache.jackrabbit.core.version.AbstractVersionManager.calculateCheckinVersionName AbstractVersionManager.java 458 at org.apache.jackrabbit.core.version.AbstractVersionManager.checkin AbstractVersionManager.java 392 at org.apache.jackrabbit.core.version.VersionManagerImpl 2.run VersionManagerImpl.java 280 at org.apache.jackrabbit.core.version.VersionManagerImpl DynamicESCFactory.doSourced VersionManagerImpl.java 563 at org.apache.jackrabbit.core.version.VersionManagerImpl.checkin VersionManagerImpl.java 276 at org.apache.jackrabbit.core.version.XAVersionManager.checkin XAVersionManager.java 155 at org.apache.jackrabbit.core.NodeImpl.checkin NodeImpl.java 3309 at com.cerner.system.configuration.repository.jcr.SimpleJackrabbitConflictTest.testNullPointerExceptionThrown SimpleJackrabbitConflictTest.java 105 I applied Ryan s patch to trunk and it fixed the NPE being thrown.What can someone do to help this issue be resolved A patch and junit have been supplied a long time ago. What else is needed for this to be resolved for one of the official releases I m sorry about the long inaction on this issue. I ve now committed Ryan s patch as it seems to solve the immediate issue. The solution however seems a bit hacky and reminds me of the double-checked locking antipattern. It would be better if the caches were loaded only on-demand and correctly invalidated on cluster changes. Or perhaps we could drop the version history caches entirely as the underlying item state managers should already take care of the performance impact.In revision 919461 I added automatic invalidation of the internal version history caches based on related update events from other cluster nodes. This still needs some testing but ideally I d like to get rid of the previous double-load solution.Resolving as fixed as the reported problem no longer occurs. We can improve the design later on in followup issues.
