UUIDDocId cache does not work properly because of weakReferences in combination with new instance for combined indexreader
Queries that use ChildAxisQuery or DescendantSelfAxisQuery make use of getParent functions to know wether the parents are correct and if the result is allowed. The getParent is called recursively for every hit and can become very expensive. Hence in DocId.UUIDDocId the parents are cached. Currently docId.UUIDDocId s are cached by having a WeakRefence to the CombinedIndexReader but this CombinedIndexReader is recreated all the time implying that a gc is allowed to remove the expensive cache. A much better solution is to not have a weakReference to the CombinedIndexReader but to a reference of each indexreader segment. This means that in getParent int n in SearchIndex the return return id.getDocumentNumber this needs to be replaced by return id.getDocumentNumber subReaders i and something similar in CachingMultiReader. That is all. Obviously when a node property is added removed changed some parts of the cached DocId.UUIDDocId will be invalid but mainly small indexes are updated frequently which obviously are less expensive to recompute.When this JIRA issue has been solved JCR-1196 will be resolved improved partly In JCR-1196 the problem about slow DescendantSelfAxisWeight ChildAxisQuery will mainly stay for the first query that extensively uses getParent calls or when a large index reader has been changed. Subsequent DescendantSelfAxisWeight ChildAxisQuery queries will run fast when only small indexes are changed or no index has been changed. return id.getDocumentNumber this needs to be replaced by return id.getDocumentNumber subReaders i and something similar in CachingMultiReader. The above does solve the problem. In SearchIndex it is more complicated than this. In SearchIndex public int getParent int n throws IOException             int i readerIndex n             DocId id subReaders i .getParentDocId n - starts i             id id.applyOffset starts i             return id.getDocumentNumber subReaders i              return id.getDocumentNumber this          replacing the last line by the subReaders i is not enough because I missed the part that subReaders i returns a CachingMultiReader keeping the problem of a cache which will be cleared to often when a single index changes . This is also logical because I did not understand how a parent document number could be found if the parent would be in a different lucene index. So in the id.getDocumentNumber subReaders i I think I need to check in which indexReader the parent is found and use this indexReader instance for the WeakReference. I ll try to implement this. The above does solve the problem. In SearchIndex it is more complicated than this. In SearchIndex Obviously the first line should have been does not solve the problem I was in a hurry - In UUIDDocId getDocumentNumber IndexReader reader when the parent docNumber is found I can look up in which indexReader instance it was found in and use this instance for the weakreference. Then I should be able to check wether this instance is still available as an indexReader in the CachingMultiReader which is the arg in getDocumentNumber. However I need to check wether this extra step does not involve to much overhead. I ll get back on this ll try to implement it this week.Just wanted to let you know that what you described is exactly how I imagined a solution. And the same concerns about the reader lookup crossed my mind... But let s see if it even matters. Looking forward to seeing your patch.I ll use a profiler to see wether the extra step might use to much cpu. If so I ll rethink the solution. First of all I ll just measure it Looking forward to seeing your patch I ll try to find time ASAP - Ard wrote Am thinking about a two step check where first a reference to the entire MultiIndexReader is checked. IF 1 check reference to the entire MultiIndexReader instance is positive return cached results. ELSE IF 2 check the index reader segment instance the parent docnumber was in if instance present recompute docNumber with respect to the new offsets in MultiIndexReader and return almost cached result. ELSE 3 recompute docNumber by search in MultiIndexReader the uncached case I would rather make it simple and just use one approach. The first check 1 is the reason why you created this issue. I think we should therefore remove this check and replace it with something that works better. The additional check 2 is not necessary IMO because we have DocId.applyOffset though we will have to modify the signature because the code currently assumes that the returned DocId is tied to the index segment it originated from. Thus the offset for that segment is passed at applyOffset . Because the UUIDDocId also relates to another index segment parent points to another segment the applyOffset in its current form is useless for the UUIDDocId implementation. Maybe we should pass in the complete information. All readers and their offsets. This allows the UUIDDocId to apply an offset properly. As for 3 this is again part of the issue we should try to solve thus we should not relate a UUIDDocId to the MultiIndexReader but to a index segment reader within it. I ll also start with a diagram explaining the various readers and how they relate to each other. The first check 1 is the reason why you created this issue Not entirely currently the CombinedIndexReader instance is used as a WeakReference and this one is recreated for every search. The MultiIndexReader instance is kept AFAICS as long as all indexes are the same. So in SearchIndex changing public int getParent int n throws IOException             .....             return id.getDocumentNumber this into public int getParent int n throws IOException             .....             return id.getDocumentNumber subReaders i would already implement 1 . This one holds when every index reader instance is the same. If one of the instances has changed we would need step 2 IIUC. Then we could check wether the instance the parent was found in is still valid and as you indicate should return the corrected DocNumber which might be different due to applyOffSet. When 1 and 2 are both invalid then the search for the parent node in subReaders i should be done again. I agree that 1 is redundant because 2 captures 1 but I added it because first of all it is something we can add right away and secondly because I think but I should measure that if the subReaders i instance MultiIndexReader did not change it is useless to do a lookup of the index reader segment the parent was in and check wether the instance is still valid. I do agree with you that if removing 1 does not imply any performance loss we should only go for 2 . But it is not correct that 1 does not solve anything to the original problem instead of the CombinedIndexReader which is recreated all the time I pass in the MultiIndexReader whose instance is kept as long as no indexes change. This is at least what I understand from the mechanism but I am not as familiar as you are with it ofcourse so I might be off. But it is not correct that 1 does not solve anything to the original problem instead of the CombinedIndexReader which is recreated all the time I pass in the MultiIndexReader whose instance is kept as long as no indexes change. If we can make the MultiIndexReader instance more stable in terms of re-using it as many times as possible this will of course help us and keep cache entries valid. But since this only applies to cases where there are no changes to the workspace it seems to me that this will not buy use much except for special occasions where the workspace is not modified for some time. This is at least what I understand from the mechanism but I am not as familiar as you are with it ofcourse so I might be off. your understanding is correct. I guess we just have a differing judgment about when and how often the cost of building cache entries and maintaining them should be spent. I guess we just have a differing judgment about when and how often the cost of building cache entries and maintaining them should be spent. I think we have the same end goal If the index segment instance in which the parent lookup was found is still valid return cached docNumber. This is the main performance we look for. And I also think we agree on the implementation regarding the segment instance reference. I only referred to option 1 as the simple first test for valid cache and then 2 . So in UUIDDocId I would create a weakReference to MultiIndexReader and a seperate one to CachingIndexReader a single segment . If 1 is valid you are ready otherwise check 2 . If 1 is equally fast as 2 performance test I agree on removing 1 I really think we are on the same track and are talking about the same mechanism for maintaining the cache. I was referring to a light weight instance validity test first and then fall back to the segment instance test. But as you indicate this one might be totally useless in a frequently modifying workspace. I ll try to implement some of these options sunday and try to capture some performance figures. WDYT You are right instead of talking we should just try it out and see whether it makes a different - will have post my findings Sunday ATM I have been able to change some parts to store in UUIDDocId a reference to the segmentIndexReader the documentNumber was found in. This means that not the entire cache is lost when the multi Index changes but only those parts that involve a segment change. Now I am looking at a clean way to recompute the docNumber because even if the segment index reader did not change the docNumber might quite likely because the multiIndexReader has changed hence the individual reader offsets as well. I ll try to find time next week for it. Perhaps somebody has an idea how to implement it clean because I do not really like the way I am heading with changing the SingleTermDocs to store the docNumber with offset and also store the docNumber without to have the doc number available in the segment. This implies in DocId I have to cast to SingleTermDocs....etc etc which is not nice. WDOT Any ideas Or should we refactor a few parts to be able to recompute the docNumber I think whatever UUIDDocId calculates should be independent of the multi index reader. That is it should only hold the document number as retrieved from the index segment. Then in a second step an offset should be applied as with the PlainDocId to accommodate the multi index reader wrapping. This probably means we have to change some of the signatures but that s OK. I think whatever UUIDDocId calculates should be independent of the multi index reader. That is it should only hold the document number as retrieved from the index segment. Then in a second step an offset should be applied Yes this is probably the cleanest way. I now also understand why we had the discussion about how to solve the issue. You were already thinking about computing the docNumber in a second step hence all that matters is the segment instance. So the latter part about the segment instance I did build though we might discuss wether it is a good way. I added a method to MultiIndexReader interface public boolean hasIndexReaderInstance IndexReader indexReader and in CachingMultiReader and CombinedIndexReader I keep track of subreaders instances with an IdentityHashMap . In UUIDDocId I can find the reader instance the doc was found in by changing SingleTermDocs by having a reference to its segment reader. Obviously now I have to cast reader.termDocs id to SingleTermDocs which we might not like. Anyway I ll try to add the second step offset in calculating the docNumber as you suggested somewhere this week and create a patch might be easier than talking about a solution . Follow up I have been trying to cache docNumbers with respect to their IndexSegments which obviously do change less frequently. Caching based on an entire CachingMultiReader is trivial but also the performance gain is to small since the multiReader changes to frequently. But I am having difficulties somebody might be able to help me with Bottom line is we do not want to cache based on the entire CachingMultiReader but on its segments it consists of. Now I build hacked for the time being something that in DocId.UUIDDocId I keep track of the segment reference through a WeakReference. But....as I didn t see behavior I was expecting I found another difficulty The multiReader which is created in MultiIndex is a CachingMultiReader consisting of ReadOnlyIndexReader s. When something changed in one of the indexes a new multiReader is constructed....but instead of reusing the non-changed ReadOnlyIndexReader instances every ReadOnlyIndexReader is re-constructed not the shared caching reader they consist of though but since the instances our multiReader consists of are recreated my WeakReferences based on segment instances are useless. So instead of using a WeakReference on the multiReader segments I could get the sharedReader instance out of it but this means casting and adding methods something we really do not want of course and i am not sure if the BitSet keeing track of deleted might have changed without the sharedReader being changed to be honest I cannot yet grasp the big picture about keeping track of the deleted bitset . So does anybody have an idea how we might be able to have in MultiIndex.getIndexReader only new instances of the ReadOnlyIndexReaders which actually changed...Or is this not an option I did try to add it to the AbstractIndex to check wether there was already an instance of ReadOnlyIndexReader but then I get AlreadyClosedException in lucene. I can make another JIRA issue for it if others think it might be valuable and not part of this issue. WDOT I recently added some documentation to the website about the index readers http jackrabbit.apache.org doc arch operate index-readers.html to be honest I cannot yet grasp the big picture about keeping track of the deleted bitset The new documentation shows how and when the deleted bit set for the ReadOnlyIndexReader is created. The ReadOnlyIndexReaders are indeed constructed on every change. That s very unfortunate and should be changed. I ll create an issue for that. While this will fix the case where an ReadOnlyIndexReader is re-constructed even though nothing changed in that segment we will still have the issue that a new ReadOnlyIndexReader is constructed if a node is deleted in that segment. Even in that case we don t want to re-calculate all the UUIDDocIds that point to this segment. So instead of using a WeakReference on the multiReader segments I could get the sharedReader instance out of it Yes that s probably the only way how to keep the UUIDDocIds valid as long as possible. A chose a similar approach in CachingMultiReader.termDocs Term . The relation between the shared reader and the read only reader is held in readersByBase. But that s quite ugly. Thinking more about this issue it might be worth looking at an alternative. There is a DocNumberCache which maps a UUID to a CachingIndexReader with a document number. This is exactly the information that is also present in a UUIDDocId. So we might just as well not cache the result in UUIDDocId but always use the DocNumberCache to resolve it. However I m not sure how much overhead that adds. I ll have to investigate that first... http jackrabbit.apache.org doc arch operate index-readers.html This is really really nice to read I just only now understand the deleted BitSet idea and that SharedIndexReader lives during the entire life of a PersistentIndex. Since in older existing indexes only documents can be deleted we keep the same SharedIndexReader even if the index changed and keep track of the deleted items in the deleted BitSet. And this should give us a very good possibility to cache the parent relationships of a node even though underlying lucene indexes change because of the deletion of a document I am pretty much recapitulating and adding nothing new and certainly nothing you don t already know but see it as thinking out loud - I ll try to look at the end of the day at your suggestion at the end of your comment and also see if i can get a hacky working version with the readersByBase. A nice solution can be made afterwards if it is a succes. After reading your documentation I am really confident we can make a very efficient cache for the docNumbers. I ll investigate as well.... - Minor thing why in DocId.UUIDDocId getDocumentNumber the synchronized method is needed at the end synchronized this          docNumber doc          this.reader new WeakReference reader It must be for this.reader new WeakReference reader AFAICS. But for setting a WeakReference does it matter when at that moment the reader instance is removed I can set a WeakReference null without problem. Because getDocumentNumber may be called from multiple concurrent threads. If the block is not synchronized there is no guarantee that the docNumber and the reader are consistent. A JVM may update the docNumber and the reader out-of-order if the code is not synchronized. Likewise if no synchronization is present the JVM may operate on local memory that e.g. represents a stale docNumber.Aaaah yes you are right. ATM I have a working test version that seems to solve this issue keep consecutive DescendantSelfAxisWeight ChildAxisQuery queries fast when gc has done its work so the WeakReferences are correct now and is also fast when incremental nodes are added deleted from the index. To test the performance improvement you need a large repository for 1.000.000 nodes where parent nodes are frequently found in different indexes. Then running queries like xpath documents caption where many nodes have this property will be much faster in consecutive runs. A query like documents date that has many common parents with caption should run fast. The problem of inital slow DescendantSelfAxisWeight ChildAxisQuery keeps being a problem. OTOH we might do some cache warming up if we start the repository. Since CachingIndexReader are kept during the live time of a persistent index it might be quite useful. Here is also what I think is confusing about http jackrabbit.apache.org doc arch operate index-readers.html There it says A SharedIndexReader is kept open for the entire lifetime of a PersistentIndex but AFAIU the CachingIndexReader which is wrapped by SharedIndexReader is already kept for lifetime of a PersistentIndex and the SharedIndexReader is merely kept for the lifetime of all running requests by reference counting. If I am correct I can change the documentation slightly . Furthermore I tested the impact of the step 1 step 2 check for the reference to the MultiIndexReader if valid return docNumber instantly or when invalid but segment reader is valid recompute docNumber. If I remove step 1 I see no performance change therefore will refactor to only have step 2 and I will always recompute the actual docNumber. I ll try to have a patch for testing ready today I have not invested Thinking more about this issue it might be worth looking at an alternative. There is a DocNumberCache which maps a UUID to a CachingIndexReader with a document number. This is exactly the information that is also present in a UUIDDocId. So we might just as well not cache the result in UUIDDocId but always use the DocNumberCache to resolve it. However I m not sure how much overhead that adds. I ll have to investigate that first... This is a patch solving the WeakReferences and improving the ChildAxisQuery and DescendantSelfAxisQuery queries speed bu properly caching parent nodex hierarchy. Obviously I do not really like the dependency in DocId.UUIDDocId on SingleTermDocs with this patch and dependency on MultiIndexReader. Perhaps we can change this later. For now perhaps somebody likes to test the patch specifically on large repositories with ChildAxisQuery or DescendantSelfAxisQuery . Test results for me show an enormous performance gain after the initial queries which are executed with empty caches. Hopefully somebody can test it.Ard thank you very much for the patch. I m about to create a performance test which basically does the following - create lots of nodes - run queries that use DescendantSelfAxisQuery and or ChildAxisQuery - at the same time randomly modify content I reviewed you patch and I also don t like the dependency to SingleTermDocs in UUIDDocId. I ve created a patch as well but took a somewhat different approach. Instead of using a weak reference to the index reader I used the creation tick in the CachingIndexReader. The creation tick uniquely identifies an index segment as well as the version of the segment. E.g. if a document is added a new CachingIndexReader is created for that segment with a new creation tick. The same will probably also work for the DocNumberCache which currently uses strong references. I d like to change that as well but that s a bit off topic and and different issue. I will run the above test with 1 the current code base 2 your patch and 3 my patch. I ll let you know about the results....Hello Marcel just read your patch. I ll try to test your solution tomorrow at the end of the day as well. AFAICS I think performance between both solutions won t be measurable. Your code is nicer as I already indicated I had some dependencies I did not like at all. When creating a lot of nodes also remember to update a lot of nodes to create the gabs in the index and lots of parents that are found in different indexes. I never new about the creation tick. If it is unique for a reader instance it should obviously work. Also nice to not have the SingleTermDocs dependance in UUIDDocId Anyway I ll check your patch tomorrow and think we have a very much better working cache here for the hierarchical relations.I also expect that the two patches will have similar performance characteristics. In the end both implement the same idea just slightly different. In contrast to your patch mine is nearly twice as large and I had to modify many existing signatures. Instead of IndexReader many methods now deal with concrete extensions of IndexReader. I m not sure if this is desirable but in some occasions it helps to better understand whether code deals with content just present in one index segment or the overall index. When creating a lot of nodes also remember to update a lot of nodes to create the gabs in the index. I try to simulate this by running a concurrent thread that modifies content while the test runs. I plan to run the tests for an hour or two to see what effect it has.If you can want to attach your test as well I can tomorrow evening do some or the same tests as well Also look at some profiling memory snapshots and some processor hotspots.....just out curiosity. Might be nice to see the getParent taking 99 cpu I saw this actually after a gc being really downgraded with your patch and mine and see if I can spot differcences sure here you go. The test creates about 1 million nodes and then runs queries using two threads for one minute. As mentioned before another thread will randomly modify nodes at the same time.thx....I ll keep you postedI like Marcels idea to use the creation tick to identity the base index reader without caring about the index reader hierarchy. This patch is a modified version of Marcels patch moving the logic out of UUIDDocId to CachingMultiReader which removes the necessity to expose OffsetIndexReaders. UUIDDocId doesn t even know about offsets anymore. I m not sure though if creating those MultiIndexReaderDoc objects is to expensive performance and memory wise although I got similar performance numbers using Marcels test. This code could easily be used for DocNumberCache as well as Marcel stated which is a big plus I think. Ok then beat me for just modifying your code I really appreciate your work on this issue.Fixed a small glitch. And btw there is still some javadoc missing. This patch is just a prototype.I have tested all patches. All three patches seem to have similar performance improvements compared to the former code they are all very much faster in the cached version . ATM I am reshuffle the indexes to have more parent lookups in other indexes and then will really see if all have the same performance. It might boil down to which patch has the nicest solution. Mine with the WeakReferences is obviously outdated and can be discarded. I think you have to decide which one you want to choose. I think Christoph s patch uses a little more memory because it keeps MultiIndexReaderDoc objects in memory but instead of keeping the MultiIndexReaderDoc in memory you could store the int and long in the DocUUID just like instead of a UUID isntance we store msb and lsb . Though we are talking only about the object overhead so 1 million MultiIndexReaderDoc would imply some 12 Mb extra memory not really shocking But still...during the test having 1.200.000 nodes in the repository I realized we are still doing something irrational . It won t be easy to implement I think because it also depends involves wether people have implemented an AccessManager but if I have the following test Query q qm.createQuery stuff count Query.XPATH if q instanceof QueryImpl      limit the result set      QueryImpl q .setLimit 1 Since my stuff count gives me 1.200.000 it makes perfect sense to users I think that even with our patches and a working cache that retaining them all would be slow. But if I set the limit to 1 or 10 I would expect to have performance certainly when you have not implemented any AccessManager . But if I set limit to 1 why would we have to check all 1.200.000 parents wether the path is correct If I get a sorted hits by lucene I would want to start with the first one and check the parent then the second etc untill I have a hit that is correct according its path. If I have a limit of 10 we would need to get 10 successes. Obviously in the worst case scenario we would still have to check every hit for its parents but this would be rather exceptional i think. Ofcourse when people have a custom AccessManager impl you only know after the access manager wether the hit was a real hit. But when having Query q qm.createQuery stuff count Query.XPATH if q instanceof QueryImpl      limit the result set      QueryImpl q .setLimit 1 and I have 1.000.000 hits and I have to wait even in the cached version a few seconds but changing stuff count into count reduces it to a couple of ms that does not make sense. I think we should consider wether we could do the DescendantSelfAxisQuery or ChildAxisQuery as some sort of lazy filter. In the end when users want to also have the total hits for stuff count we obviously are still facing a slow query. WDOT This though obviously might belong to a new jira issue or to the existing one about the DescendantSelfAxisQuery and ChildAxisQuery performance. Christoph wrote Ok then beat me for just modifying your code if it were possible I would turn that into a unix command so I could always do cat MyHackyCode.java kielify - Here are my test results. I had to reduce the number of test nodes because I exactly saw what Ard just described. Currently all hits are path checked hence the poor performance in any test run. http people.apache.org mreutegg 2007 11 JCR-1213 100k-test.html Initially the performance with the current code base is not that bad but as soon as more DocIds across index segments are created the performance drops drastically. As you can see with both Ards and my patch the performance remains stable.Finally committed a mix of christophs and my patch. The performance characteristics are very similar to the attached patches.
