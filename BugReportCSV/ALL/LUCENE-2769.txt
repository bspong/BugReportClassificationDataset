FilterIndexReader in trunk does not implement getSequentialSubReaders correctly
Since LUCENE-2459 getSequentialSubReaders in FilterIndexReader returns null so it returns an atomic reader. But If you call then any of the enum methods it throws Exception because the underlying reader is not atomic. We should move the null-returning method to SlowMultiReaderWrapper and fix FilterIndexReader s default to return in.getSequentialSubReaders . Ideally an implementation must of course also wrap the sub-readers. If we change this we have to look into other Impls like the MultiPassIndexSplitter if we need to add atomicity. In my opinion LUCENE-2459 should be reverted and all places that can not correctly filter per segment should use SlowMultiReaderWrapper as superclass like e.g. MultiPassIndexSplitter or better simply wrap with SlowMultiReaderWrapper in the ctor ctor IndexReader in super SlowMultiReaderWrapper.wrap in ok try 2 we shouldn t encourage subclassing of SlowMultiReaderWrapper Additionally to this The MultiPassIndexSplitter in 3.x and 3.0 should also return null in getSeqSubReaders. It works currently because we know how SegmentMerger works but its still incorrect. To Filter the terms correctly it should imitate a atomic reader. We can use the SlowMultiWrapper also to remove norms merging in DirectoryReader.norms field and MultiReader.norms field should also throw UOE like fields . If you need top-level norms use the SlowMultiReaderWrapper. This patch was a new FilterIndexReader subclass and it included some fixes to FilterIndexReader and also refactoring of Junit tests to better support reader subclassing. A wrap method was added to FilterIndexReader to allow subclasses to specialize subreaders. here is a hack patch for Uwe s idea about the norms. we need to change SegmentMerger to not call norms on the top-level IR but populate its normBuffer from the subs. in my opinion it seems crazy we are currently creating these big arrays this way yeah there is the hairy code for re-open that re-uses the big merged cache for the NRT case but still . Maybe i am missing something. here s another hacky update but still a few tests explicitly check these norms and need to be fixed. maybe we could add an uncached MultiNorms or something at least in src test for convenience just to fill the byte arrays so these tests can assertEquals otherwise we are going to have to put a lot of SlowMultiReaderWrappers in these tests. Here a better patch for the segment merger. We should even apply this if we not remove top-level norms It saves lots of memory during merging by using ReaderUtil to go down to segment level Don t wonder about BytesRef but we need a reference here because of the anonymous inner class. here is an updated patch with core contrib solr tests passing. For ParallelReader i forced it to require non-composite readers only e.g. SlowMultiReaderWrap them if thats not the case . TODO ParallelReader shouldnt need multifields etc anymore there are 5 Ignore d ParallelReader-related tests because of things like reopen isOptimized isCurrent merge in Uwe s improved SegmentsMerger clean up code. Here a new SegmentMerger now working only on atomic readers. All normal tests pass but it seems that addIndexesWithThreads fails during merging term vectors. This is not clear all other tests pass and the created indexes are fine. Mike Do you understand that The problem seems to be some thread safety issue in addIndexes IndexReader... . Not sure who changes who s internal structures Maybe suddenly subreaders change Last patch containes unused variable a relic from very earlier times . int starts in merge terms is not needed. I removed the SegmentMerger patches from here and moved over to LUCENE-2770. The problem noted before is now solved. The SegmentMerger missed to clone TVReaders. This was a bug not recognized before. I thought about this more i think for this issue we should not make SlowMultiReaderWrapper complicated and force ParallelReader to take atomic readers. instead we should remove norms from Multi DirReader like my patch suggests and make ParallelReader manage its own cached norms. For ParallelReader this is no worse than today but no better either. We should seriously either figure out how to fix this ParallelReader or move it to contrib. I created new issue for the norms thing LUCENE-2771 I will commit the basic patch without norms soon and update the norms patch to latest trunk. Committed basic patch revision 1036977
