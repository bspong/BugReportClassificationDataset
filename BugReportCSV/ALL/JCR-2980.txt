Nodes that have properties marked for async extraction should be available for querying
The problems only appears when dealing with nodes that have async extractors. In this case we return a lightweight copy of the node without the property that will be processed in the background . The copy algorithm ignores certain field types that have been probably introduced during the Lucene 3 upgrade not sure such as SingletonTokenStream s . So the lightweight copy does not include all the existing properties therefore the node will not appear in queries during the extraction time.fixed on trunk in rev 1128325 fixed on branch 2.2 in rev 1128329This change seems to introduce some regressions to the 2.2 branch so reopening. See https builds.apache.org job Jackrabbit-2.2 1 org.apache.jackrabbit jackrabbit-core for example build failures. I ll revert the change from the 2.2 branch so I can proceed with the 2.2.7 release. We can do another 2.2.x release with this change once we ve figured out the cause of the regression.Reverted from 2.2 in revision 1130018.ouch I ve been looking at this all day and I can t figure it out the extraction logic has changed a bit also the lucene version but still I can t put my finger on it. I still think that the test was good enough to check what is going on in that small window when the processing happens but adding the extra properties to the node copy seems to introduce some problems. also apparently running the failing tests IndexingAggregateTest.testNtFileAggregate and IndexingQueueTest.testInitialIndex 2 times makes them pass so I d point to the sync logic between the extraction and current session but I m not sure. comments are always welcomeYep I spent most of yesterday trying to understand the problem here and in the end had to just revert the change for now. We only upgraded to Lucene 3.0 in the trunk after 2.2 had already been branched see JCR-2415 which is probably related to why the fix doesn t work the same in the 2.2 branch as it does in trunk. However I m still at loss at why this seemingly innocent change is causing trouble for 2.2.Actually I just encountered this problem also on Jackrabbit trunk testInitialIndex org.apache.jackrabbit.core.query.lucene.IndexingQueueTest Time elapsed 0.626 sec FAILURE junit.framework.AssertionFailedError expected 110 but was 107         at junit.framework.Assert.fail Assert.java 47         at junit.framework.Assert.failNotEquals Assert.java 282         at junit.framework.Assert.assertEquals Assert.java 64         at junit.framework.Assert.assertEquals Assert.java 136         at junit.framework.Assert.assertEquals Assert.java 142         at org.apache.jackrabbit.core.query.lucene.IndexingQueueTest.testInitialIndex IndexingQueueTest.java 127 I have finally figured it out. It was my change that triggered this issue in fact the TokenStream that I was passing to the node s copy was not meant to be consumed more than once so sometimes the copy consumed the data leaving nothing else for the real node. To be more exact when the extraction was slow it passed to the background. If this happened the real node would loose its original data because of the TokenStream. The fix was to add reset and close methods to the SingletonTokenStream so that it can be consumed mode than once.fixed on trunk in Revision 1131652 backported to 2.2 in Revision 1131653I removed 2.2.7 as it is better to wait a bit and make sure that this time there are no more surprises It will be included in 2.2.8.
