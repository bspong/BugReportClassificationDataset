New Analysis Contributions
With the advent of the new TeeTokenFilter and SinkTokenizer there now exists some interesting new things that can be done in the analysis phase of indexing. See LUCENE-1058. This patch provides some new implementations of SinkTokenizer that may be useful. This is a fairly trivial start to to this but it creates the sinks package in the contrib Analysis section and adds a simple TokenRangeSinkTokenizer and test. This can be used to siphon off tokens that fall in a range. All it does is count the tokens that go by and add those that fall in the range. It might be useful for documents that you know have certain structures. For instance if you know the first 5 tokens of your docs are X. More to follow. Expanding to add in some other analysis capabilities Adds to the sinks package DateRecognizerSinkTokenizer which only adds dates that can be parsed by a DateFormat object TokenRangeSinkTokenizer as described earlier TokenTypeSinkTokenizer only adds to the sink if the token type is a specific value. Adds the payloads package which contains NumericPayloadTokenFilter Ð Assigns a predefined float-based payload to a Token if the type matches the specified input type of the Token. As a use case this could be used to assign a payload for all tokens that are marked as bold or some other value. Thought of another possibly useful payload convenience TokenFilter that adds the Token type as the payload. I ve always wondered why we don t make more use of the type attribute on a Token. Committed
