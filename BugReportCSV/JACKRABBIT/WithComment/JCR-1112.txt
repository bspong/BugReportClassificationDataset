CacheManager interval between recalculation of cache sizes should be configurable
Currently interval between recaluclation of cahce size is hard coded to 1000 ms. Resizing recalculation of cache size is quite expensive method especially getMemoryUsed on MLRUItemStateCache is time consuming Depending on the configuration we realized that under some load up to 10-15 percent of CPU time profiler metrics could be spend doing such recalculations. It does not seem to be needed to resize cache every second. Best this interval should be configurable in external config. file with other cache settings like memory sizes .Attached simple patch which allows to set the interval programmatically and change the default interval to 10 seconds. 1 I d wouldn t mind pushing the default interval up to a minute or even higher. I don t think there s much benefit in too aggressive cache balancing.BTW please use spaces instead of tabs for indentation.For certain use cases 10 seconds delay may result in OutOfMemoryException. I m not against applying this patch but we need to be sure it doesn t render the CacheManager ineffective. under some load Is there a way to reproduce this problem using a simple test application If not I like to write one. To do that I need some more information How many sessions how much memory is available used java -Xmx... what is the algorithm is XA used versioning how do the nodes look like how does the data look like virtual machine operating system up to 10-15 percent of CPU time profiler metrics How was this measured Thanks Thomas I can reproduce this problem or something related to this by simply importing an XML file with a few thousand nodes. The more nodes I have in the repository and the more time the system spend in rebalancing the cache pretty much at every access to the repository. I was experimenting with a system with a simple hierarchical structure like users   user1   user2   user3 for each user I had a large data structure stored as XML like an imported XML file with such a system even with only a few users accessing to the node users userX takes seconds and the more users or complex structure I have the longer it takes and all I see in the logs is resizeAll messages and all I see in the logs is resizeAll messages Don t blame the messenger. Seeing the messages doesn t mean this is the problem. The messages are disabled in the trunk. Do you have some profiling data In my view the root cause why does recalculation take so long are there hundreds of caches should be understood and fixed. Just changing the interval would hide another problem and may cause out of memory error. To solve this problem the root cause of the problem needs to be reproducible but maybe the solution will be different then .Hi I think that there are some issues with the current CacheManager that could be improved - The MLRUItemStateCache.touch method triggers the CacheManager.cacheAccessed method which may call resizeAll. When the system is heavily loaded many threads may unnecessarily be blocked by the synchronized block in CacheManager.cacheAccessed. The chances for this increase as SLEEP decreases and the time needed for resizeAll increases. This could easily be improved . - The resizeAll method is expensive for MLRUItemStateCaches which are used everywhere because it calls MLRUItemStateCache.getMemoryUsed which recalculates the size of each entry in the cache linear complexity in the size of the cache... . Since the NodeState PropertyState.calculateMemoryFootprint seem to give approximate values anyway wouldn t it be an idea to keep track of the approximate cache size in the MLRUItemStateCache itself Furthermore getMemoryUsed even blocks read-access to the cache. A large shared cache such as the one of the SharedItemStateManager suffers significantly from this I think. The minimum time between rebalancing seems small but as Thomas noted there are certain use-cases where this is needed. Isn t there a way to detect such extreme cache blowups in another way When for instance a MLRUItemStateCache keeps track of its own approximate size the time derivative of this size could be used to prevent blowups. Best wishes MartijnHi The method getMemoryUsed could be improved by keeping the current value and only add subtract when there are changes. Still from time to time a full recalculation like now is required because the size of the objects in the cache could change. If only one in 20 calls trigger a full recalculation it would result in a speed up of about 10 times. For me the CacheManager is a workaround if possible the number of caches should be reduced to one. Thomas For me the CacheManager is a workaround if possible the number of caches should be reduced to one. 1 Resolving as fixed for 1.4 based Przemo s changes in revision 592950.Merged to the 1.3 branch in revision 631606.
