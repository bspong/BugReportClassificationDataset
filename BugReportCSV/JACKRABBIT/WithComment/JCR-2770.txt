Initial size of ConcurrentCache depends on number of segments available processors 
This causes a build failure on my machine. Tests run into an OOME because the initial memory footprint of a ConcurrentCache on my machine is 8k. Many of the tests keep references to some kind of repository objects node session x-manager which means ConcurrentCache instances cannot be garbage collected immediately after a test run. I think the overall initial size of the cache should be independent of the number of segments. See proposed patch. 1 Alternatively we could just set the initial size to the default 16 as the resize logic shouldn t really affect performance to any notable degree.That was actually another point I noticed when I looked at the code. What is the reason that you set the initial size to 1024 What is the reason that you set the initial size to 1024 The three-argument constructor that s needed to enable LRU behaviour requires some value there and since there s no public constant for the default value I simply selected something that seemed reasonable. I chose a high value since I expected most practical cases to in any case use pretty large caches and since environments with lots of processors would typically also have lots of available memory. I of course forgot to consider the fixed memory limits we specify for our test runs. Essentially I just picked the value from my proverbial hat so it s fine to change it to something different especially if doing so helps prevent problems three-argument constructor ah right. thanks that explains it.I went ahead and changed the initial size of each cache segment from 1024 to 16. See revision 1005112.Resolving as fixed.Merged to the 2.1 branch in revision 1026002.And merged to the 2.0 branch in revision 1026027.
