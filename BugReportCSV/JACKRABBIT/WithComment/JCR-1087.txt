Maintain the cluster revision table
The revision table in which cluster nodes write their changes can potentially become very large. If all cluster nodes are up to date to a certain revision number then it seems unnecessary to keep the revisions with a lower number.I m linking this issue to JCR-905 because the solution of that issue has an impact on whether or not all revisions should be kept.When the cluster revision table becomes too large a cluster node without search index and local revision number cannot be started due to memory problems see attached stacktrace .The resolution of JCR-905 allows us to remove all unnecessary revision data. I.e. the minimum of all local revisions of the clusternodes gives an upperbound on the revisions that can safely be removed from the database. A solution for this issue would be to add a periodic task that removes all unnecessary revisions - All clusternodes should add their local revision to the database. - Add a configuration option in the repository.xml to let one of the clusternodes execute the cleanup task i.e. period and offset such as every night at 00 00 hours .Attached is a patch for this issue. When a DatabaseJournal is used the local revisions are also stored in the database instead of on the local file system. This information can then be used for periodic clean-ups of the JOURNAL table which may become very large. Note that this only works if all JR information except for the search index is stored in the database. The clean-up thread is disabled by default. Please comment. Thanks Hi Martijn your patch looks good to me so please go ahead and submit it. One nice thing that might be required for people already owning a database journal is there a way to easily detect whether the LOCAL REVISIONS table is missing and to tell the user to upgrade their schema Cheers DominiqueHi Dominique Good point When this patch is applied to a Jackrabbit installation that already uses the clustering feature it will break if the LOCAL REVISIONS table is not added manually. I ll look into this. MartijnHi all Unfortunately I ve been inactive for a while but now i ve more time to work on Jackrabbit which is good . I created a second patch for this issue which also addresses the upgrade scenario that Dominique mentioned - Added the LOCAL REVISIONS table to the create scripts .ddl - Added InstanceRevision interface - The InstanceRevision is now retrieved through the Journal instance - Added logic to the DatabaseJournal to i migrate to a db based InstanceRevision   and ii start a janitor thread for cleaning up old cluster revision entries I ve tested the patch only on MSSQL MySQL and Oracle because I don t have access to the other databases. I don t really like the solution for the upgrade scenario a ddl is scanned for the line that creates the LOCAL REVISIONS table but I like the alternative of having twice as many .ddl files even less. But maybe there s a third way... Best regards MartijnCommitted in revision 628697. The instance revision on the local file system is automatically migrated to the database to the LOCAL REVISIONS table. The clean-up thread is not started by default. Known caveats of the current solution - The user must make sure that all cluster nodes have written their local revision to the database before the clean-up thread runs for the first time because otherwise cluster nodes might miss updates because they have been purged and their local caches and search-indexes get out of sync. - If a cluster node is removed permanently from the cluster then its entry in the LOCAL REVISIONS table should be removed manually. Otherwise the clean-up thread will not be effective. I couldn t find any documentation for this feature at http wiki.apache.org jackrabbit Clustering Is there any documentation So far I only added a link to here Removing Old Revisions I m afraid there s no documentation yet. I ll try to add it soon.
