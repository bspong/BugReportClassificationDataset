refactor consistency checks in BundleDBPersistenceManager into a standalone class that could be re-used for other PMs
see subjectProposal. We could add the code to the AbstractBundlePM as well but I wanted to keep it separate Proposed change. 1 Looks straightforward enough and moving the code outside the PM implementations make sense. I wonder if it might be a good idea to change getAllNodeIds to return a Collection or a Set instead of an Iterable so we wouldn t need the extra getNumberOfBundles call. AFAIUI all PM implementations in any case implement getAllNodeIds with an in-memory list so the memory impact shouldn t be a problem and if it is the getAllNodeIds signature already contains the maxCount option for dealing with that issue . And implementing getAllNodeIds with an actual backend iterator opens up problems about when and how the resources used by the iterator can and should be released. PS. There s an svn executable property in the patch that probably shouldn t be there.I agree that returning a collection set or list would make sense. However if we ever change the code to use the paging feature we ll need the getCount method anyway...IIRC the paging feature in getAllNodeIds was just added just so a client could iterate over all the nodes in chunks of predefined size. At least in that use case the total number of nodes was not needed.OK so let s use a list for now do not add getNumberOfBundles and address this in the future when we actually use paging Loading the whole list in memory will run out of memory in many cases. The call isn t supposed to block other operations specially for DataStore garbage collection . Many persistence manager implementations can t return the exact size specially but not only because the call is non-blocking . Therefore the easiest solution is to revert the change and don t log the size. Or add a method getNumberOfBundlesEstimate or so. Loading the whole list in memory will run out of memory in many cases. That s best handled on the client side e.g. by making the consistency checker process things in chunks of say 1m nodes at a time. I d track that as a separate issue. don t log the size That s what I d do.
