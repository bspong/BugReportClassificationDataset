DWFlushControl does not take active DWPT out of the loop on fullFlush
We have seen several OOM on TestNRTThreads and all of them are caused by DWFlushControl missing DWPT that are set as flushPending but can t full due to a full flush going on. Yet that means that those DWPT are filling up in the background while they should actually be checked out and blocked until the full flush finishes. Even further we currently stall on the maxNumThreadStates while we should stall on the num of active thread states. I will attach a patch tomorrow. here is a patch. I fixed DWFlushControl to block flushes while a fullflush is happening and make them available once the fullflush is done. I also ensure that incoming threads help out flushing if there are DWPT about to flush but not taken yet before indexing their document. All tests pass I run them lots of times new patch - removed leftover assertion from debugging I like the Healthiness - StallControl renaming Could we add an assert that net flushPending active RAM never exceeds some multiplier 2X of the configured max RAM Could we add an assert that net flushPending active RAM never exceeds some multiplier 2X of the configured max RAM net flush pending means we only differ between flushing ram and active ram so flushing ram can easily get above such a limit if IO is slow... net flush pending means we only differ between flushing ram and active ram so flushing ram can easily get above such a limit if IO is slow... I O or just O Should we add a ThrottledIndexInput too Could we add an assert that net flushPending active RAM never exceeds some multiplier 2X of the configured max RAM net flush pending means we only differ between flushing ram and active ram so flushing ram can easily get above such a limit if IO is slow... But shouldn t stallControl kick in in that case Ie we stall all indexing if the number of flush-pending DWPTs is the number of active DWPTs I think But shouldn t stallControl kick in in that case Ie we stall all indexing if the number of flush-pending DWPTs is the number of active DWPTs I think Right so lets say we have two active thread states 1. thread 1 starts indexing max ram is 16M it indexes n docs and has 15.9 MB ram used. Now n 1 doc comes in has 5MB active mem 20.9M flush Mem 0M 2. take it out for flush active mem 0M flush Mem 20.9M 3. thread 2 starts indexing and fills ram quickly ending up with 18M memory active mem 18M flush Mem 20.9M 4. take thread 2 out for flush active mem 0M flush Mem 38.9M 5. thread 3 has already started indexing and reaches the RAM threshold 16M so we have active mem 16M flush Mem 38.9M 6. take it out for flushing now we stall currently active mem 0M flush Mem 54.9M - this is more than 3x max ram buffer. we currently stall at flush-pending DWPTs is num active DWPT 1 we can reduce that though but maybe we should swap back to ram based stalling next iteration. This patch changes the stalling mechanism from using num DWPT flushing to netBytes and stalls at 2 x maxRamBuffer if we flush on num bytes. Stalling on memory consumption allows to add an assert upper bound to the netMemory which is nice but it doesn t help if we are not flushing on RAM usage. I think what we need to do sep. issue is to allow people to add a maxTotalUsedRam which defaults to 2x maxRamBuffer if set or Runtime maxMemory 2 if flushing by docCount to allow us to stall indexing threads iff we cross that border and there is at least one DWPT flushing or pending. I did 150 runs for all Lucene Tests incl. contrib - no failure so far. Seems to be good to go. Patch looks good but hairy Simon I ran 144 iters of all Solr lucene lucene-contrib tests. I hit three fails one in Solr s TestJoin.testRandomJoin and two in Solr s HighlighterTest but I don t think these are related to this patch. Thanks mike for review and testing It makes me feel better with those asserts in there now... I will commit tomorrow. Committed in revision 1104026.
