WriteLineDocTask improvements
Make WriteLineDocTask and LineDocSource more flexible extendable allow to emit lines also for empty docs keep current behavior as default allow more less other fields Attached patch modifies LineDocSource and WriteLineDocTask to allow the described extensions. By default there are no modifications and behavior is as before. Updated patch for 3x from 3x root previous patch was from benchmark by mistake fixed typos in javadoc simplified loop over the fields in WriteLineDocTask removed volatile but added final for fields ToWrite. Without volatile one test was failing TestPerfTasksLogic.testParallelDocMaker but then I was unable to fail it again even after removing volatile. Once marking these fields final definitely volatile is not required. But I don t understand why was it needed in the first place - ParallelTask in TaskSequence clones the tasks and since WriteLineDocTask does not implement clone all parallel tasks will have a reference to same array... which in fact can be copied into a local copy by the JVM for efficiency.. but since the clone must take place only after the constructor is done the array is initialized already... If I could fail this again I would investigate it but now it always passes even without final volatile. So keeping the final as this is safe but I don t like the voodooism of it and if anyone has a better explanation it would be appreciated. It s great to make line file docs more extensible Maybe we should put the field names as a header line Then the source can get the field names from there feilds is mis-spelled The cutover to splitting by regex vs prior split-by-char makes me nervous. Have you tested perf hit Or can we go back to just using a char sep We also make a String when we didn t before. If we really want to stick w regex then we should at least pre-compile to a Pattern then use the split method on that Thanks for reviewing Mike No I didn t perf the perf task change.. I will look at this again. Nice catch about the feild name. As for putting the field names in the file - let s see how this would work We need a matching pair LineDocWriter and LineDocSource both should expect the same fields in same order In addition DocData has some fixed field names ID Body Name Date Title and a flexible Properties which can include anything else. If we move to put the field names in the header line as you suggest that would make a single line-doc-source for any lineDocWriter which is nice. It would require to modify DocData so that all fields would be maintained in props except for ID which would be still mandatory . I like it except perhaps for performance... What do you think Is this what you have in mind That s exactly what I had in mind I think for LineDocWriter we d have to tell it up front what fields in what order it should write. But then LineDocSource should be generic... though we d still have to set up the Fields properly for indexing ie some are stored some are not tokenized etc. . though we d still have to set up the Fields properly for indexing ie some are stored some are not tokenized etc. I don t think that matters I.e. LineDocSource returns DocData it s the DocMaker which creates the actual Lucene Field and Document instances. So all LDS needs to know is the name of the field. If we really want to stick w regex then we should at least pre-compile to a Pattern then use the split method on that I agree. String.split compiles a Pattern inside so we d better pre-compile that pattern once and then you pattern.split . Or can we go back to just using a char sep We also make a String when we didn t before. That s a good point Mike. But the alternative splitting on char the old way is not any better either because you don t know in advance how many fields you expect so you d have to create a List or something to store them. I guess what we should be considering is super-duper optimized code vs. a nice readable one. String.split is easily understood keeps the code compact and clear. Searching for SEP the old code is more complicated especially when you want to handle a general case. We ll be searching for SEP both ways so the only difference is whether an array is allocated or not. Maybe instead of doing the split ourselves we can have a getDocData String line which will be implemented by default to search for TITLE DATE and BODY using the optimized code and can be overridden by others to parse line differently That way we don t impose any specific splitting behavior on everyone but we lose the potential generality of LineDocSource. Is that array alloc really critical About writing the field names in the file Ð that s a nice idea but complicates DocData. We d need to change it to store a Map String String or Properties of name-value pairs. That will affect the performance of creating DocData as well as constructing a Document out of it. If we re willing to sacrifice some optimization here we can do nice things. But if we want to insist on having the most optimized code I don t think we can do much ... probably the best option is to have WLDT and LDS optimized for what they are today and let users extend to write read more fields. We can pass them the line and let them split it however they want. I don t think that matters I.e. LineDocSource returns DocData it s the DocMaker which creates the actual Lucene Field and Document instances. So all LDS needs to know is the name of the field. OK that s nice. So a simple string SEP string SEP ... header could define the field names. Is that array alloc really critical Probably fairly minor but this is a death-by-a-thousand-cuts situation Ie these changes only make our index throughput tests slower hopefully by a tiny amount but it ll add up over time. Maybe instead of doing the split ourselves we can have a getDocData String line which will be implemented by default to search for TITLE DATE and BODY using the optimized code and can be overridden by others to parse line differently I think that s good Or if we do the header idea... then a given usage need not override getDocData Like it s generic at that point If we do the header idea then we ll need to move to a more generic DocData. So instead of doing docData.title title you ll need to do docData.set title title which under the hood will store that pair in a Map or Properties. Similarly for getter . That also has some implications on perf. What is better - generality or optimized code for the common Lucene tasks and let users extend for their own purposes If we want to have the most optimized code then let s pass the line entirely to an overridable method. Lucene will offer an optimized way of tokenizing the current fields while the user will have to either provide his own optimized way for his fields or decide that he can risk some cycles in favor of simpler code e.g. calling line.split . If we do the header idea then we ll need to move to a more generic DocData. So instead of doing docData.title title you ll need to do docData.set title title which under the hood will store that pair in a Map or Properties. Similarly for getter . That also has some implications on perf. Hmm true. Really it would be better if LineDocSource could directly set Field values. Then up front on parsing the header it could make a Field and then when parsing the line it d just set these Field values. But that s a much larger change... so I think until then we should just pass the full String line to eg a processLine method And the default optimized one breaks it into the fixed name date body fields. Really it would be better if LineDocSource could directly set Field values. That will break the separation we have today Ð ContentSource returns DocData which is not a Lucene Document and DocMaker creates a Document out of it. Remember that we were in this design before Ð DocMaker was responsible for both parsing the content and creating a Document out of it. The current design is much more flexible. until then we should just pass the full String line to eg a processLine method I agree. Either processLine or getDocData or whatever but something which receives a line and returns DocData. So the separation we have today of DocData from DocMaker allows what flexibility Is it just so that we can pull multiple docs from a single DocData EG the line file could have massive docs but we want to index tiny docs so DocMaker can split them up I agree that s useful... but it does result in somewhat synthetic docs. EG 20 docs in a row will have the same title and date and any other properties . If you are eval ing a standard corpus presumably you don t do this doc splitting right The flexibility can only cost us performance though maybe it s not so much of a hit . No the flexibility is in the ability to have a TrecContentSource emitting the TREC documents and multiple DocMakers that consume them and build Lucene documents out of them. For example one DocMaker can decide to split each doc into N tiny docs. Another can choose to add facets to it. Yet another can do complex analysis on it and produce richer documents. Before that you d have to write a DocMaker for every such combination. E.g. if you wanted to add facets you d need to write a DocMaker per source of data with the same impl. DocData as an intermediary object is not expensive considering it s only bin over some already allocated Strings. And we reuse it always so you don t even allocate it more than once ... I would hate to lose that flexibility. Hi thanks Mike and Shai for the review and great comments. Attaching an updated patch. Now WriteLineDocTask writes the fields as a header line to the result file. It always does this - perhaps a property to disable the header will be useful for allowing previous behavior no header . There are quite a few involved changes to LineDocSource replaced line.split SEP by original recurring search for SEP. Method fillDocData doc fields was changed to take a line String instead of the array of fields. That method was wrapped in a new interface DocDataFiller for which there are now two implementations SimpleDocDataFiller is used when there is no header line in the input file. It is implementing the original logic before this change. This allows to continue using existing line-doc-files which have no header line. HeaderDocDataFiller is used when there exists a header line in the input file. Its implementation populates both fixed fields and flexible properties of DocData At construction of the filler a mapping is created from the field position in the header line to a setter method of docData. That mapping is not by reflection nor by a HashMap - simply an int posToM where if posToM 3 1 later when handling the field no. 3 in the line the method fillDate3 will be called and it will in turn call docData.setDate through a switch statement. If there s no mapping to a DocData setter its properties object will be populated. So this is quite general with some performance overhead though less than reflection I think I did not measure this . An extension point for overriding the filler creation is through two new methods createDocDataFiller for the case of no header line createDocDataFiller String header when a header line is found in the input Note that filler creation is done once when reading the first line of the input file. Some tests were fixed to account for the existence or absence of a header line. I think more tests are required but you can get the idea how this code will work. Bottom line LineDocSource is more general now but the code became more complex. I have mixed feelings about this - preferring simple code but the added functionality is appealing. I haven t reviewed the patch yet but I must say that from your description it sounds like LineDocSource has become very complicated. I d prefer to keep things simple. Before this issue LDS read a line and split it into 3 fields. Now we think it should be extend-able such that users can read lines and tokenize them differently for e.g. supporting more fields . I think that for that a getDocData processLine extension point is enough. After all users can write their own WLDT and LDS they don t have to use ours. The purpose here is to keep the common logic in those two classes writing reading lines to multiple in output formats only allow these classes to be somewhat more flexible. Therefore I think that the header line may not be that useful eventually. It seems to only complicate matters. Most people judging by the fact that it hasn t come up as an issue yet are either happy w the current capabilities or wrote their own matching pair to support more fields. So let s keep the current impl as optimized as it was before but allow for a simple extension point So let s keep the current impl as optimized as it was before but allow for a simple extension point I believe the original case in LineDocSource is as optimized as it was before. If you take a look at the inner class SimpleDocDataFiller - it has exactly the same logic as before. The more general logic - the one in HeaderDocDataFiller which processes any header line for you - is more complex and perhaps somewhat less efficient - but only slightly I believe as the additional cost is a switch statement per field. But please do not review this code just yet - I m in a middle of improving it By default LineDocSource should use the SimpleDocDataFiller not only when there s no header line in the file this part is covered already but also when the header line is the same as the default one the default coming from WriteLineDocTask . selecting the DocDataFiller to use should be possible through a property - as is the spirit of this package. DocDataFiller should better be named DocDataLineReader. DocDataLineReader inner methods like fillDate2 should be inlined i.e. removed HeaderDocDataLineReader should switch on an enum rather than on ints. These changes would make LineDocSource more efficient and more readable. I feel that the added functionality is worth the additional complexity in the code And for those wishing to save the extra cycles of the general HeaderDocDataLineReader it is possible to implement a custom one and pass its name as the new property docdata.line.reader. I am working on an updated patch... A thought Ð how about we do the following LineDocSource remains basically as it is today with a getDocData String line extendable method for whoever wants Instead of introducing those Fillers you create a HeaderLineDocSource which assumes the first line read is the header line and parses the following ones as appropriate. It will create LDS extending getDocData. This will not introduce a Filler in LDS and those who don t care about it don t need to know about it at all. Also it will showcase the extendability of LDS. Will that be simpler Will that be simpler It will be simpler I admit but it will harder to manage when re-reading the input file with repeat true special treatment of the header line is needed. And cannot assume that the header line exists because there are 1-line files out there without this line which is possible I would not like to force recreating and it is possible. the simple LDS as today handles no header line. As such if there is one it will wrongly treat it as a regular line. But I would like it to be able to handle both old files with no header and new files with the header. Mmmm e could for that write the header only if it differs from the default header. Perhaps this will work. I ll take a look at that again meanwhile attaching updated patch with the two inner DocDataLineReader s. Rethinking this suggestion I am afraid it will easily lead users to errors mistakes - users would have to be aware did I create that file with a header Mmm... so I must use the source which handles the header and that file is with the default settings so it needs the simple reader but man did I set it to create the header anyhow... I don t remember I ll recreate the file... Maybe some users will remember such things but I know that I will not remember and a line-reader that handles correctly all inputs out-of-the-box is much more convenient... which is what I liked in the header suggestion. For example one DocMaker can decide to split each doc into N tiny docs. Another can choose to add facets to it. Yet another can do complex analysis on it and produce richer documents. I like the flexibility to enrich the docs produced by the source set up facets semantic extraction etc. but the ability to split up docs is... dangerous I think. Ie it feels to me like DocData should in fact just be a Document. The two-step process we have now fill fields in a DocData then separately ask this DocData to make one or more Docments feels wrong. Splitting a big doc into N smaller docs can t be done well. It s synthetic data eg 20 docs in a row will have same title data and so you ll draw synthetic conclusions. The enrichment can simply be a Document processing pipeline that runs after the source document was produced from the line file. EG UIMA. When we run perf tests w luceneutil we do in fact do this split but then we shuffle the resulting line file so that you don t see 20 docs w same title in a row which skews eg compression results since a given term foo in its title will have 20 adjacent docIDs assigned and thus be unnaturally easy to compress. Likewise for the date field which makes the NRQ performance unnaturally good. If you want to chop docs up really you do it as a pre-processing step in building your line file... Before that you d have to write a DocMaker for every such combination. E.g. if you wanted to add facets you d need to write a DocMaker per source of data with the same impl. But if LineDocSource returned a Document can t you take that Document and run with it We d still have a single class that pulls Document from a line file just different Document processors that run after it. I m still not really seeing why DocData is needed except for the somewhat dangerous split-up-docs case. But we don t need to change fix this today... Patch looks great Some small things I think we should throw an exc if any of the field names contain the SEP char Can we name it parseLine instead of readLine Ie the line has already been read from the file what remains is to parse it and as a side effect change DocData to reflect that parsing . Typo sedDocData - setDocData in HeaderDocDataLineReader . I do think we should move to all line files having the field header line w back compat handled for existing line files out there . The approach in the patch looks great Ð the common fixed case of just title date body that we have today is specialized and should still be fast SimpleDocDataLineReader . Thanks for reviewing Mike I think we should throw an exc if any of the field names contain the SEP char Right good catch Can we name it parseLine Yes I like it better readLine felt wrong parseLine it will be. Also the inner class should better be called LineParser rather than DocDataLineReader . I ll patch these - and fix the typo - totogether with more tests... Updated patch tests added for better coverage and added a Changes entry. Hmmm while reviewing again before committing I noticed that the HeaderLineParser constructor never assigns FieldName.PROP in posToF. I intended to do this but forgot. Indeed emma shows that Properties handling in LineDocSource is not tested. So I enhanced LineDocSourceTest to also test for nonstandard fields and for properties. The test failes as expected and the fix was trivial. Attaching updated patch planning to commit this shortly. Committed r1083789 - 3x r1083812 - 3x undo added unused imports r1083816 - trunk Thanks Shai and Mike for reviewing and suggestions Bulk closing for 3.2
