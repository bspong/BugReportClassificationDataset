StandardTokenizer splitting all of Korean words into separate characters
StandardTokenizer splits all those Korean words inth separate character tokens. For example is one Korean word that means Hello but StandardAnalyzer separates it into five tokens of . Here are patches to preserve one Korean word not to be separated into each characters. The TestStandardAnalyzer test case attached has passed with StandardTokenizer with patch applied. These patches have been applied thanks There is one thing to note and that is a change in the token type emitted from CJK to CJ . It is possible that folks have written code to rely on that but this token type is currently brittle as it is based on the JavaCC grammar definition and I view this as an acceptable break in full backwards compatibility because it is unlikely that anyone is using that token type.
