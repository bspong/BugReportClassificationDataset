Split DocMaker into ContentSource and DocMaker
This issue proposes some refactoring to the benchmark package. Today DocMaker has two roles collecting documents from a collection and preparing a Document object. These two should actually be split up to ContentSource and DocMaker which will use a ContentSource instance. ContentSource will implement all the methods of DocMaker like getNextDocData raw size in bytes tracking etc. This can actually fit well w 1591 by having a basic ContentSource that offers input stream services and wraps a file for example with a bzip or gzip streams etc. DocMaker will implement the makeDocument methods reusing DocState etc. The idea is that collecting the Enwiki documents for example should be the same whether I create documents using DocState add payloads or index additional metadata. Same goes for Trec and Reuters collections as well as LineDocMaker. In fact if one inspects EnwikiDocMaker and LineDocMaker closely they are 99 the same and 99 different. Most of their differences lie in the way they read the data while most of the similarity lies in the way they create documents using DocState . That led to a somehwat bizzare extension of LineDocMaker by EnwikiDocMaker just the reuse of DocState . Also other DocMakers do not use that DocState today something they could have gotten for free with this refactoring proposed. So by having a EnwikiContentSource ReutersContentSource and others TREC Line Simple I can write several DocMakers such as DocStateMaker ConfigurableDocMaker one which accpets all kinds of config options and custom DocMakers payload facets sorting passing to them a ContentSource instance and reuse the same DocMaking algorithm with many content sources as well as the same ContentSource algorithm with many DocMaker implementations. This will also give us the opportunity to perf test content sources alone i.e. compare bzip gzip and regular input streams w o the overhead of creating a Document object. I ve already done so in my code environment I extend the benchmark package for my application s purposes and I like the flexibility I have. I think this can be a nice contribution to the benchmark package which can result in some code cleanup as well. While I change SortableSingleDocMaker I noticed it create a new Random in getNextDocData . Shouldn t that Random be created once Also I think it should be created with a seed While I change SortableSingleDocMaker I noticed it create a new Random in getNextDocData . Shouldn t that Random be created once Also I think it should be created with a seed OK sharing a Random instance seems good. Maybe make the seed an optional config If it s not present let it pick a random seed Maybe make the seed an optional config If it s not present let it pick a random seed I already went ahead and did that. Only if it s not present I chose 13 instead of drawing one every time. That way runs can be consistent and compared to each other. BTW am I allowed to use Java 5 generics in benchmark Or until 3.0 benchmark should stay on 1.4 as well I m asking because I heard a couple of times that contrib is allowed to move to Java 5 Probably it s best to stick w 1.4. Someday I hope we will get to 3.0 Right - the back compat for each contrib is completely up to that contrib. In the past though anything thats 1.4 has stayed 1.4 without good reason so that users are not jolted probably more out there using java 1.4 than you might think . On 3.0 when core goes 1.5 it will make sense to allow 1.5 in all the contribs that are 1.4 now. Ok I ll make sure it s 1.4 compatible then. Patch includes a new ContentSource class with appropriate extensions for all previously defined DocMakers. DocMaker is a concrete class which creates Documents based on the ContentSource DocData output. It can be configured to reuse fields. There are many ContentSource impls now but only few DocMaker such as LineDocMaker and EnwikiDocMaker - since their makeDocument logic is quite simple . All tests pass. I also modified all alg files to define content.source instead of doc.maker default is DocMaker where appropriate. I think we can start iterating on this Just attempted to patch it in - it looks like a bunch of files that don t exist are in the patch as patches rather than as the new file Having trouble with SingleDocSource and it looks like half a dozen of the other new files... I was afraid that something like that will happen. I used Eclipse refactoring and also Team - create patch . That s the output. Do you use Eclipse to patch it in What should I do with existing classes which I renamed Add new classes and delete the existing ones At least from the eclipse SVN console that s what it seems to do when I refactor a class name Can you try now Yes was using eclipse to patch. The patch you just posted appears to work - it compiled and the new files appeared to be created thanks Hey Mark are you reviewing this Did you catch something interesting so far Some updates Added to PerfTask a log.step config parameter and implemented in tearDown logging messages. Also introduced a getLogMessage int recsCount which can be overridden by sub classes. Overrode getLogMessage in the relevant tasks which logged messages such as AddDocTask DeleteDocTask WriteLineDocTask ... I also removed logging from these tasks Added ConsumeContentSource task together with a readContent.Source.alg - this can be used to simply read from a content source if we want to measure the performance of a particular impl. Removed the xerces class name from EnwikiContentSource read more below . I changed EnwikiContentSource to not specifically request for a Xerces SAXParser. However the default is to use the JRE s SAXParser which is Xerces. I wanted to remove the Xerces .jar but when I attempted to read the enwiki-20090306-pages-articles.xml it failed w an AIOOBE so I don t think we can remove the .jar yet. BTW in LUCENE-1591 I reported that I am not able to parse that particular enwiki version w and w o Xerces however Mike succeeded. So I don t know if this enwiki version is defective or it s a problem on Windows. Anyway the bottom line is we cannot remove the Xerces .jar. I think this patch is ready for commit. All benchmark tests pass. Someone else can nab this from me if they want to go ahead before I get a chance. Otherwise I ll try and take a look by the end of the weekend. I started looking at it before but just havn t yet had a chance to go back to it. In either case we will get it in soon. I hope to look at this today. Shai will this at all invalidate any benchmark algorithms that are already out there Yes it will. Basically DocMaker is now a concrete class which accepts a ContentSource and creates documents out of it. So all the DocMakers were replaced w ContentSource such as Reuters Trec etc. . I left EnwikiDocMaker and LineDocMaker to create a LineContentSource and EnwikiContentSource ignoring any content.source parameter that may be set in the config. I also updated all the current .alg files to reflect those changes. Do you think I should spell it out in CHANGES Basically the migration is super simple - if you use any doc maker which is not Enwiki or Line simply rename doc.maker to content.source and the appropriate ContentSource class. I d love other opinions. If we go with it I think we should def spell it out in the benchmark CHANGES. Benchmark has no back compat commitment as far as I see but we should consider breaking existing algorithms out there very carefully I think. And if there is a way to map the invalid values to values that keep the old behavior we should def investigate that as well. Well ... depends on what are the existing algorithms out there . .alg files that someone wrote which use existing DocMakers from benchmark would break but fixing them is a no brainer just reference the ContentSource where applicable . .alg files which use custom DocMakers are a bit more challenging since you ll need to decide if your DocMaker is a ContentSource really a DocMaker or both i.e. split it to DocMaker and ContentSource . Since I haven t changed the API of DocMaker much it shouldn t be a hard task to refactor your custom DocMaker. In general. I believe benchmark is not used in production environments and therefore it shouldn t be a real problem to adapt your benchmark .alg and or custom classes to the refactored one. You can also earn by extending DocMaker and using its DocState for a reuse logic. If we say that contrib in general does not need to maintain back-compat and we re talking about classes that are in production environments then I don t think we have a real issue here. I won t ask how much we believe benchmark is extended even though it s important or used since this issue was originated from my extension of it. I can only assume that Solr extends it too or uses it . If we say that contrib in general does not need to maintain back-compat and we re talking about classes that are in production environments then I don t think we have a real issue here. Contrib does not necessarily have a back compat but its up to each contrib to determine what its back compat policy is. Even without an explicit policy we try to do what make sense. Everytime you ignore back compat completely for certain things you risk alienating certain people. For example because the highlighter is a semi core type thing even though we have never made a back compat policy for it we don t break back compat there without good reason. I agree that the Benchmark contrib comes down on the low end of concern. In fact I m not too concerned with breaking back compat anywhere in benchmark except for the algs. Every time we break the algs we risk causing people who have written custom algs to think twice about writing and maintaining them. Generally I d expect things like that to be careful about maintaining back compat or a mode that can run older version algs. That said I m not saying this change isnt worth a little algorithm disruption. I wouldn t mind getting the opinion of another committer first though. I doubt too many people even have that many custom algs out there - but thats not a scenioro I want to help and try to perpetuate. So its not like I m sitting here saying this is a huge deal - but I think it should def be considered a bit. Well ... depends on what are the existing algorithms out there . .alg files that someone wrote which use existing DocMakers from benchmark would break but fixing them is a no brainer just reference the ContentSource where applicable . .alg files which use custom DocMakers are a bit more challenging since you ll need to decide if your DocMaker is a ContentSource really a DocMaker or both i.e. split it to DocMaker and ContentSource . Since I haven t changed the API of DocMaker much it shouldn t be a hard task to refactor your custom DocMaker. What about these changes Are they incompat as well -doc.add.log.step 500 -doc.delete.log.step 100 log.step 500 delete.log.step 100 Sorry didn t really get a chance to dig in today as I was feeling a bit under the weather. We will get it in for 2.9. So its not like I m sitting here saying this is a huge deal - but I think it should def be considered a bit. I didn t mean to imply that. In all my recent contributions back-compat played a major role. I just explained here why here I didn t give it a second thought and was actually happy I am more free to make these changes. But I definitely see your point and would love to get another committer s opinion too. What about these changes Are they incompat as well -doc.add.log.step 500 -doc.delete.log.step 100 log.step 500 delete.log.step 100 I took another step here adding code to PerfTask.tearDown which logs messages and changed all the current tasks that does it to stop doing it and instead override a getLogMessage . That consolidated the logic behind when to log messages in what format etc. It was not consistent between tasks and some newer tasks did better job than others. With that I also changed the property name which was invalid even before - doc.add.log.step wasn t used just in AddDocTask . About the delete.log.step - I first removed it relying on the new log.step but then spotted some .alg which differentiate between when how often to log messages for delete and how often for the rest so I re-instated it. If you think it matters I can change revert the name back to doc.delete.log.step. We will get it in for 2.9 Great that will relieve some of my custom benchmarking code and allow me to test on more content sources today I implemented this model just for TREC for lack of time . Okay how about something like this we document up the changes and the conversion processes in the benchmark CHANGES and then maybe check for removed alg properties in the algorithms and throw an exception pointing people to the CHANGES file if we find one Or something along those lines I d like to make the transition as smooth as possible. ok I agree. I ve already documented CHANGES. I ll add to PerfTask a deprecated method checkObsoleteSettings which will throw an exception if it finds doc.add.log.step and doc.delete.log.step . doc.maker is still a valid one but when you ll try to cast the argument to a DocMaker you ll get an exception b c it s now a concrete class and not interface. Does this make sense I ll post a patch soon. Does this make sense Okay sounds good. Silence is consent around here so I think we are good to go with this patch as soon as I go over it a bit. I ll wait till you post this last one. Patch adds a checkObsoleteSettings to PerfTask to alert on the use of doc.add.log.step and doc.delete.log.step as well as documentation in CHANGES. all benchmark tests pass. Added to changes a bit Removed modification to core Document class updated deletepercent.alg to new alg changes fixed a couple comment typos set to use content.source.forever rather than doc.maker.forever in ExtractWikipedia main String args the sort algs don t work unrelated to this patch and related to our deprecation of the auto sort field - Ryan just hit that over in solr-land too. I still want to run some tests with the wikipedia stuff but still waiting for that mondo file to download Looks pretty nice overall thanks Shai I still want to run some tests with the wikipedia stuff I added readContentSource.alg just for that purpose and ran it over the Wikipedia dump. All documents were read successfully. Removed modification to core Document class Nice I don t know how I missed that getFields .clear option. I added readContentSource.alg just for that purpose and ran it over the Wikipedia dump. All documents were read successfully. I figured you probably had but they won t end up coming after you they will come after me As expected no issues hit yet though. I ll commit this later today. they won t end up coming after you they will come after me I promise to cover for you if that happens I ll commit this later today. Thanks Thanks Shai I just committed this. Could we remove LineDocMaker entirely now And then move up the doc.random.id.limit into DocMaker for testing updateDocument performance I think we could also remove EnwikiDocMaker The only different its makeDocument seems to have is that it uses wiki s name as the id field rather than incrNumDocsCreated the sort algs don t work unrelated to this patch and related to our deprecation of the auto sort field Mark what was this issue Was it fixed already Mark what was this issue Was it fixed already Yes - if you didnt specify a type it used Auto - but a switch was made to use the new TopField collector which doesnt resolve auto. I just removed auto support - you must type the field now. https issues.apache.org jira browse LUCENE-1725 I just removed auto support - you must type the field now. OK... though it looks like it still falls back to AUTO in getType if it doesn t recognize the provided type. I ll attach a patch shortly to just accept all types that SortField accepts and throw an exception if the type isn t recognized. Attached patch. Reopening to make sure I remember to commit that patch and to maybe remove Line EnwikiDocMaker. I kept Line EnwikiDocMaker just because they contain very simple logic and are very short. I don t know if we want to pull the id stuff up to DocMaker since some DocMakers have their own ID example - TrecDocMaker . But I don t mind removing them. Just like I said now they are very optimized for the content source they work on no extra ifs etc. Especially LineDocMaker which reads a Line file that has only title date and body. Also notice that both init their own content source. But I don t have a strong feeling for removing keeping them. Are you going to do it or shall I My driver here was... updating Lucene in Action to explain all the recent changes to contrib benchmark and explaining the tiny differences between these 3 DocMakers was awkward They are nearly the same. I ll work up a patch. Attached patch that addresses the SortField.AUTO issue and deprecates Line EnwikiDocMaker. I do think we could do some speeding up of the fields handling in DocMaker for the reuse case eg make dedicated members in DocData to hold the known fields id body title etc. but I think we can wait on that for now. Just an idea when redoing the field stuff maybe we should add the DATE field as a long timestamp Date.getTime using NumericField with default precStep We could then also do benchmarks on NumericRangeQuery and easily sort by date with type long . maybe we should add the DATE field as a long timestamp Date.getTime using NumericField with default precStep 1
