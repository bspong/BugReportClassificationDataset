wordlistloader is inefficient
WordListLoader is basically used for loading up stopwords lists stem dictionaries etc. Unfortunately the api returns Set String and sometimes even HashSet String or HashMap String String I think we should break it and return CharArraySets and CharArrayMaps but leave the return value as generic Set Map . If someone objects to breaking it in 3.1 then we can do this only in 4.0 but i think it would be good to fix it both places. The reason is that if someone does new FooAnalyzer a lot probably not uncommon i think its doing a bunch of useless copying. I think we should slap lucene.internal on this API too since thats mostly how its being used. There are more problems with this loader... it uses FileReader platform-dependent encoding . I think we should break it to default to UTF-8 too. as much as i hate the fact this one uses the default encoding in its File method its only used by StopFilter etc. Our provided analyzers and Solr are treating all this stuff as UTF-8 encoded resources so I think its ok to delay until 3.2 and re-assess the best way. I made a prototype patch and it was complicated mainly because i wanted to fix this thing so that its coherent with Solr s resource loeading. bulk move 3.2 - 3.3 I tried to simplify this a little without going into changing solr not sure what robert meant by that anyway... I basically moved all File InputStream related stuff out of WordListLoader and made it fixed to CharArraySet Map - there are still nocommits in there since I wanted to get some feedback what others think before I add javadoc everywhere patch looks good... i was just referring to Solr s resource loading of stopwords and stuff. but we don t have to do that here imo we should fix the issues here first. Maybe for the javadocs on getReader we should explain that unlike the java default it creates a reader that will throw an exception if it detects the charset is wrong so this is good for configuration files-reading like WordListLoader but not recommended for say documents crawled from the web or something next iteration added javadocs removed all nocommits renamed IOUtils getReader to IOUtils getDecodingReader used a CharSet instance instead of a string in all getDecodingReader variants so we can use a cached UTF-8 CharSet instance instead of looking it up for each invocation. I think its ready... where do we add the CHANGES.txt entry for that stuff I figure since we backport this I should put it under lucene contrib CHANGES.txt I figure since we backport this I should put it under lucene contrib CHANGES.txt 1 final patch containing a CHANGES.txt entry - I am going to commit this in a minute committed to trunk and backported to 3.x Bulk close after release of 3.5
