Improve CachingWrapperFilter to optionally also cache acceptDocs if identical to liveDocs
Spinoff from LUCENE-1536 This issue removed the different cache modes completely and always applies the acceptDocs using BitsFilteredDocIdSet.wrap the cache only contains raw DocIdSet without any deletions acceptDocs. For IndexReaders that are seldom reopened this might not be as performant as it could be. If the acceptDocs IR.liveDocs those DocIdSet could also be cached with liveDocs applied. Patch adding optional boolean recacheDeletes defaulting to false. We only cache if the incoming acceptDocs reader s liveDocs. Looks fine Uwe found a sneaky problem here using acceptDocs as the cache key is bad eg FixedBitSet s equals hashCode are horribly costly... we need a WeakIdentityHashMap. I will take care and also use the map then for MMapDirectory.MMapIndexInput where I explicitely overrided the equals hashcode of the keys to be 100 identity. I did some investigation. If you want a complete WeakIdentityHashMap witha all iterators and so on its heavy to do and you must in all cases also wrap all keys with a WeakReference even for lookup unless you implement your completely own HashMap impl . The easy fix here is to use a wrapper Reference object as cache key that simply has a final field and equals hashCode that does the system hashcode. By comparing the wrapper object as key two wrapper objects are only equal if the wrapped objects are identical static final class IdentityKeyWrapper T public final T key private final int hashCode public IdentityKeyWrapper T key this.key key this.hashCode System.identityHashCode key public int hashCode return hashCode public boolean equals Object o if o this return true if o instanceof IdentityKeyWrapper return IdentityKeyWrapper T o .key this.key return false The backside is that you have to wrap the Bits interface even on a lookup but thats cheap just like boxing unboxing eden space . Here the fix. Mike I think this is fine The fix also removes the useless genericfication of FilterCache as we removed the SpanCachingWrapperFilter. Here an improved patch factoring out the wrapper object to o.a.l.util adding tests. Once this is committed I will review other code and maybe move to this wrapper class e.g. MMapIndexInput s cloned inputs There is one problem with this wrapper object and WeakHashMap. The wrapped object does not have a reference to the wrapper itsself so the wrapper may get garbage collected as nothing refers to it and the item may get removed from the map. So this does not work ...digging This is why most custom implementations of WeakIdentityHashMaps found on the net internally extend WeakReference to add equals hashCode to it. It must be one object otherwise GC may purge objects. There is no way around implementing an own WeakIdentityHashMap not fully implementing the Map interface as not needed for caches . New patch now with WeakIdentityHashMap impl from Apache CXF excluding its inefficient Collection views and supporting null keys . I also changed the CachingWrapperFilter to hold soft references to the DocIdSet as otherwise e.g. the Bits null key will never be purged as the null key cannot be reclaimed by GC . We should maybe also change FieldCache to hold soft references to its arrays as this makes it more easy to purge them for the GC in low-memory conditions even if the reader key is still alive means field cache can be purged although reader is still alive . Updated patch now also supporting purging CachingWrapperFilter s cache when the reader -core is closed. This fix should also be backported to 3.x. More cleanup and made more fields private final. I will commit this now. Committed trunk revision 1214274 Backported adding close listeners to 3.x. Phew thanks Uwe What a doozie that turned out to be After some investigation we should remove the purgeing on IndexReader Core close again as this holds strong references from the IndexReader to the CachingWrapperFilter. This would lead to problems in the following case A app has an IndexReader that never changes and is never closed but creates lots of CachingWrapperFilters for short-time caches. This will fill up the event listener queue. Reverted backport of listeners in 3.x revision 1214347 Reverted listeners in trunk revision 1214349 If I have a better idea I will open an issue. Mike and I discussed on IRC about easier ways to solve the caching problem. We came to the conclusion that using the acceptDocs may be null as a sub-key are suboptimal because the null key cannot be evicted from the WeakIdentityHashMap. Also the two caches inside each other are hard to manage. The idea was to have a combined key on segmentreader thats hard referenced by the instance changing only when deletions change. This key should also only have identity equals hashCode. IndexReader like in 3.x now supplies two keys one based on the core without deletions and a second one thats equal for all segmentreaders with same deletions and same core. The trick is to use a Object field in SegmentReader thats initialized with new Object at the beginning and transferred over to a new instance when cloned. But once deletions change we reassign a new new Object so the key changes. CachingWrapperFilter uses either the conventional coreCacheKey if if does not respect deletions at all and caches without acceptDocs or it uses the combined key IndexReader.getCombinedCoreAndDeletesKey for the cache. The WeakIdentityHashMap is therefore obsolete again I will nuke it. Patch. can t this just be on segmentreader only Not yet once we have split composite readers and atomic reader yes. But at this point i cannot handle that as SegmentReader can be replaced by SlowMultiReaderWrapper and they have no common base class LUCENE-2858 So I would like to commit this first and later move this with all this stuff to atomic readers only. Updated patch with a test for the core key and combined key. I will commit this now and then work on splitting atomic and composite readers. Committed trunk revision 1214551
